[
    {
        "id": "<7300709.c102.17356e078cf.Coremail.gp1907971839@163.com>",
        "from": "æå›½é¹ &lt;gp1907971...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 09:06:58 GMT",
        "subject": "æ¥è‡ªæå›½é¹çš„é‚®ä»¶",
        "content": "é€€è®¢",
        "depth": "0",
        "reply": "<7300709.c102.17356e078cf.Coremail.gp1907971839@163.com>"
    },
    {
        "id": "<CAMSfv0sTcU=5WerLx3sMT893G+DY1oH+QzUr8SVLRy4Zx5aBmQ@mail.gmail.com>",
        "from": "æä½³å®¸ &lt;lijiachen...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 10:03:10 GMT",
        "subject": "Flink 1.11 Hive Streaming Writeçš„é—®é¢˜",
        "content": "æƒ³è¯·æ•™ä¸‹å¤§å®¶ hive streaming writeéœ€è¦æœ‰å“ªäº›é…ç½®ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘çš„ä½œä¸šèƒ½å¤Ÿè·‘èµ·æ¥ï¼Œä½†æ˜¯æ²¡æœ‰æ•°æ®å†™å…¥hiveã€‚&#010;æ‰¹é‡çš„hiveå†™å…¥ï¼Œæµç¯å¢ƒçš„è¯»å–æ˜¯æ­£å¸¸çš„ã€‚&#010;&#010;é™„ä»£ç ï¼Œå¾ˆç®€çŸ­ï¼š&#010;&#010;public class KafkaToHiveStreaming {&#010;    public static void main(String[] arg) throws Exception{&#010;        StreamExecutionEnvironment bsEnv =&#010;StreamExecutionEnvironment.getExecutionEnvironment();&#010;        EnvironmentSettings bsSettings =&#010;EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();&#010;        StreamTableEnvironment bsTableEnv =&#010;StreamTableEnvironment.create(bsEnv, bsSettings);&#010;        String name            = \"myhive\";&#010;        String defaultDatabase = \"default\";&#010;        String hiveConfDir     =&#010;\"/Users/uzi/Downloads/Hadoop/apache-hive-3.1.2-bin/conf/\"; // a local&#010;path&#010;        String version         = \"3.1.2\";&#010;&#010;        HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;hiveConfDir, version);&#010;        bsTableEnv.registerCatalog(\"myhive\", hive);&#010;        bsTableEnv.useCatalog(\"myhive\");&#010;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;        bsTableEnv.executeSql(\"CREATE TABLE topic_products (\" +&#010;                \"  id BIGINT ,\" +&#010;                \"  order_id STRING,\" +&#010;                \"  amount DECIMAL(10, 2),\" +&#010;                \"  create_time TIMESTAMP \" +&#010;                \") WITH (\" +&#010;                \" 'connector' = 'kafka',\" +&#010;                \" 'topic' = 'order.test',\" +&#010;                \" 'properties.bootstrap.servers' = 'localhost:9092',\" +&#010;                \" 'properties.group.id' = 'testGroup',\" +&#010;                \" 'scan.startup.mode' = 'earliest-offset', \" +&#010;                \" 'format' = 'json'  \" +&#010;                \")\");&#010;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&#010;        bsTableEnv.executeSql(\"CREATE TABLE hive_sink_table_streaming (\" +&#010;                \"  id BIGINT ,\" +&#010;                \"  order_id STRING,\" +&#010;                \"  amount DECIMAL(10, 2)\" +&#010;                \"  )\");&#010;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;        bsTableEnv.executeSql(\"CREATE TABLE print_table WITH&#010;('connector' = 'print')\" +&#010;                \"LIKE INSERT INTO hive_sink_table_streaming (EXCLUDING ALL)\");&#010;&#010;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;        bsTableEnv.executeSql(\"INSERT INTO hive_sink_table_streaming SELECT \" +&#010;                \"id, \" +&#010;                \"order_id, \" +&#010;                \"amount \" +&#010;                \"FROM topic_products\");&#010;&#010;        Table table1 = bsTableEnv.from(\"hive_sink_table_streaming\");&#010;        table1.executeInsert(\"print_table\");&#010;    }&#010;}&#010;&#010;",
        "depth": "0",
        "reply": "<CAMSfv0sTcU=5WerLx3sMT893G+DY1oH+QzUr8SVLRy4Zx5aBmQ@mail.gmail.com>"
    },
    {
        "id": "<3ec68482.47cd.17357935410.Coremail.17610775726@163.com>",
        "from": "JasonLee &lt;17610775...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 12:22:19 GMT",
        "subject": "å›å¤ï¼šFlink 1.11 Hive Streaming Writeçš„é—®é¢˜",
        "content": "hi&#010;éœ€è¦å¼€å¯checkpoint&#010;&#010;&#010;| |&#010;JasonLee&#010;|&#010;|&#010;é‚®ç®±ï¼š17610775726@163.com&#010;|&#010;&#010;Signature is customized by Netease Mail Master&#010;&#010;åœ¨2020å¹´07æœˆ16æ—¥ 18:03ï¼Œæä½³å®¸ å†™é“ï¼š&#010;æƒ³è¯·æ•™ä¸‹å¤§å®¶ hive streaming writeéœ€è¦æœ‰å“ªäº›é…ç½®ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘çš„ä½œä¸šèƒ½å¤Ÿè·‘èµ·æ¥ï¼Œä½†æ˜¯æ²¡æœ‰æ•°æ®å†™å…¥hiveã€‚&#010;æ‰¹é‡çš„hiveå†™å…¥ï¼Œæµç¯å¢ƒçš„è¯»å–æ˜¯æ­£å¸¸çš„ã€‚&#010;&#010;é™„ä»£ç ï¼Œå¾ˆç®€çŸ­ï¼š&#010;&#010;public class KafkaToHiveStreaming {&#010;   public static void main(String[] arg) throws Exception{&#010;       StreamExecutionEnvironment bsEnv =&#010;StreamExecutionEnvironment.getExecutionEnvironment();&#010;       EnvironmentSettings bsSettings =&#010;EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();&#010;       StreamTableEnvironment bsTableEnv =&#010;StreamTableEnvironment.create(bsEnv, bsSettings);&#010;       String name            = \"myhive\";&#010;       String defaultDatabase = \"default\";&#010;       String hiveConfDir     =&#010;\"/Users/uzi/Downloads/Hadoop/apache-hive-3.1.2-bin/conf/\"; // a local&#010;path&#010;       String version         = \"3.1.2\";&#010;&#010;       HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;hiveConfDir, version);&#010;       bsTableEnv.registerCatalog(\"myhive\", hive);&#010;       bsTableEnv.useCatalog(\"myhive\");&#010;       bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;       bsTableEnv.executeSql(\"CREATE TABLE topic_products (\" +&#010;               \"  id BIGINT ,\" +&#010;               \"  order_id STRING,\" +&#010;               \"  amount DECIMAL(10, 2),\" +&#010;               \"  create_time TIMESTAMP \" +&#010;               \") WITH (\" +&#010;               \" 'connector' = 'kafka',\" +&#010;               \" 'topic' = 'order.test',\" +&#010;               \" 'properties.bootstrap.servers' = 'localhost:9092',\" +&#010;               \" 'properties.group.id' = 'testGroup',\" +&#010;               \" 'scan.startup.mode' = 'earliest-offset', \" +&#010;               \" 'format' = 'json'  \" +&#010;               \")\");&#010;       bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&#010;       bsTableEnv.executeSql(\"CREATE TABLE hive_sink_table_streaming (\" +&#010;               \"  id BIGINT ,\" +&#010;               \"  order_id STRING,\" +&#010;               \"  amount DECIMAL(10, 2)\" +&#010;               \"  )\");&#010;       bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;       bsTableEnv.executeSql(\"CREATE TABLE print_table WITH&#010;('connector' = 'print')\" +&#010;               \"LIKE INSERT INTO hive_sink_table_streaming (EXCLUDING ALL)\");&#010;&#010;       bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;       bsTableEnv.executeSql(\"INSERT INTO hive_sink_table_streaming SELECT \" +&#010;               \"id, \" +&#010;               \"order_id, \" +&#010;               \"amount \" +&#010;               \"FROM topic_products\");&#010;&#010;       Table table1 = bsTableEnv.from(\"hive_sink_table_streaming\");&#010;       table1.executeInsert(\"print_table\");&#010;   }&#010;}&#010;",
        "depth": "1",
        "reply": "<CAMSfv0sTcU=5WerLx3sMT893G+DY1oH+QzUr8SVLRy4Zx5aBmQ@mail.gmail.com>"
    },
    {
        "id": "<CAMSfv0uSpqTVhtq66DUw4vPQ8RW3zehLYmMqj4oFC=s0_AOUWA@mail.gmail.com>",
        "from": "æä½³å®¸ &lt;lijiachen...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 14:39:14 GMT",
        "subject": "Re: Flink 1.11 Hive Streaming Writeçš„é—®é¢˜",
        "content": "å¥½çš„ï¼Œè°¢è°¢ï½ï½ï½&#010;&#010;JasonLee &lt;17610775726@163.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ8:22å†™é“ï¼š&#010;&#010;&gt; hi&#010;&gt; éœ€è¦å¼€å¯checkpoint&#010;&gt;&#010;&gt;&#010;&gt; | |&#010;&gt; JasonLee&#010;&gt; |&#010;&gt; |&#010;&gt; é‚®ç®±ï¼š17610775726@163.com&#010;&gt; |&#010;&gt;&#010;&gt; Signature is customized by Netease Mail Master&#010;&gt;&#010;&gt; åœ¨2020å¹´07æœˆ16æ—¥ 18:03ï¼Œæä½³å®¸ å†™é“ï¼š&#010;&gt; æƒ³è¯·æ•™ä¸‹å¤§å®¶ hive streaming writeéœ€è¦æœ‰å“ªäº›é…ç½®ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘çš„ä½œä¸šèƒ½å¤Ÿè·‘èµ·æ¥ï¼Œä½†æ˜¯æ²¡æœ‰æ•°æ®å†™å…¥hiveã€‚&#010;&gt; æ‰¹é‡çš„hiveå†™å…¥ï¼Œæµç¯å¢ƒçš„è¯»å–æ˜¯æ­£å¸¸çš„ã€‚&#010;&gt;&#010;&gt; é™„ä»£ç ï¼Œå¾ˆç®€çŸ­ï¼š&#010;&gt;&#010;&gt; public class KafkaToHiveStreaming {&#010;&gt;    public static void main(String[] arg) throws Exception{&#010;&gt;        StreamExecutionEnvironment bsEnv =&#010;&gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt;        EnvironmentSettings bsSettings =&#010;&gt;&#010;&gt; EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();&#010;&gt;        StreamTableEnvironment bsTableEnv =&#010;&gt; StreamTableEnvironment.create(bsEnv, bsSettings);&#010;&gt;        String name            = \"myhive\";&#010;&gt;        String defaultDatabase = \"default\";&#010;&gt;        String hiveConfDir     =&#010;&gt; \"/Users/uzi/Downloads/Hadoop/apache-hive-3.1.2-bin/conf/\"; // a local&#010;&gt; path&#010;&gt;        String version         = \"3.1.2\";&#010;&gt;&#010;&gt;        HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; hiveConfDir, version);&#010;&gt;        bsTableEnv.registerCatalog(\"myhive\", hive);&#010;&gt;        bsTableEnv.useCatalog(\"myhive\");&#010;&gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt;        bsTableEnv.executeSql(\"CREATE TABLE topic_products (\" +&#010;&gt;                \"  id BIGINT ,\" +&#010;&gt;                \"  order_id STRING,\" +&#010;&gt;                \"  amount DECIMAL(10, 2),\" +&#010;&gt;                \"  create_time TIMESTAMP \" +&#010;&gt;                \") WITH (\" +&#010;&gt;                \" 'connector' = 'kafka',\" +&#010;&gt;                \" 'topic' = 'order.test',\" +&#010;&gt;                \" 'properties.bootstrap.servers' = 'localhost:9092',\" +&#010;&gt;                \" 'properties.group.id' = 'testGroup',\" +&#010;&gt;                \" 'scan.startup.mode' = 'earliest-offset', \" +&#010;&gt;                \" 'format' = 'json'  \" +&#010;&gt;                \")\");&#010;&gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt;&#010;&gt;        bsTableEnv.executeSql(\"CREATE TABLE hive_sink_table_streaming (\" +&#010;&gt;                \"  id BIGINT ,\" +&#010;&gt;                \"  order_id STRING,\" +&#010;&gt;                \"  amount DECIMAL(10, 2)\" +&#010;&gt;                \"  )\");&#010;&gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt;        bsTableEnv.executeSql(\"CREATE TABLE print_table WITH&#010;&gt; ('connector' = 'print')\" +&#010;&gt;                \"LIKE INSERT INTO hive_sink_table_streaming (EXCLUDING&#010;&gt; ALL)\");&#010;&gt;&#010;&gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt;        bsTableEnv.executeSql(\"INSERT INTO hive_sink_table_streaming SELECT&#010;&gt; \" +&#010;&gt;                \"id, \" +&#010;&gt;                \"order_id, \" +&#010;&gt;                \"amount \" +&#010;&gt;                \"FROM topic_products\");&#010;&gt;&#010;&gt;        Table table1 = bsTableEnv.from(\"hive_sink_table_streaming\");&#010;&gt;        table1.executeInsert(\"print_table\");&#010;&gt;    }&#010;&gt; }&#010;&gt;&#010;&#010;",
        "depth": "2",
        "reply": "<CAMSfv0sTcU=5WerLx3sMT893G+DY1oH+QzUr8SVLRy4Zx5aBmQ@mail.gmail.com>"
    },
    {
        "id": "<CAEZk043D_-9i-YrULqx0o-1iXWvM+oJtKpGkaL6S3RUksNZGCA@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 09:39:49 GMT",
        "subject": "Re: Flink 1.11 Hive Streaming Writeçš„é—®é¢˜",
        "content": "hiã€&#010;è¯·é—®è¿™ä¸ªé—®é¢˜æœ€åæ€ä¹ˆè§£å†³äº†ï¼Œæ•°æ®èƒ½æ»šåŠ¨å†™å…¥hiveäº†å˜›ï¼Œæˆ‘è¿™é¢å¼€å¯äº†checkpointä¹‹åhiveä¹Ÿæ˜¯æ²¡æ•°æ®&#010;&#010;æä½³å®¸ &lt;lijiachen218@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ10:39å†™é“ï¼š&#010;&#010;&gt; å¥½çš„ï¼Œè°¢è°¢ï½ï½ï½&#010;&gt;&#010;&gt; JasonLee &lt;17610775726@163.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ8:22å†™é“ï¼š&#010;&gt;&#010;&gt; &gt; hi&#010;&gt; &gt; éœ€è¦å¼€å¯checkpoint&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt; | |&#010;&gt; &gt; JasonLee&#010;&gt; &gt; |&#010;&gt; &gt; |&#010;&gt; &gt; é‚®ç®±ï¼š17610775726@163.com&#010;&gt; &gt; |&#010;&gt; &gt;&#010;&gt; &gt; Signature is customized by Netease Mail Master&#010;&gt; &gt;&#010;&gt; &gt; åœ¨2020å¹´07æœˆ16æ—¥ 18:03ï¼Œæä½³å®¸ å†™é“ï¼š&#010;&gt; &gt; æƒ³è¯·æ•™ä¸‹å¤§å®¶ hive streaming writeéœ€è¦æœ‰å“ªäº›é…ç½®ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘çš„ä½œä¸šèƒ½å¤Ÿè·‘èµ·æ¥ï¼Œä½†æ˜¯æ²¡æœ‰æ•°æ®å†™å…¥hiveã€‚&#010;&gt; &gt; æ‰¹é‡çš„hiveå†™å…¥ï¼Œæµç¯å¢ƒçš„è¯»å–æ˜¯æ­£å¸¸çš„ã€‚&#010;&gt; &gt;&#010;&gt; &gt; é™„ä»£ç ï¼Œå¾ˆç®€çŸ­ï¼š&#010;&gt; &gt;&#010;&gt; &gt; public class KafkaToHiveStreaming {&#010;&gt; &gt;    public static void main(String[] arg) throws Exception{&#010;&gt; &gt;        StreamExecutionEnvironment bsEnv =&#010;&gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt;        EnvironmentSettings bsSettings =&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();&#010;&gt; &gt;        StreamTableEnvironment bsTableEnv =&#010;&gt; &gt; StreamTableEnvironment.create(bsEnv, bsSettings);&#010;&gt; &gt;        String name            = \"myhive\";&#010;&gt; &gt;        String defaultDatabase = \"default\";&#010;&gt; &gt;        String hiveConfDir     =&#010;&gt; &gt; \"/Users/uzi/Downloads/Hadoop/apache-hive-3.1.2-bin/conf/\"; // a local&#010;&gt; &gt; path&#010;&gt; &gt;        String version         = \"3.1.2\";&#010;&gt; &gt;&#010;&gt; &gt;        HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; hiveConfDir, version);&#010;&gt; &gt;        bsTableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt;        bsTableEnv.useCatalog(\"myhive\");&#010;&gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt;        bsTableEnv.executeSql(\"CREATE TABLE topic_products (\" +&#010;&gt; &gt;                \"  id BIGINT ,\" +&#010;&gt; &gt;                \"  order_id STRING,\" +&#010;&gt; &gt;                \"  amount DECIMAL(10, 2),\" +&#010;&gt; &gt;                \"  create_time TIMESTAMP \" +&#010;&gt; &gt;                \") WITH (\" +&#010;&gt; &gt;                \" 'connector' = 'kafka',\" +&#010;&gt; &gt;                \" 'topic' = 'order.test',\" +&#010;&gt; &gt;                \" 'properties.bootstrap.servers' = 'localhost:9092',\" +&#010;&gt; &gt;                \" 'properties.group.id' = 'testGroup',\" +&#010;&gt; &gt;                \" 'scan.startup.mode' = 'earliest-offset', \" +&#010;&gt; &gt;                \" 'format' = 'json'  \" +&#010;&gt; &gt;                \")\");&#010;&gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt;&#010;&gt; &gt;        bsTableEnv.executeSql(\"CREATE TABLE hive_sink_table_streaming (\" +&#010;&gt; &gt;                \"  id BIGINT ,\" +&#010;&gt; &gt;                \"  order_id STRING,\" +&#010;&gt; &gt;                \"  amount DECIMAL(10, 2)\" +&#010;&gt; &gt;                \"  )\");&#010;&gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt;        bsTableEnv.executeSql(\"CREATE TABLE print_table WITH&#010;&gt; &gt; ('connector' = 'print')\" +&#010;&gt; &gt;                \"LIKE INSERT INTO hive_sink_table_streaming (EXCLUDING&#010;&gt; &gt; ALL)\");&#010;&gt; &gt;&#010;&gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt;        bsTableEnv.executeSql(\"INSERT INTO hive_sink_table_streaming&#010;&gt; SELECT&#010;&gt; &gt; \" +&#010;&gt; &gt;                \"id, \" +&#010;&gt; &gt;                \"order_id, \" +&#010;&gt; &gt;                \"amount \" +&#010;&gt; &gt;                \"FROM topic_products\");&#010;&gt; &gt;&#010;&gt; &gt;        Table table1 = bsTableEnv.from(\"hive_sink_table_streaming\");&#010;&gt; &gt;        table1.executeInsert(\"print_table\");&#010;&gt; &gt;    }&#010;&gt; &gt; }&#010;&gt; &gt;&#010;&gt;&#010;&#010;",
        "depth": "3",
        "reply": "<CAMSfv0sTcU=5WerLx3sMT893G+DY1oH+QzUr8SVLRy4Zx5aBmQ@mail.gmail.com>"
    },
    {
        "id": "<CABi+2jRf-1aWRwj4insseyy+1LL0=GFH7QwFLRGHH7wSsqWehw@mail.gmail.com>",
        "from": "Jingsong Li &lt;jingsongl...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 10:09:25 GMT",
        "subject": "Re: Flink 1.11 Hive Streaming Writeçš„é—®é¢˜",
        "content": "Hi Dream,&#010;&#010;å¯ä»¥è¯¦è¿°ä¸‹ä½ çš„æµ‹è¯•åœºæ™¯å—ï¼Ÿ&#010;&#010;Best,&#010;Jingsong&#010;&#010;On Mon, Jul 20, 2020 at 5:40 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&#010;&gt; hiã€&#010;&gt; è¯·é—®è¿™ä¸ªé—®é¢˜æœ€åæ€ä¹ˆè§£å†³äº†ï¼Œæ•°æ®èƒ½æ»šåŠ¨å†™å…¥hiveäº†å˜›ï¼Œæˆ‘è¿™é¢å¼€å¯äº†checkpointä¹‹åhiveä¹Ÿæ˜¯æ²¡æ•°æ®&#010;&gt;&#010;&gt; æä½³å®¸ &lt;lijiachen218@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ10:39å†™é“ï¼š&#010;&gt;&#010;&gt; &gt; å¥½çš„ï¼Œè°¢è°¢ï½ï½ï½&#010;&gt; &gt;&#010;&gt; &gt; JasonLee &lt;17610775726@163.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ8:22å†™é“ï¼š&#010;&gt; &gt;&#010;&gt; &gt; &gt; hi&#010;&gt; &gt; &gt; éœ€è¦å¼€å¯checkpoint&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; | |&#010;&gt; &gt; &gt; JasonLee&#010;&gt; &gt; &gt; |&#010;&gt; &gt; &gt; |&#010;&gt; &gt; &gt; é‚®ç®±ï¼š17610775726@163.com&#010;&gt; &gt; &gt; |&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; Signature is customized by Netease Mail Master&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; åœ¨2020å¹´07æœˆ16æ—¥ 18:03ï¼Œæä½³å®¸ å†™é“ï¼š&#010;&gt; &gt; &gt; æƒ³è¯·æ•™ä¸‹å¤§å®¶ hive streaming writeéœ€è¦æœ‰å“ªäº›é…ç½®ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘çš„ä½œä¸šèƒ½å¤Ÿè·‘èµ·æ¥ï¼Œä½†æ˜¯æ²¡æœ‰æ•°æ®å†™å…¥hiveã€‚&#010;&gt; &gt; &gt; æ‰¹é‡çš„hiveå†™å…¥ï¼Œæµç¯å¢ƒçš„è¯»å–æ˜¯æ­£å¸¸çš„ã€‚&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; é™„ä»£ç ï¼Œå¾ˆç®€çŸ­ï¼š&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; public class KafkaToHiveStreaming {&#010;&gt; &gt; &gt;    public static void main(String[] arg) throws Exception{&#010;&gt; &gt; &gt;        StreamExecutionEnvironment bsEnv =&#010;&gt; &gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt; &gt;        EnvironmentSettings bsSettings =&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();&#010;&gt; &gt; &gt;        StreamTableEnvironment bsTableEnv =&#010;&gt; &gt; &gt; StreamTableEnvironment.create(bsEnv, bsSettings);&#010;&gt; &gt; &gt;        String name            = \"myhive\";&#010;&gt; &gt; &gt;        String defaultDatabase = \"default\";&#010;&gt; &gt; &gt;        String hiveConfDir     =&#010;&gt; &gt; &gt; \"/Users/uzi/Downloads/Hadoop/apache-hive-3.1.2-bin/conf/\"; // a local&#010;&gt; &gt; &gt; path&#010;&gt; &gt; &gt;        String version         = \"3.1.2\";&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;        HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; &gt; hiveConfDir, version);&#010;&gt; &gt; &gt;        bsTableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt; &gt;        bsTableEnv.useCatalog(\"myhive\");&#010;&gt; &gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt; &gt;        bsTableEnv.executeSql(\"CREATE TABLE topic_products (\" +&#010;&gt; &gt; &gt;                \"  id BIGINT ,\" +&#010;&gt; &gt; &gt;                \"  order_id STRING,\" +&#010;&gt; &gt; &gt;                \"  amount DECIMAL(10, 2),\" +&#010;&gt; &gt; &gt;                \"  create_time TIMESTAMP \" +&#010;&gt; &gt; &gt;                \") WITH (\" +&#010;&gt; &gt; &gt;                \" 'connector' = 'kafka',\" +&#010;&gt; &gt; &gt;                \" 'topic' = 'order.test',\" +&#010;&gt; &gt; &gt;                \" 'properties.bootstrap.servers' = 'localhost:9092',\" +&#010;&gt; &gt; &gt;                \" 'properties.group.id' = 'testGroup',\" +&#010;&gt; &gt; &gt;                \" 'scan.startup.mode' = 'earliest-offset', \" +&#010;&gt; &gt; &gt;                \" 'format' = 'json'  \" +&#010;&gt; &gt; &gt;                \")\");&#010;&gt; &gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;        bsTableEnv.executeSql(\"CREATE TABLE hive_sink_table_streaming&#010;&gt; (\" +&#010;&gt; &gt; &gt;                \"  id BIGINT ,\" +&#010;&gt; &gt; &gt;                \"  order_id STRING,\" +&#010;&gt; &gt; &gt;                \"  amount DECIMAL(10, 2)\" +&#010;&gt; &gt; &gt;                \"  )\");&#010;&gt; &gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt; &gt;        bsTableEnv.executeSql(\"CREATE TABLE print_table WITH&#010;&gt; &gt; &gt; ('connector' = 'print')\" +&#010;&gt; &gt; &gt;                \"LIKE INSERT INTO hive_sink_table_streaming (EXCLUDING&#010;&gt; &gt; &gt; ALL)\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;        bsTableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt; &gt;        bsTableEnv.executeSql(\"INSERT INTO hive_sink_table_streaming&#010;&gt; &gt; SELECT&#010;&gt; &gt; &gt; \" +&#010;&gt; &gt; &gt;                \"id, \" +&#010;&gt; &gt; &gt;                \"order_id, \" +&#010;&gt; &gt; &gt;                \"amount \" +&#010;&gt; &gt; &gt;                \"FROM topic_products\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;        Table table1 = bsTableEnv.from(\"hive_sink_table_streaming\");&#010;&gt; &gt; &gt;        table1.executeInsert(\"print_table\");&#010;&gt; &gt; &gt;    }&#010;&gt; &gt; &gt; }&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt;&#010;&#010;&#010;-- &#010;Best, Jingsong Lee&#010;&#010;",
        "depth": "4",
        "reply": "<CAMSfv0sTcU=5WerLx3sMT893G+DY1oH+QzUr8SVLRy4Zx5aBmQ@mail.gmail.com>"
    },
    {
        "id": "<CACaQKu47pY=MJ0rKzW_97Z9GBCJpZ24LeL=CyKVkf15+00Hcuw@mail.gmail.com>",
        "from": "LakeShen &lt;shenleifight...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 10:03:11 GMT",
        "subject": "Flink on k8s ä¸­ï¼ŒJar ä»»åŠ¡ avatica-core ä¾èµ–å’Œ flink-table jar å†²çªé—®é¢˜",
        "content": "Hi ç¤¾åŒºï¼Œ&#013;&#010;&#013;&#010;æˆ‘ç°åœ¨æ­£åœ¨è¿ç§»ä»»åŠ¡åˆ° k8s ,ç›®å‰ç‰ˆæœ¬ä¸º Flink 1.6 ç‰ˆæœ¬ï¼Œk8s ä¸Šé¢ä½œä¸šè¿è¡Œæ¨¡å¼ä¸º&#010;standalone per job.&#013;&#010;&#013;&#010;ç°åœ¨é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œä¸šåŠ¡æ–¹ Flink jar ä»»åŠ¡ä½¿ç”¨äº† org.apache.calcite.avatica&#010;ä¾èµ–ï¼Œä¹Ÿå°±æ˜¯ä¸‹é¢ä¾èµ–ï¼š&#013;&#010;&lt;dependency&gt;&#013;&#010;            &lt;groupId&gt;org.apache.calcite.avatica&lt;/groupId&gt;&#013;&#010;            &lt;artifactId&gt;avatica-core&lt;/artifactId&gt;&#013;&#010;            &lt;version&gt;${avatica.version}&lt;/version&gt;&#013;&#010;        &lt;/dependency&gt;&#013;&#010;&#013;&#010;ä½†æ˜¯è¿™ä¸ªä¾èµ–å…¶å®åœ¨ flink-table æ¨¡å—ä¸­ï¼Œä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼š&#013;&#010;[image: image.png]&#013;&#010;&#013;&#010;ç”±äº flink on k8s  standalone per job æ¨¡å¼ï¼Œä¼šæŠŠ Flink ä»»åŠ¡ jar åŒ…æ”¾å…¥åˆ° flink&#010;æœ¬èº«çš„lib&#013;&#010;åŒ…ä¸­ï¼Œæˆ‘åœ¨ä»»åŠ¡å¯åŠ¨çš„æ—¶å€™ï¼Œå°±ä¼šæŠ¥ï¼š&#013;&#010;Caused by: java.lang.NoClassDefFoundError: Could not initialize class&#013;&#010;org.apache.calcite.avatica.ConnectionPropertiesImpl é”™è¯¯ã€‚&#013;&#010;&#013;&#010;æŒ‰ç…§æˆ‘çš„ç†è§£ï¼Œç”±äº Flink jar ä»»åŠ¡åŒ…ä¸­æœ‰ avatica-core ä¾èµ–ï¼ŒåŒæ—¶åœ¨ flink&#010;lib&#013;&#010;ç›®å½•ä¸‹é¢ï¼Œflink-table_2.11-1.6-RELEASE.jar ä¸­ä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼Œè¿™ä¸¤ä¸ªéƒ½åœ¨ lib&#010;ç›®å½•ä¸‹ï¼Œç„¶åå°±å‡ºç°äº†ç±»å†²çªé—®é¢˜ã€‚&#013;&#010;&#013;&#010;è¯·é—®æ€ä¹ˆè§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Œéå¸¸æœŸå¾…ä½ çš„å›å¤ã€‚&#013;&#010;&#013;&#010;Best,&#013;&#010;LakeShen&#013;&#010;",
        "depth": "0",
        "reply": "<CACaQKu47pY=MJ0rKzW_97Z9GBCJpZ24LeL=CyKVkf15+00Hcuw@mail.gmail.com>"
    },
    {
        "id": "<CAA8tFvunychdKkCJ+VAG1LfNeTMqoJgingf+36hd_ZnGOc4_Qw@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 12:19:08 GMT",
        "subject": "Re: Flink on k8s ä¸­ï¼ŒJar ä»»åŠ¡ avatica-core ä¾èµ–å’Œ flink-table jar å†²çªé—®é¢˜",
        "content": "Hi&#013;&#010;&#013;&#010;ä½ çš„å›¾æŒ‚äº†ï¼Œå¦‚æœå•çº¯æƒ³è§£å†³ jar åŒ…å†²çªçš„é—®é¢˜ï¼Œé‚£ä¹ˆ maven shade plugin[1]&#010;æˆ–è®¸å¯¹ä½ æœ‰ç”¨&#013;&#010;&#013;&#010;[1]&#013;&#010;https://maven.apache.org/plugins/maven-shade-plugin/examples/class-relocation.html&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;LakeShen &lt;shenleifighting@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:03å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; Hi ç¤¾åŒºï¼Œ&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘ç°åœ¨æ­£åœ¨è¿ç§»ä»»åŠ¡åˆ° k8s ,ç›®å‰ç‰ˆæœ¬ä¸º Flink 1.6 ç‰ˆæœ¬ï¼Œk8s ä¸Šé¢ä½œä¸šè¿è¡Œæ¨¡å¼ä¸º&#010;standalone per job.&#013;&#010;&gt;&#013;&#010;&gt; ç°åœ¨é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œä¸šåŠ¡æ–¹ Flink jar ä»»åŠ¡ä½¿ç”¨äº† org.apache.calcite.avatica&#010;ä¾èµ–ï¼Œä¹Ÿå°±æ˜¯ä¸‹é¢ä¾èµ–ï¼š&#013;&#010;&gt; &lt;dependency&gt;&#013;&#010;&gt;             &lt;groupId&gt;org.apache.calcite.avatica&lt;/groupId&gt;&#013;&#010;&gt;             &lt;artifactId&gt;avatica-core&lt;/artifactId&gt;&#013;&#010;&gt;             &lt;version&gt;${avatica.version}&lt;/version&gt;&#013;&#010;&gt;         &lt;/dependency&gt;&#013;&#010;&gt;&#013;&#010;&gt; ä½†æ˜¯è¿™ä¸ªä¾èµ–å…¶å®åœ¨ flink-table æ¨¡å—ä¸­ï¼Œä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼š&#013;&#010;&gt; [image: image.png]&#013;&#010;&gt;&#013;&#010;&gt; ç”±äº flink on k8s  standalone per job æ¨¡å¼ï¼Œä¼šæŠŠ Flink ä»»åŠ¡ jar åŒ…æ”¾å…¥åˆ°&#010;flink æœ¬èº«çš„lib&#013;&#010;&gt; åŒ…ä¸­ï¼Œæˆ‘åœ¨ä»»åŠ¡å¯åŠ¨çš„æ—¶å€™ï¼Œå°±ä¼šæŠ¥ï¼š&#013;&#010;&gt; Caused by: java.lang.NoClassDefFoundError: Could not initialize class&#013;&#010;&gt; org.apache.calcite.avatica.ConnectionPropertiesImpl é”™è¯¯ã€‚&#013;&#010;&gt;&#013;&#010;&gt; æŒ‰ç…§æˆ‘çš„ç†è§£ï¼Œç”±äº Flink jar ä»»åŠ¡åŒ…ä¸­æœ‰ avatica-core ä¾èµ–ï¼ŒåŒæ—¶åœ¨&#010;flink lib&#013;&#010;&gt; ç›®å½•ä¸‹é¢ï¼Œflink-table_2.11-1.6-RELEASE.jar ä¸­ä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼Œè¿™ä¸¤ä¸ªéƒ½åœ¨&#010;lib ç›®å½•ä¸‹ï¼Œç„¶åå°±å‡ºç°äº†ç±»å†²çªé—®é¢˜ã€‚&#013;&#010;&gt;&#013;&#010;&gt; è¯·é—®æ€ä¹ˆè§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Œéå¸¸æœŸå¾…ä½ çš„å›å¤ã€‚&#013;&#010;&gt;&#013;&#010;&gt; Best,&#013;&#010;&gt; LakeShen&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "1",
        "reply": "<CACaQKu47pY=MJ0rKzW_97Z9GBCJpZ24LeL=CyKVkf15+00Hcuw@mail.gmail.com>"
    },
    {
        "id": "<CACaQKu7ygroKjeT6BbygGV=0fh=00-5_FJRZcJ5CKTzWtjMoBA@mail.gmail.com>",
        "from": "LakeShen &lt;shenleifight...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 02:02:17 GMT",
        "subject": "Re: Flink on k8s ä¸­ï¼ŒJar ä»»åŠ¡ avatica-core ä¾èµ–å’Œ flink-table jar å†²çªé—®é¢˜",
        "content": "å—¯å—¯ï¼ŒCongxian,æ„Ÿè°¢ä½ çš„å›å¤ï¼Œæˆ‘é€šè¿‡ Maven Shaded è§£å†³é—®é¢˜ğŸ˜ã€‚&#013;&#010;&#013;&#010;Congxian Qiu &lt;qcx978132955@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ8:19å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; Hi&#013;&#010;&gt;&#013;&#010;&gt; ä½ çš„å›¾æŒ‚äº†ï¼Œå¦‚æœå•çº¯æƒ³è§£å†³ jar åŒ…å†²çªçš„é—®é¢˜ï¼Œé‚£ä¹ˆ maven shade plugin[1]&#010;æˆ–è®¸å¯¹ä½ æœ‰ç”¨&#013;&#010;&gt;&#013;&#010;&gt; [1]&#013;&#010;&gt;&#013;&#010;&gt; https://maven.apache.org/plugins/maven-shade-plugin/examples/class-relocation.html&#013;&#010;&gt; Best,&#013;&#010;&gt; Congxian&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; LakeShen &lt;shenleifighting@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:03å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt; &gt; Hi ç¤¾åŒºï¼Œ&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; æˆ‘ç°åœ¨æ­£åœ¨è¿ç§»ä»»åŠ¡åˆ° k8s ,ç›®å‰ç‰ˆæœ¬ä¸º Flink 1.6 ç‰ˆæœ¬ï¼Œk8s ä¸Šé¢ä½œä¸šè¿è¡Œæ¨¡å¼ä¸º&#010;standalone per job.&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; ç°åœ¨é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œä¸šåŠ¡æ–¹ Flink jar ä»»åŠ¡ä½¿ç”¨äº† org.apache.calcite.avatica&#010;ä¾èµ–ï¼Œä¹Ÿå°±æ˜¯ä¸‹é¢ä¾èµ–ï¼š&#013;&#010;&gt; &gt; &lt;dependency&gt;&#013;&#010;&gt; &gt;             &lt;groupId&gt;org.apache.calcite.avatica&lt;/groupId&gt;&#013;&#010;&gt; &gt;             &lt;artifactId&gt;avatica-core&lt;/artifactId&gt;&#013;&#010;&gt; &gt;             &lt;version&gt;${avatica.version}&lt;/version&gt;&#013;&#010;&gt; &gt;         &lt;/dependency&gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; ä½†æ˜¯è¿™ä¸ªä¾èµ–å…¶å®åœ¨ flink-table æ¨¡å—ä¸­ï¼Œä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼š&#013;&#010;&gt; &gt; [image: image.png]&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; ç”±äº flink on k8s  standalone per job æ¨¡å¼ï¼Œä¼šæŠŠ Flink ä»»åŠ¡ jar åŒ…æ”¾å…¥åˆ°&#010;flink æœ¬èº«çš„lib&#013;&#010;&gt; &gt; åŒ…ä¸­ï¼Œæˆ‘åœ¨ä»»åŠ¡å¯åŠ¨çš„æ—¶å€™ï¼Œå°±ä¼šæŠ¥ï¼š&#013;&#010;&gt; &gt; Caused by: java.lang.NoClassDefFoundError: Could not initialize class&#013;&#010;&gt; &gt; org.apache.calcite.avatica.ConnectionPropertiesImpl é”™è¯¯ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; æŒ‰ç…§æˆ‘çš„ç†è§£ï¼Œç”±äº Flink jar ä»»åŠ¡åŒ…ä¸­æœ‰ avatica-core ä¾èµ–ï¼ŒåŒæ—¶åœ¨&#010;flink lib&#013;&#010;&gt; &gt; ç›®å½•ä¸‹é¢ï¼Œflink-table_2.11-1.6-RELEASE.jar ä¸­ä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼Œè¿™ä¸¤ä¸ªéƒ½åœ¨&#010;lib ç›®å½•ä¸‹ï¼Œç„¶åå°±å‡ºç°äº†ç±»å†²çªé—®é¢˜ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; è¯·é—®æ€ä¹ˆè§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Œéå¸¸æœŸå¾…ä½ çš„å›å¤ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Best,&#013;&#010;&gt; &gt; LakeShen&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<CACaQKu47pY=MJ0rKzW_97Z9GBCJpZ24LeL=CyKVkf15+00Hcuw@mail.gmail.com>"
    },
    {
        "id": "<CAP+gf36icRu06Wqi11LcTzmUwxyNfDsboZd+hjKUupy8P3jf4Q@mail.gmail.com>",
        "from": "Yang Wang &lt;danrtsey...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 03:18:07 GMT",
        "subject": "Re: Flink on k8s ä¸­ï¼ŒJar ä»»åŠ¡ avatica-core ä¾èµ–å’Œ flink-table jar å†²çªé—®é¢˜",
        "content": "Flinkä»1.10å¼€å§‹æ˜¯æ”¯æŒç”¨user classloaderæ¥åŠ è½½ç”¨æˆ·jarçš„ï¼ŒåŒ…æ‹¬Standalone perjob&#013;&#010;ä½ éœ€è¦å°†jaråŒ…æ”¾åˆ°$FLINK_HOME/usrlibç›®å½•ä¸‹ï¼Œå¦‚æœæ”¾åˆ°libä¸‹å°±ä¼šç”¨æ¡†æ¶çš„classloader&#013;&#010;æ¥åŠ è½½&#013;&#010;&#013;&#010;&#013;&#010;Best,&#013;&#010;Yang&#013;&#010;&#013;&#010;LakeShen &lt;shenleifighting@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸Šåˆ10:02å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; å—¯å—¯ï¼ŒCongxian,æ„Ÿè°¢ä½ çš„å›å¤ï¼Œæˆ‘é€šè¿‡ Maven Shaded è§£å†³é—®é¢˜ğŸ˜ã€‚&#013;&#010;&gt;&#013;&#010;&gt; Congxian Qiu &lt;qcx978132955@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ8:19å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt; &gt; Hi&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; ä½ çš„å›¾æŒ‚äº†ï¼Œå¦‚æœå•çº¯æƒ³è§£å†³ jar åŒ…å†²çªçš„é—®é¢˜ï¼Œé‚£ä¹ˆ maven shade&#010;plugin[1] æˆ–è®¸å¯¹ä½ æœ‰ç”¨&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; [1]&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; https://maven.apache.org/plugins/maven-shade-plugin/examples/class-relocation.html&#013;&#010;&gt; &gt; Best,&#013;&#010;&gt; &gt; Congxian&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; LakeShen &lt;shenleifighting@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:03å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; &gt; Hi ç¤¾åŒºï¼Œ&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; æˆ‘ç°åœ¨æ­£åœ¨è¿ç§»ä»»åŠ¡åˆ° k8s ,ç›®å‰ç‰ˆæœ¬ä¸º Flink 1.6 ç‰ˆæœ¬ï¼Œk8s&#010;ä¸Šé¢ä½œä¸šè¿è¡Œæ¨¡å¼ä¸º standalone per job.&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; ç°åœ¨é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œä¸šåŠ¡æ–¹ Flink jar ä»»åŠ¡ä½¿ç”¨äº† org.apache.calcite.avatica&#010;ä¾èµ–ï¼Œä¹Ÿå°±æ˜¯ä¸‹é¢ä¾èµ–ï¼š&#013;&#010;&gt; &gt; &gt; &lt;dependency&gt;&#013;&#010;&gt; &gt; &gt;             &lt;groupId&gt;org.apache.calcite.avatica&lt;/groupId&gt;&#013;&#010;&gt; &gt; &gt;             &lt;artifactId&gt;avatica-core&lt;/artifactId&gt;&#013;&#010;&gt; &gt; &gt;             &lt;version&gt;${avatica.version}&lt;/version&gt;&#013;&#010;&gt; &gt; &gt;         &lt;/dependency&gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; ä½†æ˜¯è¿™ä¸ªä¾èµ–å…¶å®åœ¨ flink-table æ¨¡å—ä¸­ï¼Œä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼š&#013;&#010;&gt; &gt; &gt; [image: image.png]&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; ç”±äº flink on k8s  standalone per job æ¨¡å¼ï¼Œä¼šæŠŠ Flink ä»»åŠ¡ jar åŒ…æ”¾å…¥åˆ°&#010;flink&#013;&#010;&gt; æœ¬èº«çš„lib&#013;&#010;&gt; &gt; &gt; åŒ…ä¸­ï¼Œæˆ‘åœ¨ä»»åŠ¡å¯åŠ¨çš„æ—¶å€™ï¼Œå°±ä¼šæŠ¥ï¼š&#013;&#010;&gt; &gt; &gt; Caused by: java.lang.NoClassDefFoundError: Could not initialize class&#013;&#010;&gt; &gt; &gt; org.apache.calcite.avatica.ConnectionPropertiesImpl é”™è¯¯ã€‚&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; æŒ‰ç…§æˆ‘çš„ç†è§£ï¼Œç”±äº Flink jar ä»»åŠ¡åŒ…ä¸­æœ‰ avatica-core ä¾èµ–ï¼ŒåŒæ—¶åœ¨&#010;flink lib&#013;&#010;&gt; &gt; &gt; ç›®å½•ä¸‹é¢ï¼Œflink-table_2.11-1.6-RELEASE.jar ä¸­ä¹Ÿæœ‰è¿™ä¸ªä¾èµ–ï¼Œè¿™ä¸¤ä¸ªéƒ½åœ¨&#010;lib&#013;&#010;&gt; ç›®å½•ä¸‹ï¼Œç„¶åå°±å‡ºç°äº†ç±»å†²çªé—®é¢˜ã€‚&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; è¯·é—®æ€ä¹ˆè§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Œéå¸¸æœŸå¾…ä½ çš„å›å¤ã€‚&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; Best,&#013;&#010;&gt; &gt; &gt; LakeShen&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "3",
        "reply": "<CACaQKu47pY=MJ0rKzW_97Z9GBCJpZ24LeL=CyKVkf15+00Hcuw@mail.gmail.com>"
    },
    {
        "id": "<tencent_A102A9D2E3D31E32955A7C7454B611B33409@qq.com>",
        "from": "&quot;sun&quot; &lt;1392427...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 10:16:45 GMT",
        "subject": "stateæ— æ³•ä»checkpointä¸­æ¢å¤",
        "content": "é…ç½®ä»£ç env.enableCheckpointing(1000);env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&#013;&#010;//ä½œä¸šå¤±è´¥åä¸é‡å¯&#013;&#010;env.setRestartStrategy(RestartStrategies.noRestart());&#013;&#010;env.getCheckpointConfig().setCheckpointTimeout(500);&#013;&#010;env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#013;&#010;env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#013;&#010;env.setStateBackend(new RocksDBStateBackend(\"file:///opt/flink/flink-1.7.2/checkpoints\"));&#010;           ä½¿ç”¨çŠ¶æ€çš„ä»£ç private transient ListState&lt;String&amp;gt; counts;&#013;&#010;&#013;&#010;&#013;&#010;@Override&#013;&#010;public void open(Configuration parameters) throws Exception {&#013;&#010;    StateTtlConfig ttlConfig = StateTtlConfig&#013;&#010;            .newBuilder(Time.minutes(30))&#013;&#010;            .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#013;&#010;            .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#013;&#010;            .build();&#013;&#010;&#013;&#010;    ListStateDescriptor&lt;String&amp;gt; lastUserLogin = new ListStateDescriptor&lt;&amp;gt;(\"lastUserLogin\",&#010;String.class);&#013;&#010;    lastUserLogin.enableTimeToLive(ttlConfig);&#013;&#010;    counts = getRuntimeContext().getListState(lastUserLogin);&#013;&#010;}&#013;&#010;æˆ‘é‡å¯äº†task managers åã€‚å‘ç°  counts  é‡Œé¢çš„æ•°æ®éƒ½ä¸¢å¤±äº†",
        "depth": "0",
        "reply": "<tencent_A102A9D2E3D31E32955A7C7454B611B33409@qq.com>"
    },
    {
        "id": "<CAA8tFvvB5pku1i9SnP7Lk1GwJ13aLtX=BoRSJZMv4biUaKEkog@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 12:16:48 GMT",
        "subject": "Re: stateæ— æ³•ä»checkpointä¸­æ¢å¤",
        "content": "Hi&#013;&#010;&#013;&#010;1 counts çš„æ•°æ®ä¸¢å¤±äº†èƒ½å¦è¯¦ç»†æè¿°ä¸€ä¸‹å‘¢ï¼Ÿä½ é¢„æœŸæ˜¯ä»€ä¹ˆï¼Œçœ‹åˆ°ä»€ä¹ˆç°è±¡&#013;&#010;2 èƒ½å¦æŠŠä½ å…³äº counts çš„å…¶ä»–ä»£ç ä¹Ÿè´´ä¸€ä¸‹&#013;&#010;3. ä½ çš„ä½œä¸šæ˜¯å¦ä» checkpoint æ¢å¤äº†å‘¢ï¼Ÿè¿™ä¸ªå¯ä»¥ä» JM log æ¥æŸ¥çœ‹&#013;&#010;4. å¦‚æœä½ ç¡®å®šæ˜¯æ•°æ®æœ‰ä¸¢å¤±çš„è¯ï¼Œæˆ–è®¸ä½ å¯ä»¥ä½¿ç”¨ state-process-api[1] çœ‹ä¸€ä¸‹æ˜¯åºåˆ—åŒ–å‡ºå»æœ‰é—®é¢˜ï¼Œè¿˜æ˜¯&#010;restore å›æ¥æœ‰é—®é¢˜&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/state_processor_api.html&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;sun &lt;1392427699@qq.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:16å†™é“ï¼š&#013;&#010;&#013;&#010;&gt;&#013;&#010;&gt; é…ç½®ä»£ç env.enableCheckpointing(1000);env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&#013;&#010;&gt; //ä½œä¸šå¤±è´¥åä¸é‡å¯&#013;&#010;&gt; env.setRestartStrategy(RestartStrategies.noRestart());&#013;&#010;&gt; env.getCheckpointConfig().setCheckpointTimeout(500);&#013;&#010;&gt;&#013;&#010;&gt; env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#013;&#010;&gt;&#013;&#010;&gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#013;&#010;&gt; env.setStateBackend(new&#013;&#010;&gt; RocksDBStateBackend(\"file:///opt/flink/flink-1.7.2/checkpoints\"));&#013;&#010;&gt;   ä½¿ç”¨çŠ¶æ€çš„ä»£ç private transient ListState&lt;String&amp;gt; counts;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; @Override&#013;&#010;&gt; public void open(Configuration parameters) throws Exception {&#013;&#010;&gt;     StateTtlConfig ttlConfig = StateTtlConfig&#013;&#010;&gt;             .newBuilder(Time.minutes(30))&#013;&#010;&gt;             .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#013;&#010;&gt;&#013;&#010;&gt; .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#013;&#010;&gt;             .build();&#013;&#010;&gt;&#013;&#010;&gt;     ListStateDescriptor&lt;String&amp;gt; lastUserLogin = new&#013;&#010;&gt; ListStateDescriptor&lt;&amp;gt;(\"lastUserLogin\", String.class);&#013;&#010;&gt;     lastUserLogin.enableTimeToLive(ttlConfig);&#013;&#010;&gt;     counts = getRuntimeContext().getListState(lastUserLogin);&#013;&#010;&gt; }&#013;&#010;&gt; æˆ‘é‡å¯äº†task managers åã€‚å‘ç°  counts  é‡Œé¢çš„æ•°æ®éƒ½ä¸¢å¤±äº†&#013;&#010;",
        "depth": "1",
        "reply": "<tencent_A102A9D2E3D31E32955A7C7454B611B33409@qq.com>"
    },
    {
        "id": "<tencent_6E992C9F40A574D4B4984CC3966A1D94ED07@qq.com>",
        "from": "&quot;sun&quot; &lt;1392427...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:21:41 GMT",
        "subject": "å›å¤ï¼š stateæ— æ³•ä»checkpointä¸­æ¢å¤",
        "content": "ä½ å¥½ï¼šcounts çš„æ•°æ® æˆ‘æ˜¯åœ¨ä¸‹é¢æ‰“å°å‡ºæ¥äº† List&lt;String&amp;gt; list = Lists.newArrayList(counts.get())&#010;;&#013;&#010;            for(String ss : list){&#013;&#010;                System.out.println(\"!!!\" + ss);&#013;&#010;                log.info(\"!!!\" + ss);&#013;&#010;            }ï¼Œä½†æ˜¯æˆ‘é‡å¯æœåŠ¡ä¹‹åï¼Œä¹‹å‰å­˜çš„é‚£äº›å†…å®¹æ‰“å°ä¸å‡ºæ¥äº†ã€‚&#013;&#010;@Slf4j&#013;&#010;public class FlatMapTestState extends RichFlatMapFunction&lt;String, Test222&amp;gt; {&#013;&#010;&#013;&#010;&#013;&#010;    private transient ListState&lt;String&amp;gt; counts;&#013;&#010;&#013;&#010;&#013;&#010;    @Override&#013;&#010;    public void open(Configuration parameters) throws Exception {&#013;&#010;        StateTtlConfig ttlConfig = StateTtlConfig&#013;&#010;                .newBuilder(Time.minutes(30))&#013;&#010;                .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#013;&#010;                .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#013;&#010;                .build();&#013;&#010;&#013;&#010;        ListStateDescriptor&lt;String&amp;gt; lastUserLogin = new ListStateDescriptor&lt;&amp;gt;(\"lastUserLogin\",&#010;String.class);&#013;&#010;        lastUserLogin.enableTimeToLive(ttlConfig);&#013;&#010;        counts = getRuntimeContext().getListState(lastUserLogin);&#013;&#010;    }&#013;&#010;&#013;&#010;&#013;&#010;    @Override&#013;&#010;    public void flatMap(String s, Collector&lt;Test222&amp;gt; collector) throws Exception&#010;{&#013;&#010;            Test222 message = JSONUtil.toObject(s, new TypeReference&lt;Test222&amp;gt;()&#010;{&#013;&#010;            });&#013;&#010;&#013;&#010;            System.out.println(DateUtil.toLongDateString(new Date()));&#013;&#010;            log.info(DateUtil.toLongDateString(new Date()));&#013;&#010;            counts.add(message.getId());&#013;&#010;            List&lt;String&amp;gt; list = Lists.newArrayList(counts.get()) ;&#013;&#010;            for(String ss : list){&#013;&#010;                System.out.println(\"!!!\" + ss);&#013;&#010;                log.info(\"!!!\" + ss);&#013;&#010;            }&#013;&#010;              log.info(DateUtil.toLongDateString(new Date()));&#013;&#010;            System.out.println(DateUtil.toLongDateString(new Date()));&#013;&#010;    }&#013;&#010;}&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;qcx978132955@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ16æ—¥(æ˜ŸæœŸå››) æ™šä¸Š8:16&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: stateæ— æ³•ä»checkpointä¸­æ¢å¤&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Hi&#013;&#010;&#013;&#010;1 counts çš„æ•°æ®ä¸¢å¤±äº†èƒ½å¦è¯¦ç»†æè¿°ä¸€ä¸‹å‘¢ï¼Ÿä½ é¢„æœŸæ˜¯ä»€ä¹ˆï¼Œçœ‹åˆ°ä»€ä¹ˆç°è±¡&#013;&#010;2 èƒ½å¦æŠŠä½ å…³äº counts çš„å…¶ä»–ä»£ç ä¹Ÿè´´ä¸€ä¸‹&#013;&#010;3. ä½ çš„ä½œä¸šæ˜¯å¦ä» checkpoint æ¢å¤äº†å‘¢ï¼Ÿè¿™ä¸ªå¯ä»¥ä» JM log æ¥æŸ¥çœ‹&#013;&#010;4. å¦‚æœä½ ç¡®å®šæ˜¯æ•°æ®æœ‰ä¸¢å¤±çš„è¯ï¼Œæˆ–è®¸ä½ å¯ä»¥ä½¿ç”¨ state-process-api[1] çœ‹ä¸€ä¸‹æ˜¯åºåˆ—åŒ–å‡ºå»æœ‰é—®é¢˜ï¼Œè¿˜æ˜¯&#010;restore å›æ¥æœ‰é—®é¢˜&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/state_processor_api.html&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;sun &lt;1392427699@qq.com&amp;gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:16å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; é…ç½®ä»£ç env.enableCheckpointing(1000);env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&#013;&#010;&amp;gt; //ä½œä¸šå¤±è´¥åä¸é‡å¯&#013;&#010;&amp;gt; env.setRestartStrategy(RestartStrategies.noRestart());&#013;&#010;&amp;gt; env.getCheckpointConfig().setCheckpointTimeout(500);&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#013;&#010;&amp;gt; env.setStateBackend(new&#013;&#010;&amp;gt; RocksDBStateBackend(\"file:///opt/flink/flink-1.7.2/checkpoints\"));&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp; ä½¿ç”¨çŠ¶æ€çš„ä»£ç private transient ListState&lt;String&amp;amp;gt;&#010;counts;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; @Override&#013;&#010;&amp;gt; public void open(Configuration parameters) throws Exception {&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; StateTtlConfig ttlConfig = StateTtlConfig&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.newBuilder(Time.minutes(30))&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.build();&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ListStateDescriptor&lt;String&amp;amp;gt;&#010;lastUserLogin = new&#013;&#010;&amp;gt; ListStateDescriptor&lt;&amp;amp;gt;(\"lastUserLogin\", String.class);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; lastUserLogin.enableTimeToLive(ttlConfig);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; counts = getRuntimeContext().getListState(lastUserLogin);&#013;&#010;&amp;gt; }&#013;&#010;&amp;gt; æˆ‘é‡å¯äº†task managers åã€‚å‘ç°&amp;nbsp; counts&amp;nbsp; é‡Œé¢çš„æ•°æ®éƒ½ä¸¢å¤±äº†",
        "depth": "2",
        "reply": "<tencent_A102A9D2E3D31E32955A7C7454B611B33409@qq.com>"
    },
    {
        "id": "<CAA8tFvtfLPy1wHu8pzta_fo7eUM2F=PHBGt0hqubNq4qjbi0pg@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 14:58:17 GMT",
        "subject": "Re: stateæ— æ³•ä»checkpointä¸­æ¢å¤",
        "content": "Hi&#010;&#010;1 ä½ éœ€è¦å›å¤ä¸€ä¸‹æˆ‘ä¹‹å‰é—®ä½ çš„é—®é¢˜ï¼šä½ å¯ä»¥ä» JM log çœ‹ä¸€ä¸‹æ˜¯å¦ä» checkpoint&#010;æ¢å¤äº†&#010;2. è¿™é‡Œæ²¡æœ‰æ‰“å°åªæ˜¯è¡¨æ˜å½“å‰å¤„ç†çš„ key æ²¡æœ‰ state æ•°æ®ï¼Œå¹¶ä¸èƒ½è¡¨ç¤º&#010;state æ²¡æœ‰æ¢å¤å›æ¥ï¼Œstate å€¼æ˜¯ç»‘å®šåˆ°æŸä¸ª key&#010;ä¸Šçš„ï¼ˆkeyby çš„ keyï¼‰&#010;&#010;Best,&#010;Congxian&#010;&#010;&#010;sun &lt;1392427699@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:22å†™é“ï¼š&#010;&#010;&gt; ä½ å¥½ï¼šcounts çš„æ•°æ® æˆ‘æ˜¯åœ¨ä¸‹é¢æ‰“å°å‡ºæ¥äº† List&lt;String&amp;gt; list&#010;=&#010;&gt; Lists.newArrayList(counts.get()) ;&#010;&gt;             for(String ss : list){&#010;&gt;                 System.out.println(\"!!!\" + ss);&#010;&gt;                 log.info(\"!!!\" + ss);&#010;&gt;             }ï¼Œä½†æ˜¯æˆ‘é‡å¯æœåŠ¡ä¹‹åï¼Œä¹‹å‰å­˜çš„é‚£äº›å†…å®¹æ‰“å°ä¸å‡ºæ¥äº†ã€‚&#010;&gt; @Slf4j&#010;&gt; public class FlatMapTestState extends RichFlatMapFunction&lt;String,&#010;&gt; Test222&amp;gt; {&#010;&gt;&#010;&gt;&#010;&gt;     private transient ListState&lt;String&amp;gt; counts;&#010;&gt;&#010;&gt;&#010;&gt;     @Override&#010;&gt;     public void open(Configuration parameters) throws Exception {&#010;&gt;         StateTtlConfig ttlConfig = StateTtlConfig&#010;&gt;                 .newBuilder(Time.minutes(30))&#010;&gt;                 .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#010;&gt;&#010;&gt; .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#010;&gt;                 .build();&#010;&gt;&#010;&gt;         ListStateDescriptor&lt;String&amp;gt; lastUserLogin = new&#010;&gt; ListStateDescriptor&lt;&amp;gt;(\"lastUserLogin\", String.class);&#010;&gt;         lastUserLogin.enableTimeToLive(ttlConfig);&#010;&gt;         counts = getRuntimeContext().getListState(lastUserLogin);&#010;&gt;     }&#010;&gt;&#010;&gt;&#010;&gt;     @Override&#010;&gt;     public void flatMap(String s, Collector&lt;Test222&amp;gt; collector) throws&#010;&gt; Exception {&#010;&gt;             Test222 message = JSONUtil.toObject(s, new&#010;&gt; TypeReference&lt;Test222&amp;gt;() {&#010;&gt;             });&#010;&gt;&#010;&gt;             System.out.println(DateUtil.toLongDateString(new Date()));&#010;&gt;             log.info(DateUtil.toLongDateString(new Date()));&#010;&gt;             counts.add(message.getId());&#010;&gt;             List&lt;String&amp;gt; list = Lists.newArrayList(counts.get()) ;&#010;&gt;             for(String ss : list){&#010;&gt;                 System.out.println(\"!!!\" + ss);&#010;&gt;                 log.info(\"!!!\" + ss);&#010;&gt;             }&#010;&gt;               log.info(DateUtil.toLongDateString(new Date()));&#010;&gt;             System.out.println(DateUtil.toLongDateString(new Date()));&#010;&gt;     }&#010;&gt; }&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; ------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;&gt; å‘ä»¶äºº:&#010;&gt;                                                   \"user-zh\"&#010;&gt;                                                                     &lt;&#010;&gt; qcx978132955@gmail.com&amp;gt;;&#010;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ16æ—¥(æ˜ŸæœŸå››) æ™šä¸Š8:16&#010;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&gt;&#010;&gt; ä¸»é¢˜:&amp;nbsp;Re: stateæ— æ³•ä»checkpointä¸­æ¢å¤&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; Hi&#010;&gt;&#010;&gt; 1 counts çš„æ•°æ®ä¸¢å¤±äº†èƒ½å¦è¯¦ç»†æè¿°ä¸€ä¸‹å‘¢ï¼Ÿä½ é¢„æœŸæ˜¯ä»€ä¹ˆï¼Œçœ‹åˆ°ä»€ä¹ˆç°è±¡&#010;&gt; 2 èƒ½å¦æŠŠä½ å…³äº counts çš„å…¶ä»–ä»£ç ä¹Ÿè´´ä¸€ä¸‹&#010;&gt; 3. ä½ çš„ä½œä¸šæ˜¯å¦ä» checkpoint æ¢å¤äº†å‘¢ï¼Ÿè¿™ä¸ªå¯ä»¥ä» JM log æ¥æŸ¥çœ‹&#010;&gt; 4. å¦‚æœä½ ç¡®å®šæ˜¯æ•°æ®æœ‰ä¸¢å¤±çš„è¯ï¼Œæˆ–è®¸ä½ å¯ä»¥ä½¿ç”¨ state-process-api[1]&#010;çœ‹ä¸€ä¸‹æ˜¯åºåˆ—åŒ–å‡ºå»æœ‰é—®é¢˜ï¼Œè¿˜æ˜¯ restore å›æ¥æœ‰é—®é¢˜&#010;&gt;&#010;&gt; [1]&#010;&gt;&#010;&gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/state_processor_api.html&#010;&gt; Best,&#010;&gt; Congxian&#010;&gt;&#010;&gt;&#010;&gt; sun &lt;1392427699@qq.com&amp;gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:16å†™é“ï¼š&#010;&gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; é…ç½®ä»£ç env.enableCheckpointing(1000);env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&#010;&gt; &amp;gt; //ä½œä¸šå¤±è´¥åä¸é‡å¯&#010;&gt; &amp;gt; env.setRestartStrategy(RestartStrategies.noRestart());&#010;&gt; &amp;gt; env.getCheckpointConfig().setCheckpointTimeout(500);&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#010;&gt; &amp;gt; env.setStateBackend(new&#010;&gt; &amp;gt; RocksDBStateBackend(\"file:///opt/flink/flink-1.7.2/checkpoints\"));&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp; ä½¿ç”¨çŠ¶æ€çš„ä»£ç private transient ListState&lt;String&amp;amp;gt;&#010;counts;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; @Override&#010;&gt; &amp;gt; public void open(Configuration parameters) throws Exception {&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; StateTtlConfig ttlConfig = StateTtlConfig&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&gt; .newBuilder(Time.minutes(30))&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&gt; .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&gt; .build();&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ListStateDescriptor&lt;String&amp;amp;gt;&#010;&gt; lastUserLogin = new&#010;&gt; &amp;gt; ListStateDescriptor&lt;&amp;amp;gt;(\"lastUserLogin\", String.class);&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; lastUserLogin.enableTimeToLive(ttlConfig);&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; counts =&#010;&gt; getRuntimeContext().getListState(lastUserLogin);&#010;&gt; &amp;gt; }&#010;&gt; &amp;gt; æˆ‘é‡å¯äº†task managers åã€‚å‘ç°&amp;nbsp; counts&amp;nbsp; é‡Œé¢çš„æ•°æ®éƒ½ä¸¢å¤±äº†&#010;&#010;",
        "depth": "3",
        "reply": "<tencent_A102A9D2E3D31E32955A7C7454B611B33409@qq.com>"
    },
    {
        "id": "<tencent_A3A5CFA5D56636B4C4E8E86CD366D905860A@qq.com>",
        "from": "&quot;sun&quot; &lt;1392427...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 10:13:32 GMT",
        "subject": "å›å¤ï¼š stateæ— æ³•ä»checkpointä¸­æ¢å¤",
        "content": "JMæ—¥å¿—æœ‰ç‚¹ä¸ç†Ÿæ‚‰ï¼Œä¸çŸ¥é“æ˜¯å¦ä» checkpoint æ¢å¤äº†&#013;&#010;&#013;&#010;&#013;&#010;18:08:07.615 [Checkpoint Timer] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Triggering checkpoint 116 @ 1595239687615 for job acd456ff6f2f9f59ee89b126503c20f0.&#013;&#010;18:08:07.628 [flink-akka.actor.default-dispatcher-420] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Completed checkpoint 116 for job acd456ff6f2f9f59ee89b126503c20f0 (74305 bytes in 13 ms).&#013;&#010;18:08:08.615 [Checkpoint Timer] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Triggering checkpoint 117 @ 1595239688615 for job acd456ff6f2f9f59ee89b126503c20f0.&#013;&#010;18:08:08.626 [flink-akka.actor.default-dispatcher-420] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Completed checkpoint 117 for job acd456ff6f2f9f59ee89b126503c20f0 (74305 bytes in 11 ms).&#013;&#010;18:08:09.354 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Job ty-bi-flink (acd456ff6f2f9f59ee89b126503c20f0) switched from state RUNNING to CANCELLING.&#013;&#010;18:08:09.354 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (1/4) (4d8a61b0a71ff37d1e7d7da578878e55) switched from RUNNING to&#010;CANCELING.&#013;&#010;18:08:09.354 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (2/4) (97909ed1fcf34f658a3b6d9b3e8ee412) switched from RUNNING to&#010;CANCELING.&#013;&#010;18:08:09.354 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (3/4) (7be70346e0c7fc8f2b2224ca3a0907f0) switched from RUNNING to&#010;CANCELING.&#013;&#010;18:08:09.354 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (4/4) (4df2905ee56b06d9fc384e4beb228015) switched from RUNNING to&#010;CANCELING.&#013;&#010;18:08:09.355 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (1/4) (87d4c7af7d5fb5f81bae48aae77de473)&#010;switched from RUNNING to CANCELING.&#013;&#010;18:08:09.355 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (2/4) (7dfdd54faf11bc364fb6afc3dfdfb4dd)&#010;switched from RUNNING to CANCELING.&#013;&#010;18:08:09.355 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (3/4) (9035e059e465b8c520edf37ec734b43e)&#010;switched from RUNNING to CANCELING.&#013;&#010;18:08:09.355 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (4/4) (e6ff47b0da505b2aa4d775d7821b8356)&#010;switched from RUNNING to CANCELING.&#013;&#010;18:08:09.377 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (4/4) (e6ff47b0da505b2aa4d775d7821b8356)&#010;switched from CANCELING to CANCELED.&#013;&#010;18:08:09.377 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (3/4) (9035e059e465b8c520edf37ec734b43e)&#010;switched from CANCELING to CANCELED.&#013;&#010;18:08:09.378 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (2/4) (7dfdd54faf11bc364fb6afc3dfdfb4dd)&#010;switched from CANCELING to CANCELED.&#013;&#010;18:08:09.378 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (1/4) (87d4c7af7d5fb5f81bae48aae77de473)&#010;switched from CANCELING to CANCELED.&#013;&#010;18:08:09.378 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (1/4) (4d8a61b0a71ff37d1e7d7da578878e55) switched from CANCELING to&#010;CANCELED.&#013;&#010;18:08:09.379 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (2/4) (97909ed1fcf34f658a3b6d9b3e8ee412) switched from CANCELING to&#010;CANCELED.&#013;&#010;18:08:09.379 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (3/4) (7be70346e0c7fc8f2b2224ca3a0907f0) switched from CANCELING to&#010;CANCELED.&#013;&#010;18:08:09.381 [flink-akka.actor.default-dispatcher-416] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (4/4) (4df2905ee56b06d9fc384e4beb228015) switched from CANCELING to&#010;CANCELED.&#013;&#010;18:08:09.381 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Job ty-bi-flink (acd456ff6f2f9f59ee89b126503c20f0) switched from state CANCELLING to CANCELED.&#013;&#010;18:08:09.381 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Stopping checkpoint coordinator for job acd456ff6f2f9f59ee89b126503c20f0.&#013;&#010;18:08:09.381 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; o.a.f.runtime.checkpoint.StandaloneCompletedCheckpointStore&amp;nbsp;&#010;- Shutting down&#013;&#010;18:08:09.381 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CompletedCheckpoint&amp;nbsp;&#010;- Checkpoint with ID 117 at 'file:/opt/flink/flink-1.7.2/checkpoints/acd456ff6f2f9f59ee89b126503c20f0/chk-117'&#010;not discarded.&#013;&#010;18:08:09.382 [flink-akka.actor.default-dispatcher-427] INFO&amp;nbsp; org.apache.flink.runtime.dispatcher.StandaloneDispatcher&amp;nbsp;&#010;- Job acd456ff6f2f9f59ee89b126503c20f0 reached globally terminal state CANCELED.&#013;&#010;18:08:09.384 [flink-akka.actor.default-dispatcher-416] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Stopping the JobMaster for job ty-bi-flink(acd456ff6f2f9f59ee89b126503c20f0).&#013;&#010;18:08:09.385 [flink-akka.actor.default-dispatcher-416] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Close ResourceManager connection 7f7791cdc957a13cfaf639062c495fb9: JobManager is shutting&#010;down..&#013;&#010;18:08:09.385 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Suspending SlotPool.&#013;&#010;18:08:09.385 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Stopping SlotPool.&#013;&#010;18:08:09.385 [flink-akka.actor.default-dispatcher-416] INFO&amp;nbsp; o.a.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Disconnect job manager 00000000000000000000000000000000@akka.tcp://flink@rcx51101:6123/user/jobmanager_4&#010;for job acd456ff6f2f9f59ee89b126503c20f0 from the resource manager.&#013;&#010;18:08:09.385 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobManagerRunner&amp;nbsp;&#010;- JobManagerRunner already shutdown.&#013;&#010;18:08:33.384 [flink-rest-server-netty-worker-thread-4] WARN&amp;nbsp; org.apache.flink.runtime.webmonitor.handlers.JarRunHandler&amp;nbsp;&#010;- Configuring the job submission via query parameters is deprecated. Please migrate to submitting&#010;a JSON request instead.&#013;&#010;18:08:34.205 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.dispatcher.StandaloneDispatcher&amp;nbsp;&#010;- Submitting job 6dbecb3e4f536c2c92ca7931cba54fd2 (ty-bi-flink).&#013;&#010;18:08:34.205 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.rpc.akka.AkkaRpcService&amp;nbsp;&#010;- Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_5&#010;.&#013;&#010;18:08:34.206 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Initializing job ty-bi-flink (6dbecb3e4f536c2c92ca7931cba54fd2).&#013;&#010;18:08:34.206 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Using restart strategy NoRestartStrategy for ty-bi-flink (6dbecb3e4f536c2c92ca7931cba54fd2).&#013;&#010;18:08:34.206 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.rpc.akka.AkkaRpcService&amp;nbsp;&#010;- Starting RPC endpoint for org.apache.flink.runtime.jobmaster.slotpool.SlotPool at akka://flink/user/c8a89ca4-afcc-41c0-b121-bbfe4354e502&#010;.&#013;&#010;18:08:34.206 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Job recovers via failover strategy: full graph restart&#013;&#010;18:08:34.206 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Running initialization on master for job ty-bi-flink (6dbecb3e4f536c2c92ca7931cba54fd2).&#013;&#010;18:08:34.206 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Successfully ran initialization on master in 0 ms.&#013;&#010;18:08:34.207 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Using application-defined state backend: RocksDBStateBackend{checkpointStreamBackend=File&#010;State Backend (checkpoints: 'file:/opt/flink/flink-1.7.2/checkpoints', savepoints: 'null',&#010;asynchronous: UNDEFINED, fileStateThreshold: -1), localRocksDbDirectories=null, enableIncrementalCheckpointing=UNDEFINED}&#013;&#010;18:08:34.207 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Configuring application-defined state backend with job/cluster config&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobManagerRunner&amp;nbsp;&#010;- JobManager runner for job ty-bi-flink (6dbecb3e4f536c2c92ca7931cba54fd2) was granted leadership&#010;with session id 00000000-0000-0000-0000-000000000000 at akka.tcp://flink@rcx51101:6123/user/jobmanager_5.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Starting execution of job ty-bi-flink (6dbecb3e4f536c2c92ca7931cba54fd2)&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Job ty-bi-flink (6dbecb3e4f536c2c92ca7931cba54fd2) switched from state CREATED to RUNNING.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (1/4) (c06f0e753f644bdbcfe50cc8d2364cf6) switched from CREATED to&#010;SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (2/4) (5436dd5759d18472fcf171f5df9d9bc9) switched from CREATED to&#010;SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (3/4) (2a8cf04be945d59a70a3d82f50b38cd6) switched from CREATED to&#010;SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (4/4) (9797fe0ec397922dff0c8bde4fb89ba2) switched from CREATED to&#010;SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (1/4) (4127cdcd8ad7bd2011b7f8a8330663b9)&#010;switched from CREATED to SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (2/4) (c0e50cbfbab0b29973cc517056f3f561)&#010;switched from CREATED to SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (3/4) (989517f5535736062e6ce870e30742ee)&#010;switched from CREATED to SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (4/4) (eaf47a632d3e735f1341e1d6d4ec7b7f)&#010;switched from CREATED to SCHEDULED.&#013;&#010;18:08:34.208 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Connecting to ResourceManager akka.tcp://flink@rcx51101:6123/user/resourcemanager(00000000000000000000000000000000)&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{092c50cc73f659cbca805205e07b239c}]&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{16e0d6c68cbbf62c056758903c129661}]&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f727b58cc9c5abe1627216c5973f98b5}]&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bb8a60407b3fa9329ccc1ae8454bf239}]&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Resolved ResourceManager address, beginning registration&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- Registration at ResourceManager attempt 1 (timeout=100ms)&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; o.a.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Registering job manager 00000000000000000000000000000000@akka.tcp://flink@rcx51101:6123/user/jobmanager_5&#010;for job 6dbecb3e4f536c2c92ca7931cba54fd2.&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; o.a.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Registered job manager 00000000000000000000000000000000@akka.tcp://flink@rcx51101:6123/user/jobmanager_5&#010;for job 6dbecb3e4f536c2c92ca7931cba54fd2.&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-420] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.JobMaster&amp;nbsp;&#010;- JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.&#013;&#010;18:08:34.209 [flink-akka.actor.default-dispatcher-420] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Requesting new slot [SlotRequestId{bb8a60407b3fa9329ccc1ae8454bf239}] and profile ResourceProfile{cpuCores=-1.0,&#010;heapMemoryInMB=-1, directMemoryInMB=0, nativeMemoryInMB=0, networkMemoryInMB=0} from resource&#010;manager.&#013;&#010;18:08:34.210 [flink-akka.actor.default-dispatcher-420] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Requesting new slot [SlotRequestId{f727b58cc9c5abe1627216c5973f98b5}] and profile ResourceProfile{cpuCores=-1.0,&#010;heapMemoryInMB=-1, directMemoryInMB=0, nativeMemoryInMB=0, networkMemoryInMB=0} from resource&#010;manager.&#013;&#010;18:08:34.210 [flink-akka.actor.default-dispatcher-415] INFO&amp;nbsp; o.a.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=0,&#010;nativeMemoryInMB=0, networkMemoryInMB=0} for job 6dbecb3e4f536c2c92ca7931cba54fd2 with allocation&#010;id AllocationID{db118025945481bba66b8ffa734e4202}.&#013;&#010;18:08:34.210 [flink-akka.actor.default-dispatcher-420] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Requesting new slot [SlotRequestId{16e0d6c68cbbf62c056758903c129661}] and profile ResourceProfile{cpuCores=-1.0,&#010;heapMemoryInMB=-1, directMemoryInMB=0, nativeMemoryInMB=0, networkMemoryInMB=0} from resource&#010;manager.&#013;&#010;18:08:34.210 [flink-akka.actor.default-dispatcher-420] INFO&amp;nbsp; org.apache.flink.runtime.jobmaster.slotpool.SlotPool&amp;nbsp;&#010;- Requesting new slot [SlotRequestId{092c50cc73f659cbca805205e07b239c}] and profile ResourceProfile{cpuCores=-1.0,&#010;heapMemoryInMB=-1, directMemoryInMB=0, nativeMemoryInMB=0, networkMemoryInMB=0} from resource&#010;manager.&#013;&#010;18:08:34.210 [flink-akka.actor.default-dispatcher-415] INFO&amp;nbsp; o.a.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=0,&#010;nativeMemoryInMB=0, networkMemoryInMB=0} for job 6dbecb3e4f536c2c92ca7931cba54fd2 with allocation&#010;id AllocationID{d5147bcc731a51f09bdb32e366d93b02}.&#013;&#010;18:08:34.210 [flink-akka.actor.default-dispatcher-415] INFO&amp;nbsp; o.a.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=0,&#010;nativeMemoryInMB=0, networkMemoryInMB=0} for job 6dbecb3e4f536c2c92ca7931cba54fd2 with allocation&#010;id AllocationID{14001529dd0d04ebbd169241cb59f918}.&#013;&#010;18:08:34.210 [flink-akka.actor.default-dispatcher-415] INFO&amp;nbsp; o.a.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=0,&#010;nativeMemoryInMB=0, networkMemoryInMB=0} for job 6dbecb3e4f536c2c92ca7931cba54fd2 with allocation&#010;id AllocationID{bb02373b91c626c6fde666512d5b62ed}.&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (1/4) (c06f0e753f644bdbcfe50cc8d2364cf6) switched from SCHEDULED to&#010;DEPLOYING.&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying Source: Custom Source (1/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (3/4) (2a8cf04be945d59a70a3d82f50b38cd6) switched from SCHEDULED to&#010;DEPLOYING.&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying Source: Custom Source (3/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (2/4) (5436dd5759d18472fcf171f5df9d9bc9) switched from SCHEDULED to&#010;DEPLOYING.&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying Source: Custom Source (2/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (4/4) (9797fe0ec397922dff0c8bde4fb89ba2) switched from SCHEDULED to&#010;DEPLOYING.&#013;&#010;18:08:34.219 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying Source: Custom Source (4/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.220 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (4/4) (eaf47a632d3e735f1341e1d6d4ec7b7f)&#010;switched from SCHEDULED to DEPLOYING.&#013;&#010;18:08:34.220 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (4/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.222 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (3/4) (989517f5535736062e6ce870e30742ee)&#010;switched from SCHEDULED to DEPLOYING.&#013;&#010;18:08:34.222 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (3/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.222 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (2/4) (c0e50cbfbab0b29973cc517056f3f561)&#010;switched from SCHEDULED to DEPLOYING.&#013;&#010;18:08:34.222 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (2/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.222 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (1/4) (4127cdcd8ad7bd2011b7f8a8330663b9)&#010;switched from SCHEDULED to DEPLOYING.&#013;&#010;18:08:34.222 [flink-akka.actor.default-dispatcher-378] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Deploying map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (1/4) (attempt #0) to rcx51102&#013;&#010;18:08:34.506 [Checkpoint Timer] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Checkpoint triggering task Source: Custom Source (1/4) of job 6dbecb3e4f536c2c92ca7931cba54fd2&#010;is not in state RUNNING but DEPLOYING instead. Aborting checkpoint.&#013;&#010;18:08:35.036 [flink-akka.actor.default-dispatcher-430] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (3/4) (989517f5535736062e6ce870e30742ee)&#010;switched from DEPLOYING to RUNNING.&#013;&#010;18:08:35.037 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (2/4) (c0e50cbfbab0b29973cc517056f3f561)&#010;switched from DEPLOYING to RUNNING.&#013;&#010;18:08:35.057 [flink-akka.actor.default-dispatcher-430] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (4/4) (eaf47a632d3e735f1341e1d6d4ec7b7f)&#010;switched from DEPLOYING to RUNNING.&#013;&#010;18:08:35.058 [flink-akka.actor.default-dispatcher-430] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- map_sub_order_detail -&amp;gt; Sink: Print to Std. Out (1/4) (4127cdcd8ad7bd2011b7f8a8330663b9)&#010;switched from DEPLOYING to RUNNING.&#013;&#010;18:08:35.069 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (4/4) (9797fe0ec397922dff0c8bde4fb89ba2) switched from DEPLOYING to&#010;RUNNING.&#013;&#010;18:08:35.070 [flink-akka.actor.default-dispatcher-430] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (1/4) (c06f0e753f644bdbcfe50cc8d2364cf6) switched from DEPLOYING to&#010;RUNNING.&#013;&#010;18:08:35.076 [flink-akka.actor.default-dispatcher-418] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (3/4) (2a8cf04be945d59a70a3d82f50b38cd6) switched from DEPLOYING to&#010;RUNNING.&#013;&#010;18:08:35.076 [flink-akka.actor.default-dispatcher-430] INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;- Source: Custom Source (2/4) (5436dd5759d18472fcf171f5df9d9bc9) switched from DEPLOYING to&#010;RUNNING.&#013;&#010;18:08:35.506 [Checkpoint Timer] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Triggering checkpoint 1 @ 1595239715506 for job 6dbecb3e4f536c2c92ca7931cba54fd2.&#013;&#010;18:08:35.530 [flink-akka.actor.default-dispatcher-430] INFO&amp;nbsp; org.apache.flink.runtime.checkpoint.CheckpointCoordinator&amp;nbsp;&#010;- Completed checkpoint 1 for job 6dbecb3e4f536c2c92ca7931cba54fd2 (74134 bytes in 24 ms).&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;qcx978132955@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:58&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: stateæ— æ³•ä»checkpointä¸­æ¢å¤&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Hi&#013;&#010;&#013;&#010;1 ä½ éœ€è¦å›å¤ä¸€ä¸‹æˆ‘ä¹‹å‰é—®ä½ çš„é—®é¢˜ï¼šä½ å¯ä»¥ä» JM log çœ‹ä¸€ä¸‹æ˜¯å¦ä» checkpoint&#010;æ¢å¤äº†&#013;&#010;2. è¿™é‡Œæ²¡æœ‰æ‰“å°åªæ˜¯è¡¨æ˜å½“å‰å¤„ç†çš„ key æ²¡æœ‰ state æ•°æ®ï¼Œå¹¶ä¸èƒ½è¡¨ç¤º&#010;state æ²¡æœ‰æ¢å¤å›æ¥ï¼Œstate å€¼æ˜¯ç»‘å®šåˆ°æŸä¸ª key&#013;&#010;ä¸Šçš„ï¼ˆkeyby çš„ keyï¼‰&#013;&#010;&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;sun &lt;1392427699@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:22å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; ä½ å¥½ï¼šcounts çš„æ•°æ® æˆ‘æ˜¯åœ¨ä¸‹é¢æ‰“å°å‡ºæ¥äº† List&lt;String&amp;amp;gt;&#010;list =&#013;&#010;&amp;gt; Lists.newArrayList(counts.get()) ;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;for(String ss : list){&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;System.out.println(\"!!!\" + ss);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;log.info(\"!!!\" + ss);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;}ï¼Œä½†æ˜¯æˆ‘é‡å¯æœåŠ¡ä¹‹åï¼Œä¹‹å‰å­˜çš„é‚£äº›å†…å®¹æ‰“å°ä¸å‡ºæ¥äº†ã€‚&#013;&#010;&amp;gt; @Slf4j&#013;&#010;&amp;gt; public class FlatMapTestState extends RichFlatMapFunction&lt;String,&#013;&#010;&amp;gt; Test222&amp;amp;gt; {&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; private transient ListState&lt;String&amp;amp;gt;&#010;counts;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; @Override&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; public void open(Configuration parameters)&#010;throws Exception {&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; StateTtlConfig&#010;ttlConfig = StateTtlConfig&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.newBuilder(Time.minutes(30))&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.build();&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ListStateDescriptor&lt;String&amp;amp;gt;&#010;lastUserLogin = new&#013;&#010;&amp;gt; ListStateDescriptor&lt;&amp;amp;gt;(\"lastUserLogin\", String.class);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; lastUserLogin.enableTimeToLive(ttlConfig);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; counts&#010;= getRuntimeContext().getListState(lastUserLogin);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; @Override&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; public void flatMap(String s, Collector&lt;Test222&amp;amp;gt;&#010;collector) throws&#013;&#010;&amp;gt; Exception {&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;Test222 message = JSONUtil.toObject(s, new&#013;&#010;&amp;gt; TypeReference&lt;Test222&amp;amp;gt;() {&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;});&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;System.out.println(DateUtil.toLongDateString(new Date()));&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;log.info(DateUtil.toLongDateString(new Date()));&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;counts.add(message.getId());&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;List&lt;String&amp;amp;gt; list = Lists.newArrayList(counts.get()) ;&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;for(String ss : list){&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;System.out.println(\"!!!\" + ss);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;log.info(\"!!!\" + ss);&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;}&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;log.info(DateUtil.toLongDateString(new Date()));&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;System.out.println(DateUtil.toLongDateString(new Date()));&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&#013;&#010;&amp;gt; }&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ------------------&amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;nbsp;------------------&#013;&#010;&amp;gt; å‘ä»¶äºº:&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;\"user-zh\"&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&lt;&#013;&#010;&amp;gt; qcx978132955@gmail.com&amp;amp;gt;;&#013;&#010;&amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ16æ—¥(æ˜ŸæœŸå››) æ™šä¸Š8:16&#013;&#010;&amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ä¸»é¢˜:&amp;amp;nbsp;Re: stateæ— æ³•ä»checkpointä¸­æ¢å¤&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Hi&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; 1 counts çš„æ•°æ®ä¸¢å¤±äº†èƒ½å¦è¯¦ç»†æè¿°ä¸€ä¸‹å‘¢ï¼Ÿä½ é¢„æœŸæ˜¯ä»€ä¹ˆï¼Œçœ‹åˆ°ä»€ä¹ˆç°è±¡&#013;&#010;&amp;gt; 2 èƒ½å¦æŠŠä½ å…³äº counts çš„å…¶ä»–ä»£ç ä¹Ÿè´´ä¸€ä¸‹&#013;&#010;&amp;gt; 3. ä½ çš„ä½œä¸šæ˜¯å¦ä» checkpoint æ¢å¤äº†å‘¢ï¼Ÿè¿™ä¸ªå¯ä»¥ä» JM log æ¥æŸ¥çœ‹&#013;&#010;&amp;gt; 4. å¦‚æœä½ ç¡®å®šæ˜¯æ•°æ®æœ‰ä¸¢å¤±çš„è¯ï¼Œæˆ–è®¸ä½ å¯ä»¥ä½¿ç”¨ state-process-api[1]&#010;çœ‹ä¸€ä¸‹æ˜¯åºåˆ—åŒ–å‡ºå»æœ‰é—®é¢˜ï¼Œè¿˜æ˜¯ restore å›æ¥æœ‰é—®é¢˜&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; [1]&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/state_processor_api.html&#013;&#010;&amp;gt; Best,&#013;&#010;&amp;gt; Congxian&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; sun &lt;1392427699@qq.com&amp;amp;gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:16å†™é“ï¼š&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; é…ç½®ä»£ç env.enableCheckpointing(1000);env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&#013;&#010;&amp;gt; &amp;amp;gt; //ä½œä¸šå¤±è´¥åä¸é‡å¯&#013;&#010;&amp;gt; &amp;amp;gt; env.setRestartStrategy(RestartStrategies.noRestart());&#013;&#010;&amp;gt; &amp;amp;gt; env.getCheckpointConfig().setCheckpointTimeout(500);&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#013;&#010;&amp;gt; &amp;amp;gt; env.setStateBackend(new&#013;&#010;&amp;gt; &amp;amp;gt; RocksDBStateBackend(\"file:///opt/flink/flink-1.7.2/checkpoints\"));&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp; ä½¿ç”¨çŠ¶æ€çš„ä»£ç private transient ListState&lt;String&amp;amp;amp;gt;&#010;counts;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; @Override&#013;&#010;&amp;gt; &amp;amp;gt; public void open(Configuration parameters) throws Exception {&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; StateTtlConfig&#010;ttlConfig = StateTtlConfig&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#013;&#010;&amp;gt; .newBuilder(Time.minutes(30))&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#013;&#010;&amp;gt; .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#013;&#010;&amp;gt; .build();&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; ListStateDescriptor&lt;String&amp;amp;amp;gt;&#013;&#010;&amp;gt; lastUserLogin = new&#013;&#010;&amp;gt; &amp;amp;gt; ListStateDescriptor&lt;&amp;amp;amp;gt;(\"lastUserLogin\", String.class);&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; lastUserLogin.enableTimeToLive(ttlConfig);&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; counts =&#013;&#010;&amp;gt; getRuntimeContext().getListState(lastUserLogin);&#013;&#010;&amp;gt; &amp;amp;gt; }&#013;&#010;&amp;gt; &amp;amp;gt; æˆ‘é‡å¯äº†task managers åã€‚å‘ç°&amp;amp;nbsp; counts&amp;amp;nbsp;&#010;é‡Œé¢çš„æ•°æ®éƒ½ä¸¢å¤±äº†",
        "depth": "4",
        "reply": "<tencent_A102A9D2E3D31E32955A7C7454B611B33409@qq.com>"
    },
    {
        "id": "<1df8caff.a185.1735f71eec4.Coremail.17610775726@163.com>",
        "from": "JasonLee &lt;17610775...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sat, 18 Jul 2020 01:02:49 GMT",
        "subject": "å›å¤ï¼šstateæ— æ³•ä»checkpointä¸­æ¢å¤",
        "content": "hi&#010;ä½ åœ¨UIä¸Šcheckpointé‚£é‡Œå¯ä»¥çœ‹åˆ°æ˜¯å¦ä»ä¸Šä¸€æ¬¡æˆåŠŸçš„checkpointæ¢å¤äº† å…ˆç¡®å®šä¸€ä¸‹è¿™ä¸ªé—®é¢˜&#010;&#010;&#010;| |&#010;JasonLee&#010;|&#010;|&#010;é‚®ç®±ï¼š17610775726@163.com&#010;|&#010;&#010;Signature is customized by Netease Mail Master&#010;&#010;åœ¨2020å¹´07æœˆ17æ—¥ 17:21ï¼Œsun å†™é“ï¼š&#010;ä½ å¥½ï¼šcounts çš„æ•°æ® æˆ‘æ˜¯åœ¨ä¸‹é¢æ‰“å°å‡ºæ¥äº† List&lt;String&amp;gt; list = Lists.newArrayList(counts.get())&#010;;&#010;           for(String ss : list){&#010;               System.out.println(\"!!!\" + ss);&#010;               log.info(\"!!!\" + ss);&#010;           }ï¼Œä½†æ˜¯æˆ‘é‡å¯æœåŠ¡ä¹‹åï¼Œä¹‹å‰å­˜çš„é‚£äº›å†…å®¹æ‰“å°ä¸å‡ºæ¥äº†ã€‚&#010;@Slf4j&#010;public class FlatMapTestState extends RichFlatMapFunction&lt;String, Test222&amp;gt; {&#010;&#010;&#010;   private transient ListState&lt;String&amp;gt; counts;&#010;&#010;&#010;   @Override&#010;   public void open(Configuration parameters) throws Exception {&#010;       StateTtlConfig ttlConfig = StateTtlConfig&#010;               .newBuilder(Time.minutes(30))&#010;               .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#010;               .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#010;               .build();&#010;&#010;       ListStateDescriptor&lt;String&amp;gt; lastUserLogin = new ListStateDescriptor&lt;&amp;gt;(\"lastUserLogin\",&#010;String.class);&#010;       lastUserLogin.enableTimeToLive(ttlConfig);&#010;       counts = getRuntimeContext().getListState(lastUserLogin);&#010;   }&#010;&#010;&#010;   @Override&#010;   public void flatMap(String s, Collector&lt;Test222&amp;gt; collector) throws Exception&#010;{&#010;           Test222 message = JSONUtil.toObject(s, new TypeReference&lt;Test222&amp;gt;() {&#010;           });&#010;&#010;           System.out.println(DateUtil.toLongDateString(new Date()));&#010;           log.info(DateUtil.toLongDateString(new Date()));&#010;           counts.add(message.getId());&#010;           List&lt;String&amp;gt; list = Lists.newArrayList(counts.get()) ;&#010;           for(String ss : list){&#010;               System.out.println(\"!!!\" + ss);&#010;               log.info(\"!!!\" + ss);&#010;           }&#010;             log.info(DateUtil.toLongDateString(new Date()));&#010;           System.out.println(DateUtil.toLongDateString(new Date()));&#010;   }&#010;}&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;qcx978132955@gmail.com&amp;gt;;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ16æ—¥(æ˜ŸæœŸå››) æ™šä¸Š8:16&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&#010;ä¸»é¢˜:&amp;nbsp;Re: stateæ— æ³•ä»checkpointä¸­æ¢å¤&#010;&#010;&#010;&#010;Hi&#010;&#010;1 counts çš„æ•°æ®ä¸¢å¤±äº†èƒ½å¦è¯¦ç»†æè¿°ä¸€ä¸‹å‘¢ï¼Ÿä½ é¢„æœŸæ˜¯ä»€ä¹ˆï¼Œçœ‹åˆ°ä»€ä¹ˆç°è±¡&#010;2 èƒ½å¦æŠŠä½ å…³äº counts çš„å…¶ä»–ä»£ç ä¹Ÿè´´ä¸€ä¸‹&#010;3. ä½ çš„ä½œä¸šæ˜¯å¦ä» checkpoint æ¢å¤äº†å‘¢ï¼Ÿè¿™ä¸ªå¯ä»¥ä» JM log æ¥æŸ¥çœ‹&#010;4. å¦‚æœä½ ç¡®å®šæ˜¯æ•°æ®æœ‰ä¸¢å¤±çš„è¯ï¼Œæˆ–è®¸ä½ å¯ä»¥ä½¿ç”¨ state-process-api[1] çœ‹ä¸€ä¸‹æ˜¯åºåˆ—åŒ–å‡ºå»æœ‰é—®é¢˜ï¼Œè¿˜æ˜¯&#010;restore å›æ¥æœ‰é—®é¢˜&#010;&#010;[1]&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/state_processor_api.html&#010;Best,&#010;Congxian&#010;&#010;&#010;sun &lt;1392427699@qq.com&amp;gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ6:16å†™é“ï¼š&#010;&#010;&amp;gt;&#010;&amp;gt; é…ç½®ä»£ç env.enableCheckpointing(1000);env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&#010;&amp;gt; //ä½œä¸šå¤±è´¥åä¸é‡å¯&#010;&amp;gt; env.setRestartStrategy(RestartStrategies.noRestart());&#010;&amp;gt; env.getCheckpointConfig().setCheckpointTimeout(500);&#010;&amp;gt;&#010;&amp;gt; env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&amp;gt;&#010;&amp;gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#010;&amp;gt; env.setStateBackend(new&#010;&amp;gt; RocksDBStateBackend(\"file:///opt/flink/flink-1.7.2/checkpoints\"));&#010;&amp;gt;&amp;nbsp;&amp;nbsp; ä½¿ç”¨çŠ¶æ€çš„ä»£ç private transient ListState&lt;String&amp;amp;gt;&#010;counts;&#010;&amp;gt;&#010;&amp;gt;&#010;&amp;gt; @Override&#010;&amp;gt; public void open(Configuration parameters) throws Exception {&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; StateTtlConfig ttlConfig = StateTtlConfig&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.newBuilder(Time.minutes(30))&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)&#010;&amp;gt;&#010;&amp;gt; .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;.build();&#010;&amp;gt;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ListStateDescriptor&lt;String&amp;amp;gt;&#010;lastUserLogin = new&#010;&amp;gt; ListStateDescriptor&lt;&amp;amp;gt;(\"lastUserLogin\", String.class);&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; lastUserLogin.enableTimeToLive(ttlConfig);&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; counts = getRuntimeContext().getListState(lastUserLogin);&#010;&amp;gt; }&#010;&amp;gt; æˆ‘é‡å¯äº†task managers åã€‚å‘ç°&amp;nbsp; counts&amp;nbsp; é‡Œé¢çš„æ•°æ®éƒ½ä¸¢å¤±äº†",
        "depth": "3",
        "reply": "<tencent_A102A9D2E3D31E32955A7C7454B611B33409@qq.com>"
    },
    {
        "id": "<33333f3f.4b95.1735732e0b7.Coremail.xiayongquan1011@163.com>",
        "from": "xyq &lt;xiayongquan1...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 10:36:58 GMT",
        "subject": "flink1.10å‡çº§åˆ°flink1.11 jarå†²çª",
        "content": "hello  å¤§å®¶å¥½&#010; æˆ‘åœ¨flinkç”±1.10å‡çº§åˆ°1.11è¿‡ç¨‹ä¸­é‡åˆ°å¦‚ä¸‹é—®é¢˜ï¼Œè¯·é—®æ˜¯å“ªä¸ªåŒ…å†²çªäº†ï¼ˆæœ¬åœ°å¯è·‘ï¼Œä¸Šæµ‹è¯•ç¯å¢ƒå°±æŠ¥é”™ï¼‰ï¼Œè°¢è°¢ï¼š&#010;&#010;&#010;Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected exception.&#010;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:329)&#010;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:535)&#010;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:301)&#010;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;... 11 more&#010;Caused by: java.io.IOException: Could not find class 'org.apache.flink.table.runtime.typeutils.BaseRowSerializer$BaseRowSerializerSnapshot'&#010;in classpath.&#010;at org.apache.flink.util.InstantiationUtil.resolveClassByName(InstantiationUtil.java:721)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil.readAndInstantiateSnapshotClass(TypeSerializerSnapshotSerializationUtil.java:84)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshot.readVersionedSnapshot(TypeSerializerSnapshot.java:163)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil$TypeSerializerSnapshotSerializationProxy.deserializeV2(TypeSerializerSnapshotSerializationUtil.java:179)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil$TypeSerializerSnapshotSerializationProxy.read(TypeSerializerSnapshotSerializationUtil.java:150)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(TypeSerializerSnapshotSerializationUtil.java:76)&#010;at org.apache.flink.runtime.state.KeyedBackendSerializationProxy.read(KeyedBackendSerializationProxy.java:145)&#010;at org.apache.flink.contrib.streaming.state.restore.AbstractRocksDBRestoreOperation.readMetaData(AbstractRocksDBRestoreOperation.java:187)&#010;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateMetaData(RocksDBFullRestoreOperation.java:180)&#010;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:167)&#010;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:270)&#010;... 15 more&#010;Caused by: java.lang.ClassNotFoundException: org.apache.flink.table.runtime.typeutils.BaseRowSerializer$BaseRowSerializerSnapshot&#010;at java.net.URLClassLoader.findClass(URLClassLoader.java:381)&#010;at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#010;at org.apache.flink.util.FlinkUserCodeClassLoader.loadClassWithoutExceptionHandling(FlinkUserCodeClassLoader.java:61)&#010;at org.apache.flink.util.FlinkUserCodeClassLoader.loadClass(FlinkUserCodeClassLoader.java:48)&#010;at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#010;at java.lang.Class.forName0(Native Method)&#010;at java.lang.Class.forName(Class.java:348)&#010;at org.apache.flink.util.InstantiationUtil.resolveClassByName(InstantiationUtil.java:718)&#010;&#010;",
        "depth": "0",
        "reply": "<33333f3f.4b95.1735732e0b7.Coremail.xiayongquan1011@163.com>"
    },
    {
        "id": "<50538910.2f38.1735b8023c6.Coremail.xiayongquan1011@163.com>",
        "from": "xyq  &lt;xiayongquan1...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 06:39:51 GMT",
        "subject": "Re:flink1.10å‡çº§åˆ°flink1.11 jarå†²çª",
        "content": "hello  å¤§å®¶å¥½  flinkç”±1.10å‡çº§åˆ°1.11&#010;ä»savepointå¤„æ¢å¤æ•°æ®æŠ¥é”™ï¼ˆè¿™ä¸ªæŠ¥é”™çš„æ˜¯flink sqlåŒæµjoinçš„ï¼Œå¸¦çŠ¶æ€ï¼Œå…¶ä»–çš„streamçš„å•æµç¨‹åºéƒ½å·²ç»ç…§å¸¸æ¢å¤ï¼‰&#010;è¯·å¤§å®¶å¸®å¿™æŒ‡å¯¼ä¸€ä¸‹ï¼Œè°¢è°¢ã€‚&#010;&#010;&#010;æŠ¥é”™å¦‚ä¸‹ï¼š&#010;&#010;org.apache.flink.client.program.ProgramInvocationException: The main method caused an error:&#010;org.apache.flink.runtime.concurrent.FutureUtils$RetryException: Could not complete the operation.&#010;Number of retries has been exhausted.&#010;at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;at java.security.AccessController.doPrivileged(Native Method)&#010;at javax.security.auth.Subject.doAs(Subject.java:422)&#010;at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1692)&#010;at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;Caused by: java.util.concurrent.ExecutionException: org.apache.flink.runtime.concurrent.FutureUtils$RetryException:&#010;Could not complete the operation. Number of retries has been exhausted.&#010;at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)&#010;at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)&#010;at org.apache.flink.client.program.StreamContextEnvironment.getJobExecutionResult(StreamContextEnvironment.java:116)&#010;at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:80)&#010;at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1699)&#010;at com.zhidao.bigdata.plat.dophin.streaming.warehouse.dwd.iotbind.etl.DwdBaseCarlifeTIotBindGeoManage.main(DwdBaseCarlifeTIotBindGeoManage.java:282)&#010;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;at java.lang.reflect.Method.invoke(Method.java:498)&#010;at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;... 11 more&#010;Caused by: org.apache.flink.runtime.concurrent.FutureUtils$RetryException: Could not complete&#010;the operation. Number of retries has been exhausted.&#010;at org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$8(FutureUtils.java:302)&#010;at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)&#010;at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)&#010;at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)&#010;at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)&#010;at org.apache.flink.runtime.rest.RestClient.lambda$submitRequest$1(RestClient.java:342)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:500)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:493)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:472)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:413)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:538)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:531)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:111)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:323)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:685)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)&#010;at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)&#010;at java.lang.Thread.run(Thread.java:748)&#010;Caused by: java.util.concurrent.CompletionException: org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannel$AnnotatedConnectException:&#010;Connection refused: vm-9-72-centos/10.2.9.72:40620&#010;at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)&#010;at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)&#010;at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:943)&#010;at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:926)&#010;... 19 more&#010;Caused by: org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannel$AnnotatedConnectException:&#010;Connection refused: vm-9-72-centos/10.2.9.72:40620&#010;Caused by: java.net.ConnectException: Connection refused&#010;at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)&#010;at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:336)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:685)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)&#010;at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)&#010;at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)&#010;at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)&#010;at java.lang.Thread.run(Thread.java:748)&#010;========================================================================&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;åœ¨ 2020-07-16 18:36:58ï¼Œ\"xyq\" &lt;xiayongquan1011@163.com&gt; å†™é“ï¼š&#010;&#010;hello  å¤§å®¶å¥½&#010; æˆ‘åœ¨flinkç”±1.10å‡çº§åˆ°1.11è¿‡ç¨‹ä¸­é‡åˆ°å¦‚ä¸‹é—®é¢˜ï¼Œè¯·é—®æ˜¯å“ªä¸ªåŒ…å†²çªäº†ï¼ˆæœ¬åœ°å¯è·‘ï¼Œä¸Šæµ‹è¯•ç¯å¢ƒå°±æŠ¥é”™ï¼‰ï¼Œè°¢è°¢ï¼š&#010;&#010;&#010;Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected exception.&#010;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:329)&#010;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:535)&#010;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:301)&#010;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;... 11 more&#010;Caused by: java.io.IOException: Could not find class 'org.apache.flink.table.runtime.typeutils.BaseRowSerializer$BaseRowSerializerSnapshot'&#010;in classpath.&#010;at org.apache.flink.util.InstantiationUtil.resolveClassByName(InstantiationUtil.java:721)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil.readAndInstantiateSnapshotClass(TypeSerializerSnapshotSerializationUtil.java:84)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshot.readVersionedSnapshot(TypeSerializerSnapshot.java:163)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil$TypeSerializerSnapshotSerializationProxy.deserializeV2(TypeSerializerSnapshotSerializationUtil.java:179)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil$TypeSerializerSnapshotSerializationProxy.read(TypeSerializerSnapshotSerializationUtil.java:150)&#010;at org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(TypeSerializerSnapshotSerializationUtil.java:76)&#010;at org.apache.flink.runtime.state.KeyedBackendSerializationProxy.read(KeyedBackendSerializationProxy.java:145)&#010;at org.apache.flink.contrib.streaming.state.restore.AbstractRocksDBRestoreOperation.readMetaData(AbstractRocksDBRestoreOperation.java:187)&#010;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateMetaData(RocksDBFullRestoreOperation.java:180)&#010;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:167)&#010;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:270)&#010;... 15 more&#010;Caused by: java.lang.ClassNotFoundException: org.apache.flink.table.runtime.typeutils.BaseRowSerializer$BaseRowSerializerSnapshot&#010;at java.net.URLClassLoader.findClass(URLClassLoader.java:381)&#010;at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#010;at org.apache.flink.util.FlinkUserCodeClassLoader.loadClassWithoutExceptionHandling(FlinkUserCodeClassLoader.java:61)&#010;at org.apache.flink.util.FlinkUserCodeClassLoader.loadClass(FlinkUserCodeClassLoader.java:48)&#010;at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#010;at java.lang.Class.forName0(Native Method)&#010;at java.lang.Class.forName(Class.java:348)&#010;at org.apache.flink.util.InstantiationUtil.resolveClassByName(InstantiationUtil.java:718)&#010;&#010;&#010;&#010;&#010;&#010;&#010; ",
        "depth": "1",
        "reply": "<33333f3f.4b95.1735732e0b7.Coremail.xiayongquan1011@163.com>"
    },
    {
        "id": "<tencent_34880706EFB502CA3B1289616C2514B27209@qq.com>",
        "from": "&quot;op&quot; &lt;520075...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 11:16:00 GMT",
        "subject": "flink stateé—®é¢˜",
        "content": "å¤§å®¶å¥½&amp;nbsp;&#013;&#010;æˆ‘æœ‰ä¸€ä¸ªå»é‡çš„éœ€æ±‚ï¼Œæƒ³èŠ‚çœå†…å­˜ç”¨çš„bloomfilterï¼Œä»£ç å¦‚ä¸‹ï¼š&#013;&#010; .keyBy(_._1).process(new KeyedProcessFunction[String,(String,String),String]() {&#013;&#010;  var state:ValueState[BloomFilter[CharSequence",
        "depth": "0",
        "reply": "<tencent_34880706EFB502CA3B1289616C2514B27209@qq.com>"
    },
    {
        "id": "<CAA8tFvuJZPivvna_TpbaVQJUJ2hwJSgQXfj78XnTy74ZGkkHGg@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 12:09:39 GMT",
        "subject": "Re: flink stateé—®é¢˜",
        "content": "Hi&#013;&#010;&#013;&#010;ä½ å¯ä»¥å°è¯•ç”¨ state-process-api[1] çœ‹ä¸€ä¸‹ savepoint ä¸­ state çš„å†…å®¹ï¼Œå…ˆç¼©å°ä¸€ä¸‹é—®é¢˜çš„èŒƒå›´ï¼Œå¦‚æœ&#013;&#010;savepoint ä¸­å°±æ²¡æœ‰äº†ï¼Œé‚£å°±æ˜¯åºåˆ—åŒ–åˆ° savepoint çš„æ—¶å€™å‡ºé”™äº†ï¼Œsavepoitn&#010;æ˜¯æœ‰çš„ï¼Œé‚£ä¹ˆå°±æ˜¯æ¢å¤çš„æ—¶å€™å‡ºé”™äº†ã€‚&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/state_processor_api.html&#013;&#010;&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;op &lt;520075694@qq.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ7:16å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; å¤§å®¶å¥½&amp;nbsp;&#013;&#010;&gt; æˆ‘æœ‰ä¸€ä¸ªå»é‡çš„éœ€æ±‚ï¼Œæƒ³èŠ‚çœå†…å­˜ç”¨çš„bloomfilterï¼Œä»£ç å¦‚ä¸‹ï¼š&#013;&#010;&gt;  .keyBy(_._1).process(new&#013;&#010;&gt; KeyedProcessFunction[String,(String,String),String]() {&#013;&#010;&gt;   var state:ValueState[BloomFilter[CharSequence",
        "depth": "1",
        "reply": "<tencent_34880706EFB502CA3B1289616C2514B27209@qq.com>"
    },
    {
        "id": "<CAHOPYeXWtwz+WkSAogV6h8hL4=TLe+qT40nYaBDN=_1gN9yfXA@mail.gmail.com>",
        "from": "&quot;Harold.Miao&quot; &lt;miaohong...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 11:43:18 GMT",
        "subject": "[sql-client] å¦‚ä½•ç»•è¿‡äº¤äº’å¼æ¨¡å¼å»åšddl",
        "content": "hi flink users&#013;&#010;&#013;&#010;ä¼—æ‰€å‘¨çŸ¥ï¼Œsql-client.shçš„éäº¤äº’æ¨¡å¼ä¸‹çš„-uæ˜¯ä¸æ”¯æŒddlçš„ï¼Œç°åœ¨æˆ‘ä»¬æ˜¯ç”¨ä»£ç æ¥è°ƒç”¨sql-client.shæ¥åšddlï¼Œ&#013;&#010;è¿™æ ·åœ¨äº¤äº’æ¨¡å¼å¦‚ä½•å»åšã€‚ é€šè¿‡hack sql clientä»£ç å¯ä»¥å®ç°ï¼Œä½†æ˜¯ä¸æ”¹ä»£ç çš„æƒ…å†µä¸‹æœ‰æ²¡æœ‰ä»€ä¹ˆæœ€ä½³å®è·µã€‚è°¢è°¢ï¼&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;&#013;&#010;Best Regards,&#013;&#010;Harold Miao&#013;&#010;",
        "depth": "0",
        "reply": "<CAHOPYeXWtwz+WkSAogV6h8hL4=TLe+qT40nYaBDN=_1gN9yfXA@mail.gmail.com>"
    },
    {
        "id": "<CAELO931uUbQN3DT3ozSAg3BEFLH9oMnNny+HWZj6b+rwyHOAcw@mail.gmail.com>",
        "from": "Jark Wu &lt;imj...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 10:40:31 GMT",
        "subject": "Re: [sql-client] å¦‚ä½•ç»•è¿‡äº¤äº’å¼æ¨¡å¼å»åšddl",
        "content": "Hi,&#013;&#010;&#013;&#010;ä½ æƒ³è¦çš„æ˜¯ç±»ä¼¼äº sql-client.sh -u çš„åŠŸèƒ½ï¼Œç›´æ¥é€šè¿‡å‘½ä»¤è¡Œå»æ‰§è¡Œ ddl æ˜¯ä¹ˆï¼Ÿéå¸¸æŠ±æ­‰ï¼Œç›®å‰è¿™æ˜¯ä¸æ”¯æŒçš„ã€‚&#013;&#010;ç¤¾åŒºçš„e2eæµ‹è¯•ç›®å‰ä¹Ÿæ˜¯é€šè¿‡ Java ä»£ç æ¥è°ƒç”¨ sql-client.sh æ¥å®ç°æ‰§è¡Œ ddl&#010;çš„ã€‚&#013;&#010;ä¸è¿‡ç¤¾åŒºæ˜¯æœ‰è®¡åˆ’æ”¯æŒ sql-client.sh æ‰§è¡Œä¸€ä¸ª sql æ–‡ä»¶çš„ï¼Œå¯ä»¥å…³æ³¨ä¸‹FLINK-12828.&#013;&#010;&#013;&#010;Best,&#013;&#010;Jark&#013;&#010;&#013;&#010;On Thu, 16 Jul 2020 at 19:43, Harold.Miao &lt;miaohonghit@gmail.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; hi flink users&#013;&#010;&gt;&#013;&#010;&gt; ä¼—æ‰€å‘¨çŸ¥ï¼Œsql-client.shçš„éäº¤äº’æ¨¡å¼ä¸‹çš„-uæ˜¯ä¸æ”¯æŒddlçš„ï¼Œç°åœ¨æˆ‘ä»¬æ˜¯ç”¨ä»£ç æ¥è°ƒç”¨sql-client.shæ¥åšddlï¼Œ&#013;&#010;&gt; è¿™æ ·åœ¨äº¤äº’æ¨¡å¼å¦‚ä½•å»åšã€‚ é€šè¿‡hack sql clientä»£ç å¯ä»¥å®ç°ï¼Œä½†æ˜¯ä¸æ”¹ä»£ç çš„æƒ…å†µä¸‹æœ‰æ²¡æœ‰ä»€ä¹ˆæœ€ä½³å®è·µã€‚è°¢è°¢ï¼&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; --&#013;&#010;&gt;&#013;&#010;&gt; Best Regards,&#013;&#010;&gt; Harold Miao&#013;&#010;&gt;&#013;&#010;",
        "depth": "1",
        "reply": "<CAHOPYeXWtwz+WkSAogV6h8hL4=TLe+qT40nYaBDN=_1gN9yfXA@mail.gmail.com>"
    },
    {
        "id": "<CAHOPYeV11ZU6xE6EUhNO8MqigSJrhD+iTnYVZpd3eTnLS1uYhg@mail.gmail.com>",
        "from": "&quot;Harold.Miao&quot; &lt;miaohong...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 12:34:57 GMT",
        "subject": "Re: [sql-client] å¦‚ä½•ç»•è¿‡äº¤äº’å¼æ¨¡å¼å»åšddl",
        "content": "è°¢è°¢  æˆ‘æš‚æ—¶è¿™æ ·æ”¹äº†ä¸€ä¸‹&#013;&#010;&#013;&#010;public boolean submitUpdate(String statement) {&#013;&#010;   terminal.writer().println(CliStrings.messageInfo(CliStrings.MESSAGE_WILL_EXECUTE).toAnsi());&#013;&#010;   terminal.writer().println(new AttributedString(statement).toString());&#013;&#010;   terminal.flush();&#013;&#010;&#013;&#010;   final Optional&lt;SqlCommandCall&gt; parsedStatement = parseCommand(statement);&#013;&#010;   // only support INSERT INTO/OVERWRITE&#013;&#010;   return parsedStatement.map(cmdCall -&gt; {&#013;&#010;      switch (cmdCall.command) {&#013;&#010;         case INSERT_INTO:&#013;&#010;         case INSERT_OVERWRITE:&#013;&#010;            return callInsert(cmdCall);&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;*         case CREATE_TABLE:            callDdl(cmdCall.operands[0],&#013;&#010;CliStrings.MESSAGE_TABLE_CREATED);            return true;*&#013;&#010;default:&#013;&#010;            printError(CliStrings.MESSAGE_UNSUPPORTED_SQL);&#013;&#010;            return false;&#013;&#010;      }&#013;&#010;   }).orElse(false);&#013;&#010;}&#013;&#010;&#013;&#010;&#013;&#010;Jark Wu &lt;imjark@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ6:41å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; Hi,&#013;&#010;&gt;&#013;&#010;&gt; ä½ æƒ³è¦çš„æ˜¯ç±»ä¼¼äº sql-client.sh -u çš„åŠŸèƒ½ï¼Œç›´æ¥é€šè¿‡å‘½ä»¤è¡Œå»æ‰§è¡Œ&#010;ddl æ˜¯ä¹ˆï¼Ÿéå¸¸æŠ±æ­‰ï¼Œç›®å‰è¿™æ˜¯ä¸æ”¯æŒçš„ã€‚&#013;&#010;&gt; ç¤¾åŒºçš„e2eæµ‹è¯•ç›®å‰ä¹Ÿæ˜¯é€šè¿‡ Java ä»£ç æ¥è°ƒç”¨ sql-client.sh æ¥å®ç°æ‰§è¡Œ&#010;ddl çš„ã€‚&#013;&#010;&gt; ä¸è¿‡ç¤¾åŒºæ˜¯æœ‰è®¡åˆ’æ”¯æŒ sql-client.sh æ‰§è¡Œä¸€ä¸ª sql æ–‡ä»¶çš„ï¼Œå¯ä»¥å…³æ³¨ä¸‹FLINK-12828.&#013;&#010;&gt;&#013;&#010;&gt; Best,&#013;&#010;&gt; Jark&#013;&#010;&gt;&#013;&#010;&gt; On Thu, 16 Jul 2020 at 19:43, Harold.Miao &lt;miaohonghit@gmail.com&gt; wrote:&#013;&#010;&gt;&#013;&#010;&gt; &gt; hi flink users&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; ä¼—æ‰€å‘¨çŸ¥ï¼Œsql-client.shçš„éäº¤äº’æ¨¡å¼ä¸‹çš„-uæ˜¯ä¸æ”¯æŒddlçš„ï¼Œç°åœ¨æˆ‘ä»¬æ˜¯ç”¨ä»£ç æ¥è°ƒç”¨sql-client.shæ¥åšddlï¼Œ&#013;&#010;&gt; &gt; è¿™æ ·åœ¨äº¤äº’æ¨¡å¼å¦‚ä½•å»åšã€‚ é€šè¿‡hack sql clientä»£ç å¯ä»¥å®ç°ï¼Œä½†æ˜¯ä¸æ”¹ä»£ç çš„æƒ…å†µä¸‹æœ‰æ²¡æœ‰ä»€ä¹ˆæœ€ä½³å®è·µã€‚è°¢è°¢ï¼&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; --&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Best Regards,&#013;&#010;&gt; &gt; Harold Miao&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;&#013;&#010;Best Regards,&#013;&#010;Harold Miao&#013;&#010;",
        "depth": "2",
        "reply": "<CAHOPYeXWtwz+WkSAogV6h8hL4=TLe+qT40nYaBDN=_1gN9yfXA@mail.gmail.com>"
    },
    {
        "id": "<CADQYLGt8RTFtnw3gr2FwE9muDT2yGToj796SjPEXHeKpVUesew@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 12:35:01 GMT",
        "subject": "Re: [sql-client] å¦‚ä½•ç»•è¿‡äº¤äº’å¼æ¨¡å¼å»åšddl",
        "content": "sql-client.shçš„-uæ˜¯æŒ‡updateè¯­å¥ï¼Œç›®å‰åªæ”¯æŒinsertã€‚&#013;&#010;&#013;&#010;Jark Wu &lt;imjark@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ6:47å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; Hi,&#013;&#010;&gt;&#013;&#010;&gt; ä½ æƒ³è¦çš„æ˜¯ç±»ä¼¼äº sql-client.sh -u çš„åŠŸèƒ½ï¼Œç›´æ¥é€šè¿‡å‘½ä»¤è¡Œå»æ‰§è¡Œ&#010;ddl æ˜¯ä¹ˆï¼Ÿéå¸¸æŠ±æ­‰ï¼Œç›®å‰è¿™æ˜¯ä¸æ”¯æŒçš„ã€‚&#013;&#010;&gt; ç¤¾åŒºçš„e2eæµ‹è¯•ç›®å‰ä¹Ÿæ˜¯é€šè¿‡ Java ä»£ç æ¥è°ƒç”¨ sql-client.sh æ¥å®ç°æ‰§è¡Œ&#010;ddl çš„ã€‚&#013;&#010;&gt; ä¸è¿‡ç¤¾åŒºæ˜¯æœ‰è®¡åˆ’æ”¯æŒ sql-client.sh æ‰§è¡Œä¸€ä¸ª sql æ–‡ä»¶çš„ï¼Œå¯ä»¥å…³æ³¨ä¸‹FLINK-12828.&#013;&#010;&gt;&#013;&#010;&gt; Best,&#013;&#010;&gt; Jark&#013;&#010;&gt;&#013;&#010;&gt; On Thu, 16 Jul 2020 at 19:43, Harold.Miao &lt;miaohonghit@gmail.com&gt; wrote:&#013;&#010;&gt;&#013;&#010;&gt; &gt; hi flink users&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; ä¼—æ‰€å‘¨çŸ¥ï¼Œsql-client.shçš„éäº¤äº’æ¨¡å¼ä¸‹çš„-uæ˜¯ä¸æ”¯æŒddlçš„ï¼Œç°åœ¨æˆ‘ä»¬æ˜¯ç”¨ä»£ç æ¥è°ƒç”¨sql-client.shæ¥åšddlï¼Œ&#013;&#010;&gt; &gt; è¿™æ ·åœ¨äº¤äº’æ¨¡å¼å¦‚ä½•å»åšã€‚ é€šè¿‡hack sql clientä»£ç å¯ä»¥å®ç°ï¼Œä½†æ˜¯ä¸æ”¹ä»£ç çš„æƒ…å†µä¸‹æœ‰æ²¡æœ‰ä»€ä¹ˆæœ€ä½³å®è·µã€‚è°¢è°¢ï¼&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; --&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Best Regards,&#013;&#010;&gt; &gt; Harold Miao&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<CAHOPYeXWtwz+WkSAogV6h8hL4=TLe+qT40nYaBDN=_1gN9yfXA@mail.gmail.com>"
    },
    {
        "id": "<5fc1b77b.6099.173717fe87c.Coremail.zhanglianzhg@163.com>",
        "from": "zhanglianzhg  &lt;zhanglian...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 13:11:14 GMT",
        "subject": "Re:Re: [sql-client] å¦‚ä½•ç»•è¿‡äº¤äº’å¼æ¨¡å¼å»åšddl",
        "content": "çœ‹ä¸‹CliClient.javaæºç  openæ¥å£ï¼Œ&#010;final Optional&lt;SqlCommandCall&gt; cmdCall = parseCommand(line);&#010;cmdCall.ifPresent(this::callCommand);&#010;å¯ä»¥çœ‹å‡ºè§£æå­—ç¬¦ä¸²åæ‰§è¡Œå“åº”å‘½ä»¤ã€‚&#010;ç›®å‰æˆ‘ä»¬è¿™è¾¹ä¸€ä¸ªé¡¹ç›®ä¹Ÿåœ¨åšç›¸ä¼¼çš„ï¼Œå¯ä»¥ç•Œé¢å†™å¥½slqï¼Œä»¥åˆ†å·ä½œä¸ºåˆ†éš”ç¬¦è¡¨ç¤ºddlæˆ–åˆ™DMlä½œä¸ºåˆ†éš”ç¬¦ã€‚&#010;ç„¶åä»¥æ–‡ä»¶æ–¹å¼ä¿å­˜(å¯ä»¥ä½œä¸ºæ—¥å¿—ç­‰ç”¨ä½œ)ã€‚&#010;ç„¶åè‡ªå·±å®ç°ä¸€ä¸ªexcutorç±»åŒ…è£…äº†tableEnvironmentï¼Œä¸»è¦åŠŸèƒ½ç”¨ä½œstringå‘½ä»¤è§£æä»¥åŠå‘½ä»¤æ‰§è¡Œï¼Œå¯ä»¥ç®€å•çš„æŠŠflinkçš„è§£æä»¥åŠ&#010;callCommandæ‹¿è¿‡æ¥ï¼Œç„¶ååŠ ä»¥æ”¹é€ ï¼Œå†…éƒ¨æ”¯æŒddlã€dmlã€å‡½æ•°æ³¨å†Œç­‰ã€‚&#010;&#010;è¿™æ ·ä¸ç®¡åšä»€ä¹ˆtableæ“ä½œï¼Œåˆ›å»ºè¡¨æˆ–è€…æ³¨å†Œå‡½æ•°ã€æ‰§è¡Œæ“ä½œå‘½ä»¤ä¸€ä¸ªæ¥å£æå®šã€‚&#010;å…¶ä¸»è¦æ”¹åŠ¨æ˜¯ï¼šæ‰©å±•callCommandä»¥åŠSqlCommandCall&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;åœ¨ 2020-07-21 20:35:01ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#010;&gt;sql-client.shçš„-uæ˜¯æŒ‡updateè¯­å¥ï¼Œç›®å‰åªæ”¯æŒinsertã€‚&#010;&gt;&#010;&gt;Jark Wu &lt;imjark@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ6:47å†™é“ï¼š&#010;&gt;&#010;&gt;&gt; Hi,&#010;&gt;&gt;&#010;&gt;&gt; ä½ æƒ³è¦çš„æ˜¯ç±»ä¼¼äº sql-client.sh -u çš„åŠŸèƒ½ï¼Œç›´æ¥é€šè¿‡å‘½ä»¤è¡Œå»æ‰§è¡Œ&#010;ddl æ˜¯ä¹ˆï¼Ÿéå¸¸æŠ±æ­‰ï¼Œç›®å‰è¿™æ˜¯ä¸æ”¯æŒçš„ã€‚&#010;&gt;&gt; ç¤¾åŒºçš„e2eæµ‹è¯•ç›®å‰ä¹Ÿæ˜¯é€šè¿‡ Java ä»£ç æ¥è°ƒç”¨ sql-client.sh æ¥å®ç°æ‰§è¡Œ&#010;ddl çš„ã€‚&#010;&gt;&gt; ä¸è¿‡ç¤¾åŒºæ˜¯æœ‰è®¡åˆ’æ”¯æŒ sql-client.sh æ‰§è¡Œä¸€ä¸ª sql æ–‡ä»¶çš„ï¼Œå¯ä»¥å…³æ³¨ä¸‹FLINK-12828.&#010;&gt;&gt;&#010;&gt;&gt; Best,&#010;&gt;&gt; Jark&#010;&gt;&gt;&#010;&gt;&gt; On Thu, 16 Jul 2020 at 19:43, Harold.Miao &lt;miaohonghit@gmail.com&gt; wrote:&#010;&gt;&gt;&#010;&gt;&gt; &gt; hi flink users&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; ä¼—æ‰€å‘¨çŸ¥ï¼Œsql-client.shçš„éäº¤äº’æ¨¡å¼ä¸‹çš„-uæ˜¯ä¸æ”¯æŒddlçš„ï¼Œç°åœ¨æˆ‘ä»¬æ˜¯ç”¨ä»£ç æ¥è°ƒç”¨sql-client.shæ¥åšddlï¼Œ&#010;&gt;&gt; &gt; è¿™æ ·åœ¨äº¤äº’æ¨¡å¼å¦‚ä½•å»åšã€‚ é€šè¿‡hack sql clientä»£ç å¯ä»¥å®ç°ï¼Œä½†æ˜¯ä¸æ”¹ä»£ç çš„æƒ…å†µä¸‹æœ‰æ²¡æœ‰ä»€ä¹ˆæœ€ä½³å®è·µã€‚è°¢è°¢ï¼&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; --&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; Best Regards,&#010;&gt;&gt; &gt; Harold Miao&#010;&gt;&gt; &gt;&#010;&gt;&gt;&#010;",
        "depth": "3",
        "reply": "<CAHOPYeXWtwz+WkSAogV6h8hL4=TLe+qT40nYaBDN=_1gN9yfXA@mail.gmail.com>"
    },
    {
        "id": "<5D396283-1D2F-4AD2-BBF1-C5720758CAED@gmail.com>",
        "from": "å¾ç²Ÿ &lt;kevinbrandon202...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 12:01:41 GMT",
        "subject": "Fwd: ã€æ±‚åŠ©ã€‘flinkæ‰“åŒ…åˆ°é›†ç¾¤è¿è¡Œé—®é¢˜",
        "content": "&#013;&#010;&#013;&#010;&gt; ä¸‹é¢æ˜¯è¢«è½¬å‘çš„é‚®ä»¶ï¼š&#013;&#010;&gt; &#013;&#010;&gt; å‘ä»¶äºº: å¾ç²Ÿ &lt;kevinbrandon2020xu@gmail.com&gt;&#013;&#010;&gt; ä¸»é¢˜: ã€æ±‚åŠ©ã€‘flinkæ‰“åŒ…åˆ°é›†ç¾¤è¿è¡Œé—®é¢˜&#013;&#010;&gt; æ—¥æœŸ: 2020å¹´7æœˆ16æ—¥ GMT+8 ä¸‹åˆ7:51:06&#013;&#010;&gt; æ”¶ä»¶äºº: user-zh@flink.apache.org&#013;&#010;&gt; &#013;&#010;&gt; hi ï¼Œplease help me&#013;&#010;&gt; æˆ‘æ‰“åŒ…åˆ°é›†ç¾¤ä¹‹åï¼Œäº§ç”Ÿäº†å¦‚ä¸‹å›¾é”™è¯¯ã€‚&#013;&#010;&gt; flinkç‰ˆæœ¬æ˜¯1.10.1 jaråŒ…æ˜¯flnk-1.10.1-bin-scala_2.12.taz&#013;&#010;&gt; å‘½ä»¤åœ¨å›¾ç‰‡é‡Œé¢ã€‚thanks&#013;&#010;",
        "depth": "1",
        "reply": "<5D396283-1D2F-4AD2-BBF1-C5720758CAED@gmail.com>"
    },
    {
        "id": "<CAA8tFvtk05DafGzOzp8qkKLMASx+pHLcseqEi3vN+uAfNq31yg@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 12:13:09 GMT",
        "subject": "Re: ã€æ±‚åŠ©ã€‘flinkæ‰“åŒ…åˆ°é›†ç¾¤è¿è¡Œé—®é¢˜",
        "content": "Hi&#013;&#010;&#013;&#010;å›¾ç‰‡çš„æ–‡å­—å¤ªå°äº†ï¼Œå¯ä»¥çœ‹ä¸€ä¸‹è¿™ä¸ªé‚®ä»¶[1]ï¼Œåº”è¯¥æ˜¯ä¸€ä¸ªé—®é¢˜ï¼ŒæŒ‰ç†åœ¨&#010;google èƒ½å¤Ÿæœç´¢åˆ°è¿™ä¸ªé‚®ä»¶åˆ—è¡¨çš„&#013;&#010;&#013;&#010;[1]&#013;&#010;http://apache-flink.147419.n8.nabble.com/Could-not-find-a-suitable-table-factory-for-TableSourceFactory-td3287.html&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;å¾ç²Ÿ &lt;kevinbrandon2020xu@gmail.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ8:02å†™é“ï¼š&#013;&#010;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; ä¸‹é¢æ˜¯è¢«è½¬å‘çš„é‚®ä»¶ï¼š&#013;&#010;&gt;&#013;&#010;&gt; *å‘ä»¶äºº: *å¾ç²Ÿ &lt;kevinbrandon2020xu@gmail.com&gt;&#013;&#010;&gt; *ä¸»é¢˜: **ã€æ±‚åŠ©ã€‘flinkæ‰“åŒ…åˆ°é›†ç¾¤è¿è¡Œé—®é¢˜*&#013;&#010;&gt; *æ—¥æœŸ: *2020å¹´7æœˆ16æ—¥ GMT+8 ä¸‹åˆ7:51:06&#013;&#010;&gt; *æ”¶ä»¶äºº: *user-zh@flink.apache.org&#013;&#010;&gt;&#013;&#010;&gt; hi ï¼Œplease help me&#013;&#010;&gt; æˆ‘æ‰“åŒ…åˆ°é›†ç¾¤ä¹‹åï¼Œäº§ç”Ÿäº†å¦‚ä¸‹å›¾é”™è¯¯ã€‚&#013;&#010;&gt; flinkç‰ˆæœ¬æ˜¯1.10.1 jaråŒ…æ˜¯flnk-1.10.1-bin-scala_2.12.taz&#013;&#010;&gt; å‘½ä»¤åœ¨å›¾ç‰‡é‡Œé¢ã€‚thanks&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<5D396283-1D2F-4AD2-BBF1-C5720758CAED@gmail.com>"
    },
    {
        "id": "<1594901056880-0.post@n8.nabble.com>",
        "from": "æ›¹æ­¦ &lt;14701319...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 12:04:16 GMT",
        "subject": "flink 1.11 checkpointä½¿ç”¨",
        "content": "æˆ‘åœ¨ä½¿ç”¨flink 1.11.0ä¸­å¾—ddl éƒ¨åˆ† é‡‡ç”¨debezium-jsonåšcdcå¾—æ—¶å€™&#010;ä»checkpointæ¢å¤ä»¥å,æ–°æ¥op=dçš„æ•°æ®ä¼šåˆ é™¤å¤±è´¥&#010;é‡å¯å‘½ä»¤:./bin/flink run -m yarn-cluster  /root/bigdata-flink-1.0.jar -s&#010;hdfs://prehadoop01:8020/flink/checkpoints/4cc5df8b96e90c1c2a4d3719a77f51d1/chk-819/_metadata&#010;ä»£ç :   EnvironmentSettings settings = EnvironmentSettings.newInstance()&#010;                .useBlinkPlanner()&#010;                .inStreamingMode()&#010;                .build();&#010;&#010;        StreamExecutionEnvironment env =&#010;StreamExecutionEnvironment.getExecutionEnvironment();&#010;&#010;        env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#010;        env.getCheckpointConfig().setCheckpointTimeout(6000L); // è¶…æ—¶æ—¶é—´&#010;        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1); //&#010;æœ€å¤§å…è®¸åŒæ—¶å‡ºç°å‡ ä¸ªCheckPoint&#010;        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(10L); //&#010;æœ€å°å¾—é—´éš”æ—¶é—´&#010;        env.getCheckpointConfig().setPreferCheckpointForRecovery(true); //&#010;æ˜¯å¦å€¾å‘äºç”¨CheckPointåšæ•…éšœæ¢å¤&#010;        env.getCheckpointConfig().setTolerableCheckpointFailureNumber(1); //&#010;å®¹å¿å¤šå°‘æ¬¡CheckPointå¤±è´¥&#010;        //Checkpointæ–‡ä»¶æ¸…ç†ç­–ç•¥&#010;       &#010;env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#010;        //Checkpointå¤–éƒ¨æ–‡ä»¶è·¯å¾„&#010;        env.setStateBackend(new FsStateBackend(new&#010;URI(\"hdfs://172.22.20.205:8020/flink/checkpoints\"), false));&#010;TimeUnit.MINUTES), Time.of(10, TimeUnit.SECONDS)));&#010;        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env,&#010;settings);&#010;        String sourceDDL = String.format(&#010;                \"CREATE TABLE debezium_source (\" +&#010;                        \" id INT NOT NULL,\" +&#010;                        \" name STRING,\" +&#010;                        \" description STRING,\" +&#010;                        \" weight Double\" +&#010;                        \") WITH (\" +&#010;                        \" 'connector' = 'kafka-0.11',\" +&#010;                        \" 'topic' = '%s',\" +&#010;                        \" 'properties.bootstrap.servers' = '%s',\" +&#010;                        \" 'scan.startup.mode' = 'group-offsets',\" +&#010;                        \" 'format' = 'debezium-json'\" +&#010;                        \")\", \"ddd\", \" 172.22.20.206:9092\");&#010;        String sinkDDL = \"CREATE TABLE sink (\" +&#010;                \" id INT NOT NULL,\" +&#010;                \" name STRING,\" +&#010;                \" description STRING,\" +&#010;                \" weight Double,\" +&#010;                \" PRIMARY KEY (id,name, description,weight) NOT ENFORCED \" +&#010;                \") WITH (\" +&#010;                \" 'connector' = 'jdbc',\" +&#010;                \" 'url' =&#010;'jdbc:mysql://172.27.4.22:3306/test?autoReconnect=true',\" +&#010;                \" 'table-name' = 'products',\" +&#010;                \" 'driver'= 'com.mysql.cj.jdbc.Driver',\" +&#010;                \" 'username'='DataPip',\" +&#010;                \" 'password'='DataPip'\" +&#010;                \")\";&#010;        String dml = \"INSERT INTO sink SELECT  id,name ,description, weight&#010;FROM debezium_source GROUP BY id,name ,description, weight\";&#010;        tEnv.executeSql(sourceDDL);&#010;        tEnv.executeSql(sinkDDL);&#010;        tEnv.executeSql(dml);&#010;&#010;&#010;&#010;--&#010;Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&#010;",
        "depth": "0",
        "reply": "<1594901056880-0.post@n8.nabble.com>"
    },
    {
        "id": "<CADQYLGs6VbVNa5intYfA79=jtSdNp7CR4tnr=2VvJpZGW02kLA@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 13:55:30 GMT",
        "subject": "Re: flink 1.11 checkpointä½¿ç”¨",
        "content": "ä¸ºä»€ä¹ˆè¦ GROUP BY id,name ,description, weight ï¼Ÿ&#010;ç›´æ¥ \"INSERT INTO sink SELECT  id,name ,description, weight FROM&#010;debezium_source\" ä¸èƒ½æ»¡è¶³éœ€æ±‚ï¼Ÿ&#010;&#010;æ›¹æ­¦ &lt;14701319164@163.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ9:30å†™é“ï¼š&#010;&#010;&gt; æˆ‘åœ¨ä½¿ç”¨flink 1.11.0ä¸­å¾—ddl éƒ¨åˆ† é‡‡ç”¨debezium-jsonåšcdcå¾—æ—¶å€™&#010;&gt; ä»checkpointæ¢å¤ä»¥å,æ–°æ¥op=dçš„æ•°æ®ä¼šåˆ é™¤å¤±è´¥&#010;&gt; é‡å¯å‘½ä»¤:./bin/flink run -m yarn-cluster  /root/bigdata-flink-1.0.jar -s&#010;&gt;&#010;&gt; hdfs://prehadoop01:8020/flink/checkpoints/4cc5df8b96e90c1c2a4d3719a77f51d1/chk-819/_metadata&#010;&gt; ä»£ç :   EnvironmentSettings settings = EnvironmentSettings.newInstance()&#010;&gt;                 .useBlinkPlanner()&#010;&gt;                 .inStreamingMode()&#010;&gt;                 .build();&#010;&gt;&#010;&gt;         StreamExecutionEnvironment env =&#010;&gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt;&#010;&gt;         env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#010;&gt;         env.getCheckpointConfig().setCheckpointTimeout(6000L); // è¶…æ—¶æ—¶é—´&#010;&gt;         env.getCheckpointConfig().setMaxConcurrentCheckpoints(1); //&#010;&gt; æœ€å¤§å…è®¸åŒæ—¶å‡ºç°å‡ ä¸ªCheckPoint&#010;&gt;         env.getCheckpointConfig().setMinPauseBetweenCheckpoints(10L); //&#010;&gt; æœ€å°å¾—é—´éš”æ—¶é—´&#010;&gt;         env.getCheckpointConfig().setPreferCheckpointForRecovery(true); //&#010;&gt; æ˜¯å¦å€¾å‘äºç”¨CheckPointåšæ•…éšœæ¢å¤&#010;&gt;         env.getCheckpointConfig().setTolerableCheckpointFailureNumber(1);&#010;&gt; //&#010;&gt; å®¹å¿å¤šå°‘æ¬¡CheckPointå¤±è´¥&#010;&gt;         //Checkpointæ–‡ä»¶æ¸…ç†ç­–ç•¥&#010;&gt;&#010;&gt;&#010;&gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#010;&gt;         //Checkpointå¤–éƒ¨æ–‡ä»¶è·¯å¾„&#010;&gt;         env.setStateBackend(new FsStateBackend(new&#010;&gt; URI(\"hdfs://172.22.20.205:8020/flink/checkpoints\"), false));&#010;&gt; TimeUnit.MINUTES), Time.of(10, TimeUnit.SECONDS)));&#010;&gt;         StreamTableEnvironment tEnv = StreamTableEnvironment.create(env,&#010;&gt; settings);&#010;&gt;         String sourceDDL = String.format(&#010;&gt;                 \"CREATE TABLE debezium_source (\" +&#010;&gt;                         \" id INT NOT NULL,\" +&#010;&gt;                         \" name STRING,\" +&#010;&gt;                         \" description STRING,\" +&#010;&gt;                         \" weight Double\" +&#010;&gt;                         \") WITH (\" +&#010;&gt;                         \" 'connector' = 'kafka-0.11',\" +&#010;&gt;                         \" 'topic' = '%s',\" +&#010;&gt;                         \" 'properties.bootstrap.servers' = '%s',\" +&#010;&gt;                         \" 'scan.startup.mode' = 'group-offsets',\" +&#010;&gt;                         \" 'format' = 'debezium-json'\" +&#010;&gt;                         \")\", \"ddd\", \" 172.22.20.206:9092\");&#010;&gt;         String sinkDDL = \"CREATE TABLE sink (\" +&#010;&gt;                 \" id INT NOT NULL,\" +&#010;&gt;                 \" name STRING,\" +&#010;&gt;                 \" description STRING,\" +&#010;&gt;                 \" weight Double,\" +&#010;&gt;                 \" PRIMARY KEY (id,name, description,weight) NOT ENFORCED \"&#010;&gt; +&#010;&gt;                 \") WITH (\" +&#010;&gt;                 \" 'connector' = 'jdbc',\" +&#010;&gt;                 \" 'url' =&#010;&gt; 'jdbc:mysql://172.27.4.22:3306/test?autoReconnect=true',\" +&#010;&gt;                 \" 'table-name' = 'products',\" +&#010;&gt;                 \" 'driver'= 'com.mysql.cj.jdbc.Driver',\" +&#010;&gt;                 \" 'username'='DataPip',\" +&#010;&gt;                 \" 'password'='DataPip'\" +&#010;&gt;                 \")\";&#010;&gt;         String dml = \"INSERT INTO sink SELECT  id,name ,description, weight&#010;&gt; FROM debezium_source GROUP BY id,name ,description, weight\";&#010;&gt;         tEnv.executeSql(sourceDDL);&#010;&gt;         tEnv.executeSql(sinkDDL);&#010;&gt;         tEnv.executeSql(dml);&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; --&#010;&gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&gt;&#010;&#010;",
        "depth": "1",
        "reply": "<1594901056880-0.post@n8.nabble.com>"
    },
    {
        "id": "<CAELO930paSUy0dTSocZO6O7qZ-CdC9EX58Mf3sENupCw7FVfDg@mail.gmail.com>",
        "from": "Jark Wu &lt;imj...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 02:39:03 GMT",
        "subject": "Re: flink 1.11 checkpointä½¿ç”¨",
        "content": "Hi,&#010;&#010;èƒ½ç¡®è®¤ä¸€ä¸‹ kafka ä¸­æœ‰å®Œæ•´çš„å…¨é‡æ•°æ®å—ï¼Ÿ ä¹Ÿå°±æ˜¯ è¿™ä¸ª DELETE æ¶ˆæ¯ä¹‹å‰ï¼Œæœ‰å¯¹åº”çš„&#010;INSERT æ¶ˆæ¯å—ï¼Ÿ&#010;å¦‚æœæ²¡æœ‰çš„è¯ï¼Œæ˜¯å¯èƒ½ä¼šå‘ç”Ÿè¿™ä¸ªç°è±¡çš„ï¼ˆDELETE åœ¨ group by èŠ‚ç‚¹ä¼šè¢«è®¤ä¸ºè„æ•°æ®è€Œä¸¢æ‰ï¼‰ã€‚&#010;å½“ç„¶ä¹Ÿå¯ä»¥åƒ godfrey å»ºè®®çš„é‚£æ ·ï¼Œä¸ groupbyï¼Œç›´æ¥å…¨éƒ¨å­—æ®µ INSERT INTO&#010;sinkï¼ŒDELETE å°±ä¸ä¼šè¢«ä¸¢å¼ƒæ‰ã€‚&#010;&#010;Best,&#010;Jark&#010;&#010;On Thu, 16 Jul 2020 at 21:56, godfrey he &lt;godfreyhe@gmail.com&gt; wrote:&#010;&#010;&gt; ä¸ºä»€ä¹ˆè¦ GROUP BY id,name ,description, weight ï¼Ÿ&#010;&gt; ç›´æ¥ \"INSERT INTO sink SELECT  id,name ,description, weight FROM&#010;&gt; debezium_source\" ä¸èƒ½æ»¡è¶³éœ€æ±‚ï¼Ÿ&#010;&gt;&#010;&gt; æ›¹æ­¦ &lt;14701319164@163.com&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ9:30å†™é“ï¼š&#010;&gt;&#010;&gt; &gt; æˆ‘åœ¨ä½¿ç”¨flink 1.11.0ä¸­å¾—ddl éƒ¨åˆ† é‡‡ç”¨debezium-jsonåšcdcå¾—æ—¶å€™&#010;&gt; &gt; ä»checkpointæ¢å¤ä»¥å,æ–°æ¥op=dçš„æ•°æ®ä¼šåˆ é™¤å¤±è´¥&#010;&gt; &gt; é‡å¯å‘½ä»¤:./bin/flink run -m yarn-cluster  /root/bigdata-flink-1.0.jar -s&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; hdfs://prehadoop01:8020/flink/checkpoints/4cc5df8b96e90c1c2a4d3719a77f51d1/chk-819/_metadata&#010;&gt; &gt; ä»£ç :   EnvironmentSettings settings = EnvironmentSettings.newInstance()&#010;&gt; &gt;                 .useBlinkPlanner()&#010;&gt; &gt;                 .inStreamingMode()&#010;&gt; &gt;                 .build();&#010;&gt; &gt;&#010;&gt; &gt;         StreamExecutionEnvironment env =&#010;&gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt;&#010;&gt; &gt;         env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &gt;         env.getCheckpointConfig().setCheckpointTimeout(6000L); // è¶…æ—¶æ—¶é—´&#010;&gt; &gt;         env.getCheckpointConfig().setMaxConcurrentCheckpoints(1); //&#010;&gt; &gt; æœ€å¤§å…è®¸åŒæ—¶å‡ºç°å‡ ä¸ªCheckPoint&#010;&gt; &gt;         env.getCheckpointConfig().setMinPauseBetweenCheckpoints(10L); //&#010;&gt; &gt; æœ€å°å¾—é—´éš”æ—¶é—´&#010;&gt; &gt;         env.getCheckpointConfig().setPreferCheckpointForRecovery(true);&#010;&gt; //&#010;&gt; &gt; æ˜¯å¦å€¾å‘äºç”¨CheckPointåšæ•…éšœæ¢å¤&#010;&gt; &gt;         env.getCheckpointConfig().setTolerableCheckpointFailureNumber(1);&#010;&gt; &gt; //&#010;&gt; &gt; å®¹å¿å¤šå°‘æ¬¡CheckPointå¤±è´¥&#010;&gt; &gt;         //Checkpointæ–‡ä»¶æ¸…ç†ç­–ç•¥&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#010;&gt; &gt;         //Checkpointå¤–éƒ¨æ–‡ä»¶è·¯å¾„&#010;&gt; &gt;         env.setStateBackend(new FsStateBackend(new&#010;&gt; &gt; URI(\"hdfs://172.22.20.205:8020/flink/checkpoints\"), false));&#010;&gt; &gt; TimeUnit.MINUTES), Time.of(10, TimeUnit.SECONDS)));&#010;&gt; &gt;         StreamTableEnvironment tEnv = StreamTableEnvironment.create(env,&#010;&gt; &gt; settings);&#010;&gt; &gt;         String sourceDDL = String.format(&#010;&gt; &gt;                 \"CREATE TABLE debezium_source (\" +&#010;&gt; &gt;                         \" id INT NOT NULL,\" +&#010;&gt; &gt;                         \" name STRING,\" +&#010;&gt; &gt;                         \" description STRING,\" +&#010;&gt; &gt;                         \" weight Double\" +&#010;&gt; &gt;                         \") WITH (\" +&#010;&gt; &gt;                         \" 'connector' = 'kafka-0.11',\" +&#010;&gt; &gt;                         \" 'topic' = '%s',\" +&#010;&gt; &gt;                         \" 'properties.bootstrap.servers' = '%s',\" +&#010;&gt; &gt;                         \" 'scan.startup.mode' = 'group-offsets',\" +&#010;&gt; &gt;                         \" 'format' = 'debezium-json'\" +&#010;&gt; &gt;                         \")\", \"ddd\", \" 172.22.20.206:9092\");&#010;&gt; &gt;         String sinkDDL = \"CREATE TABLE sink (\" +&#010;&gt; &gt;                 \" id INT NOT NULL,\" +&#010;&gt; &gt;                 \" name STRING,\" +&#010;&gt; &gt;                 \" description STRING,\" +&#010;&gt; &gt;                 \" weight Double,\" +&#010;&gt; &gt;                 \" PRIMARY KEY (id,name, description,weight) NOT ENFORCED&#010;&gt; \"&#010;&gt; &gt; +&#010;&gt; &gt;                 \") WITH (\" +&#010;&gt; &gt;                 \" 'connector' = 'jdbc',\" +&#010;&gt; &gt;                 \" 'url' =&#010;&gt; &gt; 'jdbc:mysql://172.27.4.22:3306/test?autoReconnect=true',\" +&#010;&gt; &gt;                 \" 'table-name' = 'products',\" +&#010;&gt; &gt;                 \" 'driver'= 'com.mysql.cj.jdbc.Driver',\" +&#010;&gt; &gt;                 \" 'username'='DataPip',\" +&#010;&gt; &gt;                 \" 'password'='DataPip'\" +&#010;&gt; &gt;                 \")\";&#010;&gt; &gt;         String dml = \"INSERT INTO sink SELECT  id,name ,description,&#010;&gt; weight&#010;&gt; &gt; FROM debezium_source GROUP BY id,name ,description, weight\";&#010;&gt; &gt;         tEnv.executeSql(sourceDDL);&#010;&gt; &gt;         tEnv.executeSql(sinkDDL);&#010;&gt; &gt;         tEnv.executeSql(dml);&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt; --&#010;&gt; &gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&gt; &gt;&#010;&gt;&#010;&#010;",
        "depth": "2",
        "reply": "<1594901056880-0.post@n8.nabble.com>"
    },
    {
        "id": "<1594976934452-0.post@n8.nabble.com>",
        "from": "æ›¹æ­¦ &lt;14701319...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:08:54 GMT",
        "subject": "Re: flink 1.11 checkpointä½¿ç”¨",
        "content": "å¦‚æœå»æ‰group byä¼šæŠ›å‡ºå¼‚å¸¸,è¯·é—®æœ‰æ²¡æœ‰å…³è¿™ä¸ªå¼‚å¸¸çš„è§£å†³æ–¹å¼:&#010;Exception in thread \"main\" org.apache.flink.table.api.TableException:&#010;Provided trait [BEFORE_AND_AFTER] can't satisfy required trait&#010;[ONLY_UPDATE_AFTER]. This is a bug in planner, please file an issue.&#010;Current node is TableSourceScan(table=[[default_catalog, default_database,&#010;ddd",
        "depth": "3",
        "reply": "<1594901056880-0.post@n8.nabble.com>"
    },
    {
        "id": "<1594976982887-0.post@n8.nabble.com>",
        "from": "æ›¹æ­¦ &lt;14701319...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:09:42 GMT",
        "subject": "Re: flink 1.11 checkpointä½¿ç”¨",
        "content": "å¦‚æœå»æ‰group byä¼šæŠ›å‡ºå¼‚å¸¸,è¯·é—®æœ‰æ²¡æœ‰å…³è¿™ä¸ªå¼‚å¸¸çš„è§£å†³æ–¹å¼:&#010;Exception in thread \"main\" org.apache.flink.table.api.TableException:&#010;Provided trait [BEFORE_AND_AFTER] can't satisfy required trait&#010;[ONLY_UPDATE_AFTER]. This is a bug in planner, please file an issue.&#010;Current node is TableSourceScan(table=[[default_catalog, default_database,&#010;ddd",
        "depth": "2",
        "reply": "<1594901056880-0.post@n8.nabble.com>"
    },
    {
        "id": "<1594977167653-0.post@n8.nabble.com>",
        "from": "æ›¹æ­¦ &lt;14701319...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:12:47 GMT",
        "subject": "Re: flink 1.11 checkpointä½¿ç”¨",
        "content": "æ„Ÿè§‰å¥½åƒæ˜¯åº”ä¸ºä»checkpointå¯åŠ¨å¤±è´¥æˆ–è€…æ˜¯checkpiontæ–‡ä»¶é‡Œé¢ä¸åŒ…å«groupbyçš„ä¸­é—´ç»“æœ,è¿™ä¸ªæ€ä¹ˆæ’æŸ¥å‘€!&#010;&#010;godfrey he wrote&#010;&gt; ä¸ºä»€ä¹ˆè¦ GROUP BY id,name ,description, weight ï¼Ÿ&#010;&gt; ç›´æ¥ \"INSERT INTO sink SELECT  id,name ,description, weight FROM&#010;&gt; debezium_source\" ä¸èƒ½æ»¡è¶³éœ€æ±‚ï¼Ÿ&#010;&gt; &#010;&gt; æ›¹æ­¦ &lt;&#010;&#010;&gt; 14701319164@&#010;&#010;&gt;&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ9:30å†™é“ï¼š&#010;&gt; &#010;&gt;&gt; æˆ‘åœ¨ä½¿ç”¨flink 1.11.0ä¸­å¾—ddl éƒ¨åˆ† é‡‡ç”¨debezium-jsonåšcdcå¾—æ—¶å€™&#010;&gt;&gt; ä»checkpointæ¢å¤ä»¥å,æ–°æ¥op=dçš„æ•°æ®ä¼šåˆ é™¤å¤±è´¥&#010;&gt;&gt; é‡å¯å‘½ä»¤:./bin/flink run -m yarn-cluster  /root/bigdata-flink-1.0.jar -s&#010;&gt;&gt;&#010;&gt;&gt; hdfs://prehadoop01:8020/flink/checkpoints/4cc5df8b96e90c1c2a4d3719a77f51d1/chk-819/_metadata&#010;&gt;&gt; ä»£ç :   EnvironmentSettings settings = EnvironmentSettings.newInstance()&#010;&gt;&gt;                 .useBlinkPlanner()&#010;&gt;&gt;                 .inStreamingMode()&#010;&gt;&gt;                 .build();&#010;&gt;&gt;&#010;&gt;&gt;         StreamExecutionEnvironment env =&#010;&gt;&gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt;&gt;&#010;&gt;&gt;         env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#010;&gt;&gt;         env.getCheckpointConfig().setCheckpointTimeout(6000L); // è¶…æ—¶æ—¶é—´&#010;&gt;&gt;         env.getCheckpointConfig().setMaxConcurrentCheckpoints(1); //&#010;&gt;&gt; æœ€å¤§å…è®¸åŒæ—¶å‡ºç°å‡ ä¸ªCheckPoint&#010;&gt;&gt;         env.getCheckpointConfig().setMinPauseBetweenCheckpoints(10L); //&#010;&gt;&gt; æœ€å°å¾—é—´éš”æ—¶é—´&#010;&gt;&gt;         env.getCheckpointConfig().setPreferCheckpointForRecovery(true);&#010;&gt;&gt; //&#010;&gt;&gt; æ˜¯å¦å€¾å‘äºç”¨CheckPointåšæ•…éšœæ¢å¤&#010;&gt;&gt;         env.getCheckpointConfig().setTolerableCheckpointFailureNumber(1);&#010;&gt;&gt; //&#010;&gt;&gt; å®¹å¿å¤šå°‘æ¬¡CheckPointå¤±è´¥&#010;&gt;&gt;         //Checkpointæ–‡ä»¶æ¸…ç†ç­–ç•¥&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#010;&gt;&gt;         //Checkpointå¤–éƒ¨æ–‡ä»¶è·¯å¾„&#010;&gt;&gt;         env.setStateBackend(new FsStateBackend(new&#010;&gt;&gt; URI(\"hdfs://172.22.20.205:8020/flink/checkpoints\"), false));&#010;&gt;&gt; TimeUnit.MINUTES), Time.of(10, TimeUnit.SECONDS)));&#010;&gt;&gt;         StreamTableEnvironment tEnv = StreamTableEnvironment.create(env,&#010;&gt;&gt; settings);&#010;&gt;&gt;         String sourceDDL = String.format(&#010;&gt;&gt;                 \"CREATE TABLE debezium_source (\" +&#010;&gt;&gt;                         \" id INT NOT NULL,\" +&#010;&gt;&gt;                         \" name STRING,\" +&#010;&gt;&gt;                         \" description STRING,\" +&#010;&gt;&gt;                         \" weight Double\" +&#010;&gt;&gt;                         \") WITH (\" +&#010;&gt;&gt;                         \" 'connector' = 'kafka-0.11',\" +&#010;&gt;&gt;                         \" 'topic' = '%s',\" +&#010;&gt;&gt;                         \" 'properties.bootstrap.servers' = '%s',\" +&#010;&gt;&gt;                         \" 'scan.startup.mode' = 'group-offsets',\" +&#010;&gt;&gt;                         \" 'format' = 'debezium-json'\" +&#010;&gt;&gt;                         \")\", \"ddd\", \" 172.22.20.206:9092\");&#010;&gt;&gt;         String sinkDDL = \"CREATE TABLE sink (\" +&#010;&gt;&gt;                 \" id INT NOT NULL,\" +&#010;&gt;&gt;                 \" name STRING,\" +&#010;&gt;&gt;                 \" description STRING,\" +&#010;&gt;&gt;                 \" weight Double,\" +&#010;&gt;&gt;                 \" PRIMARY KEY (id,name, description,weight) NOT ENFORCED&#010;&gt;&gt; \"&#010;&gt;&gt; +&#010;&gt;&gt;                 \") WITH (\" +&#010;&gt;&gt;                 \" 'connector' = 'jdbc',\" +&#010;&gt;&gt;                 \" 'url' =&#010;&gt;&gt; 'jdbc:mysql://172.27.4.22:3306/test?autoReconnect=true',\" +&#010;&gt;&gt;                 \" 'table-name' = 'products',\" +&#010;&gt;&gt;                 \" 'driver'= 'com.mysql.cj.jdbc.Driver',\" +&#010;&gt;&gt;                 \" 'username'='DataPip',\" +&#010;&gt;&gt;                 \" 'password'='DataPip'\" +&#010;&gt;&gt;                 \")\";&#010;&gt;&gt;         String dml = \"INSERT INTO sink SELECT  id,name ,description,&#010;&gt;&gt; weight&#010;&gt;&gt; FROM debezium_source GROUP BY id,name ,description, weight\";&#010;&gt;&gt;         tEnv.executeSql(sourceDDL);&#010;&gt;&gt;         tEnv.executeSql(sinkDDL);&#010;&gt;&gt;         tEnv.executeSql(dml);&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; --&#010;&gt;&gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&gt;&gt;&#010;&#010;&#010;&#010;&#010;&#010;--&#010;Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&#010;",
        "depth": "2",
        "reply": "<1594901056880-0.post@n8.nabble.com>"
    },
    {
        "id": "<30C72674-A29D-46AE-AE12-CBE134F1D02B@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 11:37:13 GMT",
        "subject": "Re: flink 1.11 checkpointä½¿ç”¨",
        "content": "Hiï¼Œ æ›¹æ­¦&#010;&#010;è¿™æ˜¯ä¸€ä¸ªå·²çŸ¥bugï¼Œè¿™ä¸ªåœ¨1.11.1å’Œ1.12.0é‡Œå·²ç»ä¿®å¤ï¼Œ&#010;&#010;å¦‚æœç€æ€¥ä½¿ç”¨ï¼Œå¯ä»¥è‡ªå·±ç¼–è¯‘ä¸‹release-1.11åˆ†æ”¯ã€‚&#010;&#010;ç¥å¥½ &#010;Leonard Xu&#010;&#010;https://issues.apache.org/jira/browse/FLINK-18461 &lt;https://issues.apache.org/jira/browse/FLINK-18461&gt;&#010;&#010;&gt; åœ¨ 2020å¹´7æœˆ17æ—¥ï¼Œ17:12ï¼Œæ›¹æ­¦ &lt;14701319164@163.com&gt; å†™é“ï¼š&#010;&gt; &#010;&gt; æ„Ÿè§‰å¥½åƒæ˜¯åº”ä¸ºä»checkpointå¯åŠ¨å¤±è´¥æˆ–è€…æ˜¯checkpiontæ–‡ä»¶é‡Œé¢ä¸åŒ…å«groupbyçš„ä¸­é—´ç»“æœ,è¿™ä¸ªæ€ä¹ˆæ’æŸ¥å‘€!&#010;&gt; &#010;&gt; godfrey he wrote&#010;&gt;&gt; ä¸ºä»€ä¹ˆè¦ GROUP BY id,name ,description, weight ï¼Ÿ&#010;&gt;&gt; ç›´æ¥ \"INSERT INTO sink SELECT  id,name ,description, weight FROM&#010;&gt;&gt; debezium_source\" ä¸èƒ½æ»¡è¶³éœ€æ±‚ï¼Ÿ&#010;&gt;&gt; &#010;&gt;&gt; æ›¹æ­¦ &lt;&#010;&gt; &#010;&gt;&gt; 14701319164@&#010;&gt; &#010;&gt;&gt;&gt; äº2020å¹´7æœˆ16æ—¥å‘¨å›› ä¸‹åˆ9:30å†™é“ï¼š&#010;&gt;&gt; &#010;&gt;&gt;&gt; æˆ‘åœ¨ä½¿ç”¨flink 1.11.0ä¸­å¾—ddl éƒ¨åˆ† é‡‡ç”¨debezium-jsonåšcdcå¾—æ—¶å€™&#010;&gt;&gt;&gt; ä»checkpointæ¢å¤ä»¥å,æ–°æ¥op=dçš„æ•°æ®ä¼šåˆ é™¤å¤±è´¥&#010;&gt;&gt;&gt; é‡å¯å‘½ä»¤:./bin/flink run -m yarn-cluster  /root/bigdata-flink-1.0.jar -s&#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt; hdfs://prehadoop01:8020/flink/checkpoints/4cc5df8b96e90c1c2a4d3719a77f51d1/chk-819/_metadata&#010;&gt;&gt;&gt; ä»£ç :   EnvironmentSettings settings = EnvironmentSettings.newInstance()&#010;&gt;&gt;&gt;                .useBlinkPlanner()&#010;&gt;&gt;&gt;                .inStreamingMode()&#010;&gt;&gt;&gt;                .build();&#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt;        StreamExecutionEnvironment env =&#010;&gt;&gt;&gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt;        env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#010;&gt;&gt;&gt;        env.getCheckpointConfig().setCheckpointTimeout(6000L); // è¶…æ—¶æ—¶é—´&#010;&gt;&gt;&gt;        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1); //&#010;&gt;&gt;&gt; æœ€å¤§å…è®¸åŒæ—¶å‡ºç°å‡ ä¸ªCheckPoint&#010;&gt;&gt;&gt;        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(10L); //&#010;&gt;&gt;&gt; æœ€å°å¾—é—´éš”æ—¶é—´&#010;&gt;&gt;&gt;        env.getCheckpointConfig().setPreferCheckpointForRecovery(true);&#010;&gt;&gt;&gt; //&#010;&gt;&gt;&gt; æ˜¯å¦å€¾å‘äºç”¨CheckPointåšæ•…éšœæ¢å¤&#010;&gt;&gt;&gt;        env.getCheckpointConfig().setTolerableCheckpointFailureNumber(1);&#010;&gt;&gt;&gt; //&#010;&gt;&gt;&gt; å®¹å¿å¤šå°‘æ¬¡CheckPointå¤±è´¥&#010;&gt;&gt;&gt;        //Checkpointæ–‡ä»¶æ¸…ç†ç­–ç•¥&#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt; env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&#010;&gt;&gt;&gt;        //Checkpointå¤–éƒ¨æ–‡ä»¶è·¯å¾„&#010;&gt;&gt;&gt;        env.setStateBackend(new FsStateBackend(new&#010;&gt;&gt;&gt; URI(\"hdfs://172.22.20.205:8020/flink/checkpoints\"), false));&#010;&gt;&gt;&gt; TimeUnit.MINUTES), Time.of(10, TimeUnit.SECONDS)));&#010;&gt;&gt;&gt;        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env,&#010;&gt;&gt;&gt; settings);&#010;&gt;&gt;&gt;        String sourceDDL = String.format(&#010;&gt;&gt;&gt;                \"CREATE TABLE debezium_source (\" +&#010;&gt;&gt;&gt;                        \" id INT NOT NULL,\" +&#010;&gt;&gt;&gt;                        \" name STRING,\" +&#010;&gt;&gt;&gt;                        \" description STRING,\" +&#010;&gt;&gt;&gt;                        \" weight Double\" +&#010;&gt;&gt;&gt;                        \") WITH (\" +&#010;&gt;&gt;&gt;                        \" 'connector' = 'kafka-0.11',\" +&#010;&gt;&gt;&gt;                        \" 'topic' = '%s',\" +&#010;&gt;&gt;&gt;                        \" 'properties.bootstrap.servers' = '%s',\" +&#010;&gt;&gt;&gt;                        \" 'scan.startup.mode' = 'group-offsets',\" +&#010;&gt;&gt;&gt;                        \" 'format' = 'debezium-json'\" +&#010;&gt;&gt;&gt;                        \")\", \"ddd\", \" 172.22.20.206:9092\");&#010;&gt;&gt;&gt;        String sinkDDL = \"CREATE TABLE sink (\" +&#010;&gt;&gt;&gt;                \" id INT NOT NULL,\" +&#010;&gt;&gt;&gt;                \" name STRING,\" +&#010;&gt;&gt;&gt;                \" description STRING,\" +&#010;&gt;&gt;&gt;                \" weight Double,\" +&#010;&gt;&gt;&gt;                \" PRIMARY KEY (id,name, description,weight) NOT ENFORCED&#010;&gt;&gt;&gt; \"&#010;&gt;&gt;&gt; +&#010;&gt;&gt;&gt;                \") WITH (\" +&#010;&gt;&gt;&gt;                \" 'connector' = 'jdbc',\" +&#010;&gt;&gt;&gt;                \" 'url' =&#010;&gt;&gt;&gt; 'jdbc:mysql://172.27.4.22:3306/test?autoReconnect=true',\" +&#010;&gt;&gt;&gt;                \" 'table-name' = 'products',\" +&#010;&gt;&gt;&gt;                \" 'driver'= 'com.mysql.cj.jdbc.Driver',\" +&#010;&gt;&gt;&gt;                \" 'username'='DataPip',\" +&#010;&gt;&gt;&gt;                \" 'password'='DataPip'\" +&#010;&gt;&gt;&gt;                \")\";&#010;&gt;&gt;&gt;        String dml = \"INSERT INTO sink SELECT  id,name ,description,&#010;&gt;&gt;&gt; weight&#010;&gt;&gt;&gt; FROM debezium_source GROUP BY id,name ,description, weight\";&#010;&gt;&gt;&gt;        tEnv.executeSql(sourceDDL);&#010;&gt;&gt;&gt;        tEnv.executeSql(sinkDDL);&#010;&gt;&gt;&gt;        tEnv.executeSql(dml);&#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt; &#010;&gt;&gt;&gt; --&#010;&gt;&gt;&gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&gt;&gt;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; --&#010;&gt; Sent from: http://apache-flink.147419.n8.nabble.com/ &lt;http://apache-flink.147419.n8.nabble.com/&gt;&#010;&#010;",
        "depth": "3",
        "reply": "<1594901056880-0.post@n8.nabble.com>"
    },
    {
        "id": "<tencent_B3C761B6785686327061644D99A78E74EC05@qq.com>",
        "from": "&quot;æ²ˆé˜³&quot; &lt;122969...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 14:46:02 GMT",
        "subject": "é€€è®¢",
        "content": "é€€è®¢",
        "depth": "0",
        "reply": "<tencent_B3C761B6785686327061644D99A78E74EC05@qq.com>"
    },
    {
        "id": "<9CB39241-6082-4AE1-8E09-40525F71C4A0@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 16:12:57 GMT",
        "subject": "Re: é€€è®¢",
        "content": "Hi,&#010;æ˜¯æŒ‡å–æ¶ˆè®¢é˜…é‚®ä»¶å—ï¼Ÿ&#010;å¯ä»¥å‘é€ä»»æ„å†…å®¹çš„é‚®ä»¶åˆ°  user-zh-unsubscribe@flink.apache.org &lt;mailto:user-zh-unsubscribe@flink.apache.org&gt;&#010; å–æ¶ˆè®¢é˜…æ¥è‡ª user-zh@flink.apache.org &lt;mailto:user-zh@flink.apache.org&gt; é‚®ä»¶ç»„çš„é‚®ä»¶&#010;&#010;é‚®ä»¶ç»„çš„è®¢é˜…ç®¡ç†ï¼Œå¯ä»¥å‚è€ƒ[1]&#010;&#010;ç¥å¥½ï¼Œ&#010;Leonard Xu&#010;https://flink.apache.org/community.html#how-to-subscribe-to-a-mailing-list &lt;https://flink.apache.org/community.html#how-to-subscribe-to-a-mailing-list&gt;&#010;&#010;&gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ22:46ï¼Œæ²ˆé˜³ &lt;122969720@qq.com&gt; å†™é“ï¼š&#010;&gt; &#010;&gt; é€€è®¢&#010;&#010;&#010;",
        "depth": "1",
        "reply": "<tencent_B3C761B6785686327061644D99A78E74EC05@qq.com>"
    },
    {
        "id": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>",
        "from": "sunfulin &lt;sunfulin0...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 15:08:03 GMT",
        "subject": "flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "hiï¼Œ&#010;è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#010;é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚",
        "depth": "0",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<001B4BE4-EB68-4CB2-BCC6-B2703C8EDA74@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Thu, 16 Jul 2020 16:12:14 GMT",
        "subject": "Re: flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "Hiï¼Œ&#013;&#010;&#013;&#010;æˆ‘ç†è§£ç›®å‰å¥½åƒåšä¸åˆ°ï¼Œ cc: godfrey å¤§ä½¬çœ‹çœ‹&#013;&#010;&#013;&#010;ç¥å¥½ï¼Œ&#013;&#010;Leonard Xu&#013;&#010;&#013;&#010;&gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ23:08ï¼Œsunfulin &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#013;&#010;&gt; &#013;&#010;&gt; hiï¼Œ&#013;&#010;&gt; è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#013;&#010;&gt; é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚&#013;&#010;&#013;&#010;",
        "depth": "1",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<CADQYLGsGhTzbE-Ug=mVMPEVkt=Wv-MYyL+ErKT47+=nT0nd8Mw@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 04:09:20 GMT",
        "subject": "Re: flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "hi sunfulin,&#013;&#010;ç›®å‰è¿™ä¸ªåšä¸åˆ°ã€‚executeSQL å’Œ table to DataStream æ˜¯åˆ†åˆ«ä¼˜åŒ–å’Œæäº¤ä½œä¸šçš„ã€‚&#013;&#010;å³ä½¿åœ¨1.11 ä¹‹å‰ï¼Œtable to DataStream ä¹Ÿä¸ä¼šå’Œ sqlUpdate æˆ–è€… insertInto çš„è¯­å¥ä¸€èµ·ä¼˜åŒ–ï¼Œ&#013;&#010;è™½ç„¶åªæäº¤äº†ä¸€ä¸ªjobï¼Œä½†æ˜¯æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„pipelineï¼Œä¹Ÿæ²¡æœ‰è®¡ç®—å¤ç”¨ï¼Œå’Œä¸¤ä¸ªjobæ²¡å•¥å·®åˆ«ã€‚&#013;&#010;&#013;&#010;Bestï¼Œ&#013;&#010;Godfrey&#013;&#010;&#013;&#010;Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸Šåˆ12:12å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; Hiï¼Œ&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘ç†è§£ç›®å‰å¥½åƒåšä¸åˆ°ï¼Œ cc: godfrey å¤§ä½¬çœ‹çœ‹&#013;&#010;&gt;&#013;&#010;&gt; ç¥å¥½ï¼Œ&#013;&#010;&gt; Leonard Xu&#013;&#010;&gt;&#013;&#010;&gt; &gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ23:08ï¼Œsunfulin &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; hiï¼Œ&#013;&#010;&gt; &gt; è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql&#013;&#010;&gt; dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#013;&#010;&gt; &gt; é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn&#013;&#010;&gt; per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<74065d5.3c7f.1735b5768ef.Coremail.sunfulin0321@163.com>",
        "from": "sunfulin  &lt;sunfulin0...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 05:55:21 GMT",
        "subject": "Re:Re: flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "&#010;&#010;&#010;hi,&#010;æ„Ÿè°¢å›å¤ã€‚è¿™ä¸ªæœºåˆ¶æˆ‘ç†è§£äº†ã€‚æƒ³äº†è§£ä¸‹ï¼Œæœ‰åŠæ³•åœ¨1.11é‡Œä»ç„¶ä½¿ç”¨1.10ç‰ˆæœ¬çš„ä½œä¸šæäº¤æœºåˆ¶ä¹ˆï¼Ÿæˆ‘ç°åœ¨è™½ç„¶æŠŠä»£ç å›æ»šåˆ°1.10ç‰ˆæœ¬çš„é€»è¾‘ï¼Œä½†æ˜¯æäº¤ä½œä¸šä»ç„¶æœ‰é—®é¢˜ï¼šæ¯”å¦‚æˆ‘å¦‚æœä¸æ‰§è¡Œenv.executeï¼Œé‚£ä¹ˆtable&#010;to DataStreamçš„è¯­å¥ä¸ä¼šç”Ÿæˆæ‹“æ‰‘ã€‚&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;åœ¨ 2020-07-17 12:09:20ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#010;&gt;hi sunfulin,&#010;&gt;ç›®å‰è¿™ä¸ªåšä¸åˆ°ã€‚executeSQL å’Œ table to DataStream æ˜¯åˆ†åˆ«ä¼˜åŒ–å’Œæäº¤ä½œä¸šçš„ã€‚&#010;&gt;å³ä½¿åœ¨1.11 ä¹‹å‰ï¼Œtable to DataStream ä¹Ÿä¸ä¼šå’Œ sqlUpdate æˆ–è€… insertInto çš„è¯­å¥ä¸€èµ·ä¼˜åŒ–ï¼Œ&#010;&gt;è™½ç„¶åªæäº¤äº†ä¸€ä¸ªjobï¼Œä½†æ˜¯æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„pipelineï¼Œä¹Ÿæ²¡æœ‰è®¡ç®—å¤ç”¨ï¼Œå’Œä¸¤ä¸ªjobæ²¡å•¥å·®åˆ«ã€‚&#010;&gt;&#010;&gt;Bestï¼Œ&#010;&gt;Godfrey&#010;&gt;&#010;&gt;Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸Šåˆ12:12å†™é“ï¼š&#010;&gt;&#010;&gt;&gt; Hiï¼Œ&#010;&gt;&gt;&#010;&gt;&gt; æˆ‘ç†è§£ç›®å‰å¥½åƒåšä¸åˆ°ï¼Œ cc: godfrey å¤§ä½¬çœ‹çœ‹&#010;&gt;&gt;&#010;&gt;&gt; ç¥å¥½ï¼Œ&#010;&gt;&gt; Leonard Xu&#010;&gt;&gt;&#010;&gt;&gt; &gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ23:08ï¼Œsunfulin &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; hiï¼Œ&#010;&gt;&gt; &gt; è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql&#010;&gt;&gt; dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#010;&gt;&gt; &gt; é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn&#010;&gt;&gt; per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚&#010;&gt;&gt;&#010;&gt;&gt;&#010;",
        "depth": "3",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<788cf01f.3d22.1735b5bf659.Coremail.sunfulin0321@163.com>",
        "from": "sunfulin  &lt;sunfulin0...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 06:00:20 GMT",
        "subject": "Re:Re:Re: flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "hiï¼Œ&#010;è¡¥å……ä¸€ä¸‹ï¼Œ1.10ç‰ˆæœ¬çš„ä»£ç ä½¿ç”¨sqlUpdate + table2datastreamï¼Œå¹¶é€šè¿‡StreamExecutionEnvironment.executeæ¥æäº¤ã€‚æˆ‘å›æ»šåˆ°1.10ç‰ˆæœ¬çš„ä»£ç åï¼Œå› ä¸ºæˆ‘çœ‹1.11ç‰ˆæœ¬é‡Œå¦‚æœä½¿ç”¨sqlUpdateæ‰§è¡ŒinsertIntoï¼Œå¿…é¡»ä½¿ç”¨StreamTableEnvironment.executeæ¥æäº¤ã€‚ç°åœ¨æˆ‘çš„é—®é¢˜å°±æ˜¯è¿™ä¸ªï¼šæˆ‘æƒ³é€šè¿‡ä¸€ä¸ªjobæ¥æäº¤ã€‚ç°åœ¨æœ‰æœºåˆ¶å¯ä»¥åšä¸ï¼Ÿåœ¨1.11ç‰ˆæœ¬é‡Œæ‰§è¡Œã€‚å› ä¸ºä¹‹å‰çš„jobé€»è¾‘è¾ƒä¸ºå¤æ‚ï¼Œåšæ‹†åˆ†çš„è¯è¿˜æœ‰ç‚¹éº»çƒ¦ã€‚&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;åœ¨ 2020-07-17 13:55:21ï¼Œ\"sunfulin\" &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#010;&#010;&#010;&#010;&#010;hi,&#010;æ„Ÿè°¢å›å¤ã€‚è¿™ä¸ªæœºåˆ¶æˆ‘ç†è§£äº†ã€‚æƒ³äº†è§£ä¸‹ï¼Œæœ‰åŠæ³•åœ¨1.11é‡Œä»ç„¶ä½¿ç”¨1.10ç‰ˆæœ¬çš„ä½œä¸šæäº¤æœºåˆ¶ä¹ˆï¼Ÿæˆ‘ç°åœ¨è™½ç„¶æŠŠä»£ç å›æ»šåˆ°1.10ç‰ˆæœ¬çš„é€»è¾‘ï¼Œä½†æ˜¯æäº¤ä½œä¸šä»ç„¶æœ‰é—®é¢˜ï¼šæ¯”å¦‚æˆ‘å¦‚æœä¸æ‰§è¡Œenv.executeï¼Œé‚£ä¹ˆtable&#010;to DataStreamçš„è¯­å¥ä¸ä¼šç”Ÿæˆæ‹“æ‰‘ã€‚&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;åœ¨ 2020-07-17 12:09:20ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#010;&gt;hi sunfulin,&#010;&gt;ç›®å‰è¿™ä¸ªåšä¸åˆ°ã€‚executeSQL å’Œ table to DataStream æ˜¯åˆ†åˆ«ä¼˜åŒ–å’Œæäº¤ä½œä¸šçš„ã€‚&#010;&gt;å³ä½¿åœ¨1.11 ä¹‹å‰ï¼Œtable to DataStream ä¹Ÿä¸ä¼šå’Œ sqlUpdate æˆ–è€… insertInto çš„è¯­å¥ä¸€èµ·ä¼˜åŒ–ï¼Œ&#010;&gt;è™½ç„¶åªæäº¤äº†ä¸€ä¸ªjobï¼Œä½†æ˜¯æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„pipelineï¼Œä¹Ÿæ²¡æœ‰è®¡ç®—å¤ç”¨ï¼Œå’Œä¸¤ä¸ªjobæ²¡å•¥å·®åˆ«ã€‚&#010;&gt;&#010;&gt;Bestï¼Œ&#010;&gt;Godfrey&#010;&gt;&#010;&gt;Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸Šåˆ12:12å†™é“ï¼š&#010;&gt;&#010;&gt;&gt; Hiï¼Œ&#010;&gt;&gt;&#010;&gt;&gt; æˆ‘ç†è§£ç›®å‰å¥½åƒåšä¸åˆ°ï¼Œ cc: godfrey å¤§ä½¬çœ‹çœ‹&#010;&gt;&gt;&#010;&gt;&gt; ç¥å¥½ï¼Œ&#010;&gt;&gt; Leonard Xu&#010;&gt;&gt;&#010;&gt;&gt; &gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ23:08ï¼Œsunfulin &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; hiï¼Œ&#010;&gt;&gt; &gt; è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql&#010;&gt;&gt; dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#010;&gt;&gt; &gt; é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn&#010;&gt;&gt; per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚&#010;&gt;&gt;&#010;&gt;&gt;&#010;&#010;&#010;&#010;&#010;&#010; ",
        "depth": "4",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<CADQYLGsn_ebb=ebUMqpBwmxae=jdMZs19MtQtKOmtKNrn1oFrA@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 06:36:19 GMT",
        "subject": "Re: Re:Re: flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "åšä¸åˆ°ï¼Œ1.11é‡ŒæŠŠ StreamExecutionEnvironment.execute å’Œ&#013;&#010;StreamTableEnvironment.execute çš„é€»è¾‘å·²ç»åˆ‡åˆ†å¹²å‡€äº†ã€‚&#013;&#010;æœ‰ä¸ªæ”¹åŠ¨æ¯”è¾ƒå°çš„æ–¹æ¡ˆå¯ä»¥å‚è€ƒï¼šå¯ä»¥åœ¨åŸæ¥çš„é€»è¾‘çš„åŸºç¡€ä¸Šï¼ŒæŠŠä¸¤ç§æäº¤jobçš„æ–¹å¼æ”¾åˆ°ä¸¤ä¸ªä¸åŒçš„ç±»ä¸­ï¼Œå…¶ä»–çš„é€»è¾‘æ”¾åˆ°å¦å¤–ä¸€ä¸ªç±»å…±æ€§ã€‚&#013;&#010;&#013;&#010;sunfulin &lt;sunfulin0321@163.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:00å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; hiï¼Œ&#013;&#010;&gt; è¡¥å……ä¸€ä¸‹ï¼Œ1.10ç‰ˆæœ¬çš„ä»£ç ä½¿ç”¨sqlUpdate +&#013;&#010;&gt; table2datastreamï¼Œå¹¶é€šè¿‡StreamExecutionEnvironment.executeæ¥æäº¤ã€‚æˆ‘å›æ»šåˆ°1.10ç‰ˆæœ¬çš„ä»£ç åï¼Œå› ä¸ºæˆ‘çœ‹1.11ç‰ˆæœ¬é‡Œå¦‚æœä½¿ç”¨sqlUpdateæ‰§è¡ŒinsertIntoï¼Œå¿…é¡»ä½¿ç”¨StreamTableEnvironment.executeæ¥æäº¤ã€‚ç°åœ¨æˆ‘çš„é—®é¢˜å°±æ˜¯è¿™ä¸ªï¼šæˆ‘æƒ³é€šè¿‡ä¸€ä¸ªjobæ¥æäº¤ã€‚ç°åœ¨æœ‰æœºåˆ¶å¯ä»¥åšä¸ï¼Ÿåœ¨1.11ç‰ˆæœ¬é‡Œæ‰§è¡Œã€‚å› ä¸ºä¹‹å‰çš„jobé€»è¾‘è¾ƒä¸ºå¤æ‚ï¼Œåšæ‹†åˆ†çš„è¯è¿˜æœ‰ç‚¹éº»çƒ¦ã€‚&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; åœ¨ 2020-07-17 13:55:21ï¼Œ\"sunfulin\" &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; hi,&#013;&#010;&gt; æ„Ÿè°¢å›å¤ã€‚è¿™ä¸ªæœºåˆ¶æˆ‘ç†è§£äº†ã€‚æƒ³äº†è§£ä¸‹ï¼Œæœ‰åŠæ³•åœ¨1.11é‡Œä»ç„¶ä½¿ç”¨1.10ç‰ˆæœ¬çš„ä½œä¸šæäº¤æœºåˆ¶ä¹ˆï¼Ÿæˆ‘ç°åœ¨è™½ç„¶æŠŠä»£ç å›æ»šåˆ°1.10ç‰ˆæœ¬çš„é€»è¾‘ï¼Œä½†æ˜¯æäº¤ä½œä¸šä»ç„¶æœ‰é—®é¢˜ï¼šæ¯”å¦‚æˆ‘å¦‚æœä¸æ‰§è¡Œenv.executeï¼Œé‚£ä¹ˆtable&#013;&#010;&gt; to DataStreamçš„è¯­å¥ä¸ä¼šç”Ÿæˆæ‹“æ‰‘ã€‚&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; åœ¨ 2020-07-17 12:09:20ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt;hi sunfulin,&#013;&#010;&gt; &gt;ç›®å‰è¿™ä¸ªåšä¸åˆ°ã€‚executeSQL å’Œ table to DataStream æ˜¯åˆ†åˆ«ä¼˜åŒ–å’Œæäº¤ä½œä¸šçš„ã€‚&#013;&#010;&gt; &gt;å³ä½¿åœ¨1.11 ä¹‹å‰ï¼Œtable to DataStream ä¹Ÿä¸ä¼šå’Œ sqlUpdate æˆ–è€… insertInto&#010;çš„è¯­å¥ä¸€èµ·ä¼˜åŒ–ï¼Œ&#013;&#010;&gt; &gt;è™½ç„¶åªæäº¤äº†ä¸€ä¸ªjobï¼Œä½†æ˜¯æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„pipelineï¼Œä¹Ÿæ²¡æœ‰è®¡ç®—å¤ç”¨ï¼Œå’Œä¸¤ä¸ªjobæ²¡å•¥å·®åˆ«ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;Bestï¼Œ&#013;&#010;&gt; &gt;Godfrey&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸Šåˆ12:12å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&gt; Hiï¼Œ&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; æˆ‘ç†è§£ç›®å‰å¥½åƒåšä¸åˆ°ï¼Œ cc: godfrey å¤§ä½¬çœ‹çœ‹&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; ç¥å¥½ï¼Œ&#013;&#010;&gt; &gt;&gt; Leonard Xu&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; &gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ23:08ï¼Œsunfulin &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt; &gt; hiï¼Œ&#013;&#010;&gt; &gt;&gt; &gt; è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql&#013;&#010;&gt; &gt;&gt; dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#013;&#010;&gt; &gt;&gt; &gt; é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn&#013;&#010;&gt; &gt;&gt; per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "5",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<7ebbc904.4c00.1735b9cc25c.Coremail.sunfulin0321@163.com>",
        "from": "sunfulin  &lt;sunfulin0...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 07:11:06 GMT",
        "subject": "Re:Re: Re:Re: flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "&#010;&#010;&#010;hi,&#010;å†é—®ä¸‹ï¼Œè¿™ä¸ªæ–¹æ¡ˆè¿˜æ˜¯ä¼šæäº¤ä¸¤ä¸ªjobå§ï¼Ÿ&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;åœ¨ 2020-07-17 14:36:19ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#010;&gt;åšä¸åˆ°ï¼Œ1.11é‡ŒæŠŠ StreamExecutionEnvironment.execute å’Œ&#010;&gt;StreamTableEnvironment.execute çš„é€»è¾‘å·²ç»åˆ‡åˆ†å¹²å‡€äº†ã€‚&#010;&gt;æœ‰ä¸ªæ”¹åŠ¨æ¯”è¾ƒå°çš„æ–¹æ¡ˆå¯ä»¥å‚è€ƒï¼šå¯ä»¥åœ¨åŸæ¥çš„é€»è¾‘çš„åŸºç¡€ä¸Šï¼ŒæŠŠä¸¤ç§æäº¤jobçš„æ–¹å¼æ”¾åˆ°ä¸¤ä¸ªä¸åŒçš„ç±»ä¸­ï¼Œå…¶ä»–çš„é€»è¾‘æ”¾åˆ°å¦å¤–ä¸€ä¸ªç±»å…±æ€§ã€‚&#010;&gt;&#010;&gt;sunfulin &lt;sunfulin0321@163.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:00å†™é“ï¼š&#010;&gt;&#010;&gt;&gt; hiï¼Œ&#010;&gt;&gt; è¡¥å……ä¸€ä¸‹ï¼Œ1.10ç‰ˆæœ¬çš„ä»£ç ä½¿ç”¨sqlUpdate +&#010;&gt;&gt; table2datastreamï¼Œå¹¶é€šè¿‡StreamExecutionEnvironment.executeæ¥æäº¤ã€‚æˆ‘å›æ»šåˆ°1.10ç‰ˆæœ¬çš„ä»£ç åï¼Œå› ä¸ºæˆ‘çœ‹1.11ç‰ˆæœ¬é‡Œå¦‚æœä½¿ç”¨sqlUpdateæ‰§è¡ŒinsertIntoï¼Œå¿…é¡»ä½¿ç”¨StreamTableEnvironment.executeæ¥æäº¤ã€‚ç°åœ¨æˆ‘çš„é—®é¢˜å°±æ˜¯è¿™ä¸ªï¼šæˆ‘æƒ³é€šè¿‡ä¸€ä¸ªjobæ¥æäº¤ã€‚ç°åœ¨æœ‰æœºåˆ¶å¯ä»¥åšä¸ï¼Ÿåœ¨1.11ç‰ˆæœ¬é‡Œæ‰§è¡Œã€‚å› ä¸ºä¹‹å‰çš„jobé€»è¾‘è¾ƒä¸ºå¤æ‚ï¼Œåšæ‹†åˆ†çš„è¯è¿˜æœ‰ç‚¹éº»çƒ¦ã€‚&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; åœ¨ 2020-07-17 13:55:21ï¼Œ\"sunfulin\" &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; hi,&#010;&gt;&gt; æ„Ÿè°¢å›å¤ã€‚è¿™ä¸ªæœºåˆ¶æˆ‘ç†è§£äº†ã€‚æƒ³äº†è§£ä¸‹ï¼Œæœ‰åŠæ³•åœ¨1.11é‡Œä»ç„¶ä½¿ç”¨1.10ç‰ˆæœ¬çš„ä½œä¸šæäº¤æœºåˆ¶ä¹ˆï¼Ÿæˆ‘ç°åœ¨è™½ç„¶æŠŠä»£ç å›æ»šåˆ°1.10ç‰ˆæœ¬çš„é€»è¾‘ï¼Œä½†æ˜¯æäº¤ä½œä¸šä»ç„¶æœ‰é—®é¢˜ï¼šæ¯”å¦‚æˆ‘å¦‚æœä¸æ‰§è¡Œenv.executeï¼Œé‚£ä¹ˆtable&#010;&gt;&gt; to DataStreamçš„è¯­å¥ä¸ä¼šç”Ÿæˆæ‹“æ‰‘ã€‚&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; åœ¨ 2020-07-17 12:09:20ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#010;&gt;&gt; &gt;hi sunfulin,&#010;&gt;&gt; &gt;ç›®å‰è¿™ä¸ªåšä¸åˆ°ã€‚executeSQL å’Œ table to DataStream æ˜¯åˆ†åˆ«ä¼˜åŒ–å’Œæäº¤ä½œä¸šçš„ã€‚&#010;&gt;&gt; &gt;å³ä½¿åœ¨1.11 ä¹‹å‰ï¼Œtable to DataStream ä¹Ÿä¸ä¼šå’Œ sqlUpdate æˆ–è€… insertInto&#010;çš„è¯­å¥ä¸€èµ·ä¼˜åŒ–ï¼Œ&#010;&gt;&gt; &gt;è™½ç„¶åªæäº¤äº†ä¸€ä¸ªjobï¼Œä½†æ˜¯æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„pipelineï¼Œä¹Ÿæ²¡æœ‰è®¡ç®—å¤ç”¨ï¼Œå’Œä¸¤ä¸ªjobæ²¡å•¥å·®åˆ«ã€‚&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;Bestï¼Œ&#010;&gt;&gt; &gt;Godfrey&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸Šåˆ12:12å†™é“ï¼š&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;&gt; Hiï¼Œ&#010;&gt;&gt; &gt;&gt;&#010;&gt;&gt; &gt;&gt; æˆ‘ç†è§£ç›®å‰å¥½åƒåšä¸åˆ°ï¼Œ cc: godfrey å¤§ä½¬çœ‹çœ‹&#010;&gt;&gt; &gt;&gt;&#010;&gt;&gt; &gt;&gt; ç¥å¥½ï¼Œ&#010;&gt;&gt; &gt;&gt; Leonard Xu&#010;&gt;&gt; &gt;&gt;&#010;&gt;&gt; &gt;&gt; &gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ23:08ï¼Œsunfulin &lt;sunfulin0321@163.com&gt;&#010;å†™é“ï¼š&#010;&gt;&gt; &gt;&gt; &gt;&#010;&gt;&gt; &gt;&gt; &gt; hiï¼Œ&#010;&gt;&gt; &gt;&gt; &gt; è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql&#010;&gt;&gt; &gt;&gt; dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#010;&gt;&gt; &gt;&gt; &gt; é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn&#010;&gt;&gt; &gt;&gt; per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚&#010;&gt;&gt; &gt;&gt;&#010;&gt;&gt; &gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;",
        "depth": "6",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<CADQYLGvzeftPO08ihp8oL27BfLZL-55LhBSYJ23+7HmzFadRZg@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 07:29:48 GMT",
        "subject": "Re: Re: Re:Re: flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜",
        "content": "æ˜¯çš„ã€‚ç›®å‰æŒ‰ç…§ä½ çš„å†™æ³•åšä¸åˆ°åªæäº¤ä¸€ä¸ªjobäº†&#013;&#010;&#013;&#010;sunfulin &lt;sunfulin0321@163.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ3:11å†™é“ï¼š&#013;&#010;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; hi,&#013;&#010;&gt; å†é—®ä¸‹ï¼Œè¿™ä¸ªæ–¹æ¡ˆè¿˜æ˜¯ä¼šæäº¤ä¸¤ä¸ªjobå§ï¼Ÿ&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; åœ¨ 2020-07-17 14:36:19ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt;åšä¸åˆ°ï¼Œ1.11é‡ŒæŠŠ StreamExecutionEnvironment.execute å’Œ&#013;&#010;&gt; &gt;StreamTableEnvironment.execute çš„é€»è¾‘å·²ç»åˆ‡åˆ†å¹²å‡€äº†ã€‚&#013;&#010;&gt; &gt;æœ‰ä¸ªæ”¹åŠ¨æ¯”è¾ƒå°çš„æ–¹æ¡ˆå¯ä»¥å‚è€ƒï¼šå¯ä»¥åœ¨åŸæ¥çš„é€»è¾‘çš„åŸºç¡€ä¸Šï¼ŒæŠŠä¸¤ç§æäº¤jobçš„æ–¹å¼æ”¾åˆ°ä¸¤ä¸ªä¸åŒçš„ç±»ä¸­ï¼Œå…¶ä»–çš„é€»è¾‘æ”¾åˆ°å¦å¤–ä¸€ä¸ªç±»å…±æ€§ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;sunfulin &lt;sunfulin0321@163.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:00å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&gt; hiï¼Œ&#013;&#010;&gt; &gt;&gt; è¡¥å……ä¸€ä¸‹ï¼Œ1.10ç‰ˆæœ¬çš„ä»£ç ä½¿ç”¨sqlUpdate +&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; table2datastreamï¼Œå¹¶é€šè¿‡StreamExecutionEnvironment.executeæ¥æäº¤ã€‚æˆ‘å›æ»šåˆ°1.10ç‰ˆæœ¬çš„ä»£ç åï¼Œå› ä¸ºæˆ‘çœ‹1.11ç‰ˆæœ¬é‡Œå¦‚æœä½¿ç”¨sqlUpdateæ‰§è¡ŒinsertIntoï¼Œå¿…é¡»ä½¿ç”¨StreamTableEnvironment.executeæ¥æäº¤ã€‚ç°åœ¨æˆ‘çš„é—®é¢˜å°±æ˜¯è¿™ä¸ªï¼šæˆ‘æƒ³é€šè¿‡ä¸€ä¸ªjobæ¥æäº¤ã€‚ç°åœ¨æœ‰æœºåˆ¶å¯ä»¥åšä¸ï¼Ÿåœ¨1.11ç‰ˆæœ¬é‡Œæ‰§è¡Œã€‚å› ä¸ºä¹‹å‰çš„jobé€»è¾‘è¾ƒä¸ºå¤æ‚ï¼Œåšæ‹†åˆ†çš„è¯è¿˜æœ‰ç‚¹éº»çƒ¦ã€‚&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; åœ¨ 2020-07-17 13:55:21ï¼Œ\"sunfulin\" &lt;sunfulin0321@163.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; hi,&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; æ„Ÿè°¢å›å¤ã€‚è¿™ä¸ªæœºåˆ¶æˆ‘ç†è§£äº†ã€‚æƒ³äº†è§£ä¸‹ï¼Œæœ‰åŠæ³•åœ¨1.11é‡Œä»ç„¶ä½¿ç”¨1.10ç‰ˆæœ¬çš„ä½œä¸šæäº¤æœºåˆ¶ä¹ˆï¼Ÿæˆ‘ç°åœ¨è™½ç„¶æŠŠä»£ç å›æ»šåˆ°1.10ç‰ˆæœ¬çš„é€»è¾‘ï¼Œä½†æ˜¯æäº¤ä½œä¸šä»ç„¶æœ‰é—®é¢˜ï¼šæ¯”å¦‚æˆ‘å¦‚æœä¸æ‰§è¡Œenv.executeï¼Œé‚£ä¹ˆtable&#013;&#010;&gt; &gt;&gt; to DataStreamçš„è¯­å¥ä¸ä¼šç”Ÿæˆæ‹“æ‰‘ã€‚&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; åœ¨ 2020-07-17 12:09:20ï¼Œ\"godfrey he\" &lt;godfreyhe@gmail.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt;&gt; &gt;hi sunfulin,&#013;&#010;&gt; &gt;&gt; &gt;ç›®å‰è¿™ä¸ªåšä¸åˆ°ã€‚executeSQL å’Œ table to DataStream æ˜¯åˆ†åˆ«ä¼˜åŒ–å’Œæäº¤ä½œä¸šçš„ã€‚&#013;&#010;&gt; &gt;&gt; &gt;å³ä½¿åœ¨1.11 ä¹‹å‰ï¼Œtable to DataStream ä¹Ÿä¸ä¼šå’Œ sqlUpdate æˆ–è€…&#010;insertInto çš„è¯­å¥ä¸€èµ·ä¼˜åŒ–ï¼Œ&#013;&#010;&gt; &gt;&gt; &gt;è™½ç„¶åªæäº¤äº†ä¸€ä¸ªjobï¼Œä½†æ˜¯æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„pipelineï¼Œä¹Ÿæ²¡æœ‰è®¡ç®—å¤ç”¨ï¼Œå’Œä¸¤ä¸ªjobæ²¡å•¥å·®åˆ«ã€‚&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt; &gt;Bestï¼Œ&#013;&#010;&gt; &gt;&gt; &gt;Godfrey&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt; &gt;Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸Šåˆ12:12å†™é“ï¼š&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt; &gt;&gt; Hiï¼Œ&#013;&#010;&gt; &gt;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; &gt;&gt; æˆ‘ç†è§£ç›®å‰å¥½åƒåšä¸åˆ°ï¼Œ cc: godfrey å¤§ä½¬çœ‹çœ‹&#013;&#010;&gt; &gt;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; &gt;&gt; ç¥å¥½ï¼Œ&#013;&#010;&gt; &gt;&gt; &gt;&gt; Leonard Xu&#013;&#010;&gt; &gt;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; &gt;&gt; &gt; åœ¨ 2020å¹´7æœˆ16æ—¥ï¼Œ23:08ï¼Œsunfulin &lt;sunfulin0321@163.com&gt;&#010;å†™é“ï¼š&#013;&#010;&gt; &gt;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt; &gt;&gt; &gt; hiï¼Œ&#013;&#010;&gt; &gt;&gt; &gt;&gt; &gt; è¯·æ•™ä¸‹flink 1.11ä»»åŠ¡æäº¤çš„é—®é¢˜ã€‚å¦‚æœæˆ‘çš„ä¸€ä¸ªä½œä¸šé‡Œæ—¢æœ‰sql&#013;&#010;&gt; &gt;&gt; &gt;&gt; dmlæäº¤ï¼ˆexecuteSQLæ‰§è¡Œï¼‰ï¼Œåˆé€šè¿‡DataStream.addSinkæ¥å†™å‡ºï¼Œ&#013;&#010;&gt; &gt;&gt; &gt;&gt; &gt; é€šè¿‡StreamExecutionEnvironment.executeæäº¤ï¼Œyarn&#013;&#010;&gt; &gt;&gt; &gt;&gt; per-jobè²Œä¼¼ä¼šæäº¤ä¸¤ä¸ªä½œä¸šã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿåªæƒ³æäº¤ä¸€ä¸ªä½œä¸šã€‚&#013;&#010;&gt; &gt;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "7",
        "reply": "<42395c4a.796e.173582b0e2a.Coremail.sunfulin0321@163.com>"
    },
    {
        "id": "<CAEZk042OK8ZcSgkGKB6_y8yzb1Z4znNwksPst2afWDfv3UMJxQ@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 02:12:31 GMT",
        "subject": "flink1.9å†™æƒé™è®¤è¯çš„es6",
        "content": "hiï¼š&#013;&#010;è¯·é—®flinkå¦‚ä½•å°†æ•°æ®å†™å…¥åˆ°æƒé™è®¤è¯çš„esé›†ç¾¤å“ªï¼Œæ²¡æ‰¾åˆ°é…ç½®ç”¨æˆ·åå¯†ç çš„åœ°æ–¹ï¼Œå“ªä½å¤§ä½¬å¸®å¿™è§£ç­”ä¸€ä¸‹ã€‚ã€‚ã€‚ã€‚&#013;&#010;",
        "depth": "0",
        "reply": "<CAEZk042OK8ZcSgkGKB6_y8yzb1Z4znNwksPst2afWDfv3UMJxQ@mail.gmail.com>"
    },
    {
        "id": "<80371ff2-ea0a-431e-8336-b9e8b38b426a.jkillers@dingtalk.com>",
        "from": "&quot;å¤å¸…&quot; &lt;jkill...@dingtalk.com.INVALID&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 02:49:48 GMT",
        "subject": "å›å¤ï¼šflink1.9å†™æƒé™è®¤è¯çš„es6",
        "content": "ä½ å¥½,è¯·é—®æ˜¯FlinkSQLä¹ˆ&#010;FLinkSQLå¯ä»¥å‚è€ƒä¸‹è¿™ä»½é‚®ä»¶&#010;http://apache-flink.147419.n8.nabble.com/ddl-es-td2094.html&#010;DataStreamå¯ä»¥å°è¯•è‡ªå®šä¹‰ElasticsearchSinkå®ç°æƒé™è®¤è¯&#010;&#010;&#010;------------------------------------------------------------------&#010;å‘ä»¶äººï¼šDream-åº•é™ &lt;zhangyu@akulaku.com&gt;&#010;å‘é€æ—¶é—´ï¼š2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) 10:12&#010;æ”¶ä»¶äººï¼šuser-zh &lt;user-zh@flink.apache.org&gt;&#010;ä¸»ã€€é¢˜ï¼šflink1.9å†™æƒé™è®¤è¯çš„es6&#010;&#010;hiï¼š&#010;è¯·é—®flinkå¦‚ä½•å°†æ•°æ®å†™å…¥åˆ°æƒé™è®¤è¯çš„esé›†ç¾¤å“ªï¼Œæ²¡æ‰¾åˆ°é…ç½®ç”¨æˆ·åå¯†ç çš„åœ°æ–¹ï¼Œå“ªä½å¤§ä½¬å¸®å¿™è§£ç­”ä¸€ä¸‹ã€‚ã€‚ã€‚ã€‚&#010;",
        "depth": "1",
        "reply": "<CAEZk042OK8ZcSgkGKB6_y8yzb1Z4znNwksPst2afWDfv3UMJxQ@mail.gmail.com>"
    },
    {
        "id": "<CAFTKPZpG5PQ-kGZhQrDeX4M-2Ux6dgMagEGouGi=XkMjJRTaSQ@mail.gmail.com>",
        "from": "Yangze Guo &lt;karma...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 05:38:35 GMT",
        "subject": "Re: flink1.9å†™æƒé™è®¤è¯çš„es6",
        "content": "Hi,&#013;&#010;&#013;&#010;SQLæ·»åŠ è®¤è¯çš„é€»è¾‘å·²ç»åœ¨FLINK-18361[1] ä¸­å®Œæˆäº†ï¼Œ1.12ç‰ˆæœ¬ä¼šæ”¯æŒè¿™ä¸ªåŠŸèƒ½&#013;&#010;&#013;&#010;[1] https://issues.apache.org/jira/browse/FLINK-18361&#013;&#010;&#013;&#010;Best,&#013;&#010;Yangze Guo&#013;&#010;&#013;&#010;On Fri, Jul 17, 2020 at 10:12 AM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt;&#013;&#010;&gt; hiï¼š&#013;&#010;&gt; è¯·é—®flinkå¦‚ä½•å°†æ•°æ®å†™å…¥åˆ°æƒé™è®¤è¯çš„esé›†ç¾¤å“ªï¼Œæ²¡æ‰¾åˆ°é…ç½®ç”¨æˆ·åå¯†ç çš„åœ°æ–¹ï¼Œå“ªä½å¤§ä½¬å¸®å¿™è§£ç­”ä¸€ä¸‹ã€‚ã€‚ã€‚ã€‚&#013;&#010;",
        "depth": "1",
        "reply": "<CAEZk042OK8ZcSgkGKB6_y8yzb1Z4znNwksPst2afWDfv3UMJxQ@mail.gmail.com>"
    },
    {
        "id": "<12099057-288b-4d58-b57d-161b28976755.jkillers@dingtalk.com>",
        "from": "&quot;å¤å¸…&quot; &lt;jkill...@dingtalk.com.INVALID&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 05:57:06 GMT",
        "subject": "å›å¤ï¼š flink1.9å†™æƒé™è®¤è¯çš„es6",
        "content": "getåˆ°äº†&#010;&#010;&#010;&#010;&#010;&#010;æ¥è‡ªé’‰é’‰ä¸“å±å•†åŠ¡é‚®ç®±------------------------------------------------------------------&#010;å‘ä»¶äººï¼šYangze Guo&lt;karmagyz@gmail.com&gt;&#010;æ—¥ã€€æœŸï¼š2020å¹´07æœˆ17æ—¥ 13:38:35&#010;æ”¶ä»¶äººï¼šuser-zh&lt;user-zh@flink.apache.org&gt;&#010;ä¸»ã€€é¢˜ï¼šRe: flink1.9å†™æƒé™è®¤è¯çš„es6&#010;&#010;Hi,&#010;&#010;SQLæ·»åŠ è®¤è¯çš„é€»è¾‘å·²ç»åœ¨FLINK-18361[1] ä¸­å®Œæˆäº†ï¼Œ1.12ç‰ˆæœ¬ä¼šæ”¯æŒè¿™ä¸ªåŠŸèƒ½&#010;&#010;[1] https://issues.apache.org/jira/browse/FLINK-18361&#010;&#010;Best,&#010;Yangze Guo&#010;&#010;On Fri, Jul 17, 2020 at 10:12 AM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&gt;&#010;&gt; hiï¼š&#010;&gt; è¯·é—®flinkå¦‚ä½•å°†æ•°æ®å†™å…¥åˆ°æƒé™è®¤è¯çš„esé›†ç¾¤å“ªï¼Œæ²¡æ‰¾åˆ°é…ç½®ç”¨æˆ·åå¯†ç çš„åœ°æ–¹ï¼Œå“ªä½å¤§ä½¬å¸®å¿™è§£ç­”ä¸€ä¸‹ã€‚ã€‚ã€‚ã€‚&#010;&#010;",
        "depth": "1",
        "reply": "<CAEZk042OK8ZcSgkGKB6_y8yzb1Z4znNwksPst2afWDfv3UMJxQ@mail.gmail.com>"
    },
    {
        "id": "<fa6b4f0.5c1b.1735aa6962d.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 02:42:13 GMT",
        "subject": "flink connector formatsé—®é¢˜",
        "content": "è¯·é—®flinkå¯ä»¥è‡ªå®šä¹‰formatå—ï¼Œç›®å‰æä¾›çš„formatå¿…é¡»è¦è¿›è¡Œä¸€æ¬¡æ•°æ®è¿‡æ»¤ä¸ºè§„åˆ™æ•°æ®æ‰è¡Œï¼Œå¯ä¸å¯ä»¥è‡ªå®šä¹‰formatå®ç°è‡ªå·±çš„æ•°æ®æ ¼å¼sourceå‘¢ï¼Ÿ&#010;ç›®å‰flinkæ”¯æŒçš„ï¼š&#010;| æ ¼å¼ | æ”¯æŒçš„è¿æ¥å™¨ |&#010;| CSV | Apache Kafka, Filesystem |&#010;| JSON | Apache Kafka, Filesystem, Elasticsearch |&#010;| Apache Avro | Apache Kafka, Filesystem |&#010;| Debezium CDC | Apache Kafka |&#010;| Canal CDC | Apache Kafka |&#010;| Apache Parquet | Filesystem |&#010;| Apache ORC | Filesystem |",
        "depth": "0",
        "reply": "<fa6b4f0.5c1b.1735aa6962d.Coremail.apache22@163.com>"
    },
    {
        "id": "<1da74e7d-4640-49a4-82eb-37fdaf80f0f5.jkillers@dingtalk.com>",
        "from": "&quot;å¤å¸…&quot; &lt;jkill...@dingtalk.com.INVALID&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 02:47:36 GMT",
        "subject": "å›å¤ï¼šflink connector formatsé—®é¢˜",
        "content": "ä½ å¥½,è¿™ä¸ªæ˜¯å¯ä»¥è¿›è¡Œè‡ªå®šä¹‰çš„&#010;å‚è€ƒhttps://jxeditor.github.io/2020/06/11/FlinkSQL%E8%87%AA%E5%AE%9A%E4%B9%89FORMAT_TYPE/&#010;&#010;&#010;------------------------------------------------------------------&#010;å‘ä»¶äººï¼šé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt;&#010;å‘é€æ—¶é—´ï¼š2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) 10:42&#010;æ”¶ä»¶äººï¼šuser-zh &lt;user-zh@flink.apache.org&gt;&#010;ä¸»ã€€é¢˜ï¼šflink connector formatsé—®é¢˜&#010;&#010;è¯·é—®flinkå¯ä»¥è‡ªå®šä¹‰formatå—ï¼Œç›®å‰æä¾›çš„formatå¿…é¡»è¦è¿›è¡Œä¸€æ¬¡æ•°æ®è¿‡æ»¤ä¸ºè§„åˆ™æ•°æ®æ‰è¡Œï¼Œå¯ä¸å¯ä»¥è‡ªå®šä¹‰formatå®ç°è‡ªå·±çš„æ•°æ®æ ¼å¼sourceå‘¢ï¼Ÿ&#010;ç›®å‰flinkæ”¯æŒçš„ï¼š&#010;| æ ¼å¼ | æ”¯æŒçš„è¿æ¥å™¨ |&#010;| CSV | Apache Kafka, Filesystem |&#010;| JSON | Apache Kafka, Filesystem, Elasticsearch |&#010;| Apache Avro | Apache Kafka, Filesystem |&#010;| Debezium CDC | Apache Kafka |&#010;| Canal CDC | Apache Kafka |&#010;| Apache Parquet | Filesystem |&#010;| Apache ORC | Filesystem |",
        "depth": "1",
        "reply": "<fa6b4f0.5c1b.1735aa6962d.Coremail.apache22@163.com>"
    },
    {
        "id": "<3bb142b8.5de8.1735ab4862b.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 02:57:27 GMT",
        "subject": "å›å¤ï¼šflink connector formatsé—®é¢˜",
        "content": "&#010;&#010;æˆ‘çœ‹æ‚¨å†™äº†'format.type' = â€˜custom'ï¼Œè¿™ä¸ªcustom æ˜¯è·Ÿå“ªé‡Œå…³è”çš„å‘¢ï¼Ÿ è¿˜æ˜¯è¯´è¿™é‡Œè¦å†™ç±»è·¯å¾„ï¼Ÿ&#010;&#010;&#010;åœ¨2020å¹´07æœˆ17æ—¥ 10:47ï¼Œå¤å¸…&lt;jkillers@dingtalk.com.INVALID&gt; å†™é“ï¼š&#010;ä½ å¥½,è¿™ä¸ªæ˜¯å¯ä»¥è¿›è¡Œè‡ªå®šä¹‰çš„&#010;å‚è€ƒhttps://jxeditor.github.io/2020/06/11/FlinkSQL%E8%87%AA%E5%AE%9A%E4%B9%89FORMAT_TYPE/&#010;&#010;&#010;------------------------------------------------------------------&#010;å‘ä»¶äººï¼šé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt;&#010;å‘é€æ—¶é—´ï¼š2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) 10:42&#010;æ”¶ä»¶äººï¼šuser-zh &lt;user-zh@flink.apache.org&gt;&#010;ä¸»ã€€é¢˜ï¼šflink connector formatsé—®é¢˜&#010;&#010;è¯·é—®flinkå¯ä»¥è‡ªå®šä¹‰formatå—ï¼Œç›®å‰æä¾›çš„formatå¿…é¡»è¦è¿›è¡Œä¸€æ¬¡æ•°æ®è¿‡æ»¤ä¸ºè§„åˆ™æ•°æ®æ‰è¡Œï¼Œå¯ä¸å¯ä»¥è‡ªå®šä¹‰formatå®ç°è‡ªå·±çš„æ•°æ®æ ¼å¼sourceå‘¢ï¼Ÿ&#010;ç›®å‰flinkæ”¯æŒçš„ï¼š&#010;| æ ¼å¼ | æ”¯æŒçš„è¿æ¥å™¨ |&#010;| CSV | Apache Kafka, Filesystem |&#010;| JSON | Apache Kafka, Filesystem, Elasticsearch |&#010;| Apache Avro | Apache Kafka, Filesystem |&#010;| Debezium CDC | Apache Kafka |&#010;| Canal CDC | Apache Kafka |&#010;| Apache Parquet | Filesystem |&#010;| Apache ORC | Filesystem |",
        "depth": "2",
        "reply": "<fa6b4f0.5c1b.1735aa6962d.Coremail.apache22@163.com>"
    },
    {
        "id": "<23626b48.603a.1735ac73ca0.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 03:17:53 GMT",
        "subject": "å›å¤ï¼šflink connector formatsé—®é¢˜",
        "content": "æ‰¾åˆ°äº†ï¼Œè°¢è°¢&#010;&#010;&#010;| |&#010;apache22&#010;|&#010;|&#010;apache22@163.com&#010;|&#010;ç­¾åç”±ç½‘æ˜“é‚®ç®±å¤§å¸ˆå®šåˆ¶&#010;&#010;&#010;åœ¨2020å¹´07æœˆ17æ—¥ 10:57ï¼Œé…·é…·çš„æµ‘è›‹&lt;apache22@163.com&gt; å†™é“ï¼š&#010;&#010;&#010;æˆ‘çœ‹æ‚¨å†™äº†'format.type' = â€˜custom'ï¼Œè¿™ä¸ªcustom æ˜¯è·Ÿå“ªé‡Œå…³è”çš„å‘¢ï¼Ÿ è¿˜æ˜¯è¯´è¿™é‡Œè¦å†™ç±»è·¯å¾„ï¼Ÿ&#010;&#010;&#010;åœ¨2020å¹´07æœˆ17æ—¥ 10:47ï¼Œå¤å¸…&lt;jkillers@dingtalk.com.INVALID&gt; å†™é“ï¼š&#010;ä½ å¥½,è¿™ä¸ªæ˜¯å¯ä»¥è¿›è¡Œè‡ªå®šä¹‰çš„&#010;å‚è€ƒhttps://jxeditor.github.io/2020/06/11/FlinkSQL%E8%87%AA%E5%AE%9A%E4%B9%89FORMAT_TYPE/&#010;&#010;&#010;------------------------------------------------------------------&#010;å‘ä»¶äººï¼šé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt;&#010;å‘é€æ—¶é—´ï¼š2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) 10:42&#010;æ”¶ä»¶äººï¼šuser-zh &lt;user-zh@flink.apache.org&gt;&#010;ä¸»ã€€é¢˜ï¼šflink connector formatsé—®é¢˜&#010;&#010;è¯·é—®flinkå¯ä»¥è‡ªå®šä¹‰formatå—ï¼Œç›®å‰æä¾›çš„formatå¿…é¡»è¦è¿›è¡Œä¸€æ¬¡æ•°æ®è¿‡æ»¤ä¸ºè§„åˆ™æ•°æ®æ‰è¡Œï¼Œå¯ä¸å¯ä»¥è‡ªå®šä¹‰formatå®ç°è‡ªå·±çš„æ•°æ®æ ¼å¼sourceå‘¢ï¼Ÿ&#010;ç›®å‰flinkæ”¯æŒçš„ï¼š&#010;| æ ¼å¼ | æ”¯æŒçš„è¿æ¥å™¨ |&#010;| CSV | Apache Kafka, Filesystem |&#010;| JSON | Apache Kafka, Filesystem, Elasticsearch |&#010;| Apache Avro | Apache Kafka, Filesystem |&#010;| Debezium CDC | Apache Kafka |&#010;| Canal CDC | Apache Kafka |&#010;| Apache Parquet | Filesystem |&#010;| Apache ORC | Filesystem |",
        "depth": "3",
        "reply": "<fa6b4f0.5c1b.1735aa6962d.Coremail.apache22@163.com>"
    },
    {
        "id": "<202007171301599643296@geekplus.com.cn>",
        "from": "&quot;wanglei2@geekplus.com.cn&quot; &lt;wangl...@geekplus.com.cn&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 05:02:00 GMT",
        "subject": "flink-1.11  KafkaDynamicTableSouce groupBy ç»“æœæ€æ ·å‘é€åˆ° kafka",
        "content": "&#013;&#010; INSERT INTO kafka_dws_artemis_out_order select warehouse_id, count(*) from kafka_ods_artemis_out_order&#010;group by warehouse_id;&#013;&#010;[ERROR] Could not execute SQL statement. Reason:&#013;&#010;org.apache.flink.table.api.TableException: Table sink 'myhive.wanglei.kafka_dws_artemis_out_order'&#010;doesn't support consuming update changes which is produced by node GroupAggregate(groupBy=[warehouse_id],&#010;select=[warehouse_id, COUNT(*) AS EXPR$1])&#013;&#010;&#013;&#010;åœ¨ Flink-1.10 ä¸­å¯ä»¥æ›´æ”¹ KafkaTableSinkBase è®©å®ƒ implements RetractStream å®ç°ã€‚&#013;&#010; &#013;&#010;æˆ‘çœ‹ç°åœ¨ Flink-1.11 ä¸­æ˜¯ç”¨äº†  KafkaDynamicSourceï¼Œ KafkaDynamicSinkï¼Œè¿™æ ·æ€æ ·æ”¹åŠ¨æ‰èƒ½è®©&#010;GroupBy çš„ç»“æœä¹Ÿå‘é€åˆ° Kafka å‘¢ï¼Ÿ&#013;&#010;&#013;&#010;è°¢è°¢ï¼Œ&#013;&#010;ç‹ç£Š &#013;&#010;&#013;&#010;&#013;&#010;wanglei2@geekplus.com.cn &#013;&#010;&#013;&#010;",
        "depth": "0",
        "reply": "<202007171301599643296@geekplus.com.cn>"
    },
    {
        "id": "<CABKuJ_Q52Ky4s4zX_FQC_YB_ktwokaeriNjYjXTY+2P3rqD-gQ@mail.gmail.com>",
        "from": "Benchao Li &lt;libenc...@apache.org&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 12:18:14 GMT",
        "subject": "Re: flink-1.11 KafkaDynamicTableSouce groupBy ç»“æœæ€æ ·å‘é€åˆ° kafka",
        "content": "DynamicTableSinkæœ‰ä¸€ä¸ªæ–¹æ³•æ˜¯getChangelogModeï¼Œå¯ä»¥é€šè¿‡è¿™ä¸ªæ–¹æ³•æ¥æŒ‡å®šè¿™ä¸ªsinkæ¥æ”¶ä»€ä¹ˆç§ç±»çš„æ•°æ®&#013;&#010;&#013;&#010;wanglei2@geekplus.com.cn &lt;wanglei2@geekplus.com.cn&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ1:02å†™é“ï¼š&#013;&#010;&#013;&#010;&gt;&#013;&#010;&gt;  INSERT INTO kafka_dws_artemis_out_order select warehouse_id, count(*)&#013;&#010;&gt; from kafka_ods_artemis_out_order group by warehouse_id;&#013;&#010;&gt; [ERROR] Could not execute SQL statement. Reason:&#013;&#010;&gt; org.apache.flink.table.api.TableException: Table sink&#013;&#010;&gt; 'myhive.wanglei.kafka_dws_artemis_out_order' doesn't support consuming&#013;&#010;&gt; update changes which is produced by node&#013;&#010;&gt; GroupAggregate(groupBy=[warehouse_id], select=[warehouse_id, COUNT(*) AS&#013;&#010;&gt; EXPR$1])&#013;&#010;&gt;&#013;&#010;&gt; åœ¨ Flink-1.10 ä¸­å¯ä»¥æ›´æ”¹ KafkaTableSinkBase è®©å®ƒ implements RetractStream å®ç°ã€‚&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘çœ‹ç°åœ¨ Flink-1.11 ä¸­æ˜¯ç”¨äº†  KafkaDynamicSourceï¼Œ KafkaDynamicSinkï¼Œè¿™æ ·æ€æ ·æ”¹åŠ¨æ‰èƒ½è®©&#013;&#010;&gt; GroupBy çš„ç»“æœä¹Ÿå‘é€åˆ° Kafka å‘¢ï¼Ÿ&#013;&#010;&gt;&#013;&#010;&gt; è°¢è°¢ï¼Œ&#013;&#010;&gt; ç‹ç£Š&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; wanglei2@geekplus.com.cn&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&#013;&#010;-- &#013;&#010;&#013;&#010;Best,&#013;&#010;Benchao Li&#013;&#010;",
        "depth": "1",
        "reply": "<202007171301599643296@geekplus.com.cn>"
    },
    {
        "id": "<2020072011084378469119@geekplus.com.cn>",
        "from": "&quot;wanglei2@geekplus.com.cn&quot; &lt;wangl...@geekplus.com.cn&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 03:08:44 GMT",
        "subject": "Re: Re: flink-1.11 KafkaDynamicTableSouce groupBy ç»“æœæ€æ ·å‘é€åˆ° kafka",
        "content": "&#013;&#010;è°¢è°¢ï¼Œæˆ‘ç›´æ¥æ›´æ”¹äº† KafkaDynamicSinkBase çš„ getChangelogMode æ–¹æ³•, æ˜¯å¯ä»¥å®ç°ç›®çš„çš„ã€‚&#013;&#010;&#013;&#010;æ›´æ”¹å‰ï¼š&#013;&#010;public ChangelogMode getChangelogMode(ChangelogMode requestedMode) {&#013;&#010;    return this.encodingFormat.getChangelogMode();&#013;&#010;}&#013;&#010;æ›´æ”¹å:public ChangelogMode getChangelogMode(ChangelogMode requestedMode) {&#013;&#010;      return ChangelogMode.newBuilder()&#013;&#010;         .addContainedKind(RowKind.INSERT)&#013;&#010;         .addContainedKind(RowKind.UPDATE_AFTER)&#013;&#010;         .build();&#013;&#010;   }è€Œä¸”è¿™æ ·æ›´æ”¹ä»¥å UPDATE_BEFORE çš„è®°å½•è¢«è¿‡æ»¤æ‰äº†ï¼Œæ²¡æœ‰è¢«å‘é€åˆ° Kafka&#013;&#010;è°¢è°¢ï¼Œç‹ç£Š&#013;&#010;&#013;&#010;&#013;&#010;wanglei2@geekplus.com.cn &#013;&#010;&#013;&#010; &#013;&#010;Sender: Benchao Li&#013;&#010;Send Time: 2020-07-17 20:18&#013;&#010;Receiver: user-zh&#013;&#010;Subject: Re: flink-1.11 KafkaDynamicTableSouce groupBy ç»“æœæ€æ ·å‘é€åˆ° kafka&#013;&#010;DynamicTableSinkæœ‰ä¸€ä¸ªæ–¹æ³•æ˜¯getChangelogModeï¼Œå¯ä»¥é€šè¿‡è¿™ä¸ªæ–¹æ³•æ¥æŒ‡å®šè¿™ä¸ªsinkæ¥æ”¶ä»€ä¹ˆç§ç±»çš„æ•°æ®&#013;&#010; &#013;&#010;wanglei2@geekplus.com.cn &lt;wanglei2@geekplus.com.cn&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ1:02å†™é“ï¼š&#013;&#010; &#013;&#010;&gt;&#013;&#010;&gt;  INSERT INTO kafka_dws_artemis_out_order select warehouse_id, count(*)&#013;&#010;&gt; from kafka_ods_artemis_out_order group by warehouse_id;&#013;&#010;&gt; [ERROR] Could not execute SQL statement. Reason:&#013;&#010;&gt; org.apache.flink.table.api.TableException: Table sink&#013;&#010;&gt; 'myhive.wanglei.kafka_dws_artemis_out_order' doesn't support consuming&#013;&#010;&gt; update changes which is produced by node&#013;&#010;&gt; GroupAggregate(groupBy=[warehouse_id], select=[warehouse_id, COUNT(*) AS&#013;&#010;&gt; EXPR$1])&#013;&#010;&gt;&#013;&#010;&gt; åœ¨ Flink-1.10 ä¸­å¯ä»¥æ›´æ”¹ KafkaTableSinkBase è®©å®ƒ implements RetractStream å®ç°ã€‚&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘çœ‹ç°åœ¨ Flink-1.11 ä¸­æ˜¯ç”¨äº†  KafkaDynamicSourceï¼Œ KafkaDynamicSinkï¼Œè¿™æ ·æ€æ ·æ”¹åŠ¨æ‰èƒ½è®©&#013;&#010;&gt; GroupBy çš„ç»“æœä¹Ÿå‘é€åˆ° Kafka å‘¢ï¼Ÿ&#013;&#010;&gt;&#013;&#010;&gt; è°¢è°¢ï¼Œ&#013;&#010;&gt; ç‹ç£Š&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; wanglei2@geekplus.com.cn&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010; &#013;&#010;-- &#013;&#010; &#013;&#010;Best,&#013;&#010;Benchao Li&#013;&#010;",
        "depth": "1",
        "reply": "<202007171301599643296@geekplus.com.cn>"
    },
    {
        "id": "<tencent_806F808F82910E078458CC820180887CBC07@qq.com>",
        "from": "&quot;kcz&quot; &lt;573693...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 05:32:18 GMT",
        "subject": "flink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function",
        "content": "standalone&amp;nbsp;&#013;&#010;lib&amp;nbsp; jaråŒ…å¦‚ä¸‹&#013;&#010;flink-connector-hive_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; flink-json-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; flink-sql-connector-kafka_2.12-1.11.0.jar&amp;nbsp; log4j-api-2.12.1.jar&#013;&#010;flink-csv-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; flink-parquet_2.11-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; flink-table_2.11-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; log4j-core-2.12.1.jar&#013;&#010;flink-dist_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; flink-shaded-hadoop-2-uber-2.7.2.11-9.0.jar&amp;nbsp; flink-table-blink_2.11-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; log4j-slf4j-impl-2.12.1.jar&#013;&#010;flink-hadoop-compatibility_2.11-1.11.0.jar&amp;nbsp; flink-shaded-zookeeper-3.4.14.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; log4j-1.2-api-2.12.1.jar&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;ä»£ç å¦‚ä¸‹ï¼šideaä¸‹ä¸æŠ¥é”™&#013;&#010;StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&#013;&#010;StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);&#013;&#010;env.setParallelism(1);&#013;&#010;env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#013;&#010;// åŒä¸€æ—¶é—´åªå…è®¸è¿›è¡Œä¸€ä¸ªæ£€æŸ¥ç‚¹&#013;&#010;env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);;&#013;&#010;env.setStateBackend(new FsStateBackend(path));&#013;&#010;&#013;&#010;tableEnv.executeSql(\"CREATE TABLE source_table (\\n\" +&#013;&#010;        \"\\thost STRING,\\n\" +&#013;&#010;        \"\\turl STRING,\\n\" +&#013;&#010;        \"\\tpublic_date STRING\\n\" +&#013;&#010;        \") WITH (\\n\" +&#013;&#010;        \"\\t'connector.type' = 'kafka',\\n\" +&#013;&#010;        \"\\t'connector.version' = 'universal',\\n\" +&#013;&#010;        \"\\t'connector.startup-mode' = 'latest-offset',\\n\" +&#013;&#010;        \"\\t'connector.topic' = 'test_flink_1.11',\\n\" +&#013;&#010;        \"\\t'connector.properties.group.id' = 'domain_testGroup',\\n\" +&#013;&#010;        \"\\t'connector.properties.zookeeper.connect' = '127.0.0.1:2181',\\n\" +&#013;&#010;        \"\\t'connector.properties.bootstrap.servers' = '127.0.0.1:9092',\\n\" +&#013;&#010;        \"\\t'update-mode' = 'append',\\n\" +&#013;&#010;        \"\\t'format.type' = 'json',\\n\" +&#013;&#010;        \"\\t'format.derive-schema' = 'true'\\n\" +&#013;&#010;        \")\");&#013;&#010;&#013;&#010;tableEnv.executeSql(\"CREATE TABLE fs_table (\\n\" +&#013;&#010;        \"  host STRING,\\n\" +&#013;&#010;        \"  url STRING,\\n\" +&#013;&#010;        \"  public_date STRING\\n\" +&#013;&#010;        \") PARTITIONED BY (public_date) WITH (\\n\" +&#013;&#010;        \"  'connector'='filesystem',\\n\" +&#013;&#010;        \"  'path'='path',\\n\" +&#013;&#010;        \"  'format'='json',\\n\" +&#013;&#010;        \"  'sink.partition-commit.delay'='0s',\\n\" +&#013;&#010;        \"  'sink.partition-commit.policy.kind'='success-file'\\n\" +&#013;&#010;        \")\");&#013;&#010;&#013;&#010;tableEnv.executeSql(\"INSERT INTO  fs_table SELECT host, url, DATE_FORMAT(public_date, 'yyyy-MM-dd')&#010;FROM source_table\");&#013;&#010;TableResult result = tableEnv.executeSql(\"SELECT * FROM fs_table \");&#013;&#010;result.print();&#013;&#010;æŠ¥é”™å¦‚ä¸‹&#013;&#010;org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot instantiate user function.&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:291)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;at org.apache.flink.streaming.runtime.tasks.OperatorChain.&lt;init&amp;gt;(OperatorChain.java:126)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:453)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:522)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:721)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:546)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;at java.lang.Thread.run(Thread.java:745)&#013;&#010;Caused by: java.lang.ClassCastException: cannot assign instance of org.apache.commons.collections.map.LinkedMap&#010;to field &#013;&#010;&#013;&#010;&#013;&#010;ç¬¬äºŒä¸ªbug sinkåˆ°hdfsæ—¶å€™ï¼Œé‡‡ç”¨parquetæ—¶å€™ï¼Œlibä¸‹é¢æœ‰parquetåŒ…ï¼Œpomé‡Œé¢æ˜¯providedï¼Œä½†æ˜¯ä¼šæç¤ºè¿™ä¸ªerrorï¼Œä¹Ÿè¯•è¿‡pomé‡Œé¢ä¸æ˜¯providedï¼Œè¿˜æ˜¯ä¸OK",
        "depth": "0",
        "reply": "<tencent_806F808F82910E078458CC820180887CBC07@qq.com>"
    },
    {
        "id": "<tencent_F60E4AB13605A90023F965DF5F1F0B231508@qq.com>",
        "from": "&quot;kcz&quot; &lt;573693...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 06:17:01 GMT",
        "subject": "å›å¤ï¼šflink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function",
        "content": "ç¬¬ä¸€ä¸ªbugæç¤ºåªéœ€è¦&#013;&#010;classloader.resolve-order: parent-first&#013;&#010;ç¬¬äºŒä¸ªbugé‡‡ç”¨äº†parquetè¿˜æ²¡è§£å†³&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"kcz\"                                            &#010;                                       &lt;573693104@qq.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) ä¸­åˆ1:32&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;flink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;standalone &#013;&#010;lib&amp;nbsp; jaråŒ…å¦‚ä¸‹&#013;&#010;flink-connector-hive_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; flink-json-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; flink-sql-connector-kafka_2.12-1.11.0.jar&amp;nbsp; log4j-api-2.12.1.jar&#013;&#010;flink-csv-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; flink-parquet_2.11-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; flink-table_2.11-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; log4j-core-2.12.1.jar&#013;&#010;flink-dist_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; flink-shaded-hadoop-2-uber-2.7.2.11-9.0.jar&amp;nbsp; flink-table-blink_2.11-1.11.0.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; log4j-slf4j-impl-2.12.1.jar&#013;&#010;flink-hadoop-compatibility_2.11-1.11.0.jar&amp;nbsp; flink-shaded-zookeeper-3.4.14.jar&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; log4j-1.2-api-2.12.1.jar&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;ä»£ç å¦‚ä¸‹ï¼šideaä¸‹ä¸æŠ¥é”™&#013;&#010;StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&#013;&#010;StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);&#013;&#010;env.setParallelism(1);&#013;&#010;env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#013;&#010;// åŒä¸€æ—¶é—´åªå…è®¸è¿›è¡Œä¸€ä¸ªæ£€æŸ¥ç‚¹&#013;&#010;env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);;&#013;&#010;env.setStateBackend(new FsStateBackend(path));&#013;&#010;&#013;&#010;tableEnv.executeSql(\"CREATE TABLE source_table (\\n\" +&#013;&#010;        \"\\thost STRING,\\n\" +&#013;&#010;        \"\\turl STRING,\\n\" +&#013;&#010;        \"\\tpublic_date STRING\\n\" +&#013;&#010;        \") WITH (\\n\" +&#013;&#010;        \"\\t'connector.type' = 'kafka',\\n\" +&#013;&#010;        \"\\t'connector.version' = 'universal',\\n\" +&#013;&#010;        \"\\t'connector.startup-mode' = 'latest-offset',\\n\" +&#013;&#010;        \"\\t'connector.topic' = 'test_flink_1.11',\\n\" +&#013;&#010;        \"\\t'connector.properties.group.id' = 'domain_testGroup',\\n\" +&#013;&#010;        \"\\t'connector.properties.zookeeper.connect' = '127.0.0.1:2181',\\n\" +&#013;&#010;        \"\\t'connector.properties.bootstrap.servers' = '127.0.0.1:9092',\\n\" +&#013;&#010;        \"\\t'update-mode' = 'append',\\n\" +&#013;&#010;        \"\\t'format.type' = 'json',\\n\" +&#013;&#010;        \"\\t'format.derive-schema' = 'true'\\n\" +&#013;&#010;        \")\");&#013;&#010;&#013;&#010;tableEnv.executeSql(\"CREATE TABLE fs_table (\\n\" +&#013;&#010;        \"  host STRING,\\n\" +&#013;&#010;        \"  url STRING,\\n\" +&#013;&#010;        \"  public_date STRING\\n\" +&#013;&#010;        \") PARTITIONED BY (public_date) WITH (\\n\" +&#013;&#010;        \"  'connector'='filesystem',\\n\" +&#013;&#010;        \"  'path'='path',\\n\" +&#013;&#010;        \"  'format'='json',\\n\" +&#013;&#010;        \"  'sink.partition-commit.delay'='0s',\\n\" +&#013;&#010;        \"  'sink.partition-commit.policy.kind'='success-file'\\n\" +&#013;&#010;        \")\");&#013;&#010;&#013;&#010;tableEnv.executeSql(\"INSERT INTO  fs_table SELECT host, url, DATE_FORMAT(public_date, 'yyyy-MM-dd')&#010;FROM source_table\");&#013;&#010;TableResult result = tableEnv.executeSql(\"SELECT * FROM fs_table \");&#013;&#010;result.print();&#013;&#010;æŠ¥é”™å¦‚ä¸‹&#013;&#010;org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot instantiate user function.&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:291)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.streaming.runtime.tasks.OperatorChain.&lt;init&amp;gt;(OperatorChain.java:126)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:453)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:522)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:721)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:546)&#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:745)&#013;&#010;Caused by: java.lang.ClassCastException: cannot assign instance of org.apache.commons.collections.map.LinkedMap&#010;to field &#013;&#010;&#013;&#010;&#013;&#010;ç¬¬äºŒä¸ªbug sinkåˆ°hdfsæ—¶å€™ï¼Œé‡‡ç”¨parquetæ—¶å€™ï¼Œlibä¸‹é¢æœ‰parquetåŒ…ï¼Œpomé‡Œé¢æ˜¯providedï¼Œä½†æ˜¯ä¼šæç¤ºè¿™ä¸ªerrorï¼Œä¹Ÿè¯•è¿‡pomé‡Œé¢ä¸æ˜¯providedï¼Œè¿˜æ˜¯ä¸OK",
        "depth": "1",
        "reply": "<tencent_806F808F82910E078458CC820180887CBC07@qq.com>"
    },
    {
        "id": "<CADQYLGvJmcB-EUnWV4GenPQ+08vRX58ruvsmmvRfLcYyo01d1A@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 07:29:11 GMT",
        "subject": "Re: flink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function",
        "content": "ç¬¬äºŒä¸ªé—®é¢˜çš„å¼‚å¸¸æ ˆæ˜¯å•¥ï¼Ÿ&#010;&#010;kcz &lt;573693104@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:17å†™é“ï¼š&#010;&#010;&gt; ç¬¬ä¸€ä¸ªbugæç¤ºåªéœ€è¦&#010;&gt; classloader.resolve-order: parent-first&#010;&gt; ç¬¬äºŒä¸ªbugé‡‡ç”¨äº†parquetè¿˜æ²¡è§£å†³&#010;&gt;&#010;&gt;&#010;&gt; ------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;&gt; å‘ä»¶äºº:&#010;&gt;                                                   \"kcz\"&#010;&gt;                                                                 &lt;&#010;&gt; 573693104@qq.com&amp;gt;;&#010;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) ä¸­åˆ1:32&#010;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&gt;&#010;&gt; ä¸»é¢˜:&amp;nbsp;flink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; standalone&#010;&gt; lib&amp;nbsp; jaråŒ…å¦‚ä¸‹&#010;&gt; flink-connector-hive_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; flink-json-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; flink-sql-connector-kafka_2.12-1.11.0.jar&amp;nbsp; log4j-api-2.12.1.jar&#010;&gt; flink-csv-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; flink-parquet_2.11-1.11.0.jar&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; flink-table_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; log4j-core-2.12.1.jar&#010;&gt; flink-dist_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; flink-shaded-hadoop-2-uber-2.7.2.11-9.0.jar&amp;nbsp;&#010;&gt; flink-table-blink_2.11-1.11.0.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; log4j-slf4j-impl-2.12.1.jar&#010;&gt; flink-hadoop-compatibility_2.11-1.11.0.jar&amp;nbsp;&#010;&gt; flink-shaded-zookeeper-3.4.14.jar&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; log4j-1.2-api-2.12.1.jar&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; ä»£ç å¦‚ä¸‹ï¼šideaä¸‹ä¸æŠ¥é”™&#010;&gt; StreamExecutionEnvironment env =&#010;&gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);&#010;&gt; env.setParallelism(1);&#010;&gt; env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#010;&gt; // åŒä¸€æ—¶é—´åªå…è®¸è¿›è¡Œä¸€ä¸ªæ£€æŸ¥ç‚¹&#010;&gt; env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);;&#010;&gt; env.setStateBackend(new FsStateBackend(path));&#010;&gt;&#010;&gt; tableEnv.executeSql(\"CREATE TABLE source_table (\\n\" +&#010;&gt;         \"\\thost STRING,\\n\" +&#010;&gt;         \"\\turl STRING,\\n\" +&#010;&gt;         \"\\tpublic_date STRING\\n\" +&#010;&gt;         \") WITH (\\n\" +&#010;&gt;         \"\\t'connector.type' = 'kafka',\\n\" +&#010;&gt;         \"\\t'connector.version' = 'universal',\\n\" +&#010;&gt;         \"\\t'connector.startup-mode' = 'latest-offset',\\n\" +&#010;&gt;         \"\\t'connector.topic' = 'test_flink_1.11',\\n\" +&#010;&gt;         \"\\t'connector.properties.group.id' = 'domain_testGroup',\\n\" +&#010;&gt;         \"\\t'connector.properties.zookeeper.connect' = '127.0.0.1:2181',\\n\"&#010;&gt; +&#010;&gt;         \"\\t'connector.properties.bootstrap.servers' = '127.0.0.1:9092',\\n\"&#010;&gt; +&#010;&gt;         \"\\t'update-mode' = 'append',\\n\" +&#010;&gt;         \"\\t'format.type' = 'json',\\n\" +&#010;&gt;         \"\\t'format.derive-schema' = 'true'\\n\" +&#010;&gt;         \")\");&#010;&gt;&#010;&gt; tableEnv.executeSql(\"CREATE TABLE fs_table (\\n\" +&#010;&gt;         \"  host STRING,\\n\" +&#010;&gt;         \"  url STRING,\\n\" +&#010;&gt;         \"  public_date STRING\\n\" +&#010;&gt;         \") PARTITIONED BY (public_date) WITH (\\n\" +&#010;&gt;         \"  'connector'='filesystem',\\n\" +&#010;&gt;         \"  'path'='path',\\n\" +&#010;&gt;         \"  'format'='json',\\n\" +&#010;&gt;         \"  'sink.partition-commit.delay'='0s',\\n\" +&#010;&gt;         \"  'sink.partition-commit.policy.kind'='success-file'\\n\" +&#010;&gt;         \")\");&#010;&gt;&#010;&gt; tableEnv.executeSql(\"INSERT INTO  fs_table SELECT host, url,&#010;&gt; DATE_FORMAT(public_date, 'yyyy-MM-dd') FROM source_table\");&#010;&gt; TableResult result = tableEnv.executeSql(\"SELECT * FROM fs_table \");&#010;&gt; result.print();&#010;&gt; æŠ¥é”™å¦‚ä¸‹&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot&#010;&gt; instantiate user function.&#010;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:291)&#010;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.streaming.runtime.tasks.OperatorChain.&lt;init&amp;gt;(OperatorChain.java:126)&#010;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:453)&#010;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:522)&#010;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:721)&#010;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:546)&#010;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:745)&#010;&gt; Caused by: java.lang.ClassCastException: cannot assign instance of&#010;&gt; org.apache.commons.collections.map.LinkedMap to field&#010;&gt;&#010;&gt;&#010;&gt; ç¬¬äºŒä¸ªbug&#010;&gt; sinkåˆ°hdfsæ—¶å€™ï¼Œé‡‡ç”¨parquetæ—¶å€™ï¼Œlibä¸‹é¢æœ‰parquetåŒ…ï¼Œpomé‡Œé¢æ˜¯providedï¼Œä½†æ˜¯ä¼šæç¤ºè¿™ä¸ªerrorï¼Œä¹Ÿè¯•è¿‡pomé‡Œé¢ä¸æ˜¯providedï¼Œè¿˜æ˜¯ä¸OK&#010;&#010;",
        "depth": "2",
        "reply": "<tencent_806F808F82910E078458CC820180887CBC07@qq.com>"
    },
    {
        "id": "<tencent_C2BC1F3123620ED8B1DF0544009CF9CCDF08@qq.com>",
        "from": "&quot;kcz&quot; &lt;573693...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 08:05:02 GMT",
        "subject": "å›å¤ï¼š flink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function",
        "content": "è¿™æ˜¯ä½¿ç”¨äº†parquetçš„errorï¼š&#013;&#010;java.lang.NoClassDefFoundError: org/apache/parquet/hadoop/ParquetWriter$Builder&#013;&#010;&#009;at java.lang.ClassLoader.defineClass1(Native Method)&#013;&#010;&#009;at java.lang.ClassLoader.defineClass(ClassLoader.java:760)&#013;&#010;&#009;at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#013;&#010;&#009;at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#013;&#010;&#009;at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#013;&#010;&#009;at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#013;&#010;&#009;at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#013;&#010;&#009;at java.security.AccessController.doPrivileged(Native Method)&#013;&#010;&#009;at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#013;&#010;&#009;at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#013;&#010;&#009;at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#013;&#010;&#009;at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#013;&#010;&#009;at org.apache.flink.formats.parquet.ParquetFileSystemFormatFactory.createBulkWriterFactory(ParquetFileSystemFormatFactory.java:110)&#013;&#010;&#009;at org.apache.flink.table.filesystem.FileSystemTableSink.createWriter(FileSystemTableSink.java:274)&#013;&#010;&#009;at org.apache.flink.table.filesystem.FileSystemTableSink.consumeDataStream(FileSystemTableSink.java:154)&#013;&#010;&#009;at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:114)&#013;&#010;&#009;at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:48)&#013;&#010;&#009;at org.apache.flink.table.planner.plan.nodes.exec.ExecNode$class.translateToPlan(ExecNode.scala:58)&#013;&#010;&#009;at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlan(StreamExecLegacySink.scala:48)&#013;&#010;&#009;at org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:67)&#013;&#010;&#009;at org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:66)&#013;&#010;&#009;at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#013;&#010;&#009;at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#013;&#010;&#009;at scala.collection.Iterator$class.foreach(Iterator.scala:891)&#013;&#010;&#009;at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)&#013;&#010;&#009;at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)&#013;&#010;&#009;at scala.collection.AbstractIterable.foreach(Iterable.scala:54)&#013;&#010;&#009;at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)&#013;&#010;&#009;at scala.collection.AbstractTraversable.map(Traversable.scala:104)&#013;&#010;&#009;at org.apache.flink.table.planner.delegation.StreamPlanner.translateToPlan(StreamPlanner.scala:66)&#013;&#010;&#009;at org.apache.flink.table.planner.delegation.PlannerBase.translate(PlannerBase.scala:166)&#013;&#010;&#009;at org.apache.flink.table.api.internal.TableEnvironmentImpl.translate(TableEnvironmentImpl.java:1248)&#013;&#010;&#009;at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:694)&#013;&#010;&#009;at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeOperation(TableEnvironmentImpl.java:781)&#013;&#010;&#009;at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeSql(TableEnvironmentImpl.java:684)&#013;&#010;&#009;at com.HdfsDDL.main(HdfsDDL.java:71)&#013;&#010;&#009;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#013;&#010;&#009;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#013;&#010;&#009;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#013;&#010;&#009;at java.lang.reflect.Method.invoke(Method.java:497)&#013;&#010;&#009;at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#013;&#010;&#009;at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#013;&#010;&#009;at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#013;&#010;&#009;at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#013;&#010;&#009;at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#013;&#010;&#009;at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#013;&#010;&#009;at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#013;&#010;&#009;at org.apache.flink.client.cli.CliFrontend$$Lambda$67/388104475.call(Unknown Source)&#013;&#010;&#009;at org.apache.flink.runtime.security.contexts.HadoopSecurityContext$$Lambda$68/1470966439.run(Unknown&#010;Source)&#013;&#010;&#009;at java.security.AccessController.doPrivileged(Native Method)&#013;&#010;&#009;at javax.security.auth.Subject.doAs(Subject.java:422)&#013;&#010;&#009;at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1659)&#013;&#010;&#009;at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#013;&#010;&#009;at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#013;&#010;Caused by: java.lang.ClassNotFoundException: org.apache.parquet.hadoop.ParquetWriter$Builder&#013;&#010;&#009;at java.net.URLClassLoader.findClass(URLClassLoader.java:381)&#013;&#010;&#009;at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#013;&#010;&#009;at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)&#013;&#010;&#009;at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;godfreyhe@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) ä¸‹åˆ3:29&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: flink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;ç¬¬äºŒä¸ªé—®é¢˜çš„å¼‚å¸¸æ ˆæ˜¯å•¥ï¼Ÿ&#013;&#010;&#013;&#010;kcz &lt;573693104@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:17å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; ç¬¬ä¸€ä¸ªbugæç¤ºåªéœ€è¦&#013;&#010;&amp;gt; classloader.resolve-order: parent-first&#013;&#010;&amp;gt; ç¬¬äºŒä¸ªbugé‡‡ç”¨äº†parquetè¿˜æ²¡è§£å†³&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ------------------&amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;nbsp;------------------&#013;&#010;&amp;gt; å‘ä»¶äºº:&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;\"kcz\"&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&lt;&#013;&#010;&amp;gt; 573693104@qq.com&amp;amp;gt;;&#013;&#010;&amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) ä¸­åˆ1:32&#013;&#010;&amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ä¸»é¢˜:&amp;amp;nbsp;flink-1.11 DDL å†™å…¥hdfsé—®é¢˜ Cannot instantiate user function&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; standalone&#013;&#010;&amp;gt; lib&amp;amp;nbsp; jaråŒ…å¦‚ä¸‹&#013;&#010;&amp;gt; flink-connector-hive_2.11-1.11.0.jar&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; flink-json-1.11.0.jar&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; flink-sql-connector-kafka_2.12-1.11.0.jar&amp;amp;nbsp; log4j-api-2.12.1.jar&#013;&#010;&amp;gt; flink-csv-1.11.0.jar&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; flink-parquet_2.11-1.11.0.jar&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; flink-table_2.11-1.11.0.jar&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; log4j-core-2.12.1.jar&#013;&#010;&amp;gt; flink-dist_2.11-1.11.0.jar&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; flink-shaded-hadoop-2-uber-2.7.2.11-9.0.jar&amp;amp;nbsp;&#013;&#010;&amp;gt; flink-table-blink_2.11-1.11.0.jar&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; log4j-slf4j-impl-2.12.1.jar&#013;&#010;&amp;gt; flink-hadoop-compatibility_2.11-1.11.0.jar&amp;amp;nbsp;&#013;&#010;&amp;gt; flink-shaded-zookeeper-3.4.14.jar&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; log4j-1.2-api-2.12.1.jar&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ä»£ç å¦‚ä¸‹ï¼šideaä¸‹ä¸æŠ¥é”™&#013;&#010;&amp;gt; StreamExecutionEnvironment env =&#013;&#010;&amp;gt; StreamExecutionEnvironment.getExecutionEnvironment();&#013;&#010;&amp;gt; StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);&#013;&#010;&amp;gt; env.setParallelism(1);&#013;&#010;&amp;gt; env.enableCheckpointing(1000, CheckpointingMode.EXACTLY_ONCE);&#013;&#010;&amp;gt; // åŒä¸€æ—¶é—´åªå…è®¸è¿›è¡Œä¸€ä¸ªæ£€æŸ¥ç‚¹&#013;&#010;&amp;gt; env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);;&#013;&#010;&amp;gt; env.setStateBackend(new FsStateBackend(path));&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; tableEnv.executeSql(\"CREATE TABLE source_table (\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\thost&#010;STRING,\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\turl&#010;STRING,\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\tpublic_date&#010;STRING\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \")&#010;WITH (\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'connector.type'&#010;= 'kafka',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'connector.version'&#010;= 'universal',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'connector.startup-mode'&#010;= 'latest-offset',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'connector.topic'&#010;= 'test_flink_1.11',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'connector.properties.group.id'&#010;= 'domain_testGroup',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'connector.properties.zookeeper.connect'&#010;= '127.0.0.1:2181',\\n\"&#013;&#010;&amp;gt; +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'connector.properties.bootstrap.servers'&#010;= '127.0.0.1:9092',\\n\"&#013;&#010;&amp;gt; +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'update-mode'&#010;= 'append',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'format.type'&#010;= 'json',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"\\t'format.derive-schema'&#010;= 'true'\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \")\");&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; tableEnv.executeSql(\"CREATE TABLE fs_table (\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;host STRING,\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;url STRING,\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;public_date STRING\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \")&#010;PARTITIONED BY (public_date) WITH (\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;'connector'='filesystem',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;'path'='path',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;'format'='json',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;'sink.partition-commit.delay'='0s',\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"&amp;nbsp;&#010;'sink.partition-commit.policy.kind'='success-file'\\n\" +&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \")\");&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; tableEnv.executeSql(\"INSERT INTO&amp;nbsp; fs_table SELECT host, url,&#013;&#010;&amp;gt; DATE_FORMAT(public_date, 'yyyy-MM-dd') FROM source_table\");&#013;&#010;&amp;gt; TableResult result = tableEnv.executeSql(\"SELECT * FROM fs_table \");&#013;&#010;&amp;gt; result.print();&#013;&#010;&amp;gt; æŠ¥é”™å¦‚ä¸‹&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot&#013;&#010;&amp;gt; instantiate user function.&#013;&#010;&amp;gt; &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:291)&#013;&#010;&amp;gt; &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.OperatorChain.&lt;init&amp;amp;gt;(OperatorChain.java:126)&#013;&#010;&amp;gt; &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:453)&#013;&#010;&amp;gt; &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:522)&#013;&#010;&amp;gt; &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:721)&#013;&#010;&amp;gt; &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:546)&#013;&#010;&amp;gt; &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at java.lang.Thread.run(Thread.java:745)&#013;&#010;&amp;gt; Caused by: java.lang.ClassCastException: cannot assign instance of&#013;&#010;&amp;gt; org.apache.commons.collections.map.LinkedMap to field&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ç¬¬äºŒä¸ªbug&#013;&#010;&amp;gt; sinkåˆ°hdfsæ—¶å€™ï¼Œé‡‡ç”¨parquetæ—¶å€™ï¼Œlibä¸‹é¢æœ‰parquetåŒ…ï¼Œpomé‡Œé¢æ˜¯providedï¼Œä½†æ˜¯ä¼šæç¤ºè¿™ä¸ªerrorï¼Œä¹Ÿè¯•è¿‡pomé‡Œé¢ä¸æ˜¯providedï¼Œè¿˜æ˜¯ä¸OK",
        "depth": "3",
        "reply": "<tencent_806F808F82910E078458CC820180887CBC07@qq.com>"
    },
    {
        "id": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>",
        "from": "Luan Cooper &lt;gc.su...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 06:40:11 GMT",
        "subject": "SQL æŠ¥é”™åªæœ‰ flink runtime çš„ NPE",
        "content": "Hi&#010;&#010;æˆ‘æœ‰è¿™ä¹ˆä¸€ä¸ª SQL&#010;INSERT INTO es&#010;SELECT&#010;a,&#010;udf_xxx(b)&#010;FROM mongo_oplog -- è‡ªå®šä¹‰ TableFactory&#010;&#010;Job æäº¤å fail äº†ï¼Œä» Job æäº¤åˆ° Fail åªæœ‰ä¸€å¤„æ¥è‡ªéä¸šåŠ¡ä»£ç çš„ NPE å¦‚ä¸‹ï¼Œæ²¡æœ‰ä»»ä½•ä¸šåŠ¡ä»£ç &#010;Exceptionï¼Œå¯ä»¥ç¨³å®šé‡ç°&#010;&#010;LUE _UTF-16LE'v2'))) AS return_received_time]) (1/1)&#010;(bdf9b131f82a8ebc440165b82b89e570) switched from RUNNING to FAILED.&#010;&#010;java.lang.NullPointerException&#010;&#010;at StreamExecCalc$8016.split$7938$(Unknown Source)&#010;&#010;at StreamExecCalc$8016.processElement(Unknown Source)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:173)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:151)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:128)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:69)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:311)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:187)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:487)&#010;&#010;at&#010;org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:470)&#010;&#010;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&#010;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&#010;at java.lang.Thread.run(Thread.java:748)&#010;&#010;è¯·é—®è¿™ç§æ€æ ·æƒ…å†µæ’æŸ¥é—®é¢˜ï¼Ÿ&#010;æœ‰ä»»ä½•çº¿ç´¢éƒ½å¯ä»¥&#010;&#010;æ„Ÿè°¢&#010;&#010;",
        "depth": "0",
        "reply": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>"
    },
    {
        "id": "<CADQYLGtTYzi4q1B3kiYRv+kifnf8gMeskvUtyp9ZZgpXaFe8Sw@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 06:53:30 GMT",
        "subject": "Re: SQL æŠ¥é”™åªæœ‰ flink runtime çš„ NPE",
        "content": "udf_xxxçš„é€»è¾‘æ˜¯å•¥ï¼Ÿ&#010;&#010;&#010;Luan Cooper &lt;gc.suprs@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:40å†™é“ï¼š&#010;&#010;&gt; Hi&#010;&gt;&#010;&gt; æˆ‘æœ‰è¿™ä¹ˆä¸€ä¸ª SQL&#010;&gt; INSERT INTO es&#010;&gt; SELECT&#010;&gt; a,&#010;&gt; udf_xxx(b)&#010;&gt; FROM mongo_oplog -- è‡ªå®šä¹‰ TableFactory&#010;&gt;&#010;&gt; Job æäº¤å fail äº†ï¼Œä» Job æäº¤åˆ° Fail åªæœ‰ä¸€å¤„æ¥è‡ªéä¸šåŠ¡ä»£ç çš„&#010;NPE å¦‚ä¸‹ï¼Œæ²¡æœ‰ä»»ä½•ä¸šåŠ¡ä»£ç  Exceptionï¼Œå¯ä»¥ç¨³å®šé‡ç°&#010;&gt;&#010;&gt; LUE _UTF-16LE'v2'))) AS return_received_time]) (1/1)&#010;&gt; (bdf9b131f82a8ebc440165b82b89e570) switched from RUNNING to FAILED.&#010;&gt;&#010;&gt; java.lang.NullPointerException&#010;&gt;&#010;&gt; at StreamExecCalc$8016.split$7938$(Unknown Source)&#010;&gt;&#010;&gt; at StreamExecCalc$8016.processElement(Unknown Source)&#010;&gt;&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:173)&#010;&gt;&#010;&gt; at&#010;&gt; org.apache.flink.streaming.runtime.io&#010;&gt; .StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:151)&#010;&gt;&#010;&gt; at&#010;&gt; org.apache.flink.streaming.runtime.io&#010;&gt; .StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:128)&#010;&gt;&#010;&gt; at&#010;&gt; org.apache.flink.streaming.runtime.io&#010;&gt; .StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:69)&#010;&gt;&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:311)&#010;&gt;&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:187)&#010;&gt;&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:487)&#010;&gt;&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:470)&#010;&gt;&#010;&gt; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;&#010;&gt; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;&#010;&gt; at java.lang.Thread.run(Thread.java:748)&#010;&gt;&#010;&gt; è¯·é—®è¿™ç§æ€æ ·æƒ…å†µæ’æŸ¥é—®é¢˜ï¼Ÿ&#010;&gt; æœ‰ä»»ä½•çº¿ç´¢éƒ½å¯ä»¥&#010;&gt;&#010;&gt; æ„Ÿè°¢&#010;&gt;&#010;&#010;",
        "depth": "1",
        "reply": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>"
    },
    {
        "id": "<CABD9WQH7Zcr3d+7grv2VB3EKzuXnoPt_OcuYoD_iE07ERYoisA@mail.gmail.com>",
        "from": "Luan Cooper &lt;gc.su...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 08:01:42 GMT",
        "subject": "Re: SQL æŠ¥é”™åªæœ‰ flink runtime çš„ NPE",
        "content": "å®é™…æœ‰ 20 å·¦å³ä¸ªå­—æ®µï¼Œç”¨åˆ°çš„ UDF æœ‰ COALESCE / CAST / JSON_PATH / TIMESTAMP ç±»&#010;*æ˜¯æŒ‡ UDF è¿”å›äº† NULL å¯¼è‡´çš„å—ï¼Ÿ*&#010;&#010;&#010;On Fri, Jul 17, 2020 at 2:54 PM godfrey he &lt;godfreyhe@gmail.com&gt; wrote:&#010;&#010;&gt; udf_xxxçš„é€»è¾‘æ˜¯å•¥ï¼Ÿ&#010;&gt;&#010;&gt;&#010;&gt; Luan Cooper &lt;gc.suprs@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:40å†™é“ï¼š&#010;&gt;&#010;&gt; &gt; Hi&#010;&gt; &gt;&#010;&gt; &gt; æˆ‘æœ‰è¿™ä¹ˆä¸€ä¸ª SQL&#010;&gt; &gt; INSERT INTO es&#010;&gt; &gt; SELECT&#010;&gt; &gt; a,&#010;&gt; &gt; udf_xxx(b)&#010;&gt; &gt; FROM mongo_oplog -- è‡ªå®šä¹‰ TableFactory&#010;&gt; &gt;&#010;&gt; &gt; Job æäº¤å fail äº†ï¼Œä» Job æäº¤åˆ° Fail åªæœ‰ä¸€å¤„æ¥è‡ªéä¸šåŠ¡ä»£ç çš„&#010;NPE å¦‚ä¸‹ï¼Œæ²¡æœ‰ä»»ä½•ä¸šåŠ¡ä»£ç &#010;&gt; Exceptionï¼Œå¯ä»¥ç¨³å®šé‡ç°&#010;&gt; &gt;&#010;&gt; &gt; LUE _UTF-16LE'v2'))) AS return_received_time]) (1/1)&#010;&gt; &gt; (bdf9b131f82a8ebc440165b82b89e570) switched from RUNNING to FAILED.&#010;&gt; &gt;&#010;&gt; &gt; java.lang.NullPointerException&#010;&gt; &gt;&#010;&gt; &gt; at StreamExecCalc$8016.split$7938$(Unknown Source)&#010;&gt; &gt;&#010;&gt; &gt; at StreamExecCalc$8016.processElement(Unknown Source)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:173)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt; &gt; .StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:151)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt; &gt; .StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:128)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt; &gt; .StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:69)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:311)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:187)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:487)&#010;&gt; &gt;&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:470)&#010;&gt; &gt;&#010;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &gt;&#010;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &gt;&#010;&gt; &gt; at java.lang.Thread.run(Thread.java:748)&#010;&gt; &gt;&#010;&gt; &gt; è¯·é—®è¿™ç§æ€æ ·æƒ…å†µæ’æŸ¥é—®é¢˜ï¼Ÿ&#010;&gt; &gt; æœ‰ä»»ä½•çº¿ç´¢éƒ½å¯ä»¥&#010;&gt; &gt;&#010;&gt; &gt; æ„Ÿè°¢&#010;&gt; &gt;&#010;&gt;&#010;&#010;",
        "depth": "2",
        "reply": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>"
    },
    {
        "id": "<CABD9WQG5=m9TqGtJV=NAHQCzBGLWP5dMzGzQxSeWa+yJgP=RqQ@mail.gmail.com>",
        "from": "Luan Cooper &lt;gc.su...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 08:11:16 GMT",
        "subject": "Re: SQL æŠ¥é”™åªæœ‰ flink runtime çš„ NPE",
        "content": "é™„ä¸€ä¸ª Job Graph ä¿¡æ¯ï¼Œåœ¨ Cal å¤„æŒ‚äº†&#010;[image: image.png]&#010;&#010;On Fri, Jul 17, 2020 at 4:01 PM Luan Cooper &lt;gc.suprs@gmail.com&gt; wrote:&#010;&#010;&gt; å®é™…æœ‰ 20 å·¦å³ä¸ªå­—æ®µï¼Œç”¨åˆ°çš„ UDF æœ‰ COALESCE / CAST / JSON_PATH / TIMESTAMP&#010;ç±»&#010;&gt; *æ˜¯æŒ‡ UDF è¿”å›äº† NULL å¯¼è‡´çš„å—ï¼Ÿ*&#010;&gt;&#010;&gt;&#010;&gt; On Fri, Jul 17, 2020 at 2:54 PM godfrey he &lt;godfreyhe@gmail.com&gt; wrote:&#010;&gt;&#010;&gt;&gt; udf_xxxçš„é€»è¾‘æ˜¯å•¥ï¼Ÿ&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; Luan Cooper &lt;gc.suprs@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:40å†™é“ï¼š&#010;&gt;&gt;&#010;&gt;&gt; &gt; Hi&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; æˆ‘æœ‰è¿™ä¹ˆä¸€ä¸ª SQL&#010;&gt;&gt; &gt; INSERT INTO es&#010;&gt;&gt; &gt; SELECT&#010;&gt;&gt; &gt; a,&#010;&gt;&gt; &gt; udf_xxx(b)&#010;&gt;&gt; &gt; FROM mongo_oplog -- è‡ªå®šä¹‰ TableFactory&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; Job æäº¤å fail äº†ï¼Œä» Job æäº¤åˆ° Fail åªæœ‰ä¸€å¤„æ¥è‡ªéä¸šåŠ¡ä»£ç çš„&#010;NPE å¦‚ä¸‹ï¼Œæ²¡æœ‰ä»»ä½•ä¸šåŠ¡ä»£ç &#010;&gt;&gt; Exceptionï¼Œå¯ä»¥ç¨³å®šé‡ç°&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; LUE _UTF-16LE'v2'))) AS return_received_time]) (1/1)&#010;&gt;&gt; &gt; (bdf9b131f82a8ebc440165b82b89e570) switched from RUNNING to FAILED.&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; java.lang.NullPointerException&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at StreamExecCalc$8016.split$7938$(Unknown Source)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at StreamExecCalc$8016.processElement(Unknown Source)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;&#010;&gt;&gt; org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:173)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt;&gt; &gt; .StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:151)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt;&gt; &gt; .StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:128)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt;&gt; &gt; .StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:69)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;&#010;&gt;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:311)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;&#010;&gt;&gt; org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:187)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;&#010;&gt;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:487)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt;&#010;&gt;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:470)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; at java.lang.Thread.run(Thread.java:748)&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; è¯·é—®è¿™ç§æ€æ ·æƒ…å†µæ’æŸ¥é—®é¢˜ï¼Ÿ&#010;&gt;&gt; &gt; æœ‰ä»»ä½•çº¿ç´¢éƒ½å¯ä»¥&#010;&gt;&gt; &gt;&#010;&gt;&gt; &gt; æ„Ÿè°¢&#010;&gt;&gt; &gt;&#010;&gt;&gt;&#010;&gt;&#010;&#010;",
        "depth": "3",
        "reply": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>"
    },
    {
        "id": "<CADQYLGt+JB3G9D9OiZq3m2RFG1NqjjuoBTKwVPvBjGVNL7Wfaw@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 07:27:58 GMT",
        "subject": "Re: SQL æŠ¥é”™åªæœ‰ flink runtime çš„ NPE",
        "content": "çœ‹ä¸åˆ°å›¾ç‰‡ä¿¡æ¯ï¼Œæ¢ä¸€ä¸ªå›¾åºŠå·¥å…·ä¸Šä¼ å›¾ç‰‡å§&#010;&#010;Luan Cooper &lt;gc.suprs@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ4:11å†™é“ï¼š&#010;&#010;&gt; é™„ä¸€ä¸ª Job Graph ä¿¡æ¯ï¼Œåœ¨ Cal å¤„æŒ‚äº†&#010;&gt; [image: image.png]&#010;&gt;&#010;&gt; On Fri, Jul 17, 2020 at 4:01 PM Luan Cooper &lt;gc.suprs@gmail.com&gt; wrote:&#010;&gt;&#010;&gt;&gt; å®é™…æœ‰ 20 å·¦å³ä¸ªå­—æ®µï¼Œç”¨åˆ°çš„ UDF æœ‰ COALESCE / CAST / JSON_PATH / TIMESTAMP&#010;ç±»&#010;&gt;&gt; *æ˜¯æŒ‡ UDF è¿”å›äº† NULL å¯¼è‡´çš„å—ï¼Ÿ*&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; On Fri, Jul 17, 2020 at 2:54 PM godfrey he &lt;godfreyhe@gmail.com&gt; wrote:&#010;&gt;&gt;&#010;&gt;&gt;&gt; udf_xxxçš„é€»è¾‘æ˜¯å•¥ï¼Ÿ&#010;&gt;&gt;&gt;&#010;&gt;&gt;&gt;&#010;&gt;&gt;&gt; Luan Cooper &lt;gc.suprs@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:40å†™é“ï¼š&#010;&gt;&gt;&gt;&#010;&gt;&gt;&gt; &gt; Hi&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; æˆ‘æœ‰è¿™ä¹ˆä¸€ä¸ª SQL&#010;&gt;&gt;&gt; &gt; INSERT INTO es&#010;&gt;&gt;&gt; &gt; SELECT&#010;&gt;&gt;&gt; &gt; a,&#010;&gt;&gt;&gt; &gt; udf_xxx(b)&#010;&gt;&gt;&gt; &gt; FROM mongo_oplog -- è‡ªå®šä¹‰ TableFactory&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; Job æäº¤å fail äº†ï¼Œä» Job æäº¤åˆ° Fail åªæœ‰ä¸€å¤„æ¥è‡ªéä¸šåŠ¡ä»£ç çš„&#010;NPE å¦‚ä¸‹ï¼Œæ²¡æœ‰ä»»ä½•ä¸šåŠ¡ä»£ç &#010;&gt;&gt;&gt; Exceptionï¼Œå¯ä»¥ç¨³å®šé‡ç°&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; LUE _UTF-16LE'v2'))) AS return_received_time]) (1/1)&#010;&gt;&gt;&gt; &gt; (bdf9b131f82a8ebc440165b82b89e570) switched from RUNNING to FAILED.&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; java.lang.NullPointerException&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at StreamExecCalc$8016.split$7938$(Unknown Source)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at StreamExecCalc$8016.processElement(Unknown Source)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:173)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt;&gt;&gt; &gt; .StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:151)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt;&gt;&gt; &gt; .StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:128)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#010;&gt;&gt;&gt; &gt; .StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:69)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:311)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:187)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:487)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:470)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; at java.lang.Thread.run(Thread.java:748)&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; è¯·é—®è¿™ç§æ€æ ·æƒ…å†µæ’æŸ¥é—®é¢˜ï¼Ÿ&#010;&gt;&gt;&gt; &gt; æœ‰ä»»ä½•çº¿ç´¢éƒ½å¯ä»¥&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt; &gt; æ„Ÿè°¢&#010;&gt;&gt;&gt; &gt;&#010;&gt;&gt;&gt;&#010;&gt;&gt;&#010;&#010;",
        "depth": "4",
        "reply": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>"
    },
    {
        "id": "<CAELO931+JZycL+trnwZVYgUd9bkS=64Rkntd-nwXv+nBA5jfeA@mail.gmail.com>",
        "from": "Jark Wu &lt;imj...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 14:15:18 GMT",
        "subject": "Re: SQL æŠ¥é”™åªæœ‰ flink runtime çš„ NPE",
        "content": "è¿™ä¸ªå¼‚å¸¸ä¸€èˆ¬æ˜¯ç”±äº UDF çš„å®ç°ç”¨äº†ä¸»ç±»å‹ï¼ˆintï¼‰ï¼Œä½†æ˜¯å®é™…çš„å­—æ®µå€¼æœ‰&#010;null å€¼ã€‚&#013;&#010;ä½ å¯ä»¥è¯•è¯•å…ˆåšä¸ª where æ¡ä»¶è¿‡æ»¤ï¼Œå°† null å€¼è¿‡æ»¤æ‰ï¼Ÿ&#013;&#010;&#013;&#010;Best,&#013;&#010;Jark&#013;&#010;&#013;&#010;&#013;&#010;On Mon, 20 Jul 2020 at 15:28, godfrey he &lt;godfreyhe@gmail.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; çœ‹ä¸åˆ°å›¾ç‰‡ä¿¡æ¯ï¼Œæ¢ä¸€ä¸ªå›¾åºŠå·¥å…·ä¸Šä¼ å›¾ç‰‡å§&#013;&#010;&gt;&#013;&#010;&gt; Luan Cooper &lt;gc.suprs@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ4:11å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt; &gt; é™„ä¸€ä¸ª Job Graph ä¿¡æ¯ï¼Œåœ¨ Cal å¤„æŒ‚äº†&#013;&#010;&gt; &gt; [image: image.png]&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; On Fri, Jul 17, 2020 at 4:01 PM Luan Cooper &lt;gc.suprs@gmail.com&gt; wrote:&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&gt; å®é™…æœ‰ 20 å·¦å³ä¸ªå­—æ®µï¼Œç”¨åˆ°çš„ UDF æœ‰ COALESCE / CAST / JSON_PATH&#010;/ TIMESTAMP ç±»&#013;&#010;&gt; &gt;&gt; *æ˜¯æŒ‡ UDF è¿”å›äº† NULL å¯¼è‡´çš„å—ï¼Ÿ*&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; On Fri, Jul 17, 2020 at 2:54 PM godfrey he &lt;godfreyhe@gmail.com&gt; wrote:&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&gt; udf_xxxçš„é€»è¾‘æ˜¯å•¥ï¼Ÿ&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; &gt;&gt;&gt; Luan Cooper &lt;gc.suprs@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ2:40å†™é“ï¼š&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; Hi&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; æˆ‘æœ‰è¿™ä¹ˆä¸€ä¸ª SQL&#013;&#010;&gt; &gt;&gt;&gt; &gt; INSERT INTO es&#013;&#010;&gt; &gt;&gt;&gt; &gt; SELECT&#013;&#010;&gt; &gt;&gt;&gt; &gt; a,&#013;&#010;&gt; &gt;&gt;&gt; &gt; udf_xxx(b)&#013;&#010;&gt; &gt;&gt;&gt; &gt; FROM mongo_oplog -- è‡ªå®šä¹‰ TableFactory&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; Job æäº¤å fail äº†ï¼Œä» Job æäº¤åˆ° Fail åªæœ‰ä¸€å¤„æ¥è‡ªéä¸šåŠ¡ä»£ç çš„&#010;NPE å¦‚ä¸‹ï¼Œæ²¡æœ‰ä»»ä½•ä¸šåŠ¡ä»£ç &#013;&#010;&gt; &gt;&gt;&gt; Exceptionï¼Œå¯ä»¥ç¨³å®šé‡ç°&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; LUE _UTF-16LE'v2'))) AS return_received_time]) (1/1)&#013;&#010;&gt; &gt;&gt;&gt; &gt; (bdf9b131f82a8ebc440165b82b89e570) switched from RUNNING to FAILED.&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; java.lang.NullPointerException&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at StreamExecCalc$8016.split$7938$(Unknown Source)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at StreamExecCalc$8016.processElement(Unknown Source)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:173)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; .StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:151)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#013;&#010;&gt; &gt;&gt;&gt; &gt; .StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:128)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt; org.apache.flink.streaming.runtime.io&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; .StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:69)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:311)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:187)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:487)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:470)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; è¯·é—®è¿™ç§æ€æ ·æƒ…å†µæ’æŸ¥é—®é¢˜ï¼Ÿ&#013;&#010;&gt; &gt;&gt;&gt; &gt; æœ‰ä»»ä½•çº¿ç´¢éƒ½å¯ä»¥&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt; &gt; æ„Ÿè°¢&#013;&#010;&gt; &gt;&gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "5",
        "reply": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>"
    },
    {
        "id": "<202007201926375043500@163.com>",
        "from": "&quot;sjlsumaitong@163.com&quot; &lt;sjlsumait...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 11:26:37 GMT",
        "subject": "æµ‹è¯•ä¸€ä¸‹ç¤¾åŒºé‚®ä»¶",
        "content": "å¿½ç•¥&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;sjlsumaitong@163.com&#013;&#010; &#013;&#010;",
        "depth": "1",
        "reply": "<CABD9WQF6DA4LPDiV6ArMz32E=Fsr-ZqaSt6c8znXYYXBFtx7cw@mail.gmail.com>"
    },
    {
        "id": "<tencent_A0FBE40366E4D3613256AB4009202BFFFA05@qq.com>",
        "from": "&quot;kcz&quot; &lt;573693...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 08:24:48 GMT",
        "subject": "flink-1.11 ddl å†™å…¥json æ ¼å¼æ•°æ®åˆ°hdfsé—®é¢˜",
        "content": "ä»£ç å¼•ç”¨&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/filesystem.html#full-example&#013;&#010;å°†parquetæ¢æˆäº†jsonä¹‹åï¼ŒchkæˆåŠŸï¼Œä½†æ˜¯æ–‡ä»¶çŠ¶æ€ä¸€ç›´å¤„äºin-progressçŠ¶æ€ï¼Œæˆ‘åº”è¯¥å¦‚ä½•è®©å®ƒæˆåŠŸå‘¢ï¼Ÿ&#013;&#010;parquetç›®å‰æ˜¯å·²ç»successäº†ã€‚",
        "depth": "0",
        "reply": "<tencent_A0FBE40366E4D3613256AB4009202BFFFA05@qq.com>"
    },
    {
        "id": "<CABi+2jT6yRVMxX4Us-q3cPhEu16wbTKFUR-UA6tys8ZEJ7M5ww@mail.gmail.com>",
        "from": "Jingsong Li &lt;jingsongl...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 08:57:40 GMT",
        "subject": "Re: flink-1.11 ddl å†™å…¥json æ ¼å¼æ•°æ®åˆ°hdfsé—®é¢˜",
        "content": "Hi,&#013;&#010;&#013;&#010;å¦‚åŒ[1]é‡Œé¢è¯´çš„ï¼Œå¯¹äºcsvå’Œjsonï¼Œä½ è¿˜éœ€è¦é…ç½®rollingç›¸å…³å‚æ•°ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å¯ä»¥ä¸åœ¨checkpointå¼ºè¡Œrollingçš„ã€‚&#013;&#010;&#013;&#010;NOTE: For row formats (csv, json), you can set the parameter&#013;&#010;sink.rolling-policy.file-size or sink.rolling-policy.rollover-interval in&#013;&#010;the connector properties and parameter execution.checkpointing.interval in&#013;&#010;flink-conf.yaml together if you donâ€™t want to wait a long period before&#013;&#010;observe the data exists in file system. For other formats (avro, orc), you&#013;&#010;can just set parameter execution.checkpointing.interval in flink-conf.yaml.&#013;&#010;&#013;&#010;æ‰€ä»¥å¦‚æœä½ æƒ³é€šè¿‡æ—¶é—´æ¥rollingï¼Œä½ è¿˜éœ€è¦é…sink.rolling-policy.rollover-intervalå’Œsink.rolling-policy.check-interval&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-master/dev/table/connectors/filesystem.html#rolling-policy&#013;&#010;&#013;&#010;Best,&#013;&#010;Jingsong&#013;&#010;&#013;&#010;On Fri, Jul 17, 2020 at 4:25 PM kcz &lt;573693104@qq.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; ä»£ç å¼•ç”¨&#013;&#010;&gt;&#013;&#010;&gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/filesystem.html#full-example&#013;&#010;&gt; å°†parquetæ¢æˆäº†jsonä¹‹åï¼ŒchkæˆåŠŸï¼Œä½†æ˜¯æ–‡ä»¶çŠ¶æ€ä¸€ç›´å¤„äºin-progressçŠ¶æ€ï¼Œæˆ‘åº”è¯¥å¦‚ä½•è®©å®ƒæˆåŠŸå‘¢ï¼Ÿ&#013;&#010;&gt; parquetç›®å‰æ˜¯å·²ç»successäº†ã€‚&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;Best, Jingsong Lee&#013;&#010;",
        "depth": "1",
        "reply": "<tencent_A0FBE40366E4D3613256AB4009202BFFFA05@qq.com>"
    },
    {
        "id": "<tencent_F751EC5D813F404C7ED6F7C347F5C8B18306@qq.com>",
        "from": "&quot;kcz&quot; &lt;573693...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:26:13 GMT",
        "subject": "å›å¤ï¼š flink-1.11 ddl å†™å…¥json æ ¼å¼æ•°æ®åˆ°hdfsé—®é¢˜",
        "content": "tksè§£å†³äº†ï¼Œæœ‰ä¸€ä¸ªå°é—®é¢˜ï¼Œæ–‡æ¡£å†™äº†30m,ä½†æ˜¯ä»£ç å®é™…ä¸æ”¯æŒmæ¥ä»£è¡¨åˆ†é’Ÿ&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;jingsonglee0@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) ä¸‹åˆ4:57&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: flink-1.11 ddl å†™å…¥json æ ¼å¼æ•°æ®åˆ°hdfsé—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Hi,&#013;&#010;&#013;&#010;å¦‚åŒ[1]é‡Œé¢è¯´çš„ï¼Œå¯¹äºcsvå’Œjsonï¼Œä½ è¿˜éœ€è¦é…ç½®rollingç›¸å…³å‚æ•°ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å¯ä»¥ä¸åœ¨checkpointå¼ºè¡Œrollingçš„ã€‚&#013;&#010;&#013;&#010;NOTE: For row formats (csv, json), you can set the parameter&#013;&#010;sink.rolling-policy.file-size or sink.rolling-policy.rollover-interval in&#013;&#010;the connector properties and parameter execution.checkpointing.interval in&#013;&#010;flink-conf.yaml together if you donâ€™t want to wait a long period before&#013;&#010;observe the data exists in file system. For other formats (avro, orc), you&#013;&#010;can just set parameter execution.checkpointing.interval in flink-conf.yaml.&#013;&#010;&#013;&#010;æ‰€ä»¥å¦‚æœä½ æƒ³é€šè¿‡æ—¶é—´æ¥rollingï¼Œä½ è¿˜éœ€è¦é…sink.rolling-policy.rollover-intervalå’Œsink.rolling-policy.check-interval&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-master/dev/table/connectors/filesystem.html#rolling-policy&#013;&#010;&#013;&#010;Best,&#013;&#010;Jingsong&#013;&#010;&#013;&#010;On Fri, Jul 17, 2020 at 4:25 PM kcz &lt;573693104@qq.com&amp;gt; wrote:&#013;&#010;&#013;&#010;&amp;gt; ä»£ç å¼•ç”¨&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/filesystem.html#full-example&#013;&#010;&amp;gt; å°†parquetæ¢æˆäº†jsonä¹‹åï¼ŒchkæˆåŠŸï¼Œä½†æ˜¯æ–‡ä»¶çŠ¶æ€ä¸€ç›´å¤„äºin-progressçŠ¶æ€ï¼Œæˆ‘åº”è¯¥å¦‚ä½•è®©å®ƒæˆåŠŸå‘¢ï¼Ÿ&#013;&#010;&amp;gt; parquetç›®å‰æ˜¯å·²ç»successäº†ã€‚&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;Best, Jingsong Lee",
        "depth": "2",
        "reply": "<tencent_A0FBE40366E4D3613256AB4009202BFFFA05@qq.com>"
    },
    {
        "id": "<D88CE995-B16B-4275-BDA0-398B22493305@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 11:48:25 GMT",
        "subject": "Re: flink-1.11 ddl å†™å…¥json æ ¼å¼æ•°æ®åˆ°hdfsé—®é¢˜",
        "content": "æ˜¯çš„&#010;&#010;æ„Ÿè°¢åé¦ˆï¼Œæ–‡æ¡£é‡Œå•ä½é—®é¢˜ï¼Œåˆ†é’Ÿå¯¹åº”çš„æ˜¯ min&#010;&#010;&#010;&gt; åœ¨ 2020å¹´7æœˆ17æ—¥ï¼Œ17:26ï¼Œkcz &lt;573693104@qq.com&gt; å†™é“ï¼š&#010;&gt; &#010;&gt; tksè§£å†³äº†ï¼Œæœ‰ä¸€ä¸ªå°é—®é¢˜ï¼Œæ–‡æ¡£å†™äº†30m,ä½†æ˜¯ä»£ç å®é™…ä¸æ”¯æŒmæ¥ä»£è¡¨åˆ†é’Ÿ&#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; ------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;&gt; å‘ä»¶äºº:                                                                          &#010;                                             \"user-zh\"                                   &#010;                                                &lt;jingsonglee0@gmail.com &lt;mailto:jingsonglee0@gmail.com&gt;&amp;gt;;&#010;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) ä¸‹åˆ4:57&#010;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org &lt;mailto:user-zh@flink.apache.org&gt;&amp;gt;;&#010;&gt; &#010;&gt; ä¸»é¢˜:&amp;nbsp;Re: flink-1.11 ddl å†™å…¥json æ ¼å¼æ•°æ®åˆ°hdfsé—®é¢˜&#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; Hi,&#010;&gt; &#010;&gt; å¦‚åŒ[1]é‡Œé¢è¯´çš„ï¼Œå¯¹äºcsvå’Œjsonï¼Œä½ è¿˜éœ€è¦é…ç½®rollingç›¸å…³å‚æ•°ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å¯ä»¥ä¸åœ¨checkpointå¼ºè¡Œrollingçš„ã€‚&#010;&gt; &#010;&gt; NOTE: For row formats (csv, json), you can set the parameter&#010;&gt; sink.rolling-policy.file-size or sink.rolling-policy.rollover-interval in&#010;&gt; the connector properties and parameter execution.checkpointing.interval in&#010;&gt; flink-conf.yaml together if you donâ€™t want to wait a long period before&#010;&gt; observe the data exists in file system. For other formats (avro, orc), you&#010;&gt; can just set parameter execution.checkpointing.interval in flink-conf.yaml.&#010;&gt; &#010;&gt; æ‰€ä»¥å¦‚æœä½ æƒ³é€šè¿‡æ—¶é—´æ¥rollingï¼Œä½ è¿˜éœ€è¦é…sink.rolling-policy.rollover-intervalå’Œsink.rolling-policy.check-interval&#010;&gt; &#010;&gt; [1]&#010;&gt; https://ci.apache.org/projects/flink/flink-docs-master/dev/table/connectors/filesystem.html#rolling-policy&#010;&gt; &#010;&gt; Best,&#010;&gt; Jingsong&#010;&gt; &#010;&gt; On Fri, Jul 17, 2020 at 4:25 PM kcz &lt;573693104@qq.com&amp;gt; wrote:&#010;&gt; &#010;&gt; &amp;gt; ä»£ç å¼•ç”¨&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/filesystem.html#full-example&#010;&lt;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/filesystem.html#full-example&gt;&#010;&gt; &amp;gt; å°†parquetæ¢æˆäº†jsonä¹‹åï¼ŒchkæˆåŠŸï¼Œä½†æ˜¯æ–‡ä»¶çŠ¶æ€ä¸€ç›´å¤„äºin-progressçŠ¶æ€ï¼Œæˆ‘åº”è¯¥å¦‚ä½•è®©å®ƒæˆåŠŸå‘¢ï¼Ÿ&#010;&gt; &amp;gt; parquetç›®å‰æ˜¯å·²ç»successäº†ã€‚&#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; -- &#010;&gt; Best, Jingsong Lee&#010;&#010;&#010;",
        "depth": "3",
        "reply": "<tencent_A0FBE40366E4D3613256AB4009202BFFFA05@qq.com>"
    },
    {
        "id": "<CAEZk043gMHjUuk0=Mj4=io+9oGp=9A8wqD0ONVR_PgbH+AK4Wg@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:05:12 GMT",
        "subject": "flink1.11å†™hive",
        "content": "hiï¼š&#013;&#010;æˆ‘è¿™é¢åœ¨flinkä¸­æ³¨å†Œhivecatalogï¼Œæƒ³å°†kafkaæ•°æ®æµå¼å†™å…¥åˆ°hiveè¡¨ä¸­ï¼Œä½†æ˜¯ç°åœ¨å»ºç«‹kafkaè¡¨çš„æ—¶å€™é»˜è®¤ä¼šä¿å­˜å…ƒæ•°æ®åˆ°hiveè¡¨ï¼Œè¯·é—®æœ‰åŠæ³•ä¸ä¿å­˜è¿™ä¸ªkafkaå…ƒæ•°æ®è¡¨å—ï¼Ÿå¦‚æœä¸æ³¨å†Œhivecatalogçš„è¯æ²¡åŠæ³•å†™æ•°æ®åˆ°hiveå§ã€‚ã€‚ã€‚ã€‚&#013;&#010;",
        "depth": "0",
        "reply": "<CAEZk043gMHjUuk0=Mj4=io+9oGp=9A8wqD0ONVR_PgbH+AK4Wg@mail.gmail.com>"
    },
    {
        "id": "<CABi+2jQ4=uvytLxXEkAFi6=0SUk2NUnzbMKGSE9VWnUFLDTHXw@mail.gmail.com>",
        "from": "Jingsong Li &lt;jingsongl...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:12:50 GMT",
        "subject": "Re: flink1.11å†™hive",
        "content": "CREATE TEMPORARY TABLE kafka_table...&#013;&#010;å¥½åƒæ²¡æ–‡æ¡£ï¼Œæˆ‘å»ºä¸ªJIRAè·Ÿè¸ªä¸‹&#013;&#010;https://issues.apache.org/jira/browse/FLINK-18624&#013;&#010;&#013;&#010;Best,&#013;&#010;Jingsong&#013;&#010;&#013;&#010;On Fri, Jul 17, 2020 at 5:05 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; hiï¼š&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘è¿™é¢åœ¨flinkä¸­æ³¨å†Œhivecatalogï¼Œæƒ³å°†kafkaæ•°æ®æµå¼å†™å…¥åˆ°hiveè¡¨ä¸­ï¼Œä½†æ˜¯ç°åœ¨å»ºç«‹kafkaè¡¨çš„æ—¶å€™é»˜è®¤ä¼šä¿å­˜å…ƒæ•°æ®åˆ°hiveè¡¨ï¼Œè¯·é—®æœ‰åŠæ³•ä¸ä¿å­˜è¿™ä¸ªkafkaå…ƒæ•°æ®è¡¨å—ï¼Ÿå¦‚æœä¸æ³¨å†Œhivecatalogçš„è¯æ²¡åŠæ³•å†™æ•°æ®åˆ°hiveå§ã€‚ã€‚ã€‚ã€‚&#013;&#010;&gt;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;Best, Jingsong Lee&#013;&#010;",
        "depth": "1",
        "reply": "<CAEZk043gMHjUuk0=Mj4=io+9oGp=9A8wqD0ONVR_PgbH+AK4Wg@mail.gmail.com>"
    },
    {
        "id": "<CADH6UNSU+BU+RL80MQuE5HU_evdR=1ND+pAxgYszsuWodqsc4A@mail.gmail.com>",
        "from": "Rui Li &lt;lirui.fu...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 03:42:15 GMT",
        "subject": "Re: flink1.11å†™hive",
        "content": "å»ºè¡¨çš„æ—¶å€™ä¹Ÿå¯ä»¥æŒ‡å®šCatalogçš„ï¼Œåˆ›å»ºkafkaè¡¨æŒ‡å®šdefault_catalogå°±ä¸ä¼šåˆ›å»ºåˆ°hive&#010;Catalogé‡Œå»äº†&#013;&#010;&#013;&#010;On Fri, Jul 17, 2020 at 5:13 PM Jingsong Li &lt;jingsonglee0@gmail.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; CREATE TEMPORARY TABLE kafka_table...&#013;&#010;&gt; å¥½åƒæ²¡æ–‡æ¡£ï¼Œæˆ‘å»ºä¸ªJIRAè·Ÿè¸ªä¸‹&#013;&#010;&gt; https://issues.apache.org/jira/browse/FLINK-18624&#013;&#010;&gt;&#013;&#010;&gt; Best,&#013;&#010;&gt; Jingsong&#013;&#010;&gt;&#013;&#010;&gt; On Fri, Jul 17, 2020 at 5:05 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt;&#013;&#010;&gt; &gt; hiï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; æˆ‘è¿™é¢åœ¨flinkä¸­æ³¨å†Œhivecatalogï¼Œæƒ³å°†kafkaæ•°æ®æµå¼å†™å…¥åˆ°hiveè¡¨ä¸­ï¼Œä½†æ˜¯ç°åœ¨å»ºç«‹kafkaè¡¨çš„æ—¶å€™é»˜è®¤ä¼šä¿å­˜å…ƒæ•°æ®åˆ°hiveè¡¨ï¼Œè¯·é—®æœ‰åŠæ³•ä¸ä¿å­˜è¿™ä¸ªkafkaå…ƒæ•°æ®è¡¨å—ï¼Ÿå¦‚æœä¸æ³¨å†Œhivecatalogçš„è¯æ²¡åŠæ³•å†™æ•°æ®åˆ°hiveå§ã€‚ã€‚ã€‚ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; --&#013;&#010;&gt; Best, Jingsong Lee&#013;&#010;&gt;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;Best regards!&#013;&#010;Rui Li&#013;&#010;",
        "depth": "2",
        "reply": "<CAEZk043gMHjUuk0=Mj4=io+9oGp=9A8wqD0ONVR_PgbH+AK4Wg@mail.gmail.com>"
    },
    {
        "id": "<CAEZk043Lqp9PdDG+Nt_tRBtR4npqbHp14Az1GrVOCOK+P-Wb2A@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:14:19 GMT",
        "subject": "connector hiveä¾èµ–å†²çª",
        "content": "hiï¼š&#013;&#010;å¤§ä½¬ä»¬ï¼Œä¸‹é¢è¿æ¥hiveçš„ä¾èµ–åŒ…çš„å“ªä¸ªä¼ é€’ä¾èµ–å¯¼è‡´çš„jaråŒ…å†²çªï¼Œæˆ‘ä»1.9åˆ°1.11æ¯æ¬¡åœ¨mavenæŒ‰ç…§å®˜æ–¹æ–‡æ¡£å¼•åŒ…éƒ½ä¼šå‡ºç°ä¾èµ–å†²çªã€‚ã€‚ã€‚ã€‚1.9åˆšå‘å¸ƒçš„æ—¶å€™å¯¹ä¸‹é¢çš„å¼•åŒ…æœ‰åšä¾èµ–æ’é™¤ï¼Œåæ¥æ–‡æ¡£æ”¹äº†&#013;&#010;&#013;&#010;// Flink's Hive connector.Contains flink-hadoop-compatibility and flink-orc jars&#013;&#010;       flink-connector-hive_2.11-1.11.0.jar&#013;&#010;       // Hive dependencies&#013;&#010;       hive-exec-2.3.4.jar&#013;&#010;",
        "depth": "0",
        "reply": "<CAEZk043Lqp9PdDG+Nt_tRBtR4npqbHp14Az1GrVOCOK+P-Wb2A@mail.gmail.com>"
    },
    {
        "id": "<CABi+2jSBPTG8w+v3jk_k0xCC0KU2DSvOLr6fdeao9z3-S40VzA@mail.gmail.com>",
        "from": "Jingsong Li &lt;jingsongl...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:16:37 GMT",
        "subject": "Re: connector hiveä¾èµ–å†²çª",
        "content": "ç”¨bundle jarå¯ä»¥æå®šå—ï¼Ÿ&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#using-bundled-hive-jar&#013;&#010;&#013;&#010;Best,&#013;&#010;Jingsong&#013;&#010;&#013;&#010;On Fri, Jul 17, 2020 at 5:14 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; hiï¼š&#013;&#010;&gt;&#013;&#010;&gt; å¤§ä½¬ä»¬ï¼Œä¸‹é¢è¿æ¥hiveçš„ä¾èµ–åŒ…çš„å“ªä¸ªä¼ é€’ä¾èµ–å¯¼è‡´çš„jaråŒ…å†²çªï¼Œæˆ‘ä»1.9åˆ°1.11æ¯æ¬¡åœ¨mavenæŒ‰ç…§å®˜æ–¹æ–‡æ¡£å¼•åŒ…éƒ½ä¼šå‡ºç°ä¾èµ–å†²çªã€‚ã€‚ã€‚ã€‚1.9åˆšå‘å¸ƒçš„æ—¶å€™å¯¹ä¸‹é¢çš„å¼•åŒ…æœ‰åšä¾èµ–æ’é™¤ï¼Œåæ¥æ–‡æ¡£æ”¹äº†&#013;&#010;&gt;&#013;&#010;&gt; // Flink's Hive connector.Contains flink-hadoop-compatibility and&#013;&#010;&gt; flink-orc jars&#013;&#010;&gt;        flink-connector-hive_2.11-1.11.0.jar&#013;&#010;&gt;        // Hive dependencies&#013;&#010;&gt;        hive-exec-2.3.4.jar&#013;&#010;&gt;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;Best, Jingsong Lee&#013;&#010;",
        "depth": "1",
        "reply": "<CAEZk043Lqp9PdDG+Nt_tRBtR4npqbHp14Az1GrVOCOK+P-Wb2A@mail.gmail.com>"
    },
    {
        "id": "<CAEZk0409dePRp+qwUkKJj4H2Zt-ghWiHWqEmMsBTD-SQr5zuBQ@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:24:00 GMT",
        "subject": "Re: connector hiveä¾èµ–å†²çª",
        "content": "1.9å’Œ1.10æ—¶å€™æ’é™¤ä¸€äº›ä¼ é€’ä¾èµ–ååœ¨ideaå’Œæ‰“uber jaråœ¨é›†ç¾¤ç¯å¢ƒéƒ½å¯ä»¥è¿è¡Œï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–çš„è¯åœ¨ideaè¿è¡Œä¸äº†ï¼›&#013;&#010;1.11ç°åœ¨åªåœ¨æœ¬åœ°æµ‹å“ªï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–ideaè¿è¡Œä¸äº†ï¼Œé›†ç¾¤ç¯å¢ƒè¿˜æ²¡å¼„ï¼Œä½†æ˜¯æˆ‘æ„Ÿè§‰åœ¨ideaç›´æ¥runè¿™ä¸ªåŠŸèƒ½å¥½å¤šäººéƒ½éœ€è¦ï¼Œæ–‡æ¡£æ˜¯ä¸æ˜¯å¯ä»¥æ”¹è¿›ä¸€ä¸‹&#013;&#010;&#013;&#010;Jingsong Li &lt;jingsonglee0@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:16å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; ç”¨bundle jarå¯ä»¥æå®šå—ï¼Ÿ&#013;&#010;&gt;&#013;&#010;&gt; [1]&#013;&#010;&gt;&#013;&#010;&gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#using-bundled-hive-jar&#013;&#010;&gt;&#013;&#010;&gt; Best,&#013;&#010;&gt; Jingsong&#013;&#010;&gt;&#013;&#010;&gt; On Fri, Jul 17, 2020 at 5:14 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt;&#013;&#010;&gt; &gt; hiï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; å¤§ä½¬ä»¬ï¼Œä¸‹é¢è¿æ¥hiveçš„ä¾èµ–åŒ…çš„å“ªä¸ªä¼ é€’ä¾èµ–å¯¼è‡´çš„jaråŒ…å†²çªï¼Œæˆ‘ä»1.9åˆ°1.11æ¯æ¬¡åœ¨mavenæŒ‰ç…§å®˜æ–¹æ–‡æ¡£å¼•åŒ…éƒ½ä¼šå‡ºç°ä¾èµ–å†²çªã€‚ã€‚ã€‚ã€‚1.9åˆšå‘å¸ƒçš„æ—¶å€™å¯¹ä¸‹é¢çš„å¼•åŒ…æœ‰åšä¾èµ–æ’é™¤ï¼Œåæ¥æ–‡æ¡£æ”¹äº†&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; // Flink's Hive connector.Contains flink-hadoop-compatibility and&#013;&#010;&gt; &gt; flink-orc jars&#013;&#010;&gt; &gt;        flink-connector-hive_2.11-1.11.0.jar&#013;&#010;&gt; &gt;        // Hive dependencies&#013;&#010;&gt; &gt;        hive-exec-2.3.4.jar&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; --&#013;&#010;&gt; Best, Jingsong Lee&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<CAEZk043Lqp9PdDG+Nt_tRBtR4npqbHp14Az1GrVOCOK+P-Wb2A@mail.gmail.com>"
    },
    {
        "id": "<CAEZk040nWi8jF4Cb6pptxf-QUeiB9GKEpWWh_1kzZUz0C5GgbQ@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:32:11 GMT",
        "subject": "Re: connector hiveä¾èµ–å†²çª",
        "content": "hi&#013;&#010;æˆ‘ç”¨çš„æ˜¯ç”¨æˆ·å®šä¹‰ä¾èµ–ï¼Œæ²¡æœ‰ç”¨æ†ç»‘ä¾èµ–åŒ…ï¼Œæ†ç»‘ä¾èµ–åŒ…è¿˜è¦è‡ªå·±ä¸‹è½½ä¸€æ¬¡ã€‚ã€‚ã€‚ã€‚ã€‚&#013;&#010;&#013;&#010;Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:24å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; 1.9å’Œ1.10æ—¶å€™æ’é™¤ä¸€äº›ä¼ é€’ä¾èµ–ååœ¨ideaå’Œæ‰“uber jaråœ¨é›†ç¾¤ç¯å¢ƒéƒ½å¯ä»¥è¿è¡Œï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–çš„è¯åœ¨ideaè¿è¡Œä¸äº†ï¼›&#013;&#010;&gt; 1.11ç°åœ¨åªåœ¨æœ¬åœ°æµ‹å“ªï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–ideaè¿è¡Œä¸äº†ï¼Œé›†ç¾¤ç¯å¢ƒè¿˜æ²¡å¼„ï¼Œä½†æ˜¯æˆ‘æ„Ÿè§‰åœ¨ideaç›´æ¥runè¿™ä¸ªåŠŸèƒ½å¥½å¤šäººéƒ½éœ€è¦ï¼Œæ–‡æ¡£æ˜¯ä¸æ˜¯å¯ä»¥æ”¹è¿›ä¸€ä¸‹&#013;&#010;&gt;&#013;&#010;&gt; Jingsong Li &lt;jingsonglee0@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:16å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt;&gt; ç”¨bundle jarå¯ä»¥æå®šå—ï¼Ÿ&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt; [1]&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#using-bundled-hive-jar&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt; Best,&#013;&#010;&gt;&gt; Jingsong&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt; On Fri, Jul 17, 2020 at 5:14 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt; &gt; hiï¼š&#013;&#010;&gt;&gt; &gt;&#013;&#010;&gt;&gt; &gt;&#013;&#010;&gt;&gt; å¤§ä½¬ä»¬ï¼Œä¸‹é¢è¿æ¥hiveçš„ä¾èµ–åŒ…çš„å“ªä¸ªä¼ é€’ä¾èµ–å¯¼è‡´çš„jaråŒ…å†²çªï¼Œæˆ‘ä»1.9åˆ°1.11æ¯æ¬¡åœ¨mavenæŒ‰ç…§å®˜æ–¹æ–‡æ¡£å¼•åŒ…éƒ½ä¼šå‡ºç°ä¾èµ–å†²çªã€‚ã€‚ã€‚ã€‚1.9åˆšå‘å¸ƒçš„æ—¶å€™å¯¹ä¸‹é¢çš„å¼•åŒ…æœ‰åšä¾èµ–æ’é™¤ï¼Œåæ¥æ–‡æ¡£æ”¹äº†&#013;&#010;&gt;&gt; &gt;&#013;&#010;&gt;&gt; &gt; // Flink's Hive connector.Contains flink-hadoop-compatibility and&#013;&#010;&gt;&gt; &gt; flink-orc jars&#013;&#010;&gt;&gt; &gt;        flink-connector-hive_2.11-1.11.0.jar&#013;&#010;&gt;&gt; &gt;        // Hive dependencies&#013;&#010;&gt;&gt; &gt;        hive-exec-2.3.4.jar&#013;&#010;&gt;&gt; &gt;&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt; --&#013;&#010;&gt;&gt; Best, Jingsong Lee&#013;&#010;&gt;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "3",
        "reply": "<CAEZk043Lqp9PdDG+Nt_tRBtR4npqbHp14Az1GrVOCOK+P-Wb2A@mail.gmail.com>"
    },
    {
        "id": "<CADH6UNSkFZJqAyP=KeZDpOaeKb=nrY_JXkyyjD3q0y5FtViLHQ@mail.gmail.com>",
        "from": "Rui Li &lt;lirui.fu...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 03:47:56 GMT",
        "subject": "Re: connector hiveä¾èµ–å†²çª",
        "content": "ç°åœ¨å…·ä½“æ˜¯é‡åˆ°äº†ä»€ä¹ˆå†²çªå‘€ï¼Ÿhive&#013;&#010;connectoræœ¬èº«åœ¨ä¾èµ–hiveçš„æ—¶å€™ç¡®å®ä¹Ÿæ’é™¤äº†å¾ˆå¤šä¼ é€’ä¾èµ–ï¼Œæ‰èƒ½æ­£å¸¸è¿è¡ŒUTå’ŒITã€‚ä¹Ÿå¯ä»¥å‚è€ƒæˆ‘ä»¬çš„pomæ¥çœ‹æ’é™¤äº†å“ªäº›ä¾èµ–ï¼š&#013;&#010;https://github.com/apache/flink/blob/release-1.11.0/flink-connectors/flink-connector-hive/pom.xml&#013;&#010;&#013;&#010;On Fri, Jul 17, 2020 at 5:32 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; hi&#013;&#010;&gt; æˆ‘ç”¨çš„æ˜¯ç”¨æˆ·å®šä¹‰ä¾èµ–ï¼Œæ²¡æœ‰ç”¨æ†ç»‘ä¾èµ–åŒ…ï¼Œæ†ç»‘ä¾èµ–åŒ…è¿˜è¦è‡ªå·±ä¸‹è½½ä¸€æ¬¡ã€‚ã€‚ã€‚ã€‚ã€‚&#013;&#010;&gt;&#013;&#010;&gt; Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:24å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt; &gt; 1.9å’Œ1.10æ—¶å€™æ’é™¤ä¸€äº›ä¼ é€’ä¾èµ–ååœ¨ideaå’Œæ‰“uber jaråœ¨é›†ç¾¤ç¯å¢ƒéƒ½å¯ä»¥è¿è¡Œï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–çš„è¯åœ¨ideaè¿è¡Œä¸äº†ï¼›&#013;&#010;&gt; &gt;&#013;&#010;&gt; 1.11ç°åœ¨åªåœ¨æœ¬åœ°æµ‹å“ªï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–ideaè¿è¡Œä¸äº†ï¼Œé›†ç¾¤ç¯å¢ƒè¿˜æ²¡å¼„ï¼Œä½†æ˜¯æˆ‘æ„Ÿè§‰åœ¨ideaç›´æ¥runè¿™ä¸ªåŠŸèƒ½å¥½å¤šäººéƒ½éœ€è¦ï¼Œæ–‡æ¡£æ˜¯ä¸æ˜¯å¯ä»¥æ”¹è¿›ä¸€ä¸‹&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Jingsong Li &lt;jingsonglee0@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:16å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&gt; ç”¨bundle jarå¯ä»¥æå®šå—ï¼Ÿ&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; [1]&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#using-bundled-hive-jar&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; Best,&#013;&#010;&gt; &gt;&gt; Jingsong&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; On Fri, Jul 17, 2020 at 5:14 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; &gt; hiï¼š&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; å¤§ä½¬ä»¬ï¼Œä¸‹é¢è¿æ¥hiveçš„ä¾èµ–åŒ…çš„å“ªä¸ªä¼ é€’ä¾èµ–å¯¼è‡´çš„jaråŒ…å†²çªï¼Œæˆ‘ä»1.9åˆ°1.11æ¯æ¬¡åœ¨mavenæŒ‰ç…§å®˜æ–¹æ–‡æ¡£å¼•åŒ…éƒ½ä¼šå‡ºç°ä¾èµ–å†²çªã€‚ã€‚ã€‚ã€‚1.9åˆšå‘å¸ƒçš„æ—¶å€™å¯¹ä¸‹é¢çš„å¼•åŒ…æœ‰åšä¾èµ–æ’é™¤ï¼Œåæ¥æ–‡æ¡£æ”¹äº†&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt; &gt; // Flink's Hive connector.Contains flink-hadoop-compatibility and&#013;&#010;&gt; &gt;&gt; &gt; flink-orc jars&#013;&#010;&gt; &gt;&gt; &gt;        flink-connector-hive_2.11-1.11.0.jar&#013;&#010;&gt; &gt;&gt; &gt;        // Hive dependencies&#013;&#010;&gt; &gt;&gt; &gt;        hive-exec-2.3.4.jar&#013;&#010;&gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&gt; --&#013;&#010;&gt; &gt;&gt; Best, Jingsong Lee&#013;&#010;&gt; &gt;&gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;Best regards!&#013;&#010;Rui Li&#013;&#010;",
        "depth": "4",
        "reply": "<CAEZk043Lqp9PdDG+Nt_tRBtR4npqbHp14Az1GrVOCOK+P-Wb2A@mail.gmail.com>"
    },
    {
        "id": "<CAEZk0426M+Y8k-KARfpQbEiFPXB4PDgm=4GFx6jN3cOPD6=E+A@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 09:20:06 GMT",
        "subject": "Re: connector hiveä¾èµ–å†²çª",
        "content": "hi,&#013;&#010;ä¸æ’é™¤ä¾èµ–çš„è¯ç¯å¢ƒéƒ½èµ·ä¸æ¥çš„å“ˆï¼Œ&#013;&#010;java.lang.IncompatibleClassChangeError: Implementing class&#013;&#010;&#013;&#010;at java.lang.ClassLoader.defineClass1(Native Method)&#013;&#010;at java.lang.ClassLoader.defineClass(ClassLoader.java:756)&#013;&#010;at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#013;&#010;at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)&#013;&#010;at java.net.URLClassLoader.access$100(URLClassLoader.java:74)&#013;&#010;at java.net.URLClassLoader$1.run(URLClassLoader.java:369)&#013;&#010;at java.net.URLClassLoader$1.run(URLClassLoader.java:363)&#013;&#010;at java.security.AccessController.doPrivileged(Native Method)&#013;&#010;at java.net.URLClassLoader.findClass(URLClassLoader.java:362)&#013;&#010;at java.lang.ClassLoader.loadClass(ClassLoader.java:418)&#013;&#010;at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355)&#013;&#010;at java.lang.ClassLoader.loadClass(ClassLoader.java:351)&#013;&#010;at&#013;&#010;org.apache.flink.table.planner.delegation.PlannerBase.&lt;init&gt;(PlannerBase.scala:112)&#013;&#010;at&#013;&#010;org.apache.flink.table.planner.delegation.StreamPlanner.&lt;init&gt;(StreamPlanner.scala:48)&#013;&#010;at&#013;&#010;org.apache.flink.table.planner.delegation.BlinkPlannerFactory.create(BlinkPlannerFactory.java:50)&#013;&#010;at&#013;&#010;org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.create(StreamTableEnvironmentImpl.java:130)&#013;&#010;at&#013;&#010;org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:111)&#013;&#010;at&#013;&#010;com.akulaku.data.flink.ParserDataTest.parserDataTest(ParserDataTest.java:24)&#013;&#010;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#013;&#010;at&#013;&#010;sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#013;&#010;at&#013;&#010;sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#013;&#010;at java.lang.reflect.Method.invoke(Method.java:498)&#013;&#010;at&#013;&#010;org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)&#013;&#010;at&#013;&#010;org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)&#013;&#010;at&#013;&#010;org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)&#013;&#010;at&#013;&#010;org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)&#013;&#010;at&#013;&#010;org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)&#013;&#010;at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)&#013;&#010;at&#013;&#010;org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)&#013;&#010;at&#013;&#010;org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)&#013;&#010;at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)&#013;&#010;at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)&#013;&#010;at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)&#013;&#010;at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)&#013;&#010;at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)&#013;&#010;at org.junit.runners.ParentRunner.run(ParentRunner.java:363)&#013;&#010;at org.junit.runner.JUnitCore.run(JUnitCore.java:137)&#013;&#010;at&#013;&#010;com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)&#013;&#010;at&#013;&#010;com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)&#013;&#010;at&#013;&#010;com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230)&#013;&#010;at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58)&#013;&#010;&#013;&#010;Rui Li &lt;lirui.fudan@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸Šåˆ11:48å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; ç°åœ¨å…·ä½“æ˜¯é‡åˆ°äº†ä»€ä¹ˆå†²çªå‘€ï¼Ÿhive&#013;&#010;&gt; connectoræœ¬èº«åœ¨ä¾èµ–hiveçš„æ—¶å€™ç¡®å®ä¹Ÿæ’é™¤äº†å¾ˆå¤šä¼ é€’ä¾èµ–ï¼Œæ‰èƒ½æ­£å¸¸è¿è¡ŒUTå’ŒITã€‚ä¹Ÿå¯ä»¥å‚è€ƒæˆ‘ä»¬çš„pomæ¥çœ‹æ’é™¤äº†å“ªäº›ä¾èµ–ï¼š&#013;&#010;&gt;&#013;&#010;&gt; https://github.com/apache/flink/blob/release-1.11.0/flink-connectors/flink-connector-hive/pom.xml&#013;&#010;&gt;&#013;&#010;&gt; On Fri, Jul 17, 2020 at 5:32 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt;&#013;&#010;&gt; &gt; hi&#013;&#010;&gt; &gt; æˆ‘ç”¨çš„æ˜¯ç”¨æˆ·å®šä¹‰ä¾èµ–ï¼Œæ²¡æœ‰ç”¨æ†ç»‘ä¾èµ–åŒ…ï¼Œæ†ç»‘ä¾èµ–åŒ…è¿˜è¦è‡ªå·±ä¸‹è½½ä¸€æ¬¡ã€‚ã€‚ã€‚ã€‚ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:24å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; &gt; 1.9å’Œ1.10æ—¶å€™æ’é™¤ä¸€äº›ä¼ é€’ä¾èµ–ååœ¨ideaå’Œæ‰“uber jaråœ¨é›†ç¾¤ç¯å¢ƒéƒ½å¯ä»¥è¿è¡Œï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–çš„è¯åœ¨ideaè¿è¡Œä¸äº†ï¼›&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; 1.11ç°åœ¨åªåœ¨æœ¬åœ°æµ‹å“ªï¼Œä¸æ’é™¤ä¼ é€’ä¾èµ–ideaè¿è¡Œä¸äº†ï¼Œé›†ç¾¤ç¯å¢ƒè¿˜æ²¡å¼„ï¼Œä½†æ˜¯æˆ‘æ„Ÿè§‰åœ¨ideaç›´æ¥runè¿™ä¸ªåŠŸèƒ½å¥½å¤šäººéƒ½éœ€è¦ï¼Œæ–‡æ¡£æ˜¯ä¸æ˜¯å¯ä»¥æ”¹è¿›ä¸€ä¸‹&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; Jingsong Li &lt;jingsonglee0@gmail.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:16å†™é“ï¼š&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&gt; ç”¨bundle jarå¯ä»¥æå®šå—ï¼Ÿ&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&gt; [1]&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#using-bundled-hive-jar&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&gt; Best,&#013;&#010;&gt; &gt; &gt;&gt; Jingsong&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&gt; On Fri, Jul 17, 2020 at 5:14 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt;&#010;wrote:&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&gt; &gt; hiï¼š&#013;&#010;&gt; &gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; å¤§ä½¬ä»¬ï¼Œä¸‹é¢è¿æ¥hiveçš„ä¾èµ–åŒ…çš„å“ªä¸ªä¼ é€’ä¾èµ–å¯¼è‡´çš„jaråŒ…å†²çªï¼Œæˆ‘ä»1.9åˆ°1.11æ¯æ¬¡åœ¨mavenæŒ‰ç…§å®˜æ–¹æ–‡æ¡£å¼•åŒ…éƒ½ä¼šå‡ºç°ä¾èµ–å†²çªã€‚ã€‚ã€‚ã€‚1.9åˆšå‘å¸ƒçš„æ—¶å€™å¯¹ä¸‹é¢çš„å¼•åŒ…æœ‰åšä¾èµ–æ’é™¤ï¼Œåæ¥æ–‡æ¡£æ”¹äº†&#013;&#010;&gt; &gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt; &gt;&gt; &gt; // Flink's Hive connector.Contains flink-hadoop-compatibility and&#013;&#010;&gt; &gt; &gt;&gt; &gt; flink-orc jars&#013;&#010;&gt; &gt; &gt;&gt; &gt;        flink-connector-hive_2.11-1.11.0.jar&#013;&#010;&gt; &gt; &gt;&gt; &gt;        // Hive dependencies&#013;&#010;&gt; &gt; &gt;&gt; &gt;        hive-exec-2.3.4.jar&#013;&#010;&gt; &gt; &gt;&gt; &gt;&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&gt; --&#013;&#010;&gt; &gt; &gt;&gt; Best, Jingsong Lee&#013;&#010;&gt; &gt; &gt;&gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; --&#013;&#010;&gt; Best regards!&#013;&#010;&gt; Rui Li&#013;&#010;&gt;&#013;&#010;",
        "depth": "5",
        "reply": "<CAEZk043Lqp9PdDG+Nt_tRBtR4npqbHp14Az1GrVOCOK+P-Wb2A@mail.gmail.com>"
    },
    {
        "id": "<tencent_5E2B0E14A76295A54920A59B9E0204506908@qq.com>",
        "from": "&quot;867127831&quot; &lt;867127...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 09:26:58 GMT",
        "subject": "flinkä¸å¸¦å‚æ•°çš„udfå§‹ç»ˆè¿”å›ç¬¬ä¸€æ¬¡è°ƒç”¨çš„ç»“æœ",
        "content": "hi, æˆ‘æœ‰ä¸€ä¸ªä¸å¸¦å‚æ•°çš„udfï¼Œç”¨äºè¿”å›ç³»ç»Ÿå½“å‰æ—¶é—´çš„å­—ç¬¦ä¸²æ ¼å¼ï¼Œä½†æ˜¯è°ƒç”¨æ—¶æ¯æ¬¡éƒ½è¿”å›è¿™ä¸ªudfç¬¬ä¸€æ¬¡è°ƒç”¨çš„ç»“æœï¼Œæ‰€ä»¥æ‹¿åˆ°çš„æ—¶é—´å…¨éƒ¨éƒ½æ˜¯ä¸€æ ·çš„&#013;&#010;&#013;&#010;&#013;&#010;udfçš„å®æ—¶å¦‚ä¸‹ï¼š&#013;&#010;&#013;&#010;&#013;&#010;public class GetTimeFunc extends ScalarFunction {&#013;&#010;&#009;public String eval() {&#013;&#010;&#009;&#009;return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date());&#013;&#010;&#009;}&#013;&#010;}&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;è¯·é—®ï¼Œé’ˆå¯¹è¿™ç§æ²¡æœ‰å…¥å‚çš„udfï¼Œflinkå†…éƒ¨æ˜¯æœ‰åšä»€ä¹ˆä¼˜åŒ–å—ï¼Œå¯¼è‡´æ¯æ¬¡è°ƒç”¨è¿”å›çš„ç»“æœéƒ½ä¸€æ ·ï¼Ÿ",
        "depth": "0",
        "reply": "<tencent_5E2B0E14A76295A54920A59B9E0204506908@qq.com>"
    },
    {
        "id": "<CABKuJ_S4k1b5OTTYbc8d7=Qy3AKy9_wSnEq4cQgkhHWnd1D0Cg@mail.gmail.com>",
        "from": "Benchao Li &lt;libenc...@apache.org&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 11:50:50 GMT",
        "subject": "Re: flinkä¸å¸¦å‚æ•°çš„udfå§‹ç»ˆè¿”å›ç¬¬ä¸€æ¬¡è°ƒç”¨çš„ç»“æœ",
        "content": "æ˜¯çš„ï¼Œè¿™ç§å°±è¢«å½“åšå¸¸é‡è¢«ä¼˜åŒ–æ‰äº†ã€‚&#013;&#010;ä½ å¯ä»¥è¦†ç›–ä¸€ä¸‹ScalarFunction#isDeterministicæ–¹æ³•ï¼Œè¯´æ˜ä½ è¿™ä¸ªå‡½æ•°æ—¶éç¡®å®šæ€§çš„ï¼Œå°±ä¸ä¼šè¢«ä¼˜åŒ–æ‰äº†ã€‚&#013;&#010;&#013;&#010;867127831 &lt;867127831@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ5:27å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; hi, æˆ‘æœ‰ä¸€ä¸ªä¸å¸¦å‚æ•°çš„udfï¼Œç”¨äºè¿”å›ç³»ç»Ÿå½“å‰æ—¶é—´çš„å­—ç¬¦ä¸²æ ¼å¼ï¼Œä½†æ˜¯è°ƒç”¨æ—¶æ¯æ¬¡éƒ½è¿”å›è¿™ä¸ªudfç¬¬ä¸€æ¬¡è°ƒç”¨çš„ç»“æœï¼Œæ‰€ä»¥æ‹¿åˆ°çš„æ—¶é—´å…¨éƒ¨éƒ½æ˜¯ä¸€æ ·çš„&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; udfçš„å®æ—¶å¦‚ä¸‹ï¼š&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; public class GetTimeFunc extends ScalarFunction {&#013;&#010;&gt;         public String eval() {&#013;&#010;&gt;                 return new SimpleDateFormat(\"yyyy-MM-dd&#013;&#010;&gt; HH:mm:ss\").format(new Date());&#013;&#010;&gt;         }&#013;&#010;&gt; }&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; è¯·é—®ï¼Œé’ˆå¯¹è¿™ç§æ²¡æœ‰å…¥å‚çš„udfï¼Œflinkå†…éƒ¨æ˜¯æœ‰åšä»€ä¹ˆä¼˜åŒ–å—ï¼Œå¯¼è‡´æ¯æ¬¡è°ƒç”¨è¿”å›çš„ç»“æœéƒ½ä¸€æ ·ï¼Ÿ&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;&#013;&#010;Best,&#013;&#010;Benchao Li&#013;&#010;",
        "depth": "1",
        "reply": "<tencent_5E2B0E14A76295A54920A59B9E0204506908@qq.com>"
    },
    {
        "id": "<1594988110813-0.post@n8.nabble.com>",
        "from": "Jun He &lt;867127...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 12:15:10 GMT",
        "subject": "Re: flinkä¸å¸¦å‚æ•°çš„udfå§‹ç»ˆè¿”å›ç¬¬ä¸€æ¬¡è°ƒç”¨çš„ç»“æœ",
        "content": "æ„Ÿè°¢ï¼Œæ˜¯è¿™ä¸ªåŸå› ã€‚&#010;&#010;&#010;&#010;--&#010;Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&#010;",
        "depth": "2",
        "reply": "<tencent_5E2B0E14A76295A54920A59B9E0204506908@qq.com>"
    },
    {
        "id": "<tencent_8CBD88635E10004B1F4327727F83355EF506@qq.com>",
        "from": "&quot;Z-Z&quot; &lt;zz9876543...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 10:22:07 GMT",
        "subject": "Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#010;---&amp;gt; /jobs/{jobid}/savepoints ---&amp;gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#013;&#010;2020-07-17 09:51:48,925 INFO&amp;nbsp; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp;&#010;- Request slot with profile ResourceProfile{UNKNOWN} for job 7639673873b707aa86c4387aa7b4aac3&#010;with allocation id e8865cdbfe4c3c33099c7112bc2e3231.&#013;&#010;2020-07-17 09:51:48,952 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Source: Custom Source -&amp;gt; Filter (1/1) (1177659bff014e8dbc3f0508055d4307)&#010;switched from SCHEDULED to DEPLOYING.&#013;&#010;2020-07-17 09:51:48,952 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Deploying Source: Custom Source -&amp;gt; Filter (1/1)&#010;(attempt #0) to e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;2020-07-17 09:51:48,953 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Source: Custom Source (1/1) (141f0dc22b624b39e21127f637ba63c2)&#010;switched from SCHEDULED to DEPLOYING.&#013;&#010;2020-07-17 09:51:48,953 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to e63d829deafc144cd82efd73979dd056&#010;@ 083f69d029de (dataPort=35758)&#013;&#010;2020-07-17 09:51:48,954 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Source: Custom Source (1/1) (274b3df03e1fab627059c1a78e4a26da)&#010;switched from SCHEDULED to DEPLOYING.&#013;&#010;2020-07-17 09:51:48,954 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to e63d829deafc144cd82efd73979dd056&#010;@ 083f69d029de (dataPort=35758)&#013;&#010;2020-07-17 09:51:48,954 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched&#010;from SCHEDULED to DEPLOYING.&#013;&#010;2020-07-17 09:51:48,954 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to e63d829deafc144cd82efd73979dd056&#010;@ 083f69d029de (dataPort=35758)&#013;&#010;2020-07-17 09:51:48,955 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Co-Process -&amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#010;(618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to DEPLOYING.&#013;&#010;2020-07-17 09:51:48,955 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Deploying Co-Process -&amp;gt; (Sink: Unnamed, Sink: Unnamed)&#010;(1/1) (attempt #0) to e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;2020-07-17 09:51:49,346 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Co-Process -&amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#010;(618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING to RUNNING.&#013;&#010;2020-07-17 09:51:49,370 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Source: Custom Source (1/1) (274b3df03e1fab627059c1a78e4a26da)&#010;switched from DEPLOYING to RUNNING.&#013;&#010;2020-07-17 09:51:49,370 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Source: Custom Source (1/1) (141f0dc22b624b39e21127f637ba63c2)&#010;switched from DEPLOYING to RUNNING.&#013;&#010;2020-07-17 09:51:49,377 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched&#010;from DEPLOYING to RUNNING.&#013;&#010;2020-07-17 09:51:49,377 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Source: Custom Source -&amp;gt; Filter (1/1) (1177659bff014e8dbc3f0508055d4307)&#010;switched from DEPLOYING to RUNNING.&#013;&#010;2020-07-17 09:51:49,493 INFO&amp;nbsp; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched&#010;from RUNNING to FAILED.&#013;&#010;java.lang.Exception: Exception while creating StreamOperatorStateContext.&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&#009;at java.lang.Thread.run(Thread.java:748)&#013;&#010;Caused by: org.apache.flink.util.FlinkException: Could not restore keyed state backend for&#010;LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1) from any of the 1 provided&#010;restore options.&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&#009;... 9 more&#013;&#010;Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected exception.&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&#009;... 11 more&#013;&#010;Caused by: java.io.EOFException&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&#009;at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&#009;... 15 more",
        "depth": "0",
        "reply": "<tencent_8CBD88635E10004B1F4327727F83355EF506@qq.com>"
    },
    {
        "id": "<CAA8tFvuODQompr38MjN6nuD0_5VPAZMCZcKS4-onkpQUmOEjCA@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 14:52:10 GMT",
        "subject": "Re: Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "Hi&#010;&#010;è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹  Co-Process (1/1)&#010;(d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨&#010;083f69d029de&#010;è¿™å°æœºå™¨ä¸Šã€‚&#010;&#010;Best,&#010;Congxian&#010;&#010;&#010;Z-Z &lt;zz9876543210@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#010;&#010;&gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#010;&gt; ---&amp;gt; /jobs/{jobid}/savepoints ---&amp;gt;&#010;&gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#010;&gt; 2020-07-17 09:51:48,925 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;nbsp; -&#010;&gt; Request slot with profile ResourceProfile{UNKNOWN} for job&#010;&gt; 7639673873b707aa86c4387aa7b4aac3 with allocation id&#010;&gt; e8865cdbfe4c3c33099c7112bc2e3231.&#010;&gt; 2020-07-17 09:51:48,952 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Source: Custom Source -&amp;gt; Filter (1/1)&#010;&gt; (1177659bff014e8dbc3f0508055d4307) switched from SCHEDULED to DEPLOYING.&#010;&gt; 2020-07-17 09:51:48,952 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Deploying Source: Custom Source -&amp;gt; Filter (1/1) (attempt #0) to&#010;&gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; 2020-07-17 09:51:48,953 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Source: Custom Source (1/1) (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; 2020-07-17 09:51:48,953 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#010;&gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; 2020-07-17 09:51:48,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Source: Custom Source (1/1) (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; 2020-07-17 09:51:48,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#010;&gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; 2020-07-17 09:51:48,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched from&#010;&gt; SCHEDULED to DEPLOYING.&#010;&gt; 2020-07-17 09:51:48,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to&#010;&gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; 2020-07-17 09:51:48,955 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Co-Process -&amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#010;&gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to DEPLOYING.&#010;&gt; 2020-07-17 09:51:48,955 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Deploying Co-Process -&amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#010;&gt; (attempt #0) to e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; (dataPort=35758)&#010;&gt; 2020-07-17 09:51:49,346 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Co-Process -&amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#010;&gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING to RUNNING.&#010;&gt; 2020-07-17 09:51:49,370 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Source: Custom Source (1/1) (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; switched from DEPLOYING to RUNNING.&#010;&gt; 2020-07-17 09:51:49,370 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Source: Custom Source (1/1) (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; switched from DEPLOYING to RUNNING.&#010;&gt; 2020-07-17 09:51:49,377 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched from&#010;&gt; DEPLOYING to RUNNING.&#010;&gt; 2020-07-17 09:51:49,377 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Source: Custom Source -&amp;gt; Filter (1/1)&#010;&gt; (1177659bff014e8dbc3f0508055d4307) switched from DEPLOYING to RUNNING.&#010;&gt; 2020-07-17 09:51:49,493 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched from&#010;&gt; RUNNING to FAILED.&#010;&gt; java.lang.Exception: Exception while creating StreamOperatorStateContext.&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;         at java.lang.Thread.run(Thread.java:748)&#010;&gt; Caused by: org.apache.flink.util.FlinkException: Could not restore keyed&#010;&gt; state backend for&#010;&gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1) from&#010;&gt; any of the 1 provided restore options.&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt;         ... 9 more&#010;&gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught&#010;&gt; unexpected exception.&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt;         ... 11 more&#010;&gt; Caused by: java.io.EOFException&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt;         at&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt;         ... 15 more&#010;&#010;",
        "depth": "1",
        "reply": "<tencent_8CBD88635E10004B1F4327727F83355EF506@qq.com>"
    },
    {
        "id": "<tencent_7C2215791E004C7D699D9FFD25D687D50D08@qq.com>",
        "from": "&quot;Z-Z&quot; &lt;zz9876543...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 15:10:12 GMT",
        "subject": "å›å¤ï¼š Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "Flink 1.10.0 ,taskmanageræŠ¥é”™æ—¥å¿—å¦‚ä¸‹ï¼š&#013;&#010;&#013;&#010;&#013;&#010;2020-07-17 15:06:43,913 ERROR org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;nbsp;&#010;- Caught unexpected exception.&#013;&#010;java.io.EOFException&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&#009;at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&#009;at java.lang.Thread.run(Thread.java:748)&#013;&#010;2020-07-17 15:06:43,914 WARN&amp;nbsp; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;nbsp;&#010;- Exception while restoring keyed state backend for KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1)&#010;from alternative (1/1), will retry while more alternatives are available.&#013;&#010;org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected exception.&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&#009;at java.lang.Thread.run(Thread.java:748)&#013;&#010;Caused by: java.io.EOFException&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&#009;at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&#009;... 15 more&#013;&#010;2020-07-17 15:06:43,915 INFO&amp;nbsp; org.apache.kafka.clients.producer.KafkaProducer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Closing the&#010;Kafka producer with timeoutMillis = 9223372036854775807 ms.&#013;&#010;2020-07-17 15:06:43,918 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Co-Keyed-Process -&amp;gt; Flat Map -&amp;gt; Sink: Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab)&#010;switched from RUNNING to FAILED.&#013;&#010;java.lang.Exception: Exception while creating StreamOperatorStateContext.&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&#009;at java.lang.Thread.run(Thread.java:748)&#013;&#010;Caused by: org.apache.flink.util.FlinkException: Could not restore keyed state backend for&#010;KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from any of the 1 provided restore&#010;options.&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&#009;... 9 more&#013;&#010;Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected exception.&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&#009;... 11 more&#013;&#010;Caused by: java.io.EOFException&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&#009;at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&#009;at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&#009;... 15 more&#013;&#010;2020-07-17 15:06:43,919 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Freeing task resources for Co-Keyed-Process -&amp;gt; Flat Map -&amp;gt; Sink:&#010;Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab).&#013;&#010;2020-07-17 15:06:43,919 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Ensuring all FileSystem streams are closed for task Co-Keyed-Process -&amp;gt;&#010;Flat Map -&amp;gt; Sink: Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) [FAILED]&#013;&#010;2020-07-17 15:06:43,931 INFO&amp;nbsp; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; - Un-registering task and sending final&#010;execution state FAILED to JobManager for task Co-Keyed-Process -&amp;gt; Flat Map -&amp;gt;&#010;Sink: Unnamed (1/1) bb8f0a84e07ef90b1e11ca2825e0efab.&#013;&#010;2020-07-17 15:06:43,947 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Attempting to cancel task Source: Custom Source -&amp;gt; Flat Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;2020-07-17 15:06:43,947 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Source: Custom Source -&amp;gt; Flat Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce)&#010;switched from RUNNING to CANCELING.&#013;&#010;2020-07-17 15:06:43,947 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Triggering cancellation of task code Source: Custom Source -&amp;gt; Flat Map&#010;(1/1) (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;2020-07-17 15:06:43,949 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Attempting to cancel task Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;2020-07-17 15:06:43,949 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600) switched from RUNNING&#010;to CANCELING.&#013;&#010;2020-07-17 15:06:43,949 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Triggering cancellation of task code Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;2020-07-17 15:06:43,954 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Source: Custom Source -&amp;gt; Flat Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce)&#010;switched from CANCELING to CANCELED.&#013;&#010;2020-07-17 15:06:43,954 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Freeing task resources for Source: Custom Source -&amp;gt; Flat Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;2020-07-17 15:06:43,954 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Ensuring all FileSystem streams are closed for task Source: Custom Source -&amp;gt;&#010;Flat Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) [CANCELED]&#013;&#010;2020-07-17 15:06:43,954 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600) switched from CANCELING&#010;to CANCELED.&#013;&#010;2020-07-17 15:06:43,955 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Freeing task resources for Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;2020-07-17 15:06:43,954 INFO&amp;nbsp; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; - Un-registering task and sending final&#010;execution state CANCELED to JobManager for task Source: Custom Source -&amp;gt; Flat Map (1/1)&#010;9cb8dcd4982223adcb6f007f1ffccdce.&#013;&#010;2020-07-17 15:06:43,962 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;- Ensuring all FileSystem streams are closed for task Source: Custom Source (1/1)&#010;(00621ff5d788d00c73ccaaea04717600) [CANCELED]&#013;&#010;2020-07-17 15:06:43,962 INFO&amp;nbsp; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; - Un-registering task and sending final&#010;execution state CANCELED to JobManager for task Source: Custom Source (1/1) 00621ff5d788d00c73ccaaea04717600.&#013;&#010;2020-07-17 15:06:44,077 WARN&amp;nbsp; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'transaction.timeout.ms'&#010;was supplied but isn't a known config.&#013;&#010;2020-07-17 15:06:44,077 WARN&amp;nbsp; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'key.serializer'&#010;was supplied but isn't a known config.&#013;&#010;2020-07-17 15:06:44,077 WARN&amp;nbsp; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'value.serializer'&#010;was supplied but isn't a known config.&#013;&#010;2020-07-17 15:06:44,077 INFO&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;-&#010;Kafka version : 0.11.0.2&#013;&#010;2020-07-17 15:06:44,077 INFO&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;-&#010;Kafka commitId : 73be1e1168f91ee2&#013;&#010;2020-07-17 15:06:44,077 WARN&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;-&#010;Error registering AppInfo mbean&#013;&#010;javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=consumer-3&#013;&#010;&#009;at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&#009;at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&#009;at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&#009;at org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:757)&#013;&#010;&#009;at org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:633)&#013;&#010;&#009;at org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:615)&#013;&#010;&#009;at org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&#009;at org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;2020-07-17 15:06:44,079 INFO&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;-&#010;Kafka version : 0.11.0.2&#013;&#010;2020-07-17 15:06:44,079 INFO&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;-&#010;Kafka commitId : 73be1e1168f91ee2&#013;&#010;2020-07-17 15:06:44,079 WARN&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;-&#010;Error registering AppInfo mbean&#013;&#010;javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=consumer-4&#013;&#010;&#009;at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&#009;at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&#009;at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&#009;at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&#009;at org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:757)&#013;&#010;&#009;at org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:633)&#013;&#010;&#009;at org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:615)&#013;&#010;&#009;at org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&#009;at org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;qcx978132955@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:52&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Hi&#013;&#010;&#013;&#010;è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹&amp;nbsp; Co-Process (1/1)&#013;&#010;(d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨&#010;083f69d029de&#013;&#010;è¿™å°æœºå™¨ä¸Šã€‚&#013;&#010;&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;Z-Z &lt;zz9876543210@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#013;&#010;&amp;gt; ---&amp;amp;gt; /jobs/{jobid}/savepoints ---&amp;amp;gt;&#013;&#010;&amp;gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#013;&#010;&amp;gt; 2020-07-17 09:51:48,925 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;amp;nbsp;&#010;-&#013;&#010;&amp;gt; Request slot with profile ResourceProfile{UNKNOWN} for job&#013;&#010;&amp;gt; 7639673873b707aa86c4387aa7b4aac3 with allocation id&#013;&#010;&amp;gt; e8865cdbfe4c3c33099c7112bc2e3231.&#013;&#010;&amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Source: Custom Source -&amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Deploying Source: Custom Source -&amp;amp;gt; Filter (1/1) (attempt&#010;#0) to&#013;&#010;&amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1) (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#013;&#010;&amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1) (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#013;&#010;&amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched from&#013;&#010;&amp;gt; SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to&#013;&#010;&amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Co-Process -&amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Deploying Co-Process -&amp;amp;gt; (Sink: Unnamed, Sink: Unnamed)&#010;(1/1)&#013;&#010;&amp;gt; (attempt #0) to e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#013;&#010;&amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; 2020-07-17 09:51:49,346 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Co-Process -&amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1) (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1) (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched from&#013;&#010;&amp;gt; DEPLOYING to RUNNING.&#013;&#010;&amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Source: Custom Source -&amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; 2020-07-17 09:51:49,493 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp; &amp;amp;nbsp;&#010;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b) switched from&#013;&#010;&amp;gt; RUNNING to FAILED.&#013;&#010;&amp;gt; java.lang.Exception: Exception while creating StreamOperatorStateContext.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore keyed&#013;&#010;&amp;gt; state backend for&#013;&#010;&amp;gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1) from&#013;&#010;&amp;gt; any of the 1 provided restore options.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ...&#010;9 more&#013;&#010;&amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught&#013;&#010;&amp;gt; unexpected exception.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ...&#010;11 more&#013;&#010;&amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ...&#010;15 more",
        "depth": "2",
        "reply": "<tencent_8CBD88635E10004B1F4327727F83355EF506@qq.com>"
    },
    {
        "id": "<CAA8tFvtjXpW3ir1EoTAGeTyfL8J9pLEOLXo5KGw5dy_s9-5vMg@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sun, 19 Jul 2020 12:22:00 GMT",
        "subject": "Re: Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "Hi&#010;&#010;ä»ä½ ç»™çš„è¿™éƒ¨åˆ†æ—¥å¿—çœ‹ï¼Œæ˜¯æ¢å¤çš„æ—¶å€™é‡åˆ° EOF äº†ï¼Œè¿™ä¸ªæ¯”è¾ƒå¥‡æ€ª&#010;1 ä½ ä¹‹å‰çš„ savepoint æ˜¯ä½¿ç”¨ RocksDBStateBackend ç”Ÿæˆçš„å—&#010;2 ä½ è¿˜æœ‰ä¹‹å‰åœ¨ DFS ä¸Šçš„ savepoint æ–‡ä»¶å—ï¼Ÿå¯èƒ½éœ€è¦ç»“åˆ DFS ä¸Šçš„æ–‡ä»¶ä¸€èµ·çœ‹ä¸€ä¸‹è¿™ä¸ªé—®é¢˜æ€ä¹ˆæ¥çš„&#010;&#010;Best,&#010;Congxian&#010;&#010;&#010;Z-Z &lt;zz9876543210@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ11:10å†™é“ï¼š&#010;&#010;&gt; Flink 1.10.0 ,taskmanageræŠ¥é”™æ—¥å¿—å¦‚ä¸‹ï¼š&#010;&gt;&#010;&gt;&#010;&gt; 2020-07-17 15:06:43,913 ERROR&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;nbsp;&#010;&gt; - Caught unexpected exception.&#010;&gt; java.io.EOFException&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt;         at&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;         at java.lang.Thread.run(Thread.java:748)&#010;&gt; 2020-07-17 15:06:43,914 WARN&amp;nbsp;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;nbsp; -&#010;&gt; Exception while restoring keyed state backend for&#010;&gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#010;&gt; alternative (1/1), will retry while more alternatives are available.&#010;&gt; org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected&#010;&gt; exception.&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;         at java.lang.Thread.run(Thread.java:748)&#010;&gt; Caused by: java.io.EOFException&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt;         at&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt;         ... 15 more&#010;&gt; 2020-07-17 15:06:43,915 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.clients.producer.KafkaProducer&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Closing the Kafka producer with timeoutMillis&#010;&gt; = 9223372036854775807 ms.&#010;&gt; 2020-07-17 15:06:43,918 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Co-Keyed-Process -&amp;gt;&#010;Flat Map&#010;&gt; -&amp;gt; Sink: Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) switched from&#010;&gt; RUNNING to FAILED.&#010;&gt; java.lang.Exception: Exception while creating StreamOperatorStateContext.&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;         at java.lang.Thread.run(Thread.java:748)&#010;&gt; Caused by: org.apache.flink.util.FlinkException: Could not restore keyed&#010;&gt; state backend for&#010;&gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from any of&#010;&gt; the 1 provided restore options.&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt;         ... 9 more&#010;&gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught&#010;&gt; unexpected exception.&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt;         ... 11 more&#010;&gt; Caused by: java.io.EOFException&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt;         at java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt;         at&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt;         ... 15 more&#010;&gt; 2020-07-17 15:06:43,919 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Freeing task resources&#010;for&#010;&gt; Co-Keyed-Process -&amp;gt; Flat Map -&amp;gt; Sink: Unnamed (1/1)&#010;&gt; (bb8f0a84e07ef90b1e11ca2825e0efab).&#010;&gt; 2020-07-17 15:06:43,919 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Ensuring all FileSystem&#010;streams&#010;&gt; are closed for task Co-Keyed-Process -&amp;gt; Flat Map -&amp;gt; Sink: Unnamed&#010;&gt; (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) [FAILED]&#010;&gt; 2020-07-17 15:06:43,931 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; - Un-registering task and sending final execution&#010;&gt; state FAILED to JobManager for task Co-Keyed-Process -&amp;gt; Flat Map -&amp;gt;&#010;&gt; Sink: Unnamed (1/1) bb8f0a84e07ef90b1e11ca2825e0efab.&#010;&gt; 2020-07-17 15:06:43,947 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Attempting to cancel&#010;task&#010;&gt; Source: Custom Source -&amp;gt; Flat Map (1/1)&#010;&gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; 2020-07-17 15:06:43,947 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Source: Custom Source&#010;-&amp;gt; Flat&#010;&gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from RUNNING to&#010;&gt; CANCELING.&#010;&gt; 2020-07-17 15:06:43,947 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Triggering cancellation&#010;of task&#010;&gt; code Source: Custom Source -&amp;gt; Flat Map (1/1)&#010;&gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; 2020-07-17 15:06:43,949 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Attempting to cancel&#010;task&#010;&gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#010;&gt; 2020-07-17 15:06:43,949 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Source: Custom Source&#010;(1/1)&#010;&gt; (00621ff5d788d00c73ccaaea04717600) switched from RUNNING to CANCELING.&#010;&gt; 2020-07-17 15:06:43,949 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Triggering cancellation&#010;of task&#010;&gt; code Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#010;&gt; 2020-07-17 15:06:43,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Source: Custom Source&#010;-&amp;gt; Flat&#010;&gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from CANCELING to&#010;&gt; CANCELED.&#010;&gt; 2020-07-17 15:06:43,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Freeing task resources&#010;for&#010;&gt; Source: Custom Source -&amp;gt; Flat Map (1/1)&#010;&gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; 2020-07-17 15:06:43,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Ensuring all FileSystem&#010;streams&#010;&gt; are closed for task Source: Custom Source -&amp;gt; Flat Map (1/1)&#010;&gt; (9cb8dcd4982223adcb6f007f1ffccdce) [CANCELED]&#010;&gt; 2020-07-17 15:06:43,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Source: Custom Source&#010;(1/1)&#010;&gt; (00621ff5d788d00c73ccaaea04717600) switched from CANCELING to CANCELED.&#010;&gt; 2020-07-17 15:06:43,955 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Freeing task resources&#010;for&#010;&gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#010;&gt; 2020-07-17 15:06:43,954 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; - Un-registering task and sending final execution&#010;&gt; state CANCELED to JobManager for task Source: Custom Source -&amp;gt; Flat Map&#010;&gt; (1/1) 9cb8dcd4982223adcb6f007f1ffccdce.&#010;&gt; 2020-07-17 15:06:43,962 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Ensuring all FileSystem&#010;streams&#010;&gt; are closed for task Source: Custom Source (1/1)&#010;&gt; (00621ff5d788d00c73ccaaea04717600) [CANCELED]&#010;&gt; 2020-07-17 15:06:43,962 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; - Un-registering task and sending final execution&#010;&gt; state CANCELED to JobManager for task Source: Custom Source (1/1)&#010;&gt; 00621ff5d788d00c73ccaaea04717600.&#010;&gt; 2020-07-17 15:06:44,077 WARN&amp;nbsp;&#010;&gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'transaction.timeout.ms' was&#010;&gt; supplied but isn't a known config.&#010;&gt; 2020-07-17 15:06:44,077 WARN&amp;nbsp;&#010;&gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'key.serializer' was supplied but&#010;&gt; isn't a known config.&#010;&gt; 2020-07-17 15:06:44,077 WARN&amp;nbsp;&#010;&gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'value.serializer' was supplied&#010;&gt; but isn't a known config.&#010;&gt; 2020-07-17 15:06:44,077 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka version : 0.11.0.2&#010;&gt; 2020-07-17 15:06:44,077 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#010;&gt; 2020-07-17 15:06:44,077 WARN&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Error registering&#010;AppInfo mbean&#010;&gt; javax.management.InstanceAlreadyExistsException:&#010;&gt; kafka.consumer:type=app-info,id=consumer-3&#010;&gt;         at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#010;&gt;         at&#010;&gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#010;&gt;         at&#010;&gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#010;&gt;         at&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:757)&#010;&gt;         at&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:633)&#010;&gt;         at&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:615)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#010;&gt; 2020-07-17 15:06:44,079 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka version : 0.11.0.2&#010;&gt; 2020-07-17 15:06:44,079 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#010;&gt; 2020-07-17 15:06:44,079 WARN&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Error registering&#010;AppInfo mbean&#010;&gt; javax.management.InstanceAlreadyExistsException:&#010;&gt; kafka.consumer:type=app-info,id=consumer-4&#010;&gt;         at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#010;&gt;         at&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#010;&gt;         at&#010;&gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#010;&gt;         at&#010;&gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#010;&gt;         at&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:757)&#010;&gt;         at&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:633)&#010;&gt;         at&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;gt;(KafkaConsumer.java:615)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; ------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;&gt; å‘ä»¶äºº:&#010;&gt;                                                   \"user-zh\"&#010;&gt;                                                                     &lt;&#010;&gt; qcx978132955@gmail.com&amp;gt;;&#010;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:52&#010;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&gt;&#010;&gt; ä¸»é¢˜:&amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; Hi&#010;&gt;&#010;&gt; è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹&amp;nbsp; Co-Process (1/1)&#010;&gt; (d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨&#010;083f69d029de&#010;&gt; è¿™å°æœºå™¨ä¸Šã€‚&#010;&gt;&#010;&gt; Best,&#010;&gt; Congxian&#010;&gt;&#010;&gt;&#010;&gt; Z-Z &lt;zz9876543210@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#010;&gt;&#010;&gt; &amp;gt;&#010;&gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#010;&gt; &amp;gt; ---&amp;amp;gt; /jobs/{jobid}/savepoints ---&amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#010;&gt; &amp;gt; 2020-07-17 09:51:48,925 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;amp;nbsp;&#010;&gt; -&#010;&gt; &amp;gt; Request slot with profile ResourceProfile{UNKNOWN} for job&#010;&gt; &amp;gt; 7639673873b707aa86c4387aa7b4aac3 with allocation id&#010;&gt; &amp;gt; e8865cdbfe4c3c33099c7112bc2e3231.&#010;&gt; &amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Source: Custom Source -&amp;amp;gt; Filter (1/1)&#010;&gt; &amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from SCHEDULED to&#010;&gt; DEPLOYING.&#010;&gt; &amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Deploying Source: Custom Source -&amp;amp;gt; Filter (1/1)&#010;&gt; (attempt #0) to&#010;&gt; &amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; &amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; &amp;gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#010;&gt; &amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; &amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; &amp;gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#010;&gt; &amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; &amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#010;&gt; switched from&#010;&gt; &amp;gt; SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to&#010;&gt; &amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#010;&gt; &amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Co-Process -&amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#010;&gt; &amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to&#010;&gt; DEPLOYING.&#010;&gt; &amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Deploying Co-Process -&amp;amp;gt; (Sink: Unnamed, Sink:&#010;&gt; Unnamed) (1/1)&#010;&gt; &amp;gt; (attempt #0) to e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; &amp;gt; (dataPort=35758)&#010;&gt; &amp;gt; 2020-07-17 09:51:49,346 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Co-Process -&amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#010;&gt; &amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; &amp;gt; switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; &amp;gt; switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#010;&gt; switched from&#010;&gt; &amp;gt; DEPLOYING to RUNNING.&#010;&gt; &amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Source: Custom Source -&amp;amp;gt; Filter (1/1)&#010;&gt; &amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; 2020-07-17 09:51:49,493 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#010;&gt; switched from&#010;&gt; &amp;gt; RUNNING to FAILED.&#010;&gt; &amp;gt; java.lang.Exception: Exception while creating&#010;&gt; StreamOperatorStateContext.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore&#010;&gt; keyed&#010;&gt; &amp;gt; state backend for&#010;&gt; &amp;gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1)&#010;&gt; from&#010;&gt; &amp;gt; any of the 1 provided restore options.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;... 9 more&#010;&gt; &amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException:&#010;&gt; Caught&#010;&gt; &amp;gt; unexpected exception.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;... 11 more&#010;&gt; &amp;gt; Caused by: java.io.EOFException&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;... 15 more&#010;&#010;",
        "depth": "3",
        "reply": "<tencent_8CBD88635E10004B1F4327727F83355EF506@qq.com>"
    },
    {
        "id": "<tencent_2F3C4800883EA9CED47E64EB93EA7F11B307@qq.com>",
        "from": "&quot;Z-Z&quot; &lt;zz9876543...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 01:42:02 GMT",
        "subject": "å›å¤ï¼š Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "è°¢è°¢å›å¤ï¼š&#013;&#010;ä¹‹å‰çš„savepointéƒ½æ˜¯é€šè¿‡RocksDBStateBackendç”Ÿæˆçš„ï¼›&#013;&#010;è¿™ä¸ªsavepointæˆ‘é€šè¿‡webui æäº¤ä»»åŠ¡å°±æ²¡é—®é¢˜ï¼Œä½ æ˜¯è¯´åœ¨IDEä¸Šè°ƒè¯•savepointå—&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                                                                        \"user-zh\"                                                                                    &lt;qcx978132955@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ19æ—¥(æ˜ŸæœŸå¤©) æ™šä¸Š8:22&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Hi&#013;&#010;&#013;&#010;ä»ä½ ç»™çš„è¿™éƒ¨åˆ†æ—¥å¿—çœ‹ï¼Œæ˜¯æ¢å¤çš„æ—¶å€™é‡åˆ° EOF äº†ï¼Œè¿™ä¸ªæ¯”è¾ƒå¥‡æ€ª&#013;&#010;1 ä½ ä¹‹å‰çš„ savepoint æ˜¯ä½¿ç”¨ RocksDBStateBackend ç”Ÿæˆçš„å—&#013;&#010;2 ä½ è¿˜æœ‰ä¹‹å‰åœ¨ DFS ä¸Šçš„ savepoint æ–‡ä»¶å—ï¼Ÿå¯èƒ½éœ€è¦ç»“åˆ DFS ä¸Šçš„æ–‡ä»¶ä¸€èµ·çœ‹ä¸€ä¸‹è¿™ä¸ªé—®é¢˜æ€ä¹ˆæ¥çš„&#013;&#010;&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;Z-Z &lt;zz9876543210@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ11:10å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; Flink 1.10.0 ,taskmanageræŠ¥é”™æ—¥å¿—å¦‚ä¸‹ï¼š&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; 2020-07-17 15:06:43,913 ERROR&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;amp;nbsp;&#013;&#010;&amp;gt; - Caught unexpected exception.&#013;&#010;&amp;gt; java.io.EOFException&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; 2020-07-17 15:06:43,914 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;amp;nbsp; -&#013;&#010;&amp;gt; Exception while restoring keyed state backend for&#013;&#010;&amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#013;&#010;&amp;gt; alternative (1/1), will retry while more alternatives are available.&#013;&#010;&amp;gt; org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected&#013;&#010;&amp;gt; exception.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 15 more&#013;&#010;&amp;gt; 2020-07-17 15:06:43,915 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.producer.KafkaProducer&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Closing the Kafka producer with timeoutMillis&#013;&#010;&amp;gt; = 9223372036854775807 ms.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,918 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Co-Keyed-Process -&amp;amp;gt; Flat Map&#013;&#010;&amp;gt; -&amp;amp;gt; Sink: Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) switched from&#013;&#010;&amp;gt; RUNNING to FAILED.&#013;&#010;&amp;gt; java.lang.Exception: Exception while creating StreamOperatorStateContext.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore keyed&#013;&#010;&amp;gt; state backend for&#013;&#010;&amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from any of&#013;&#010;&amp;gt; the 1 provided restore options.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 9 more&#013;&#010;&amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught&#013;&#010;&amp;gt; unexpected exception.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 11 more&#013;&#010;&amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 15 more&#013;&#010;&amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Freeing task resources for&#013;&#010;&amp;gt; Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt; Sink: Unnamed (1/1)&#013;&#010;&amp;gt; (bb8f0a84e07ef90b1e11ca2825e0efab).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Ensuring all FileSystem streams&#013;&#010;&amp;gt; are closed for task Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt; Sink: Unnamed&#013;&#010;&amp;gt; (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) [FAILED]&#013;&#010;&amp;gt; 2020-07-17 15:06:43,931 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending final execution&#013;&#010;&amp;gt; state FAILED to JobManager for task Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt;&#013;&#010;&amp;gt; Sink: Unnamed (1/1) bb8f0a84e07ef90b1e11ca2825e0efab.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Attempting to cancel task&#013;&#010;&amp;gt; Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source -&amp;amp;gt; Flat&#013;&#010;&amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from RUNNING to&#013;&#010;&amp;gt; CANCELING.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Triggering cancellation of task&#013;&#010;&amp;gt; code Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Attempting to cancel task&#013;&#010;&amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source (1/1)&#013;&#010;&amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from RUNNING to CANCELING.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Triggering cancellation of task&#013;&#010;&amp;gt; code Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source -&amp;amp;gt; Flat&#013;&#010;&amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from CANCELING to&#013;&#010;&amp;gt; CANCELED.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Freeing task resources for&#013;&#010;&amp;gt; Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Ensuring all FileSystem streams&#013;&#010;&amp;gt; are closed for task Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce) [CANCELED]&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source (1/1)&#013;&#010;&amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from CANCELING to CANCELED.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,955 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Freeing task resources for&#013;&#010;&amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending final execution&#013;&#010;&amp;gt; state CANCELED to JobManager for task Source: Custom Source -&amp;amp;gt; Flat Map&#013;&#010;&amp;gt; (1/1) 9cb8dcd4982223adcb6f007f1ffccdce.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Ensuring all FileSystem streams&#013;&#010;&amp;gt; are closed for task Source: Custom Source (1/1)&#013;&#010;&amp;gt; (00621ff5d788d00c73ccaaea04717600) [CANCELED]&#013;&#010;&amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending final execution&#013;&#010;&amp;gt; state CANCELED to JobManager for task Source: Custom Source (1/1)&#013;&#010;&amp;gt; 00621ff5d788d00c73ccaaea04717600.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'transaction.timeout.ms' was&#013;&#010;&amp;gt; supplied but isn't a known config.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'key.serializer' was supplied but&#013;&#010;&amp;gt; isn't a known config.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'value.serializer' was supplied&#013;&#010;&amp;gt; but isn't a known config.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka version : 0.11.0.2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Error registering AppInfo mbean&#013;&#010;&amp;gt; javax.management.InstanceAlreadyExistsException:&#013;&#010;&amp;gt; kafka.consumer:type=app-info,id=consumer-3&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:757)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:633)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:615)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;&amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka version : 0.11.0.2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,079 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Error registering AppInfo mbean&#013;&#010;&amp;gt; javax.management.InstanceAlreadyExistsException:&#013;&#010;&amp;gt; kafka.consumer:type=app-info,id=consumer-4&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:757)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:633)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:615)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ------------------&amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;nbsp;------------------&#013;&#010;&amp;gt; å‘ä»¶äºº:&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"user-zh\"&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;&#013;&#010;&amp;gt; qcx978132955@gmail.com&amp;amp;gt;;&#013;&#010;&amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:52&#013;&#010;&amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ä¸»é¢˜:&amp;amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Hi&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹&amp;amp;nbsp; Co-Process (1/1)&#013;&#010;&amp;gt; (d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨ 083f69d029de&#013;&#010;&amp;gt; è¿™å°æœºå™¨ä¸Šã€‚&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Best,&#013;&#010;&amp;gt; Congxian&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Z-Z &lt;zz9876543210@qq.com&amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#013;&#010;&amp;gt; &amp;amp;gt; ---&amp;amp;amp;gt; /jobs/{jobid}/savepoints ---&amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,925 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; -&#013;&#010;&amp;gt; &amp;amp;gt; Request slot with profile ResourceProfile{UNKNOWN} for job&#013;&#010;&amp;gt; &amp;amp;gt; 7639673873b707aa86c4387aa7b4aac3 with allocation id&#013;&#010;&amp;gt; &amp;amp;gt; e8865cdbfe4c3c33099c7112bc2e3231.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from SCHEDULED to&#013;&#010;&amp;gt; DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source -&amp;amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; &amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; &amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to&#013;&#010;&amp;gt; DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Co-Process -&amp;amp;amp;gt; (Sink: Unnamed, Sink:&#013;&#010;&amp;gt; Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (attempt #0) to e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#013;&#010;&amp;gt; &amp;amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,346 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; &amp;amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; &amp;amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,493 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; RUNNING to FAILED.&#013;&#010;&amp;gt; &amp;amp;gt; java.lang.Exception: Exception while creating&#013;&#010;&amp;gt; StreamOperatorStateContext.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore&#013;&#010;&amp;gt; keyed&#013;&#010;&amp;gt; &amp;amp;gt; state backend for&#013;&#010;&amp;gt; &amp;amp;gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1)&#013;&#010;&amp;gt; from&#013;&#010;&amp;gt; &amp;amp;gt; any of the 1 provided restore options.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; ... 9 more&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException:&#013;&#010;&amp;gt; Caught&#013;&#010;&amp;gt; &amp;amp;gt; unexpected exception.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; ... 11 more&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; ... 15 more",
        "depth": "4",
        "reply": "<tencent_8CBD88635E10004B1F4327727F83355EF506@qq.com>"
    },
    {
        "id": "<tencent_670E96B137058A0044F977DFD91F56237F08@qq.com>",
        "from": "&quot;kcz&quot; &lt;573693...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 11:29:39 GMT",
        "subject": "flink-1.11 é›†æˆhive-1.2.1 DDLé—®é¢˜",
        "content": "idea æœ¬åœ°æµ‹è¯•&#013;&#010;è·Ÿhiveæœ‰å…³pomä¾èµ–&#013;&#010;hive-exec flink-connector-hive_2.11&#013;&#010;ä»£ç å¦‚ä¸‹:&#013;&#010; StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&#013;&#010;        env.setParallelism(1);&#013;&#010;        env.enableCheckpointing(60*1000, CheckpointingMode.EXACTLY_ONCE);&#013;&#010;        // åŒä¸€æ—¶é—´åªå…è®¸è¿›è¡Œä¸€ä¸ªæ£€æŸ¥ç‚¹&#013;&#010;        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);&#013;&#010;&#013;&#010;        env.setStateBackend(new FsStateBackend(path));&#013;&#010;        &#013;&#010;        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);&#013;&#010;&#013;&#010;        String name            = \"myhive\";&#013;&#010;        String defaultDatabase = \"situation\";&#013;&#010;        String hiveConfDir     = \"/load/data/hive/hive-conf\"; // a local path&#013;&#010;        String version         = \"1.2.1\";&#013;&#010;&#013;&#010;        HiveCatalog hive = new HiveCatalog(name, defaultDatabase, hiveConfDir, version);&#013;&#010;        tableEnv.registerCatalog(\"myhive\", hive);&#013;&#010;&#013;&#010;// set the HiveCatalog as the current catalog of the session&#013;&#010;        tableEnv.useCatalog(\"myhive\");&#013;&#010;        tableEnv.executeSql(\"CREATE DATABASE IF NOT EXISTS stream_tmp\");&#013;&#010;        tableEnv.executeSql(\"DROP TABLE IF EXISTS stream_tmp.source_table\");&#013;&#010;&#013;&#010;&#013;&#010;æŠ¥é”™å¦‚ä¸‹ï¼š&#013;&#010;&amp;nbsp;&#013;&#010;Exception in thread \"main\" java.lang.IncompatibleClassChangeError: Implementing class&#013;&#010;&#009;at java.lang.ClassLoader.defineClass1(Native Method)&#013;&#010;&#009;at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#013;&#010;&#009;at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#013;&#010;&#009;at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#013;&#010;&#009;at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#013;&#010;&#009;at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#013;&#010;&#009;at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#013;&#010;&#009;at java.security.AccessController.doPrivileged(Native Method)&#013;&#010;&#009;at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#013;&#010;&#009;at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#013;&#010;&#009;at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)&#013;&#010;&#009;at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#013;&#010;&#009;at org.apache.flink.table.planner.delegation.PlannerBase.&lt;init&amp;gt;(PlannerBase.scala:112)&#013;&#010;&#009;at org.apache.flink.table.planner.delegation.StreamPlanner.&lt;init&amp;gt;(StreamPlanner.scala:48)&#013;&#010;&#009;at org.apache.flink.table.planner.delegation.BlinkPlannerFactory.create(BlinkPlannerFactory.java:50)&#013;&#010;&#009;at org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.create(StreamTableEnvironmentImpl.java:130)&#013;&#010;&#009;at org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:111)&#013;&#010;&#009;at com.hive.HiveTest.main(HiveTest.java:33)",
        "depth": "0",
        "reply": "<tencent_670E96B137058A0044F977DFD91F56237F08@qq.com>"
    },
    {
        "id": "<CADH6UNQYgtoWROKBmdNLOdka0E=Ab5FjfsK5uoWNuLdbju5KYw@mail.gmail.com>",
        "from": "Rui Li &lt;lirui.fu...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 03:38:46 GMT",
        "subject": "Re: flink-1.11 é›†æˆhive-1.2.1 DDLé—®é¢˜",
        "content": "stacktraceä¸Šçœ‹èµ·æ¥æ˜¯åˆ›å»ºblink plannerçš„æ—¶å€™å‡ºé”™çš„ã€‚æ£€æŸ¥ä¸‹ä¾èµ–çš„blink plannerç‰ˆæœ¬æ˜¯ä¸æ˜¯æ­£ç¡®ï¼Ÿ&#010;&#010;On Fri, Jul 17, 2020 at 7:29 PM kcz &lt;573693104@qq.com&gt; wrote:&#010;&#010;&gt; idea æœ¬åœ°æµ‹è¯•&#010;&gt; è·Ÿhiveæœ‰å…³pomä¾èµ–&#010;&gt; hive-exec flink-connector-hive_2.11&#010;&gt; ä»£ç å¦‚ä¸‹:&#010;&gt;  StreamExecutionEnvironment env =&#010;&gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt;         env.setParallelism(1);&#010;&gt;         env.enableCheckpointing(60*1000, CheckpointingMode.EXACTLY_ONCE);&#010;&gt;         // åŒä¸€æ—¶é—´åªå…è®¸è¿›è¡Œä¸€ä¸ªæ£€æŸ¥ç‚¹&#010;&gt;         env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);&#010;&gt;&#010;&gt;         env.setStateBackend(new FsStateBackend(path));&#010;&gt;&#010;&gt;         StreamTableEnvironment tableEnv =&#010;&gt; StreamTableEnvironment.create(env);&#010;&gt;&#010;&gt;         String name            = \"myhive\";&#010;&gt;         String defaultDatabase = \"situation\";&#010;&gt;         String hiveConfDir     = \"/load/data/hive/hive-conf\"; // a local&#010;&gt; path&#010;&gt;         String version         = \"1.2.1\";&#010;&gt;&#010;&gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; hiveConfDir, version);&#010;&gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt;&#010;&gt; // set the HiveCatalog as the current catalog of the session&#010;&gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt;         tableEnv.executeSql(\"CREATE DATABASE IF NOT EXISTS stream_tmp\");&#010;&gt;         tableEnv.executeSql(\"DROP TABLE IF EXISTS&#010;&gt; stream_tmp.source_table\");&#010;&gt;&#010;&gt;&#010;&gt; æŠ¥é”™å¦‚ä¸‹ï¼š&#010;&gt; &amp;nbsp;&#010;&gt; Exception in thread \"main\" java.lang.IncompatibleClassChangeError:&#010;&gt; Implementing class&#010;&gt;         at java.lang.ClassLoader.defineClass1(Native Method)&#010;&gt;         at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#010;&gt;         at&#010;&gt; java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#010;&gt;         at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#010;&gt;         at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#010;&gt;         at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#010;&gt;         at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#010;&gt;         at java.security.AccessController.doPrivileged(Native Method)&#010;&gt;         at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#010;&gt;         at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#010;&gt;         at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)&#010;&gt;         at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.delegation.PlannerBase.&lt;init&amp;gt;(PlannerBase.scala:112)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.delegation.StreamPlanner.&lt;init&amp;gt;(StreamPlanner.scala:48)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.delegation.BlinkPlannerFactory.create(BlinkPlannerFactory.java:50)&#010;&gt;         at&#010;&gt; org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.create(StreamTableEnvironmentImpl.java:130)&#010;&gt;         at&#010;&gt; org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:111)&#010;&gt;         at com.hive.HiveTest.main(HiveTest.java:33)&#010;&#010;&#010;&#010;-- &#010;Best regards!&#010;Rui Li&#010;&#010;",
        "depth": "1",
        "reply": "<tencent_670E96B137058A0044F977DFD91F56237F08@qq.com>"
    },
    {
        "id": "<CACt=kDscXcBptpboFXf3yv_vrLAxEKpvY0AjpkjvEXfDFtgM_A@mail.gmail.com>",
        "from": "Kurt Young &lt;ykt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 04:02:53 GMT",
        "subject": "Re: flink-1.11 é›†æˆhive-1.2.1 DDLé—®é¢˜",
        "content": "1.11 æŠŠé»˜è®¤planneræ¢æˆblinkäº†ï¼Œéœ€è¦æ·»åŠ ä¸‹blink plannerçš„ä¾èµ–&#010;&#010;Best,&#010;Kurt&#010;&#010;&#010;On Mon, Jul 20, 2020 at 11:39 AM Rui Li &lt;lirui.fudan@gmail.com&gt; wrote:&#010;&#010;&gt; stacktraceä¸Šçœ‹èµ·æ¥æ˜¯åˆ›å»ºblink plannerçš„æ—¶å€™å‡ºé”™çš„ã€‚æ£€æŸ¥ä¸‹ä¾èµ–çš„blink&#010;plannerç‰ˆæœ¬æ˜¯ä¸æ˜¯æ­£ç¡®ï¼Ÿ&#010;&gt;&#010;&gt; On Fri, Jul 17, 2020 at 7:29 PM kcz &lt;573693104@qq.com&gt; wrote:&#010;&gt;&#010;&gt; &gt; idea æœ¬åœ°æµ‹è¯•&#010;&gt; &gt; è·Ÿhiveæœ‰å…³pomä¾èµ–&#010;&gt; &gt; hive-exec flink-connector-hive_2.11&#010;&gt; &gt; ä»£ç å¦‚ä¸‹:&#010;&gt; &gt;  StreamExecutionEnvironment env =&#010;&gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt;         env.setParallelism(1);&#010;&gt; &gt;         env.enableCheckpointing(60*1000, CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &gt;         // åŒä¸€æ—¶é—´åªå…è®¸è¿›è¡Œä¸€ä¸ªæ£€æŸ¥ç‚¹&#010;&gt; &gt;         env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);&#010;&gt; &gt;&#010;&gt; &gt;         env.setStateBackend(new FsStateBackend(path));&#010;&gt; &gt;&#010;&gt; &gt;         StreamTableEnvironment tableEnv =&#010;&gt; &gt; StreamTableEnvironment.create(env);&#010;&gt; &gt;&#010;&gt; &gt;         String name            = \"myhive\";&#010;&gt; &gt;         String defaultDatabase = \"situation\";&#010;&gt; &gt;         String hiveConfDir     = \"/load/data/hive/hive-conf\"; // a local&#010;&gt; &gt; path&#010;&gt; &gt;         String version         = \"1.2.1\";&#010;&gt; &gt;&#010;&gt; &gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; hiveConfDir, version);&#010;&gt; &gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt;&#010;&gt; &gt; // set the HiveCatalog as the current catalog of the session&#010;&gt; &gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt; &gt;         tableEnv.executeSql(\"CREATE DATABASE IF NOT EXISTS stream_tmp\");&#010;&gt; &gt;         tableEnv.executeSql(\"DROP TABLE IF EXISTS&#010;&gt; &gt; stream_tmp.source_table\");&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt; æŠ¥é”™å¦‚ä¸‹ï¼š&#010;&gt; &gt; &amp;nbsp;&#010;&gt; &gt; Exception in thread \"main\" java.lang.IncompatibleClassChangeError:&#010;&gt; &gt; Implementing class&#010;&gt; &gt;         at java.lang.ClassLoader.defineClass1(Native Method)&#010;&gt; &gt;         at java.lang.ClassLoader.defineClass(ClassLoader.java:763)&#010;&gt; &gt;         at&#010;&gt; &gt; java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)&#010;&gt; &gt;         at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)&#010;&gt; &gt;         at java.net.URLClassLoader.access$100(URLClassLoader.java:73)&#010;&gt; &gt;         at java.net.URLClassLoader$1.run(URLClassLoader.java:368)&#010;&gt; &gt;         at java.net.URLClassLoader$1.run(URLClassLoader.java:362)&#010;&gt; &gt;         at java.security.AccessController.doPrivileged(Native Method)&#010;&gt; &gt;         at java.net.URLClassLoader.findClass(URLClassLoader.java:361)&#010;&gt; &gt;         at java.lang.ClassLoader.loadClass(ClassLoader.java:424)&#010;&gt; &gt;         at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)&#010;&gt; &gt;         at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&#010;&gt; &gt;         at&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.PlannerBase.&lt;init&amp;gt;(PlannerBase.scala:112)&#010;&gt; &gt;         at&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.StreamPlanner.&lt;init&amp;gt;(StreamPlanner.scala:48)&#010;&gt; &gt;         at&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.BlinkPlannerFactory.create(BlinkPlannerFactory.java:50)&#010;&gt; &gt;         at&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.create(StreamTableEnvironmentImpl.java:130)&#010;&gt; &gt;         at&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:111)&#010;&gt; &gt;         at com.hive.HiveTest.main(HiveTest.java:33)&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; --&#010;&gt; Best regards!&#010;&gt; Rui Li&#010;&gt;&#010;&#010;",
        "depth": "2",
        "reply": "<tencent_670E96B137058A0044F977DFD91F56237F08@qq.com>"
    },
    {
        "id": "<tencent_A24E3CA568F93F848264AE155E0FCE7CEB09@qq.com>",
        "from": "&quot;claylin&quot; &lt;1012539...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 12:28:27 GMT",
        "subject": "sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™",
        "content": "hi allæˆ‘è¿™è¾¹æœ‰ä¸ªåµŒå¥—çš„jsonæ•°ç»„ï¼ŒæŠ¥ç±»å‹è½¬æ¢é”™è¯¯(ts AS CAST(FROM_UNIXTIME(hiido_time)&#010;AS TIMESTAMP(3)),è¿™é‡ŒæŠ¥é”™)ï¼Œæ˜¯ä¸æ˜¯ä¸èƒ½è¿™ä¹ˆå†™&#013;&#010;create table hiido_push_sdk_mq (&#013;&#010;datas&amp;nbsp; &amp;nbsp;ARRAY&lt;ROW&lt;`from` string,hdid string,event string,hiido_time&#010;bigint,ts AS CAST(FROM_UNIXTIME(hiido_time) AS TIMESTAMP(3)),WATERMARK FOR ts AS ts - INTERVAL&#010;'5' MINUTE&amp;gt;&amp;gt;&#013;&#010;) with (&#013;&#010;'connector' = 'kafka',&#013;&#010;'topic' = 'hiido_pushsdk_event',&#013;&#010;'properties.bootstrap.servers' = 'kafkafs002-core001.yy.com:8103,kafkafs002-core002.yy.com:8103,kafkafs002-core003.yy.com:8103',&#013;&#010;'properties.group.id' = 'push_click_sql_version_consumer',&#013;&#010;'scan.startup.mode' = 'latest-offset',&#013;&#010;'format.type' = 'json');&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;é”™è¯¯å¦‚ä¸‹ï¼š&#013;&#010;[ERROR] 2020-07-17 20:17:50,640(562284338) --&amp;gt; [http-nio-8080-exec-10] com.yy.push.flink.sql.gateway.sql.parse.SqlCommandParser.parseBySqlParser(SqlCommandParser.java:77):&#010;parseBySqlParser, parse: com.yy.push.flink.sql.gateway.context.JobContext$1@5d5f32d1, stmt:&#010;create table hiido_push_sdk_mq (&amp;nbsp; &amp;nbsp; datas&amp;nbsp; &amp;nbsp;ARRAY&lt;ROW&lt;`from`&#010;string,hdid string,event string,hiido_time bigint,ts AS CAST(FROM_UNIXTIME(hiido_time) AS&#010;TIMESTAMP(3)),WATERMARK FOR ts AS ts - INTERVAL '5' MINUTE&amp;gt;&amp;gt;) with ('connector'&#010;= 'kafka','topic' = 'hiido_pushsdk_event','properties.bootstrap.servers' = 'kafkafs002-core001.yy.com:8103,kafkafs002-core002.yy.com:8103,kafkafs002-core003.yy.com:8103','properties.group.id'&#010;= 'push_click_sql_version_consumer','scan.startup.mode' = 'latest-offset','format.type' =&#010;'json'), error info: SQL parse failed. Encountered \"AS\" at line 1, column 115.&#013;&#010;Was expecting one of:&#013;&#010;&amp;nbsp; &amp;nbsp; \"ROW\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; &lt;BRACKET_QUOTED_IDENTIFIER&amp;gt; ...&#013;&#010;&amp;nbsp; &amp;nbsp; &lt;QUOTED_IDENTIFIER&amp;gt; ...&#013;&#010;&amp;nbsp; &amp;nbsp; &lt;BACK_QUOTED_IDENTIFIER&amp;gt; ...&#013;&#010;&amp;nbsp; &amp;nbsp; &lt;IDENTIFIER&amp;gt; ...&#013;&#010;&amp;nbsp; &amp;nbsp; &lt;UNICODE_QUOTED_IDENTIFIER&amp;gt; ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"STRING\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"BYTES\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"ARRAY\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"MULTISET\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"RAW\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"BOOLEAN\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"INTEGER\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"INT\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"TINYINT\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"SMALLINT\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"BIGINT\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"REAL\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"DOUBLE\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"FLOAT\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"BINARY\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"VARBINARY\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"DECIMAL\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"DEC\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"NUMERIC\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"ANY\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"CHARACTER\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"CHAR\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"VARCHAR\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"DATE\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"TIME\" ...&#013;&#010;&amp;nbsp; &amp;nbsp; \"TIMESTAMP\" ...",
        "depth": "0",
        "reply": "<tencent_A24E3CA568F93F848264AE155E0FCE7CEB09@qq.com>"
    },
    {
        "id": "<CABKuJ_ROkO4DHdx9dL7ZO1FsZ54uWB1LR2VecmeFm5EJRQm3GA@mail.gmail.com>",
        "from": "Benchao Li &lt;libenc...@apache.org&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 12:33:33 GMT",
        "subject": "Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™",
        "content": "è®¡ç®—åˆ—åªèƒ½å†™åœ¨æœ€å¤–å±‚ï¼Œä¸èƒ½åœ¨åµŒå¥—ç±»å‹é‡Œé¢æœ‰è®¡ç®—åˆ—ã€‚&#010;&#010;claylin &lt;1012539884@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:28å†™é“ï¼š&#010;&#010;&gt; hi allæˆ‘è¿™è¾¹æœ‰ä¸ªåµŒå¥—çš„jsonæ•°ç»„ï¼ŒæŠ¥ç±»å‹è½¬æ¢é”™è¯¯(ts AS CAST(FROM_UNIXTIME(hiido_time)&#010;AS&#010;&gt; TIMESTAMP(3)),è¿™é‡ŒæŠ¥é”™)ï¼Œæ˜¯ä¸æ˜¯ä¸èƒ½è¿™ä¹ˆå†™&#010;&gt; create table hiido_push_sdk_mq (&#010;&gt; datas&amp;nbsp; &amp;nbsp;ARRAY&lt;ROW&lt;`from` string,hdid string,event&#010;&gt; string,hiido_time bigint,ts AS CAST(FROM_UNIXTIME(hiido_time) AS&#010;&gt; TIMESTAMP(3)),WATERMARK FOR ts AS ts - INTERVAL '5' MINUTE&amp;gt;&amp;gt;&#010;&gt; ) with (&#010;&gt; 'connector' = 'kafka',&#010;&gt; 'topic' = 'hiido_pushsdk_event',&#010;&gt; 'properties.bootstrap.servers' = 'kafkafs002-core001.yy.com:8103,&#010;&gt; kafkafs002-core002.yy.com:8103,kafkafs002-core003.yy.com:8103',&#010;&gt; 'properties.group.id' = 'push_click_sql_version_consumer',&#010;&gt; 'scan.startup.mode' = 'latest-offset',&#010;&gt; 'format.type' = 'json');&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; é”™è¯¯å¦‚ä¸‹ï¼š&#010;&gt; [ERROR] 2020-07-17 20:17:50,640(562284338) --&amp;gt; [http-nio-8080-exec-10]&#010;&gt; com.yy.push.flink.sql.gateway.sql.parse.SqlCommandParser.parseBySqlParser(SqlCommandParser.java:77):&#010;&gt; parseBySqlParser, parse:&#010;&gt; com.yy.push.flink.sql.gateway.context.JobContext$1@5d5f32d1, stmt: create&#010;&gt; table hiido_push_sdk_mq (&amp;nbsp; &amp;nbsp; datas&amp;nbsp; &amp;nbsp;ARRAY&lt;ROW&lt;`from`&#010;&gt; string,hdid string,event string,hiido_time bigint,ts AS&#010;&gt; CAST(FROM_UNIXTIME(hiido_time) AS TIMESTAMP(3)),WATERMARK FOR ts AS ts -&#010;&gt; INTERVAL '5' MINUTE&amp;gt;&amp;gt;) with ('connector' = 'kafka','topic' =&#010;&gt; 'hiido_pushsdk_event','properties.bootstrap.servers' = '&#010;&gt; kafkafs002-core001.yy.com:8103,kafkafs002-core002.yy.com:8103,&#010;&gt; kafkafs002-core003.yy.com:8103','properties.group.id' =&#010;&gt; 'push_click_sql_version_consumer','scan.startup.mode' =&#010;&gt; 'latest-offset','format.type' = 'json'), error info: SQL parse failed.&#010;&gt; Encountered \"AS\" at line 1, column 115.&#010;&gt; Was expecting one of:&#010;&gt; &amp;nbsp; &amp;nbsp; \"ROW\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; &lt;BRACKET_QUOTED_IDENTIFIER&amp;gt; ...&#010;&gt; &amp;nbsp; &amp;nbsp; &lt;QUOTED_IDENTIFIER&amp;gt; ...&#010;&gt; &amp;nbsp; &amp;nbsp; &lt;BACK_QUOTED_IDENTIFIER&amp;gt; ...&#010;&gt; &amp;nbsp; &amp;nbsp; &lt;IDENTIFIER&amp;gt; ...&#010;&gt; &amp;nbsp; &amp;nbsp; &lt;UNICODE_QUOTED_IDENTIFIER&amp;gt; ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"STRING\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"BYTES\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"ARRAY\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"MULTISET\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"RAW\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"BOOLEAN\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"INTEGER\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"INT\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"TINYINT\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"SMALLINT\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"BIGINT\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"REAL\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"DOUBLE\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"FLOAT\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"BINARY\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"VARBINARY\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"DECIMAL\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"DEC\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"NUMERIC\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"ANY\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"CHARACTER\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"CHAR\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"VARCHAR\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"DATE\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"TIME\" ...&#010;&gt; &amp;nbsp; &amp;nbsp; \"TIMESTAMP\" ...&#010;&#010;&#010;&#010;-- &#010;&#010;Best,&#010;Benchao Li&#010;&#010;",
        "depth": "1",
        "reply": "<tencent_A24E3CA568F93F848264AE155E0FCE7CEB09@qq.com>"
    },
    {
        "id": "<tencent_071F4541B7D7DCAFD7674975909E6FB40B08@qq.com>",
        "from": "&quot;claylin&quot; &lt;1012539...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 12:37:09 GMT",
        "subject": "å›å¤ï¼š sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™",
        "content": "é‚£æˆ‘è¿™ç§å†…åµŒå¼çš„æ•°æ®ç»“æ„æ˜¯ä¸èƒ½åœ¨sqlé‡Œé¢è§£æäº†ï¼Œæ•°ç»„æ¯è¡Œè½¬æˆè¡¨ä¸­çš„ä¸€åˆ—ï¼Œè¿˜æœ‰watermarkï¼Œåªèƒ½åœ¨å¤–éƒ¨å¤„ç†æˆå•æ¡è®°å½•ç„¶åç”¨flinkå¤„ç†äº†å—&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;libenchao@apache.org&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š8:33&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;è®¡ç®—åˆ—åªèƒ½å†™åœ¨æœ€å¤–å±‚ï¼Œä¸èƒ½åœ¨åµŒå¥—ç±»å‹é‡Œé¢æœ‰è®¡ç®—åˆ—ã€‚&#013;&#010;&#013;&#010;claylin &lt;1012539884@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:28å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; hi allæˆ‘è¿™è¾¹æœ‰ä¸ªåµŒå¥—çš„jsonæ•°ç»„ï¼ŒæŠ¥ç±»å‹è½¬æ¢é”™è¯¯(ts AS CAST(FROM_UNIXTIME(hiido_time)&#010;AS&#013;&#010;&amp;gt; TIMESTAMP(3)),è¿™é‡ŒæŠ¥é”™)ï¼Œæ˜¯ä¸æ˜¯ä¸èƒ½è¿™ä¹ˆå†™&#013;&#010;&amp;gt; create table hiido_push_sdk_mq (&#013;&#010;&amp;gt; datas&amp;amp;nbsp; &amp;amp;nbsp;ARRAY&lt;ROW&lt;`from` string,hdid string,event&#013;&#010;&amp;gt; string,hiido_time bigint,ts AS CAST(FROM_UNIXTIME(hiido_time) AS&#013;&#010;&amp;gt; TIMESTAMP(3)),WATERMARK FOR ts AS ts - INTERVAL '5' MINUTE&amp;amp;gt;&amp;amp;gt;&#013;&#010;&amp;gt; ) with (&#013;&#010;&amp;gt; 'connector' = 'kafka',&#013;&#010;&amp;gt; 'topic' = 'hiido_pushsdk_event',&#013;&#010;&amp;gt; 'properties.bootstrap.servers' = 'kafkafs002-core001.yy.com:8103,&#013;&#010;&amp;gt; kafkafs002-core002.yy.com:8103,kafkafs002-core003.yy.com:8103',&#013;&#010;&amp;gt; 'properties.group.id' = 'push_click_sql_version_consumer',&#013;&#010;&amp;gt; 'scan.startup.mode' = 'latest-offset',&#013;&#010;&amp;gt; 'format.type' = 'json');&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; é”™è¯¯å¦‚ä¸‹ï¼š&#013;&#010;&amp;gt; [ERROR] 2020-07-17 20:17:50,640(562284338) --&amp;amp;gt; [http-nio-8080-exec-10]&#013;&#010;&amp;gt; com.yy.push.flink.sql.gateway.sql.parse.SqlCommandParser.parseBySqlParser(SqlCommandParser.java:77):&#013;&#010;&amp;gt; parseBySqlParser, parse:&#013;&#010;&amp;gt; com.yy.push.flink.sql.gateway.context.JobContext$1@5d5f32d1, stmt: create&#013;&#010;&amp;gt; table hiido_push_sdk_mq (&amp;amp;nbsp; &amp;amp;nbsp; datas&amp;amp;nbsp; &amp;amp;nbsp;ARRAY&lt;ROW&lt;`from`&#013;&#010;&amp;gt; string,hdid string,event string,hiido_time bigint,ts AS&#013;&#010;&amp;gt; CAST(FROM_UNIXTIME(hiido_time) AS TIMESTAMP(3)),WATERMARK FOR ts AS ts -&#013;&#010;&amp;gt; INTERVAL '5' MINUTE&amp;amp;gt;&amp;amp;gt;) with ('connector' = 'kafka','topic'&#010;=&#013;&#010;&amp;gt; 'hiido_pushsdk_event','properties.bootstrap.servers' = '&#013;&#010;&amp;gt; kafkafs002-core001.yy.com:8103,kafkafs002-core002.yy.com:8103,&#013;&#010;&amp;gt; kafkafs002-core003.yy.com:8103','properties.group.id' =&#013;&#010;&amp;gt; 'push_click_sql_version_consumer','scan.startup.mode' =&#013;&#010;&amp;gt; 'latest-offset','format.type' = 'json'), error info: SQL parse failed.&#013;&#010;&amp;gt; Encountered \"AS\" at line 1, column 115.&#013;&#010;&amp;gt; Was expecting one of:&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ROW\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;BRACKET_QUOTED_IDENTIFIER&amp;amp;gt; ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;QUOTED_IDENTIFIER&amp;amp;gt; ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;BACK_QUOTED_IDENTIFIER&amp;amp;gt; ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;IDENTIFIER&amp;amp;gt; ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;UNICODE_QUOTED_IDENTIFIER&amp;amp;gt; ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"STRING\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BYTES\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ARRAY\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"MULTISET\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"RAW\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BOOLEAN\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"INTEGER\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"INT\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TINYINT\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"SMALLINT\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BIGINT\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"REAL\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DOUBLE\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"FLOAT\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BINARY\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"VARBINARY\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DECIMAL\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DEC\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"NUMERIC\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ANY\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"CHARACTER\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"CHAR\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"VARCHAR\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DATE\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TIME\" ...&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TIMESTAMP\" ...&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;&#013;&#010;Best,&#013;&#010;Benchao Li",
        "depth": "2",
        "reply": "<tencent_A24E3CA568F93F848264AE155E0FCE7CEB09@qq.com>"
    },
    {
        "id": "<CABKuJ_TXy8P21k5yCY9nD9_m9=PB=GgjWso5YjskHUNF7rJaWw@mail.gmail.com>",
        "from": "Benchao Li &lt;libenc...@apache.org&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 12:41:51 GMT",
        "subject": "Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™",
        "content": "ä½ çš„æ„æ€æ˜¯æƒ³å…ˆæŠŠjsoné‡Œé¢çš„arrayå±•å¼€æˆå¤šè¡Œï¼Œç„¶åwatermarkåŸºäºè¿™ä¸ªå±•å¼€åçš„æ•°æ®æ¥ç”Ÿæˆæ˜¯ä¹ˆï¼Ÿ&#010;&#010;claylin &lt;1012539884@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:37å†™é“ï¼š&#010;&#010;&gt; é‚£æˆ‘è¿™ç§å†…åµŒå¼çš„æ•°æ®ç»“æ„æ˜¯ä¸èƒ½åœ¨sqlé‡Œé¢è§£æäº†ï¼Œæ•°ç»„æ¯è¡Œè½¬æˆè¡¨ä¸­çš„ä¸€åˆ—ï¼Œè¿˜æœ‰watermarkï¼Œåªèƒ½åœ¨å¤–éƒ¨å¤„ç†æˆå•æ¡è®°å½•ç„¶åç”¨flinkå¤„ç†äº†å—&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; ------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;&gt; å‘ä»¶äºº:&#010;&gt;                                                   \"user-zh\"&#010;&gt;                                                                     &lt;&#010;&gt; libenchao@apache.org&amp;gt;;&#010;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š8:33&#010;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&gt;&#010;&gt; ä¸»é¢˜:&amp;nbsp;Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; è®¡ç®—åˆ—åªèƒ½å†™åœ¨æœ€å¤–å±‚ï¼Œä¸èƒ½åœ¨åµŒå¥—ç±»å‹é‡Œé¢æœ‰è®¡ç®—åˆ—ã€‚&#010;&gt;&#010;&gt; claylin &lt;1012539884@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:28å†™é“ï¼š&#010;&gt;&#010;&gt; &amp;gt; hi allæˆ‘è¿™è¾¹æœ‰ä¸ªåµŒå¥—çš„jsonæ•°ç»„ï¼ŒæŠ¥ç±»å‹è½¬æ¢é”™è¯¯(ts AS CAST(FROM_UNIXTIME(hiido_time)&#010;AS&#010;&gt; &amp;gt; TIMESTAMP(3)),è¿™é‡ŒæŠ¥é”™)ï¼Œæ˜¯ä¸æ˜¯ä¸èƒ½è¿™ä¹ˆå†™&#010;&gt; &amp;gt; create table hiido_push_sdk_mq (&#010;&gt; &amp;gt; datas&amp;amp;nbsp; &amp;amp;nbsp;ARRAY&lt;ROW&lt;`from` string,hdid string,event&#010;&gt; &amp;gt; string,hiido_time bigint,ts AS CAST(FROM_UNIXTIME(hiido_time) AS&#010;&gt; &amp;gt; TIMESTAMP(3)),WATERMARK FOR ts AS ts - INTERVAL '5'&#010;&gt; MINUTE&amp;amp;gt;&amp;amp;gt;&#010;&gt; &amp;gt; ) with (&#010;&gt; &amp;gt; 'connector' = 'kafka',&#010;&gt; &amp;gt; 'topic' = 'hiido_pushsdk_event',&#010;&gt; &amp;gt; 'properties.bootstrap.servers' = 'kafkafs002-core001.yy.com:8103,&#010;&gt; &amp;gt; kafkafs002-core002.yy.com:8103,kafkafs002-core003.yy.com:8103',&#010;&gt; &amp;gt; 'properties.group.id' = 'push_click_sql_version_consumer',&#010;&gt; &amp;gt; 'scan.startup.mode' = 'latest-offset',&#010;&gt; &amp;gt; 'format.type' = 'json');&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; é”™è¯¯å¦‚ä¸‹ï¼š&#010;&gt; &amp;gt; [ERROR] 2020-07-17 20:17:50,640(562284338) --&amp;amp;gt;&#010;&gt; [http-nio-8080-exec-10]&#010;&gt; &amp;gt;&#010;&gt; com.yy.push.flink.sql.gateway.sql.parse.SqlCommandParser.parseBySqlParser(SqlCommandParser.java:77):&#010;&gt; &amp;gt; parseBySqlParser, parse:&#010;&gt; &amp;gt; com.yy.push.flink.sql.gateway.context.JobContext$1@5d5f32d1, stmt:&#010;&gt; create&#010;&gt; &amp;gt; table hiido_push_sdk_mq (&amp;amp;nbsp; &amp;amp;nbsp; datas&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp;ARRAY&lt;ROW&lt;`from`&#010;&gt; &amp;gt; string,hdid string,event string,hiido_time bigint,ts AS&#010;&gt; &amp;gt; CAST(FROM_UNIXTIME(hiido_time) AS TIMESTAMP(3)),WATERMARK FOR ts AS&#010;&gt; ts -&#010;&gt; &amp;gt; INTERVAL '5' MINUTE&amp;amp;gt;&amp;amp;gt;) with ('connector' =&#010;&gt; 'kafka','topic' =&#010;&gt; &amp;gt; 'hiido_pushsdk_event','properties.bootstrap.servers' = '&#010;&gt; &amp;gt; kafkafs002-core001.yy.com:8103,kafkafs002-core002.yy.com:8103,&#010;&gt; &amp;gt; kafkafs002-core003.yy.com:8103','properties.group.id' =&#010;&gt; &amp;gt; 'push_click_sql_version_consumer','scan.startup.mode' =&#010;&gt; &amp;gt; 'latest-offset','format.type' = 'json'), error info: SQL parse failed.&#010;&gt; &amp;gt; Encountered \"AS\" at line 1, column 115.&#010;&gt; &amp;gt; Was expecting one of:&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ROW\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;BRACKET_QUOTED_IDENTIFIER&amp;amp;gt; ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;QUOTED_IDENTIFIER&amp;amp;gt; ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;BACK_QUOTED_IDENTIFIER&amp;amp;gt; ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;IDENTIFIER&amp;amp;gt; ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;UNICODE_QUOTED_IDENTIFIER&amp;amp;gt; ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"STRING\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BYTES\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ARRAY\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"MULTISET\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"RAW\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BOOLEAN\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"INTEGER\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"INT\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TINYINT\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"SMALLINT\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BIGINT\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"REAL\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DOUBLE\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"FLOAT\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BINARY\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"VARBINARY\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DECIMAL\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DEC\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"NUMERIC\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ANY\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"CHARACTER\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"CHAR\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"VARCHAR\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DATE\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TIME\" ...&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TIMESTAMP\" ...&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; --&#010;&gt;&#010;&gt; Best,&#010;&gt; Benchao Li&#010;&#010;&#010;&#010;-- &#010;&#010;Best,&#010;Benchao Li&#010;&#010;",
        "depth": "3",
        "reply": "<tencent_A24E3CA568F93F848264AE155E0FCE7CEB09@qq.com>"
    },
    {
        "id": "<CABKuJ_Q3cX0bp9VDfzcwP_ccEF+-SCBEubxSu+WKp319z=heCQ@mail.gmail.com>",
        "from": "Benchao Li &lt;libenc...@apache.org&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 12:51:34 GMT",
        "subject": "Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™",
        "content": "å¦‚æœæ˜¯çš„è¯ï¼Œç°åœ¨çš„ç¡®æ˜¯è¿˜åšä¸åˆ°ï¼Œä¸è¿‡æœ‰ä¸€ä¸ªissue[1] æ­£åœ¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚&#010;&#010;[1] https://issues.apache.org/jira/browse/FLINK-18590&#010;&#010;Benchao Li &lt;libenchao@apache.org&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:41å†™é“ï¼š&#010;&#010;&gt; ä½ çš„æ„æ€æ˜¯æƒ³å…ˆæŠŠjsoné‡Œé¢çš„arrayå±•å¼€æˆå¤šè¡Œï¼Œç„¶åwatermarkåŸºäºè¿™ä¸ªå±•å¼€åçš„æ•°æ®æ¥ç”Ÿæˆæ˜¯ä¹ˆï¼Ÿ&#010;&gt;&#010;&gt; claylin &lt;1012539884@qq.com&gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:37å†™é“ï¼š&#010;&gt;&#010;&gt;&gt; é‚£æˆ‘è¿™ç§å†…åµŒå¼çš„æ•°æ®ç»“æ„æ˜¯ä¸èƒ½åœ¨sqlé‡Œé¢è§£æäº†ï¼Œæ•°ç»„æ¯è¡Œè½¬æˆè¡¨ä¸­çš„ä¸€åˆ—ï¼Œè¿˜æœ‰watermarkï¼Œåªèƒ½åœ¨å¤–éƒ¨å¤„ç†æˆå•æ¡è®°å½•ç„¶åç”¨flinkå¤„ç†äº†å—&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; ------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;&gt;&gt; å‘ä»¶äºº:&#010;&gt;&gt;                                                   \"user-zh\"&#010;&gt;&gt;                                                                     &lt;&#010;&gt;&gt; libenchao@apache.org&amp;gt;;&#010;&gt;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š8:33&#010;&gt;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&gt;&gt;&#010;&gt;&gt; ä¸»é¢˜:&amp;nbsp;Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; è®¡ç®—åˆ—åªèƒ½å†™åœ¨æœ€å¤–å±‚ï¼Œä¸èƒ½åœ¨åµŒå¥—ç±»å‹é‡Œé¢æœ‰è®¡ç®—åˆ—ã€‚&#010;&gt;&gt;&#010;&gt;&gt; claylin &lt;1012539884@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:28å†™é“ï¼š&#010;&gt;&gt;&#010;&gt;&gt; &amp;gt; hi allæˆ‘è¿™è¾¹æœ‰ä¸ªåµŒå¥—çš„jsonæ•°ç»„ï¼ŒæŠ¥ç±»å‹è½¬æ¢é”™è¯¯(ts AS CAST(FROM_UNIXTIME(hiido_time)&#010;AS&#010;&gt;&gt; &amp;gt; TIMESTAMP(3)),è¿™é‡ŒæŠ¥é”™)ï¼Œæ˜¯ä¸æ˜¯ä¸èƒ½è¿™ä¹ˆå†™&#010;&gt;&gt; &amp;gt; create table hiido_push_sdk_mq (&#010;&gt;&gt; &amp;gt; datas&amp;amp;nbsp; &amp;amp;nbsp;ARRAY&lt;ROW&lt;`from` string,hdid string,event&#010;&gt;&gt; &amp;gt; string,hiido_time bigint,ts AS CAST(FROM_UNIXTIME(hiido_time) AS&#010;&gt;&gt; &amp;gt; TIMESTAMP(3)),WATERMARK FOR ts AS ts - INTERVAL '5'&#010;&gt;&gt; MINUTE&amp;amp;gt;&amp;amp;gt;&#010;&gt;&gt; &amp;gt; ) with (&#010;&gt;&gt; &amp;gt; 'connector' = 'kafka',&#010;&gt;&gt; &amp;gt; 'topic' = 'hiido_pushsdk_event',&#010;&gt;&gt; &amp;gt; 'properties.bootstrap.servers' = 'kafkafs002-core001.yy.com:8103,&#010;&gt;&gt; &amp;gt; kafkafs002-core002.yy.com:8103,kafkafs002-core003.yy.com:8103',&#010;&gt;&gt; &amp;gt; 'properties.group.id' = 'push_click_sql_version_consumer',&#010;&gt;&gt; &amp;gt; 'scan.startup.mode' = 'latest-offset',&#010;&gt;&gt; &amp;gt; 'format.type' = 'json');&#010;&gt;&gt; &amp;gt;&#010;&gt;&gt; &amp;gt;&#010;&gt;&gt; &amp;gt;&#010;&gt;&gt; &amp;gt;&#010;&gt;&gt; &amp;gt; é”™è¯¯å¦‚ä¸‹ï¼š&#010;&gt;&gt; &amp;gt; [ERROR] 2020-07-17 20:17:50,640(562284338) --&amp;amp;gt;&#010;&gt;&gt; [http-nio-8080-exec-10]&#010;&gt;&gt; &amp;gt;&#010;&gt;&gt; com.yy.push.flink.sql.gateway.sql.parse.SqlCommandParser.parseBySqlParser(SqlCommandParser.java:77):&#010;&gt;&gt; &amp;gt; parseBySqlParser, parse:&#010;&gt;&gt; &amp;gt; com.yy.push.flink.sql.gateway.context.JobContext$1@5d5f32d1, stmt:&#010;&gt;&gt; create&#010;&gt;&gt; &amp;gt; table hiido_push_sdk_mq (&amp;amp;nbsp; &amp;amp;nbsp; datas&amp;amp;nbsp;&#010;&gt;&gt; &amp;amp;nbsp;ARRAY&lt;ROW&lt;`from`&#010;&gt;&gt; &amp;gt; string,hdid string,event string,hiido_time bigint,ts AS&#010;&gt;&gt; &amp;gt; CAST(FROM_UNIXTIME(hiido_time) AS TIMESTAMP(3)),WATERMARK FOR ts AS&#010;&gt;&gt; ts -&#010;&gt;&gt; &amp;gt; INTERVAL '5' MINUTE&amp;amp;gt;&amp;amp;gt;) with ('connector' =&#010;&gt;&gt; 'kafka','topic' =&#010;&gt;&gt; &amp;gt; 'hiido_pushsdk_event','properties.bootstrap.servers' = '&#010;&gt;&gt; &amp;gt; kafkafs002-core001.yy.com:8103,kafkafs002-core002.yy.com:8103,&#010;&gt;&gt; &amp;gt; kafkafs002-core003.yy.com:8103','properties.group.id' =&#010;&gt;&gt; &amp;gt; 'push_click_sql_version_consumer','scan.startup.mode' =&#010;&gt;&gt; &amp;gt; 'latest-offset','format.type' = 'json'), error info: SQL parse&#010;&gt;&gt; failed.&#010;&gt;&gt; &amp;gt; Encountered \"AS\" at line 1, column 115.&#010;&gt;&gt; &amp;gt; Was expecting one of:&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ROW\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;BRACKET_QUOTED_IDENTIFIER&amp;amp;gt;&#010;...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;QUOTED_IDENTIFIER&amp;amp;gt; ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;BACK_QUOTED_IDENTIFIER&amp;amp;gt; ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;IDENTIFIER&amp;amp;gt; ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &lt;UNICODE_QUOTED_IDENTIFIER&amp;amp;gt;&#010;...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"STRING\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BYTES\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ARRAY\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"MULTISET\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"RAW\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BOOLEAN\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"INTEGER\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"INT\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TINYINT\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"SMALLINT\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BIGINT\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"REAL\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DOUBLE\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"FLOAT\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"BINARY\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"VARBINARY\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DECIMAL\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DEC\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"NUMERIC\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"ANY\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"CHARACTER\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"CHAR\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"VARCHAR\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"DATE\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TIME\" ...&#010;&gt;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; \"TIMESTAMP\" ...&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; --&#010;&gt;&gt;&#010;&gt;&gt; Best,&#010;&gt;&gt; Benchao Li&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; --&#010;&gt;&#010;&gt; Best,&#010;&gt; Benchao Li&#010;&gt;&#010;&#010;&#010;-- &#010;&#010;Best,&#010;Benchao Li&#010;&#010;",
        "depth": "4",
        "reply": "<tencent_A24E3CA568F93F848264AE155E0FCE7CEB09@qq.com>"
    },
    {
        "id": "<tencent_8908E7FAFF55F00CAD2ED5D38896E2432905@qq.com>",
        "from": "&quot;claylin&quot; &lt;1012539...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 17 Jul 2020 13:26:25 GMT",
        "subject": "å›å¤ï¼š sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™",
        "content": "å—¯äº†è§£äº†è°¢è°¢å¤§ä½¬&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;libenchao@apache.org&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š8:51&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;å¦‚æœæ˜¯çš„è¯ï¼Œç°åœ¨çš„ç¡®æ˜¯è¿˜åšä¸åˆ°ï¼Œä¸è¿‡æœ‰ä¸€ä¸ªissue[1] æ­£åœ¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚&#013;&#010;&#013;&#010;[1] https://issues.apache.org/jira/browse/FLINK-18590&#013;&#010;&#013;&#010;Benchao Li &lt;libenchao@apache.org&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:41å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; ä½ çš„æ„æ€æ˜¯æƒ³å…ˆæŠŠjsoné‡Œé¢çš„arrayå±•å¼€æˆå¤šè¡Œï¼Œç„¶åwatermarkåŸºäºè¿™ä¸ªå±•å¼€åçš„æ•°æ®æ¥ç”Ÿæˆæ˜¯ä¹ˆï¼Ÿ&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; claylin &lt;1012539884@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:37å†™é“ï¼š&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; é‚£æˆ‘è¿™ç§å†…åµŒå¼çš„æ•°æ®ç»“æ„æ˜¯ä¸èƒ½åœ¨sqlé‡Œé¢è§£æäº†ï¼Œæ•°ç»„æ¯è¡Œè½¬æˆè¡¨ä¸­çš„ä¸€åˆ—ï¼Œè¿˜æœ‰watermarkï¼Œåªèƒ½åœ¨å¤–éƒ¨å¤„ç†æˆå•æ¡è®°å½•ç„¶åç”¨flinkå¤„ç†äº†å—&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; ------------------&amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;nbsp;------------------&#013;&#010;&amp;gt;&amp;gt; å‘ä»¶äºº:&#013;&#010;&amp;gt;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;\"user-zh\"&#013;&#010;&amp;gt;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&lt;&#013;&#010;&amp;gt;&amp;gt; libenchao@apache.org&amp;amp;gt;;&#013;&#010;&amp;gt;&amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š8:33&#013;&#010;&amp;gt;&amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; ä¸»é¢˜:&amp;amp;nbsp;Re: sql å†…åµŒjosnæ•°ç»„è§£ææŠ¥ ç±»å‹è½¬æ¢æŠ¥é”™&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; è®¡ç®—åˆ—åªèƒ½å†™åœ¨æœ€å¤–å±‚ï¼Œä¸èƒ½åœ¨åµŒå¥—ç±»å‹é‡Œé¢æœ‰è®¡ç®—åˆ—ã€‚&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; claylin &lt;1012539884@qq.com&amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ8:28å†™é“ï¼š&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; hi allæˆ‘è¿™è¾¹æœ‰ä¸ªåµŒå¥—çš„jsonæ•°ç»„ï¼ŒæŠ¥ç±»å‹è½¬æ¢é”™è¯¯(ts&#010;AS CAST(FROM_UNIXTIME(hiido_time) AS&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; TIMESTAMP(3)),è¿™é‡ŒæŠ¥é”™)ï¼Œæ˜¯ä¸æ˜¯ä¸èƒ½è¿™ä¹ˆå†™&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; create table hiido_push_sdk_mq (&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; datas&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;ARRAY&lt;ROW&lt;`from`&#010;string,hdid string,event&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; string,hiido_time bigint,ts AS CAST(FROM_UNIXTIME(hiido_time)&#010;AS&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; TIMESTAMP(3)),WATERMARK FOR ts AS ts - INTERVAL '5'&#013;&#010;&amp;gt;&amp;gt; MINUTE&amp;amp;amp;gt;&amp;amp;amp;gt;&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; ) with (&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'connector' = 'kafka',&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'topic' = 'hiido_pushsdk_event',&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'properties.bootstrap.servers' = 'kafkafs002-core001.yy.com:8103,&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; kafkafs002-core002.yy.com:8103,kafkafs002-core003.yy.com:8103',&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'properties.group.id' = 'push_click_sql_version_consumer',&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'scan.startup.mode' = 'latest-offset',&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'format.type' = 'json');&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; é”™è¯¯å¦‚ä¸‹ï¼š&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; [ERROR] 2020-07-17 20:17:50,640(562284338) --&amp;amp;amp;gt;&#013;&#010;&amp;gt;&amp;gt; [http-nio-8080-exec-10]&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt;&amp;gt; com.yy.push.flink.sql.gateway.sql.parse.SqlCommandParser.parseBySqlParser(SqlCommandParser.java:77):&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; parseBySqlParser, parse:&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; com.yy.push.flink.sql.gateway.context.JobContext$1@5d5f32d1,&#010;stmt:&#013;&#010;&amp;gt;&amp;gt; create&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; table hiido_push_sdk_mq (&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;datas&amp;amp;amp;nbsp;&#013;&#010;&amp;gt;&amp;gt; &amp;amp;amp;nbsp;ARRAY&lt;ROW&lt;`from`&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; string,hdid string,event string,hiido_time bigint,ts AS&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; CAST(FROM_UNIXTIME(hiido_time) AS TIMESTAMP(3)),WATERMARK FOR&#010;ts AS&#013;&#010;&amp;gt;&amp;gt; ts -&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; INTERVAL '5' MINUTE&amp;amp;amp;gt;&amp;amp;amp;gt;) with ('connector'&#010;=&#013;&#010;&amp;gt;&amp;gt; 'kafka','topic' =&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'hiido_pushsdk_event','properties.bootstrap.servers' = '&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; kafkafs002-core001.yy.com:8103,kafkafs002-core002.yy.com:8103,&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; kafkafs002-core003.yy.com:8103','properties.group.id' =&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'push_click_sql_version_consumer','scan.startup.mode' =&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; 'latest-offset','format.type' = 'json'), error info: SQL parse&#013;&#010;&amp;gt;&amp;gt; failed.&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; Encountered \"AS\" at line 1, column 115.&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; Was expecting one of:&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"ROW\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &lt;BRACKET_QUOTED_IDENTIFIER&amp;amp;amp;gt;&#010;...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &lt;QUOTED_IDENTIFIER&amp;amp;amp;gt;&#010;...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &lt;BACK_QUOTED_IDENTIFIER&amp;amp;amp;gt;&#010;...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &lt;IDENTIFIER&amp;amp;amp;gt;&#010;...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &lt;UNICODE_QUOTED_IDENTIFIER&amp;amp;amp;gt;&#010;...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"STRING\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"BYTES\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"ARRAY\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"MULTISET\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"RAW\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"BOOLEAN\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"INTEGER\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"INT\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"TINYINT\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"SMALLINT\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"BIGINT\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"REAL\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"DOUBLE\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"FLOAT\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"BINARY\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"VARBINARY\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"DECIMAL\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"DEC\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"NUMERIC\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"ANY\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"CHARACTER\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"CHAR\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"VARCHAR\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"DATE\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"TIME\" ...&#013;&#010;&amp;gt;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; \"TIMESTAMP\" ...&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; --&#013;&#010;&amp;gt;&amp;gt;&#013;&#010;&amp;gt;&amp;gt; Best,&#013;&#010;&amp;gt;&amp;gt; Benchao Li&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; --&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Best,&#013;&#010;&amp;gt; Benchao Li&#013;&#010;&amp;gt;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;&#013;&#010;Best,&#013;&#010;Benchao Li",
        "depth": "5",
        "reply": "<tencent_A24E3CA568F93F848264AE155E0FCE7CEB09@qq.com>"
    },
    {
        "id": "<tencent_11A2A5049DE257A24CF3D5475B07597A670A@qq.com>",
        "from": "&quot;Evan&quot; &lt;chengyanan1...@foxmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sat, 18 Jul 2020 09:47:24 GMT",
        "subject": "FlinkSQL ä»»åŠ¡æäº¤å ä»»åŠ¡åç§°é—®é¢˜",
        "content": "ä»£ç å¤§æ¦‚æ˜¯è¿™æ ·å­çš„ï¼Œä¸€å¼ kafka sourceè¡¨ï¼Œä¸€å¼ es Sinkè¡¨ï¼Œæœ€åé€šè¿‡tableEnv.executeSql(\"insert&#010;into esSinkTable select ... from kafkaSourceTable\")æ‰§è¡Œ&#013;&#010;ä»»åŠ¡æäº¤åä»»åŠ¡åç§°ä¸ºâ€œinset-into_æŸæŸcatalog_æŸæŸdatabase.æŸæŸTableâ€&#013;&#010;&#013;&#010;&#013;&#010;è¿™æ ·å¾ˆä¸å‹å¥½å•Šï¼Œèƒ½ä¸èƒ½æˆ‘è‡ªå·±æŒ‡å®šä»»åŠ¡åç§°å‘¢ï¼Ÿ",
        "depth": "0",
        "reply": "<tencent_11A2A5049DE257A24CF3D5475B07597A670A@qq.com>"
    },
    {
        "id": "<CAADy7x4ghDLVG7OrtskbbvmDjv_12NTeJsuj76i5A_eaYCHRjA@mail.gmail.com>",
        "from": "Jeff Zhang &lt;zjf...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sat, 18 Jul 2020 13:45:33 GMT",
        "subject": "Re: FlinkSQL ä»»åŠ¡æäº¤å ä»»åŠ¡åç§°é—®é¢˜",
        "content": "åœ¨zeppelinä¸­ä½ å¯ä»¥æŒ‡å®šinsert è¯­å¥çš„job nameï¼Œå¦‚ä¸‹å›¾ï¼Œï¼ˆå¯¹Zeppelinæ„Ÿå…´è¶£çš„ï¼Œå¯ä»¥åŠ å…¥é’‰é’‰ç¾¤ï¼š32803524ï¼‰&#013;&#010;&#013;&#010;%flink.ssql(jobName=\"my job\")&#013;&#010;&#013;&#010;insert into sink_kafka select status, direction, cast(event_ts/1000000000&#013;&#010;as timestamp(3)) from source_kafka where status &lt;&gt; 'foo'&#013;&#010;&#013;&#010;[image: image.png]&#013;&#010;&#013;&#010;Evan &lt;chengyanan1008@foxmail.com&gt; äº2020å¹´7æœˆ18æ—¥å‘¨å…­ ä¸‹åˆ5:47å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; ä»£ç å¤§æ¦‚æ˜¯è¿™æ ·å­çš„ï¼Œä¸€å¼ kafka sourceè¡¨ï¼Œä¸€å¼ es Sinkè¡¨ï¼Œæœ€åé€šè¿‡tableEnv.executeSql(\"insert&#010;into&#013;&#010;&gt; esSinkTable select ... from kafkaSourceTable\")æ‰§è¡Œ&#013;&#010;&gt; ä»»åŠ¡æäº¤åä»»åŠ¡åç§°ä¸ºâ€œinset-into_æŸæŸcatalog_æŸæŸdatabase.æŸæŸTableâ€&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; è¿™æ ·å¾ˆä¸å‹å¥½å•Šï¼Œèƒ½ä¸èƒ½æˆ‘è‡ªå·±æŒ‡å®šä»»åŠ¡åç§°å‘¢ï¼Ÿ&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;-- &#013;&#010;Best Regards&#013;&#010;&#013;&#010;Jeff Zhang&#013;&#010;",
        "depth": "1",
        "reply": "<tencent_11A2A5049DE257A24CF3D5475B07597A670A@qq.com>"
    },
    {
        "id": "<CADQYLGv=UQ7=wGFBufNhs_5Wop7bP5g2bwWQNvWWEASkfeeDZQ@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sun, 19 Jul 2020 01:34:49 GMT",
        "subject": "Re: FlinkSQL ä»»åŠ¡æäº¤å ä»»åŠ¡åç§°é—®é¢˜",
        "content": "hi Evan,&#013;&#010;æ„Ÿè°¢åé¦ˆï¼Œç›®å‰å·²ç»æœ‰ä¸€ä¸ªissue [1]åœ¨è·Ÿè¸ªè¯¥é—®é¢˜ï¼Œå¯ä»¥å…³æ³¨åç»­è¿›å±•&#013;&#010;&#013;&#010;[1] https://issues.apache.org/jira/browse/FLINK-18545&#013;&#010;&lt;https://issues.apache.org/jira/browse/FLINK-18545?jql=project%20%3D%20FLINK%20AND%20resolution%20%3D%20Unresolved%20AND%20text%20~%20%22job%20name%22%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC&gt;&#013;&#010;&#013;&#010;Best,&#013;&#010;Godfrey&#013;&#010;&#013;&#010;Jeff Zhang &lt;zjffdu@gmail.com&gt; äº2020å¹´7æœˆ18æ—¥å‘¨å…­ ä¸‹åˆ9:52å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; åœ¨zeppelinä¸­ä½ å¯ä»¥æŒ‡å®šinsert è¯­å¥çš„job nameï¼Œå¦‚ä¸‹å›¾ï¼Œï¼ˆå¯¹Zeppelinæ„Ÿå…´è¶£çš„ï¼Œå¯ä»¥åŠ å…¥é’‰é’‰ç¾¤ï¼š32803524ï¼‰&#013;&#010;&gt;&#013;&#010;&gt; %flink.ssql(jobName=\"my job\")&#013;&#010;&gt;&#013;&#010;&gt; insert into sink_kafka select status, direction, cast(event_ts/1000000000&#013;&#010;&gt; as timestamp(3)) from source_kafka where status &lt;&gt; 'foo'&#013;&#010;&gt;&#013;&#010;&gt; [image: image.png]&#013;&#010;&gt;&#013;&#010;&gt; Evan &lt;chengyanan1008@foxmail.com&gt; äº2020å¹´7æœˆ18æ—¥å‘¨å…­ ä¸‹åˆ5:47å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt;&gt; ä»£ç å¤§æ¦‚æ˜¯è¿™æ ·å­çš„ï¼Œä¸€å¼ kafka sourceè¡¨ï¼Œä¸€å¼ es Sinkè¡¨ï¼Œæœ€åé€šè¿‡tableEnv.executeSql(\"insert&#010;into&#013;&#010;&gt;&gt; esSinkTable select ... from kafkaSourceTable\")æ‰§è¡Œ&#013;&#010;&gt;&gt; ä»»åŠ¡æäº¤åä»»åŠ¡åç§°ä¸ºâ€œinset-into_æŸæŸcatalog_æŸæŸdatabase.æŸæŸTableâ€&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt;&#013;&#010;&gt;&gt; è¿™æ ·å¾ˆä¸å‹å¥½å•Šï¼Œèƒ½ä¸èƒ½æˆ‘è‡ªå·±æŒ‡å®šä»»åŠ¡åç§°å‘¢ï¼Ÿ&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; --&#013;&#010;&gt; Best Regards&#013;&#010;&gt;&#013;&#010;&gt; Jeff Zhang&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<tencent_11A2A5049DE257A24CF3D5475B07597A670A@qq.com>"
    },
    {
        "id": "<tencent_C469F1D4530573284C61167C22CCC69B9D08@qq.com>",
        "from": "&quot;ã‚é‡è »éŠæˆ²Ï‡&quot; &lt;zhoujiazhi1...@vip.qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sat, 18 Jul 2020 12:37:03 GMT",
        "subject": "å¦‚ä½•åœ¨ProcessAllWindowFunctionä¸­è§¦å‘æ¸…é™¤è‡ªå®šä¹‰çš„ValueStateçŠ¶æ€",
        "content": "å¤§å®¶å¥½&#013;&#010;&#013;&#010;æƒ³é—®ä¸‹å¦‚ä½•åœ¨ProcessAllWindowFunctionä¸­è§¦å‘æ¸…é™¤ValueStateçŠ¶æ€ï¼Œåœ¨KeydProcessFounctionä¸­æœ‰onTimeræ–¹æ³•ä¸­æ¸…é™¤ï¼Œä½†æ˜¯ProcessAllWindowFunctionæ²¡æœ‰ã€‚&#013;&#010;&#013;&#010;&#013;&#010;è°¢è°¢ï¼",
        "depth": "0",
        "reply": "<tencent_C469F1D4530573284C61167C22CCC69B9D08@qq.com>"
    },
    {
        "id": "<tencent_46CCEC32A2C07201DA3400F8F211EEE68605@qq.com>",
        "from": "&quot;smq&quot; &lt;374060...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sun, 19 Jul 2020 13:35:23 GMT",
        "subject": "flink sinkåˆ°kafka",
        "content": "å¤§å®¶å¥½ï¼Œæˆ‘æƒ³é€šè¿‡avroæ ¼å¼sinkåˆ°kafka,è¯·é—®è¯¥æ€ä¹ˆå®ç°ï¼Œå®˜ç½‘ä¸Šæ²¡æ‰¾åˆ°ç›¸å…³æ–¹æ³•ã€‚",
        "depth": "0",
        "reply": "<tencent_46CCEC32A2C07201DA3400F8F211EEE68605@qq.com>"
    },
    {
        "id": "<CADQYLGtjkAjmtgJ7YhExa9GP5uex5usuY0pGYGy3FrWMw3hkPQ@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sun, 19 Jul 2020 15:05:18 GMT",
        "subject": "Re: flink sinkåˆ°kafka",
        "content": "å¦‚æœä½ æ˜¯ç”¨flink sqlçš„ï¼Œå¯ä»¥é€šè¿‡DDLçš„æ–¹å¼æ¥å®šä¹‰kafka sinkï¼Œå‚è€ƒ [1]&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/kafka.html&#013;&#010;&#013;&#010;Best,&#013;&#010;Godfrey&#013;&#010;&#013;&#010;smq &lt;374060171@qq.com&gt; äº2020å¹´7æœˆ19æ—¥å‘¨æ—¥ ä¸‹åˆ9:36å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; å¤§å®¶å¥½ï¼Œæˆ‘æƒ³é€šè¿‡avroæ ¼å¼sinkåˆ°kafka,è¯·é—®è¯¥æ€ä¹ˆå®ç°ï¼Œå®˜ç½‘ä¸Šæ²¡æ‰¾åˆ°ç›¸å…³æ–¹æ³•ã€‚&#013;&#010;",
        "depth": "1",
        "reply": "<tencent_46CCEC32A2C07201DA3400F8F211EEE68605@qq.com>"
    },
    {
        "id": "<tencent_7DF0016C971D70B93787662A11F79672D008@qq.com>",
        "from": "æ˜å¯ å­™ &lt;374060...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 01:15:05 GMT",
        "subject": "å›å¤: flink sinkåˆ°kafka",
        "content": "è°¢è°¢ï¼Œæˆ‘è¯•è¯•&#013;&#010;&#013;&#010;å‘é€è‡ª Windows 10 ç‰ˆé‚®ä»¶åº”ç”¨&#013;&#010;&#013;&#010;å‘ä»¶äºº: godfrey he&#013;&#010;å‘é€æ—¶é—´: 2020å¹´7æœˆ19æ—¥ 23:06&#013;&#010;æ”¶ä»¶äºº: user-zh&#013;&#010;ä¸»é¢˜: Re: flink sinkåˆ°kafka&#013;&#010;&#013;&#010;å¦‚æœä½ æ˜¯ç”¨flink sqlçš„ï¼Œå¯ä»¥é€šè¿‡DDLçš„æ–¹å¼æ¥å®šä¹‰kafka sinkï¼Œå‚è€ƒ [1]&#013;&#010;&#013;&#010;[1]&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/connectors/kafka.html&#013;&#010;&#013;&#010;Best,&#013;&#010;Godfrey&#013;&#010;&#013;&#010;smq &lt;374060171@qq.com&gt; äº2020å¹´7æœˆ19æ—¥å‘¨æ—¥ ä¸‹åˆ9:36å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; å¤§å®¶å¥½ï¼Œæˆ‘æƒ³é€šè¿‡avroæ ¼å¼sinkåˆ°kafka,è¯·é—®è¯¥æ€ä¹ˆå®ç°ï¼Œå®˜ç½‘ä¸Šæ²¡æ‰¾åˆ°ç›¸å…³æ–¹æ³•ã€‚&#013;&#010;&#013;&#010;",
        "depth": "2",
        "reply": "<tencent_46CCEC32A2C07201DA3400F8F211EEE68605@qq.com>"
    },
    {
        "id": "<tencent_010040FBFE3A4FFBCBAC43AACB4528F26C09@qq.com>",
        "from": "&quot;Z-Z&quot; &lt;zz9876543...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 03:32:49 GMT",
        "subject": "å›å¤ï¼š Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "è¿™æ˜¯taskmanageræ–°æŠ¥çš„ä¸€ä¸ªé”™ï¼Œè¿˜æ˜¯è·Ÿä¹‹å‰ä¸€æ ·ï¼Œç”¨cliæäº¤æŠ¥é”™ï¼Œç”¨webuiæäº¤å°±æ²¡é—®é¢˜ï¼š&#013;&#010;2020-07-20 03:29:25,959 WARN&amp;nbsp; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'value.serializer' was supplied but isn't a known config.&#013;&#010;2020-07-20 03:29:25,959 INFO&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka version : 0.11.0.2&#013;&#010;2020-07-20 03:29:25,959 INFO&amp;nbsp; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#013;&#010;2020-07-20 03:29:25,974 ERROR org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;nbsp; - Caught unexpected exception.&#013;&#010;java.lang.ArrayIndexOutOfBoundsException: 0&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&#009;at java.lang.Thread.run(Thread.java:748)&#013;&#010;2020-07-20 03:29:25,974 WARN&amp;nbsp; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;nbsp; - Exception while restoring keyed state backend for StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1) from alternative (1/1), will retry while more alternatives are available.&#013;&#010;org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected exception.&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&#009;at java.lang.Thread.run(Thread.java:748)&#013;&#010;Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&#009;... 15 more&#013;&#010;2020-07-20 03:29:25,975 INFO&amp;nbsp; org.apache.kafka.clients.producer.KafkaProducer&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.&#013;&#010;2020-07-20 03:29:25,979 INFO&amp;nbsp; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Map -&amp;gt; Filter -&amp;gt; Sink: Unnamed (1/1) (ed554502aa995fe53f1cf0cb8adf633c) switched from RUNNING to FAILED.&#013;&#010;java.lang.Exception: Exception while creating StreamOperatorStateContext.&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&#009;at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&#009;at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&#009;at java.lang.Thread.run(Thread.java:748)&#013;&#010;Caused by: org.apache.flink.util.FlinkException: Could not restore keyed state backend for StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1) from any of the 1 provided restore options.&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&#009;... 9 more&#013;&#010;Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected exception.&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&#009;at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&#009;... 11 more&#013;&#010;Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&#009;at org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;è°¢è°¢å›å¤ï¼š&#013;&#010;ä¹‹å‰çš„savepointéƒ½æ˜¯é€šè¿‡RocksDBStateBackendç”Ÿæˆçš„ï¼›&#013;&#010;è¿™ä¸ªsavepointæˆ‘é€šè¿‡webui æäº¤ä»»åŠ¡å°±æ²¡é—®é¢˜ï¼Œä½ æ˜¯è¯´åœ¨IDEä¸Šè°ƒè¯•savepointå—&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------ åŸå§‹é‚®ä»¶ ------------------&#013;&#010;å‘ä»¶äºº:                                                                                                                        \"user-zh\"                                                                                    &lt;qcx978132955@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ19æ—¥(æ˜ŸæœŸå¤©) æ™šä¸Š8:22&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Hi&#013;&#010;&#013;&#010;ä»ä½ ç»™çš„è¿™éƒ¨åˆ†æ—¥å¿—çœ‹ï¼Œæ˜¯æ¢å¤çš„æ—¶å€™é‡åˆ° EOF äº†ï¼Œè¿™ä¸ªæ¯”è¾ƒå¥‡æ€ª&#013;&#010;1 ä½ ä¹‹å‰çš„ savepoint æ˜¯ä½¿ç”¨ RocksDBStateBackend ç”Ÿæˆçš„å—&#013;&#010;2 ä½ è¿˜æœ‰ä¹‹å‰åœ¨ DFS ä¸Šçš„ savepoint æ–‡ä»¶å—ï¼Ÿå¯èƒ½éœ€è¦ç»“åˆ DFS ä¸Šçš„æ–‡ä»¶ä¸€èµ·çœ‹ä¸€ä¸‹è¿™ä¸ªé—®é¢˜æ€ä¹ˆæ¥çš„&#013;&#010;&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;Z-Z &lt;zz9876543210@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ11:10å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; Flink 1.10.0 ,taskmanageræŠ¥é”™æ—¥å¿—å¦‚ä¸‹ï¼š&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; 2020-07-17 15:06:43,913 ERROR&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;amp;nbsp;&#013;&#010;&amp;gt; - Caught unexpected exception.&#013;&#010;&amp;gt; java.io.EOFException&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; 2020-07-17 15:06:43,914 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;amp;nbsp; -&#013;&#010;&amp;gt; Exception while restoring keyed state backend for&#013;&#010;&amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#013;&#010;&amp;gt; alternative (1/1), will retry while more alternatives are available.&#013;&#010;&amp;gt; org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected&#013;&#010;&amp;gt; exception.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 15 more&#013;&#010;&amp;gt; 2020-07-17 15:06:43,915 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.producer.KafkaProducer&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Closing the Kafka producer with timeoutMillis&#013;&#010;&amp;gt; = 9223372036854775807 ms.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,918 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Co-Keyed-Process -&amp;amp;gt; Flat Map&#013;&#010;&amp;gt; -&amp;amp;gt; Sink: Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) switched from&#013;&#010;&amp;gt; RUNNING to FAILED.&#013;&#010;&amp;gt; java.lang.Exception: Exception while creating StreamOperatorStateContext.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore keyed&#013;&#010;&amp;gt; state backend for&#013;&#010;&amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from any of&#013;&#010;&amp;gt; the 1 provided restore options.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 9 more&#013;&#010;&amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught&#013;&#010;&amp;gt; unexpected exception.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 11 more&#013;&#010;&amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 15 more&#013;&#010;&amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Freeing task resources for&#013;&#010;&amp;gt; Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt; Sink: Unnamed (1/1)&#013;&#010;&amp;gt; (bb8f0a84e07ef90b1e11ca2825e0efab).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Ensuring all FileSystem streams&#013;&#010;&amp;gt; are closed for task Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt; Sink: Unnamed&#013;&#010;&amp;gt; (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) [FAILED]&#013;&#010;&amp;gt; 2020-07-17 15:06:43,931 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending final execution&#013;&#010;&amp;gt; state FAILED to JobManager for task Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt;&#013;&#010;&amp;gt; Sink: Unnamed (1/1) bb8f0a84e07ef90b1e11ca2825e0efab.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Attempting to cancel task&#013;&#010;&amp;gt; Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source -&amp;amp;gt; Flat&#013;&#010;&amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from RUNNING to&#013;&#010;&amp;gt; CANCELING.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Triggering cancellation of task&#013;&#010;&amp;gt; code Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Attempting to cancel task&#013;&#010;&amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source (1/1)&#013;&#010;&amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from RUNNING to CANCELING.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Triggering cancellation of task&#013;&#010;&amp;gt; code Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source -&amp;amp;gt; Flat&#013;&#010;&amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from CANCELING to&#013;&#010;&amp;gt; CANCELED.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Freeing task resources for&#013;&#010;&amp;gt; Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Ensuring all FileSystem streams&#013;&#010;&amp;gt; are closed for task Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce) [CANCELED]&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Source: Custom Source (1/1)&#013;&#010;&amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from CANCELING to CANCELED.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,955 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Freeing task resources for&#013;&#010;&amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending final execution&#013;&#010;&amp;gt; state CANCELED to JobManager for task Source: Custom Source -&amp;amp;gt; Flat Map&#013;&#010;&amp;gt; (1/1) 9cb8dcd4982223adcb6f007f1ffccdce.&#013;&#010;&amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Ensuring all FileSystem streams&#013;&#010;&amp;gt; are closed for task Source: Custom Source (1/1)&#013;&#010;&amp;gt; (00621ff5d788d00c73ccaaea04717600) [CANCELED]&#013;&#010;&amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending final execution&#013;&#010;&amp;gt; state CANCELED to JobManager for task Source: Custom Source (1/1)&#013;&#010;&amp;gt; 00621ff5d788d00c73ccaaea04717600.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'transaction.timeout.ms' was&#013;&#010;&amp;gt; supplied but isn't a known config.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'key.serializer' was supplied but&#013;&#010;&amp;gt; isn't a known config.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'value.serializer' was supplied&#013;&#010;&amp;gt; but isn't a known config.&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka version : 0.11.0.2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Error registering AppInfo mbean&#013;&#010;&amp;gt; javax.management.InstanceAlreadyExistsException:&#013;&#010;&amp;gt; kafka.consumer:type=app-info,id=consumer-3&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:757)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:633)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:615)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;&amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka version : 0.11.0.2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#013;&#010;&amp;gt; 2020-07-17 15:06:44,079 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Error registering AppInfo mbean&#013;&#010;&amp;gt; javax.management.InstanceAlreadyExistsException:&#013;&#010;&amp;gt; kafka.consumer:type=app-info,id=consumer-4&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:757)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:633)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:615)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ------------------&amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;nbsp;------------------&#013;&#010;&amp;gt; å‘ä»¶äºº:&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; \"user-zh\"&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; &lt;&#013;&#010;&amp;gt; qcx978132955@gmail.com&amp;amp;gt;;&#013;&#010;&amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:52&#013;&#010;&amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ä¸»é¢˜:&amp;amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Hi&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹&amp;amp;nbsp; Co-Process (1/1)&#013;&#010;&amp;gt; (d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨ 083f69d029de&#013;&#010;&amp;gt; è¿™å°æœºå™¨ä¸Šã€‚&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Best,&#013;&#010;&amp;gt; Congxian&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Z-Z &lt;zz9876543210@qq.com&amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#013;&#010;&amp;gt; &amp;amp;gt; ---&amp;amp;amp;gt; /jobs/{jobid}/savepoints ---&amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,925 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; -&#013;&#010;&amp;gt; &amp;amp;gt; Request slot with profile ResourceProfile{UNKNOWN} for job&#013;&#010;&amp;gt; &amp;amp;gt; 7639673873b707aa86c4387aa7b4aac3 with allocation id&#013;&#010;&amp;gt; &amp;amp;gt; e8865cdbfe4c3c33099c7112bc2e3231.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from SCHEDULED to&#013;&#010;&amp;gt; DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source -&amp;amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; &amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; &amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1) (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to&#013;&#010;&amp;gt; DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Co-Process -&amp;amp;amp;gt; (Sink: Unnamed, Sink:&#013;&#010;&amp;gt; Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (attempt #0) to e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#013;&#010;&amp;gt; &amp;amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,346 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;gt; (Sink: Unnamed, Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; &amp;amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; &amp;amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,493 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1) (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; RUNNING to FAILED.&#013;&#010;&amp;gt; &amp;amp;gt; java.lang.Exception: Exception while creating&#013;&#010;&amp;gt; StreamOperatorStateContext.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore&#013;&#010;&amp;gt; keyed&#013;&#010;&amp;gt; &amp;amp;gt; state backend for&#013;&#010;&amp;gt; &amp;amp;gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1)&#013;&#010;&amp;gt; from&#013;&#010;&amp;gt; &amp;amp;gt; any of the 1 provided restore options.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; ... 9 more&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException:&#013;&#010;&amp;gt; Caught&#013;&#010;&amp;gt; &amp;amp;gt; unexpected exception.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; ... 11 more&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; ... 15 more",
        "depth": "0",
        "reply": "<tencent_010040FBFE3A4FFBCBAC43AACB4528F26C09@qq.com>"
    },
    {
        "id": "<CAA8tFvvk1EcvBAOiBx6vu+539qKde+rg5tjf8uKNxxua_+-kXg@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 06:30:33 GMT",
        "subject": "Re: Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "Hi&#010;&#010;è¿™ä¸ªè°ƒè¯•å¯ä»¥åœ¨ IDEA è¿›è¡Œçš„ã€‚&#010;&#010;å¦å¤–ä½ è¯´çš„é€šè¿‡ web ui æäº¤æ²¡æœ‰é—®é¢˜ã€‚è¯·é—®ä¸‹ï¼Œæ˜¯åŒä¸€ä¸ª savepoint é€šè¿‡ flink run æäº¤æœ‰é—®é¢˜ï¼Œé€šè¿‡ web ui&#010;æäº¤æ²¡æœ‰é—®é¢˜å—ï¼Ÿå¦‚æœæ˜¯çš„ï¼Œèƒ½å¦åˆ†äº«ä¸‹ä½ çš„æ“ä½œè¿‡ç¨‹å’Œå‘½ä»¤å‘¢ï¼Ÿ&#010;&#010;Best,&#010;Congxian&#010;&#010;&#010;Z-Z &lt;zz9876543210@qq.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸Šåˆ11:33å†™é“ï¼š&#010;&#010;&gt; è¿™æ˜¯taskmanageræ–°æŠ¥çš„ä¸€ä¸ªé”™ï¼Œè¿˜æ˜¯è·Ÿä¹‹å‰ä¸€æ ·ï¼Œç”¨cliæäº¤æŠ¥é”™ï¼Œç”¨webuiæäº¤å°±æ²¡é—®é¢˜ï¼š&#010;&gt; 2020-07-20 03:29:25,959 WARN&amp;nbsp;&#010;&gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; - The configuration 'value.serializer' was supplied&#010;&gt; but isn't a known config.&#010;&gt; 2020-07-20 03:29:25,959 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka version : 0.11.0.2&#010;&gt; 2020-07-20 03:29:25,959 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#010;&gt; 2020-07-20 03:29:25,974 ERROR&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;nbsp;&#010;&gt; - Caught unexpected exception.&#010;&gt; java.lang.ArrayIndexOutOfBoundsException: 0&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;         at java.lang.Thread.run(Thread.java:748)&#010;&gt; 2020-07-20 03:29:25,974 WARN&amp;nbsp;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;nbsp; -&#010;&gt; Exception while restoring keyed state backend for&#010;&gt; StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1) from alternative (1/1),&#010;&gt; will retry while more alternatives are available.&#010;&gt; org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected&#010;&gt; exception.&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;         at java.lang.Thread.run(Thread.java:748)&#010;&gt; Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt;         ... 15 more&#010;&gt; 2020-07-20 03:29:25,975 INFO&amp;nbsp;&#010;&gt; org.apache.kafka.clients.producer.KafkaProducer&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Closing the Kafka producer with timeoutMillis&#010;&gt; = 9223372036854775807 ms.&#010;&gt; 2020-07-20 03:29:25,979 INFO&amp;nbsp;&#010;&gt; org.apache.flink.runtime.taskmanager.Task&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;- Map -&amp;gt; Filter -&amp;gt; Sink:&#010;&gt; Unnamed (1/1) (ed554502aa995fe53f1cf0cb8adf633c) switched from RUNNING to&#010;&gt; FAILED.&#010;&gt; java.lang.Exception: Exception while creating StreamOperatorStateContext.&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt;         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt;         at java.lang.Thread.run(Thread.java:748)&#010;&gt; Caused by: org.apache.flink.util.FlinkException: Could not restore keyed&#010;&gt; state backend for StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1) from any&#010;&gt; of the 1 provided restore options.&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt;         ... 9 more&#010;&gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught&#010;&gt; unexpected exception.&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt;         at&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt;         ... 11 more&#010;&gt; Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt;         at&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; è°¢è°¢å›å¤ï¼š&#010;&gt; ä¹‹å‰çš„savepointéƒ½æ˜¯é€šè¿‡RocksDBStateBackendç”Ÿæˆçš„ï¼›&#010;&gt; è¿™ä¸ªsavepointæˆ‘é€šè¿‡webui æäº¤ä»»åŠ¡å°±æ²¡é—®é¢˜ï¼Œä½ æ˜¯è¯´åœ¨IDEä¸Šè°ƒè¯•savepointå—&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; ------------------ åŸå§‹é‚®ä»¶ ------------------&#010;&gt; å‘ä»¶äºº:&#010;&gt;                                                   \"user-zh\"&#010;&gt;                                                                     &lt;&#010;&gt; qcx978132955@gmail.com&amp;gt;;&#010;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ19æ—¥(æ˜ŸæœŸå¤©) æ™šä¸Š8:22&#010;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&gt;&#010;&gt; ä¸»é¢˜:&amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; Hi&#010;&gt;&#010;&gt; ä»ä½ ç»™çš„è¿™éƒ¨åˆ†æ—¥å¿—çœ‹ï¼Œæ˜¯æ¢å¤çš„æ—¶å€™é‡åˆ° EOF äº†ï¼Œè¿™ä¸ªæ¯”è¾ƒå¥‡æ€ª&#010;&gt; 1 ä½ ä¹‹å‰çš„ savepoint æ˜¯ä½¿ç”¨ RocksDBStateBackend ç”Ÿæˆçš„å—&#010;&gt; 2 ä½ è¿˜æœ‰ä¹‹å‰åœ¨ DFS ä¸Šçš„ savepoint æ–‡ä»¶å—ï¼Ÿå¯èƒ½éœ€è¦ç»“åˆ DFS ä¸Šçš„æ–‡ä»¶ä¸€èµ·çœ‹ä¸€ä¸‹è¿™ä¸ªé—®é¢˜æ€ä¹ˆæ¥çš„&#010;&gt;&#010;&gt; Best,&#010;&gt; Congxian&#010;&gt;&#010;&gt;&#010;&gt; Z-Z &lt;zz9876543210@qq.com&amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ11:10å†™é“ï¼š&#010;&gt;&#010;&gt; &amp;gt; Flink 1.10.0 ,taskmanageræŠ¥é”™æ—¥å¿—å¦‚ä¸‹ï¼š&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; 2020-07-17 15:06:43,913 ERROR&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;amp;nbsp;&#010;&gt; &amp;gt; - Caught unexpected exception.&#010;&gt; &amp;gt; java.io.EOFException&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; 2020-07-17 15:06:43,914 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;amp;nbsp;&#010;&gt; -&#010;&gt; &amp;gt; Exception while restoring keyed state backend for&#010;&gt; &amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#010;&gt; &amp;gt; alternative (1/1), will retry while more alternatives are available.&#010;&gt; &amp;gt; org.apache.flink.runtime.state.BackendBuildingException: Caught&#010;&gt; unexpected&#010;&gt; &amp;gt; exception.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; Caused by: java.io.EOFException&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 15 more&#010;&gt; &amp;gt; 2020-07-17 15:06:43,915 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.clients.producer.KafkaProducer&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Closing the Kafka&#010;&gt; producer with timeoutMillis&#010;&gt; &amp;gt; = 9223372036854775807 ms.&#010;&gt; &amp;gt; 2020-07-17 15:06:43,918 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Co-Keyed-Process -&amp;amp;gt; Flat Map&#010;&gt; &amp;gt; -&amp;amp;gt; Sink: Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab)&#010;&gt; switched from&#010;&gt; &amp;gt; RUNNING to FAILED.&#010;&gt; &amp;gt; java.lang.Exception: Exception while creating&#010;&gt; StreamOperatorStateContext.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore&#010;&gt; keyed&#010;&gt; &amp;gt; state backend for&#010;&gt; &amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#010;&gt; any of&#010;&gt; &amp;gt; the 1 provided restore options.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 9 more&#010;&gt; &amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException:&#010;&gt; Caught&#010;&gt; &amp;gt; unexpected exception.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 11 more&#010;&gt; &amp;gt; Caused by: java.io.EOFException&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; ... 15 more&#010;&gt; &amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Freeing task resources for&#010;&gt; &amp;gt; Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt; Sink: Unnamed (1/1)&#010;&gt; &amp;gt; (bb8f0a84e07ef90b1e11ca2825e0efab).&#010;&gt; &amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Ensuring all FileSystem streams&#010;&gt; &amp;gt; are closed for task Co-Keyed-Process -&amp;amp;gt; Flat Map -&amp;amp;gt;&#010;&gt; Sink: Unnamed&#010;&gt; &amp;gt; (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) [FAILED]&#010;&gt; &amp;gt; 2020-07-17 15:06:43,931 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending&#010;&gt; final execution&#010;&gt; &amp;gt; state FAILED to JobManager for task Co-Keyed-Process -&amp;amp;gt; Flat&#010;&gt; Map -&amp;amp;gt;&#010;&gt; &amp;gt; Sink: Unnamed (1/1) bb8f0a84e07ef90b1e11ca2825e0efab.&#010;&gt; &amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Attempting to cancel task&#010;&gt; &amp;gt; Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#010;&gt; &amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; &amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Source: Custom Source -&amp;amp;gt; Flat&#010;&gt; &amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from RUNNING to&#010;&gt; &amp;gt; CANCELING.&#010;&gt; &amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Triggering cancellation of task&#010;&gt; &amp;gt; code Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#010;&gt; &amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; &amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Attempting to cancel task&#010;&gt; &amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#010;&gt; &amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Source: Custom Source (1/1)&#010;&gt; &amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from RUNNING to CANCELING.&#010;&gt; &amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Triggering cancellation of task&#010;&gt; &amp;gt; code Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#010;&gt; &amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Source: Custom Source -&amp;amp;gt; Flat&#010;&gt; &amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from CANCELING&#010;&gt; to&#010;&gt; &amp;gt; CANCELED.&#010;&gt; &amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Freeing task resources for&#010;&gt; &amp;gt; Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#010;&gt; &amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; &amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Ensuring all FileSystem streams&#010;&gt; &amp;gt; are closed for task Source: Custom Source -&amp;amp;gt; Flat Map (1/1)&#010;&gt; &amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce) [CANCELED]&#010;&gt; &amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Source: Custom Source (1/1)&#010;&gt; &amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from CANCELING to&#010;&gt; CANCELED.&#010;&gt; &amp;gt; 2020-07-17 15:06:43,955 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Freeing task resources for&#010;&gt; &amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#010;&gt; &amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending&#010;&gt; final execution&#010;&gt; &amp;gt; state CANCELED to JobManager for task Source: Custom Source -&amp;amp;gt;&#010;&gt; Flat Map&#010;&gt; &amp;gt; (1/1) 9cb8dcd4982223adcb6f007f1ffccdce.&#010;&gt; &amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Ensuring all FileSystem streams&#010;&gt; &amp;gt; are closed for task Source: Custom Source (1/1)&#010;&gt; &amp;gt; (00621ff5d788d00c73ccaaea04717600) [CANCELED]&#010;&gt; &amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - Un-registering task and sending&#010;&gt; final execution&#010;&gt; &amp;gt; state CANCELED to JobManager for task Source: Custom Source (1/1)&#010;&gt; &amp;gt; 00621ff5d788d00c73ccaaea04717600.&#010;&gt; &amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration '&#010;&gt; transaction.timeout.ms' was&#010;&gt; &amp;gt; supplied but isn't a known config.&#010;&gt; &amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'key.serializer'&#010;&gt; was supplied but&#010;&gt; &amp;gt; isn't a known config.&#010;&gt; &amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration&#010;&gt; 'value.serializer' was supplied&#010;&gt; &amp;gt; but isn't a known config.&#010;&gt; &amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Kafka version : 0.11.0.2&#010;&gt; &amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Kafka commitId : 73be1e1168f91ee2&#010;&gt; &amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Error registering AppInfo mbean&#010;&gt; &amp;gt; javax.management.InstanceAlreadyExistsException:&#010;&gt; &amp;gt; kafka.consumer:type=app-info,id=consumer-3&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:757)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:633)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:615)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#010;&gt; &amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Kafka version : 0.11.0.2&#010;&gt; &amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Kafka commitId : 73be1e1168f91ee2&#010;&gt; &amp;gt; 2020-07-17 15:06:44,079 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Error registering AppInfo mbean&#010;&gt; &amp;gt; javax.management.InstanceAlreadyExistsException:&#010;&gt; &amp;gt; kafka.consumer:type=app-info,id=consumer-4&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:757)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:633)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;gt;(KafkaConsumer.java:615)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; ------------------&amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;nbsp;------------------&#010;&gt; &amp;gt; å‘ä»¶äºº:&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&gt; &amp;nbsp; \"user-zh\"&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&gt; &amp;nbsp; &lt;&#010;&gt; &amp;gt; qcx978132955@gmail.com&amp;amp;gt;;&#010;&gt; &amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:52&#010;&gt; &amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; ä¸»é¢˜:&amp;amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; Hi&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹&amp;amp;nbsp; Co-Process (1/1)&#010;&gt; &amp;gt; (d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨&#010;&gt; 083f69d029de&#010;&gt; &amp;gt; è¿™å°æœºå™¨ä¸Šã€‚&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; Best,&#010;&gt; &amp;gt; Congxian&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; Z-Z &lt;zz9876543210@qq.com&amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#010;&gt; &amp;gt; &amp;amp;gt; ---&amp;amp;amp;gt; /jobs/{jobid}/savepoints ---&amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,925 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; -&#010;&gt; &amp;gt; &amp;amp;gt; Request slot with profile ResourceProfile{UNKNOWN} for job&#010;&gt; &amp;gt; &amp;amp;gt; 7639673873b707aa86c4387aa7b4aac3 with allocation id&#010;&gt; &amp;gt; &amp;amp;gt; e8865cdbfe4c3c33099c7112bc2e3231.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;gt; Filter&#010;&gt; (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from SCHEDULED to&#010;&gt; &amp;gt; DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source&#010;&gt; -&amp;amp;amp;gt; Filter (1/1)&#010;&gt; &amp;gt; (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; &amp;gt; &amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1)&#010;&gt; (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; &amp;gt; &amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1)&#010;&gt; (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1)&#010;&gt; (d0309f26a545e74643382ed3f758269b)&#010;&gt; &amp;gt; switched from&#010;&gt; &amp;gt; &amp;amp;gt; SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;gt; (Sink: Unnamed,&#010;&gt; Sink: Unnamed) (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to&#010;&gt; &amp;gt; DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Deploying Co-Process -&amp;amp;amp;gt; (Sink:&#010;&gt; Unnamed, Sink:&#010;&gt; &amp;gt; Unnamed) (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (attempt #0) to e63d829deafc144cd82efd73979dd056 @&#010;&gt; 083f69d029de&#010;&gt; &amp;gt; &amp;amp;gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,346 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;gt; (Sink: Unnamed,&#010;&gt; Sink: Unnamed) (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING&#010;&gt; to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; &amp;gt; &amp;amp;gt; switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; &amp;gt; &amp;amp;gt; switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1)&#010;&gt; (d0309f26a545e74643382ed3f758269b)&#010;&gt; &amp;gt; switched from&#010;&gt; &amp;gt; &amp;amp;gt; DEPLOYING to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;gt; Filter&#010;&gt; (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from DEPLOYING&#010;&gt; to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 09:51:49,493 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; - Co-Process (1/1)&#010;&gt; (d0309f26a545e74643382ed3f758269b)&#010;&gt; &amp;gt; switched from&#010;&gt; &amp;gt; &amp;amp;gt; RUNNING to FAILED.&#010;&gt; &amp;gt; &amp;amp;gt; java.lang.Exception: Exception while creating&#010;&gt; &amp;gt; StreamOperatorStateContext.&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; &amp;amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not&#010;&gt; restore&#010;&gt; &amp;gt; keyed&#010;&gt; &amp;gt; &amp;amp;gt; state backend for&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1)&#010;&gt; &amp;gt; from&#010;&gt; &amp;gt; &amp;amp;gt; any of the 1 provided restore options.&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; ... 9 more&#010;&gt; &amp;gt; &amp;amp;gt; Caused by:&#010;&gt; org.apache.flink.runtime.state.BackendBuildingException:&#010;&gt; &amp;gt; Caught&#010;&gt; &amp;gt; &amp;amp;gt; unexpected exception.&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; ... 11 more&#010;&gt; &amp;gt; &amp;amp;gt; Caused by: java.io.EOFException&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; ... 15 more&#010;&#010;",
        "depth": "1",
        "reply": "<tencent_010040FBFE3A4FFBCBAC43AACB4528F26C09@qq.com>"
    },
    {
        "id": "<tencent_34754EF6AB58B7571B8990E4B90004F48D0A@qq.com>",
        "from": "&quot;Z-Z&quot; &lt;zz9876543...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 08:15:07 GMT",
        "subject": "å›å¤ï¼š Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "é€šè¿‡ cli å‘½ä»¤æ˜¯ åœ¨jobmanagerç›®å½• æ‰§è¡Œ bin/flink run -d -p 1 -s {savepointuri} /data/test.jar&amp;nbsp; ----&amp;gt;è¿™ç§ä¼šæŠ¥è«åå…¶å¦™çš„é”™è¯¯ï¼Œå¦‚ä¹‹å‰çš„é‚®ä»¶&#013;&#010;é€šè¿‡webuiå°±æ˜¯åœ¨http://jobmanager:8081&amp;nbsp; submit new&amp;nbsp; jobé‡Œæ·»åŠ jaråŒ…ï¼ŒæŒ‡å®šç›¸åŒçš„savepoint pathå’Œå¹¶è¡Œåº¦æäº¤ä»»åŠ¡ ----&amp;gt; è¿™æ ·æ“ä½œå°±æ²¡é—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                                                                        \"user-zh\"                                                                                    &lt;qcx978132955@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ20æ—¥(æ˜ŸæœŸä¸€) ä¸‹åˆ2:30&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Hi&#013;&#010;&#013;&#010;è¿™ä¸ªè°ƒè¯•å¯ä»¥åœ¨ IDEA è¿›è¡Œçš„ã€‚&#013;&#010;&#013;&#010;å¦å¤–ä½ è¯´çš„é€šè¿‡ web ui æäº¤æ²¡æœ‰é—®é¢˜ã€‚è¯·é—®ä¸‹ï¼Œæ˜¯åŒä¸€ä¸ª savepoint é€šè¿‡ flink run æäº¤æœ‰é—®é¢˜ï¼Œé€šè¿‡ web ui&#013;&#010;æäº¤æ²¡æœ‰é—®é¢˜å—ï¼Ÿå¦‚æœæ˜¯çš„ï¼Œèƒ½å¦åˆ†äº«ä¸‹ä½ çš„æ“ä½œè¿‡ç¨‹å’Œå‘½ä»¤å‘¢ï¼Ÿ&#013;&#010;&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;Z-Z &lt;zz9876543210@qq.com&amp;gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸Šåˆ11:33å†™é“ï¼š&#013;&#010;&#013;&#010;&amp;gt; è¿™æ˜¯taskmanageræ–°æŠ¥çš„ä¸€ä¸ªé”™ï¼Œè¿˜æ˜¯è·Ÿä¹‹å‰ä¸€æ ·ï¼Œç”¨cliæäº¤æŠ¥é”™ï¼Œç”¨webuiæäº¤å°±æ²¡é—®é¢˜ï¼š&#013;&#010;&amp;gt; 2020-07-20 03:29:25,959 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration 'value.serializer' was supplied&#013;&#010;&amp;gt; but isn't a known config.&#013;&#010;&amp;gt; 2020-07-20 03:29:25,959 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka version : 0.11.0.2&#013;&#010;&amp;gt; 2020-07-20 03:29:25,959 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Kafka commitId : 73be1e1168f91ee2&#013;&#010;&amp;gt; 2020-07-20 03:29:25,974 ERROR&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;amp;nbsp;&#013;&#010;&amp;gt; - Caught unexpected exception.&#013;&#010;&amp;gt; java.lang.ArrayIndexOutOfBoundsException: 0&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; 2020-07-20 03:29:25,974 WARN&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;amp;nbsp; -&#013;&#010;&amp;gt; Exception while restoring keyed state backend for&#013;&#010;&amp;gt; StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1) from alternative (1/1),&#013;&#010;&amp;gt; will retry while more alternatives are available.&#013;&#010;&amp;gt; org.apache.flink.runtime.state.BackendBuildingException: Caught unexpected&#013;&#010;&amp;gt; exception.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 15 more&#013;&#010;&amp;gt; 2020-07-20 03:29:25,975 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.kafka.clients.producer.KafkaProducer&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Closing the Kafka producer with timeoutMillis&#013;&#010;&amp;gt; = 9223372036854775807 ms.&#013;&#010;&amp;gt; 2020-07-20 03:29:25,979 INFO&amp;amp;nbsp;&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Map -&amp;amp;gt; Filter -&amp;amp;gt; Sink:&#013;&#010;&amp;gt; Unnamed (1/1) (ed554502aa995fe53f1cf0cb8adf633c) switched from RUNNING to&#013;&#010;&amp;gt; FAILED.&#013;&#010;&amp;gt; java.lang.Exception: Exception while creating StreamOperatorStateContext.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore keyed&#013;&#010;&amp;gt; state backend for StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1) from any&#013;&#010;&amp;gt; of the 1 provided restore options.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 9 more&#013;&#010;&amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException: Caught&#013;&#010;&amp;gt; unexpected exception.&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 11 more&#013;&#010;&amp;gt; Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; è°¢è°¢å›å¤ï¼š&#013;&#010;&amp;gt; ä¹‹å‰çš„savepointéƒ½æ˜¯é€šè¿‡RocksDBStateBackendç”Ÿæˆçš„ï¼›&#013;&#010;&amp;gt; è¿™ä¸ªsavepointæˆ‘é€šè¿‡webui æäº¤ä»»åŠ¡å°±æ²¡é—®é¢˜ï¼Œä½ æ˜¯è¯´åœ¨IDEä¸Šè°ƒè¯•savepointå—&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ------------------ åŸå§‹é‚®ä»¶ ------------------&#013;&#010;&amp;gt; å‘ä»¶äºº:&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; \"user-zh\"&#013;&#010;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;&#013;&#010;&amp;gt; qcx978132955@gmail.com&amp;amp;gt;;&#013;&#010;&amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ19æ—¥(æ˜ŸæœŸå¤©) æ™šä¸Š8:22&#013;&#010;&amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ä¸»é¢˜:&amp;amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Hi&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; ä»ä½ ç»™çš„è¿™éƒ¨åˆ†æ—¥å¿—çœ‹ï¼Œæ˜¯æ¢å¤çš„æ—¶å€™é‡åˆ° EOF äº†ï¼Œè¿™ä¸ªæ¯”è¾ƒå¥‡æ€ª&#013;&#010;&amp;gt; 1 ä½ ä¹‹å‰çš„ savepoint æ˜¯ä½¿ç”¨ RocksDBStateBackend ç”Ÿæˆçš„å—&#013;&#010;&amp;gt; 2 ä½ è¿˜æœ‰ä¹‹å‰åœ¨ DFS ä¸Šçš„ savepoint æ–‡ä»¶å—ï¼Ÿå¯èƒ½éœ€è¦ç»“åˆ DFS ä¸Šçš„æ–‡ä»¶ä¸€èµ·çœ‹ä¸€ä¸‹è¿™ä¸ªé—®é¢˜æ€ä¹ˆæ¥çš„&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Best,&#013;&#010;&amp;gt; Congxian&#013;&#010;&amp;gt;&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; Z-Z &lt;zz9876543210@qq.com&amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ11:10å†™é“ï¼š&#013;&#010;&amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; Flink 1.10.0 ,taskmanageræŠ¥é”™æ—¥å¿—å¦‚ä¸‹ï¼š&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,913 ERROR&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; - Caught unexpected exception.&#013;&#010;&amp;gt; &amp;amp;gt; java.io.EOFException&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,914 WARN&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; -&#013;&#010;&amp;gt; &amp;amp;gt; Exception while restoring keyed state backend for&#013;&#010;&amp;gt; &amp;amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#013;&#010;&amp;gt; &amp;amp;gt; alternative (1/1), will retry while more alternatives are available.&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.state.BackendBuildingException: Caught&#013;&#010;&amp;gt; unexpected&#013;&#010;&amp;gt; &amp;amp;gt; exception.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; ... 15 more&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,915 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.clients.producer.KafkaProducer&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;- Closing the Kafka&#013;&#010;&amp;gt; producer with timeoutMillis&#013;&#010;&amp;gt; &amp;amp;gt; = 9223372036854775807 ms.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,918 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Co-Keyed-Process -&amp;amp;amp;gt; Flat Map&#013;&#010;&amp;gt; &amp;amp;gt; -&amp;amp;amp;gt; Sink: Unnamed (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab)&#013;&#010;&amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; RUNNING to FAILED.&#013;&#010;&amp;gt; &amp;amp;gt; java.lang.Exception: Exception while creating&#013;&#010;&amp;gt; StreamOperatorStateContext.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore&#013;&#010;&amp;gt; keyed&#013;&#010;&amp;gt; &amp;amp;gt; state backend for&#013;&#010;&amp;gt; &amp;amp;gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#013;&#010;&amp;gt; any of&#013;&#010;&amp;gt; &amp;amp;gt; the 1 provided restore options.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; ... 9 more&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException:&#013;&#010;&amp;gt; Caught&#013;&#010;&amp;gt; &amp;amp;gt; unexpected exception.&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; ... 11 more&#013;&#010;&amp;gt; &amp;amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; ... 15 more&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Freeing task resources for&#013;&#010;&amp;gt; &amp;amp;gt; Co-Keyed-Process -&amp;amp;amp;gt; Flat Map -&amp;amp;amp;gt; Sink: Unnamed (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (bb8f0a84e07ef90b1e11ca2825e0efab).&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Ensuring all FileSystem streams&#013;&#010;&amp;gt; &amp;amp;gt; are closed for task Co-Keyed-Process -&amp;amp;amp;gt; Flat Map -&amp;amp;amp;gt;&#013;&#010;&amp;gt; Sink: Unnamed&#013;&#010;&amp;gt; &amp;amp;gt; (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) [FAILED]&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,931 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - Un-registering task and sending&#013;&#010;&amp;gt; final execution&#013;&#010;&amp;gt; &amp;amp;gt; state FAILED to JobManager for task Co-Keyed-Process -&amp;amp;amp;gt; Flat&#013;&#010;&amp;gt; Map -&amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; Sink: Unnamed (1/1) bb8f0a84e07ef90b1e11ca2825e0efab.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Attempting to cancel task&#013;&#010;&amp;gt; &amp;amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat&#013;&#010;&amp;gt; &amp;amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from RUNNING to&#013;&#010;&amp;gt; &amp;amp;gt; CANCELING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Triggering cancellation of task&#013;&#010;&amp;gt; &amp;amp;gt; code Source: Custom Source -&amp;amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Attempting to cancel task&#013;&#010;&amp;gt; &amp;amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from RUNNING to CANCELING.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Triggering cancellation of task&#013;&#010;&amp;gt; &amp;amp;gt; code Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat&#013;&#010;&amp;gt; &amp;amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from CANCELING&#013;&#010;&amp;gt; to&#013;&#010;&amp;gt; &amp;amp;gt; CANCELED.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Freeing task resources for&#013;&#010;&amp;gt; &amp;amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Ensuring all FileSystem streams&#013;&#010;&amp;gt; &amp;amp;gt; are closed for task Source: Custom Source -&amp;amp;amp;gt; Flat Map (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce) [CANCELED]&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from CANCELING to&#013;&#010;&amp;gt; CANCELED.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,955 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Freeing task resources for&#013;&#010;&amp;gt; &amp;amp;gt; Source: Custom Source (1/1) (00621ff5d788d00c73ccaaea04717600).&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - Un-registering task and sending&#013;&#010;&amp;gt; final execution&#013;&#010;&amp;gt; &amp;amp;gt; state CANCELED to JobManager for task Source: Custom Source -&amp;amp;amp;gt;&#013;&#010;&amp;gt; Flat Map&#013;&#010;&amp;gt; &amp;amp;gt; (1/1) 9cb8dcd4982223adcb6f007f1ffccdce.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Ensuring all FileSystem streams&#013;&#010;&amp;gt; &amp;amp;gt; are closed for task Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (00621ff5d788d00c73ccaaea04717600) [CANCELED]&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - Un-registering task and sending&#013;&#010;&amp;gt; final execution&#013;&#010;&amp;gt; &amp;amp;gt; state CANCELED to JobManager for task Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; 00621ff5d788d00c73ccaaea04717600.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - The configuration '&#013;&#010;&amp;gt; transaction.timeout.ms' was&#013;&#010;&amp;gt; &amp;amp;gt; supplied but isn't a known config.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - The configuration 'key.serializer'&#013;&#010;&amp;gt; was supplied but&#013;&#010;&amp;gt; &amp;amp;gt; isn't a known config.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - The configuration&#013;&#010;&amp;gt; 'value.serializer' was supplied&#013;&#010;&amp;gt; &amp;amp;gt; but isn't a known config.&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Kafka version : 0.11.0.2&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Kafka commitId : 73be1e1168f91ee2&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Error registering AppInfo mbean&#013;&#010;&amp;gt; &amp;amp;gt; javax.management.InstanceAlreadyExistsException:&#013;&#010;&amp;gt; &amp;amp;gt; kafka.consumer:type=app-info,id=consumer-3&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:757)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:633)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:615)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Kafka version : 0.11.0.2&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Kafka commitId : 73be1e1168f91ee2&#013;&#010;&amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,079 WARN&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#013;&#010;&amp;gt; Error registering AppInfo mbean&#013;&#010;&amp;gt; &amp;amp;gt; javax.management.InstanceAlreadyExistsException:&#013;&#010;&amp;gt; &amp;amp;gt; kafka.consumer:type=app-info,id=consumer-4&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:757)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:633)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:615)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; &amp;amp;nbsp; at&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; ------------------&amp;amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;amp;nbsp;------------------&#013;&#010;&amp;gt; &amp;amp;gt; å‘ä»¶äºº:&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; \"user-zh\"&#013;&#010;&amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;nbsp; &lt;&#013;&#010;&amp;gt; &amp;amp;gt; qcx978132955@gmail.com&amp;amp;amp;gt;;&#013;&#010;&amp;gt; &amp;amp;gt; å‘é€æ—¶é—´:&amp;amp;amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:52&#013;&#010;&amp;gt; &amp;amp;gt; æ”¶ä»¶äºº:&amp;amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;amp;gt;;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; ä¸»é¢˜:&amp;amp;amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; Hi&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹&amp;amp;amp;nbsp; Co-Process (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨&#013;&#010;&amp;gt; 083f69d029de&#013;&#010;&amp;gt; &amp;amp;gt; è¿™å°æœºå™¨ä¸Šã€‚&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; Best,&#013;&#010;&amp;gt; &amp;amp;gt; Congxian&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; Z-Z &lt;zz9876543210@qq.com&amp;amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; ---&amp;amp;amp;amp;gt; /jobs/{jobid}/savepoints ---&amp;amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,925 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; -&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Request slot with profile ResourceProfile{UNKNOWN} for job&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 7639673873b707aa86c4387aa7b4aac3 with allocation id&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e8865cdbfe4c3c33099c7112bc2e3231.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;amp;gt; Filter&#013;&#010;&amp;gt; (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from SCHEDULED to&#013;&#010;&amp;gt; &amp;amp;gt; DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Source: Custom Source&#013;&#010;&amp;gt; -&amp;amp;amp;amp;gt; Filter (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#013;&#010;&amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1)&#013;&#010;&amp;gt; (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#013;&#010;&amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Source: Custom Source (1/1)&#013;&#010;&amp;gt; (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#013;&#010;&amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process (1/1)&#013;&#010;&amp;gt; (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; &amp;amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; SCHEDULED to DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Co-Process (1/1) (attempt #0) to&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#013;&#010;&amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;amp;gt; (Sink: Unnamed,&#013;&#010;&amp;gt; Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from SCHEDULED to&#013;&#010;&amp;gt; &amp;amp;gt; DEPLOYING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Co-Process -&amp;amp;amp;amp;gt; (Sink:&#013;&#010;&amp;gt; Unnamed, Sink:&#013;&#010;&amp;gt; &amp;amp;gt; Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (attempt #0) to e63d829deafc144cd82efd73979dd056 @&#013;&#010;&amp;gt; 083f69d029de&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (dataPort=35758)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,346 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process -&amp;amp;amp;amp;gt; (Sink: Unnamed,&#013;&#010;&amp;gt; Sink: Unnamed) (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched from DEPLOYING&#013;&#010;&amp;gt; to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process (1/1)&#013;&#010;&amp;gt; (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; &amp;amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; DEPLOYING to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source -&amp;amp;amp;amp;gt; Filter&#013;&#010;&amp;gt; (1/1)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched from DEPLOYING&#013;&#010;&amp;gt; to RUNNING.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,493 INFO&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process (1/1)&#013;&#010;&amp;gt; (d0309f26a545e74643382ed3f758269b)&#013;&#010;&amp;gt; &amp;amp;gt; switched from&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; RUNNING to FAILED.&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; java.lang.Exception: Exception while creating&#013;&#010;&amp;gt; &amp;amp;gt; StreamOperatorStateContext.&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; java.lang.Thread.run(Thread.java:748)&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not&#013;&#010;&amp;gt; restore&#013;&#010;&amp;gt; &amp;amp;gt; keyed&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; state backend for&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1)&#013;&#010;&amp;gt; &amp;amp;gt; from&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; any of the 1 provided restore options.&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; ... 9 more&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Caused by:&#013;&#010;&amp;gt; org.apache.flink.runtime.state.BackendBuildingException:&#013;&#010;&amp;gt; &amp;amp;gt; Caught&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; unexpected exception.&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; ... 11 more&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Caused by: java.io.EOFException&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; at&#013;&#010;&amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#013;&#010;&amp;gt; &amp;amp;gt;&#013;&#010;&amp;gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#013;&#010;&amp;gt; ... 15 more",
        "depth": "2",
        "reply": "<tencent_010040FBFE3A4FFBCBAC43AACB4528F26C09@qq.com>"
    },
    {
        "id": "<CAA8tFvtrBEMvkOE2nTTES29h09K=fntvY-Y8-s_2eZ3E1SBAuQ@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:09:18 GMT",
        "subject": "Re: Flink Cli éƒ¨ç½²é—®é¢˜",
        "content": "Hi  Z-Z&#010;    è¿™ç§æƒ…å†µæ¯”è¾ƒå¥‡æ€ªçš„ã€‚ä½ è¿™ä¸ªæ˜¯ç¨³å®šå¤ç°çš„å—ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸ªç¨³å®šå¤ç°çš„ä½œä¸šä»£ç ï¼Œä»¥åŠç›¸å…³æ­¥éª¤å‘¢ï¼Ÿæˆ‘å°è¯•æœ¬åœ°å¤ç°ä¸€ä¸‹&#010;&#010;&#010;Best,&#010;Congxian&#010;&#010;&#010;Z-Z &lt;zz9876543210@qq.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ4:17å†™é“ï¼š&#010;&#010;&gt; é€šè¿‡ cli å‘½ä»¤æ˜¯ åœ¨jobmanagerç›®å½• æ‰§è¡Œ bin/flink run -d -p 1 -s {savepointuri}&#010;&gt; /data/test.jar&amp;nbsp; ----&amp;gt;è¿™ç§ä¼šæŠ¥è«åå…¶å¦™çš„é”™è¯¯ï¼Œå¦‚ä¹‹å‰çš„é‚®ä»¶&#010;&gt; é€šè¿‡webuiå°±æ˜¯åœ¨http://jobmanager:8081&amp;nbsp; submit new&amp;nbsp;&#010;&gt; jobé‡Œæ·»åŠ jaråŒ…ï¼ŒæŒ‡å®šç›¸åŒçš„savepoint pathå’Œå¹¶è¡Œåº¦æäº¤ä»»åŠ¡ ----&amp;gt; è¿™æ ·æ“ä½œå°±æ²¡é—®é¢˜&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; ------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#010;&gt; å‘ä»¶äºº:&#010;&gt;                                                   \"user-zh\"&#010;&gt;                                                                     &lt;&#010;&gt; qcx978132955@gmail.com&amp;gt;;&#010;&gt; å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ20æ—¥(æ˜ŸæœŸä¸€) ä¸‹åˆ2:30&#010;&gt; æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#010;&gt;&#010;&gt; ä¸»é¢˜:&amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; Hi&#010;&gt;&#010;&gt; è¿™ä¸ªè°ƒè¯•å¯ä»¥åœ¨ IDEA è¿›è¡Œçš„ã€‚&#010;&gt;&#010;&gt; å¦å¤–ä½ è¯´çš„é€šè¿‡ web ui æäº¤æ²¡æœ‰é—®é¢˜ã€‚è¯·é—®ä¸‹ï¼Œæ˜¯åŒä¸€ä¸ª savepoint é€šè¿‡ flink run æäº¤æœ‰é—®é¢˜ï¼Œé€šè¿‡ web ui&#010;&gt; æäº¤æ²¡æœ‰é—®é¢˜å—ï¼Ÿå¦‚æœæ˜¯çš„ï¼Œèƒ½å¦åˆ†äº«ä¸‹ä½ çš„æ“ä½œè¿‡ç¨‹å’Œå‘½ä»¤å‘¢ï¼Ÿ&#010;&gt;&#010;&gt; Best,&#010;&gt; Congxian&#010;&gt;&#010;&gt;&#010;&gt; Z-Z &lt;zz9876543210@qq.com&amp;gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸Šåˆ11:33å†™é“ï¼š&#010;&gt;&#010;&gt; &amp;gt; è¿™æ˜¯taskmanageræ–°æŠ¥çš„ä¸€ä¸ªé”™ï¼Œè¿˜æ˜¯è·Ÿä¹‹å‰ä¸€æ ·ï¼Œç”¨cliæäº¤æŠ¥é”™ï¼Œç”¨webuiæäº¤å°±æ²¡é—®é¢˜ï¼š&#010;&gt; &amp;gt; 2020-07-20 03:29:25,959 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; - The configuration&#010;&gt; 'value.serializer' was supplied&#010;&gt; &amp;gt; but isn't a known config.&#010;&gt; &amp;gt; 2020-07-20 03:29:25,959 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Kafka version : 0.11.0.2&#010;&gt; &amp;gt; 2020-07-20 03:29:25,959 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Kafka commitId : 73be1e1168f91ee2&#010;&gt; &amp;gt; 2020-07-20 03:29:25,974 ERROR&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;amp;nbsp;&#010;&gt; &amp;gt; - Caught unexpected exception.&#010;&gt; &amp;gt; java.lang.ArrayIndexOutOfBoundsException: 0&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; 2020-07-20 03:29:25,974 WARN&amp;amp;nbsp;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;amp;nbsp;&#010;&gt; -&#010;&gt; &amp;gt; Exception while restoring keyed state backend for&#010;&gt; &amp;gt; StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1) from alternative&#010;&gt; (1/1),&#010;&gt; &amp;gt; will retry while more alternatives are available.&#010;&gt; &amp;gt; org.apache.flink.runtime.state.BackendBuildingException: Caught&#010;&gt; unexpected&#010;&gt; &amp;gt; exception.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 15 more&#010;&gt; &amp;gt; 2020-07-20 03:29:25,975 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.kafka.clients.producer.KafkaProducer&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;- Closing the Kafka&#010;&gt; producer with timeoutMillis&#010;&gt; &amp;gt; = 9223372036854775807 ms.&#010;&gt; &amp;gt; 2020-07-20 03:29:25,979 INFO&amp;amp;nbsp;&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;-&#010;&gt; Map -&amp;amp;gt; Filter -&amp;amp;gt; Sink:&#010;&gt; &amp;gt; Unnamed (1/1) (ed554502aa995fe53f1cf0cb8adf633c) switched from&#010;&gt; RUNNING to&#010;&gt; &amp;gt; FAILED.&#010;&gt; &amp;gt; java.lang.Exception: Exception while creating&#010;&gt; StreamOperatorStateContext.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not restore&#010;&gt; keyed&#010;&gt; &amp;gt; state backend for StreamMap_caf773fe289bfdb867e0b4bd0c431c5f_(1/1)&#010;&gt; from any&#010;&gt; &amp;gt; of the 1 provided restore options.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 9 more&#010;&gt; &amp;gt; Caused by: org.apache.flink.runtime.state.BackendBuildingException:&#010;&gt; Caught&#010;&gt; &amp;gt; unexpected exception.&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ... 11 more&#010;&gt; &amp;gt; Caused by: java.lang.ArrayIndexOutOfBoundsException: 0&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.snapshot.RocksSnapshotUtil.hasMetaDataFollowsFlag(RocksSnapshotUtil.java:45)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:223)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; at&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; è°¢è°¢å›å¤ï¼š&#010;&gt; &amp;gt; ä¹‹å‰çš„savepointéƒ½æ˜¯é€šè¿‡RocksDBStateBackendç”Ÿæˆçš„ï¼›&#010;&gt; &amp;gt; è¿™ä¸ªsavepointæˆ‘é€šè¿‡webui æäº¤ä»»åŠ¡å°±æ²¡é—®é¢˜ï¼Œä½ æ˜¯è¯´åœ¨IDEä¸Šè°ƒè¯•savepointå—&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; ------------------ åŸå§‹é‚®ä»¶ ------------------&#010;&gt; &amp;gt; å‘ä»¶äºº:&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&gt; \"user-zh\"&#010;&gt; &amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#010;&gt; &lt;&#010;&gt; &amp;gt; qcx978132955@gmail.com&amp;amp;gt;;&#010;&gt; &amp;gt; å‘é€æ—¶é—´:&amp;amp;nbsp;2020å¹´7æœˆ19æ—¥(æ˜ŸæœŸå¤©) æ™šä¸Š8:22&#010;&gt; &amp;gt; æ”¶ä»¶äºº:&amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;amp;gt;;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; ä¸»é¢˜:&amp;amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; Hi&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; ä»ä½ ç»™çš„è¿™éƒ¨åˆ†æ—¥å¿—çœ‹ï¼Œæ˜¯æ¢å¤çš„æ—¶å€™é‡åˆ° EOF äº†ï¼Œè¿™ä¸ªæ¯”è¾ƒå¥‡æ€ª&#010;&gt; &amp;gt; 1 ä½ ä¹‹å‰çš„ savepoint æ˜¯ä½¿ç”¨ RocksDBStateBackend ç”Ÿæˆçš„å—&#010;&gt; &amp;gt; 2 ä½ è¿˜æœ‰ä¹‹å‰åœ¨ DFS ä¸Šçš„ savepoint æ–‡ä»¶å—ï¼Ÿå¯èƒ½éœ€è¦ç»“åˆ DFS ä¸Šçš„æ–‡ä»¶ä¸€èµ·çœ‹ä¸€ä¸‹è¿™ä¸ªé—®é¢˜æ€ä¹ˆæ¥çš„&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; Best,&#010;&gt; &amp;gt; Congxian&#010;&gt; &amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; Z-Z &lt;zz9876543210@qq.com&amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ11:10å†™é“ï¼š&#010;&gt; &amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; Flink 1.10.0 ,taskmanageræŠ¥é”™æ—¥å¿—å¦‚ä¸‹ï¼š&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,913 ERROR&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; - Caught unexpected exception.&#010;&gt; &amp;gt; &amp;amp;gt; java.io.EOFException&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,914 WARN&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; -&#010;&gt; &amp;gt; &amp;amp;gt; Exception while restoring keyed state backend for&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#010;&gt; &amp;gt; &amp;amp;gt; alternative (1/1), will retry while more alternatives are&#010;&gt; available.&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.state.BackendBuildingException:&#010;&gt; Caught&#010;&gt; &amp;gt; unexpected&#010;&gt; &amp;gt; &amp;amp;gt; exception.&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; &amp;amp;gt; Caused by: java.io.EOFException&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; ... 15 more&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,915 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.kafka.clients.producer.KafkaProducer&amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; Closing the Kafka&#010;&gt; &amp;gt; producer with timeoutMillis&#010;&gt; &amp;gt; &amp;amp;gt; = 9223372036854775807 ms.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,918 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Co-Keyed-Process -&amp;amp;amp;gt; Flat Map&#010;&gt; &amp;gt; &amp;amp;gt; -&amp;amp;amp;gt; Sink: Unnamed (1/1)&#010;&gt; (bb8f0a84e07ef90b1e11ca2825e0efab)&#010;&gt; &amp;gt; switched from&#010;&gt; &amp;gt; &amp;amp;gt; RUNNING to FAILED.&#010;&gt; &amp;gt; &amp;amp;gt; java.lang.Exception: Exception while creating&#010;&gt; &amp;gt; StreamOperatorStateContext.&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; &amp;amp;gt; Caused by: org.apache.flink.util.FlinkException: Could not&#010;&gt; restore&#010;&gt; &amp;gt; keyed&#010;&gt; &amp;gt; &amp;amp;gt; state backend for&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; KeyedCoProcessOperator_00360b8021b192d84949201d4fea80f2_(1/1) from&#010;&gt; &amp;gt; any of&#010;&gt; &amp;gt; &amp;amp;gt; the 1 provided restore options.&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; ... 9 more&#010;&gt; &amp;gt; &amp;amp;gt; Caused by:&#010;&gt; org.apache.flink.runtime.state.BackendBuildingException:&#010;&gt; &amp;gt; Caught&#010;&gt; &amp;gt; &amp;amp;gt; unexpected exception.&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; ... 11 more&#010;&gt; &amp;gt; &amp;amp;gt; Caused by: java.io.EOFException&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; ... 15 more&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Freeing task resources for&#010;&gt; &amp;gt; &amp;amp;gt; Co-Keyed-Process -&amp;amp;amp;gt; Flat Map -&amp;amp;amp;gt; Sink:&#010;&gt; Unnamed (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (bb8f0a84e07ef90b1e11ca2825e0efab).&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,919 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Ensuring all FileSystem streams&#010;&gt; &amp;gt; &amp;amp;gt; are closed for task Co-Keyed-Process -&amp;amp;amp;gt; Flat Map&#010;&gt; -&amp;amp;amp;gt;&#010;&gt; &amp;gt; Sink: Unnamed&#010;&gt; &amp;gt; &amp;amp;gt; (1/1) (bb8f0a84e07ef90b1e11ca2825e0efab) [FAILED]&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,931 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; -&#010;&gt; Un-registering task and sending&#010;&gt; &amp;gt; final execution&#010;&gt; &amp;gt; &amp;amp;gt; state FAILED to JobManager for task Co-Keyed-Process&#010;&gt; -&amp;amp;amp;gt; Flat&#010;&gt; &amp;gt; Map -&amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; Sink: Unnamed (1/1) bb8f0a84e07ef90b1e11ca2825e0efab.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Attempting to cancel task&#010;&gt; &amp;gt; &amp;amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat Map (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat&#010;&gt; &amp;gt; &amp;amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from&#010;&gt; RUNNING to&#010;&gt; &amp;gt; &amp;amp;gt; CANCELING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,947 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Triggering cancellation of task&#010;&gt; &amp;gt; &amp;amp;gt; code Source: Custom Source -&amp;amp;amp;gt; Flat Map (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Attempting to cancel task&#010;&gt; &amp;gt; &amp;amp;gt; Source: Custom Source (1/1)&#010;&gt; (00621ff5d788d00c73ccaaea04717600).&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Source: Custom Source (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from RUNNING to&#010;&gt; CANCELING.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,949 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Triggering cancellation of task&#010;&gt; &amp;gt; &amp;amp;gt; code Source: Custom Source (1/1)&#010;&gt; (00621ff5d788d00c73ccaaea04717600).&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat&#010;&gt; &amp;gt; &amp;amp;gt; Map (1/1) (9cb8dcd4982223adcb6f007f1ffccdce) switched from&#010;&gt; CANCELING&#010;&gt; &amp;gt; to&#010;&gt; &amp;gt; &amp;amp;gt; CANCELED.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Freeing task resources for&#010;&gt; &amp;gt; &amp;amp;gt; Source: Custom Source -&amp;amp;amp;gt; Flat Map (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce).&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Ensuring all FileSystem streams&#010;&gt; &amp;gt; &amp;amp;gt; are closed for task Source: Custom Source -&amp;amp;amp;gt; Flat&#010;&gt; Map (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (9cb8dcd4982223adcb6f007f1ffccdce) [CANCELED]&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Source: Custom Source (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (00621ff5d788d00c73ccaaea04717600) switched from CANCELING to&#010;&gt; &amp;gt; CANCELED.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,955 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Freeing task resources for&#010;&gt; &amp;gt; &amp;amp;gt; Source: Custom Source (1/1)&#010;&gt; (00621ff5d788d00c73ccaaea04717600).&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,954 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; -&#010;&gt; Un-registering task and sending&#010;&gt; &amp;gt; final execution&#010;&gt; &amp;gt; &amp;amp;gt; state CANCELED to JobManager for task Source: Custom Source&#010;&gt; -&amp;amp;amp;gt;&#010;&gt; &amp;gt; Flat Map&#010;&gt; &amp;gt; &amp;amp;gt; (1/1) 9cb8dcd4982223adcb6f007f1ffccdce.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Ensuring all FileSystem streams&#010;&gt; &amp;gt; &amp;amp;gt; are closed for task Source: Custom Source (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (00621ff5d788d00c73ccaaea04717600) [CANCELED]&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:43,962 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.taskexecutor.TaskExecutor&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; -&#010;&gt; Un-registering task and sending&#010;&gt; &amp;gt; final execution&#010;&gt; &amp;gt; &amp;amp;gt; state CANCELED to JobManager for task Source: Custom Source&#010;&gt; (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; 00621ff5d788d00c73ccaaea04717600.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - The&#010;&gt; configuration '&#010;&gt; &amp;gt; transaction.timeout.ms' was&#010;&gt; &amp;gt; &amp;amp;gt; supplied but isn't a known config.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - The&#010;&gt; configuration 'key.serializer'&#010;&gt; &amp;gt; was supplied but&#010;&gt; &amp;gt; &amp;amp;gt; isn't a known config.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.ConsumerConfig&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; - The&#010;&gt; configuration&#010;&gt; &amp;gt; 'value.serializer' was supplied&#010;&gt; &amp;gt; &amp;amp;gt; but isn't a known config.&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Kafka version : 0.11.0.2&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Kafka commitId : 73be1e1168f91ee2&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,077 WARN&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Error registering AppInfo mbean&#010;&gt; &amp;gt; &amp;amp;gt; javax.management.InstanceAlreadyExistsException:&#010;&gt; &amp;gt; &amp;amp;gt; kafka.consumer:type=app-info,id=consumer-3&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:757)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:633)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:615)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Kafka version : 0.11.0.2&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,079 INFO&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Kafka commitId : 73be1e1168f91ee2&#010;&gt; &amp;gt; &amp;amp;gt; 2020-07-17 15:06:44,079 WARN&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.kafka.common.utils.AppInfoParser&amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;&#010;&gt; &amp;amp;amp;nbsp; &amp;amp;amp;nbsp;-&#010;&gt; &amp;gt; Error registering AppInfo mbean&#010;&gt; &amp;gt; &amp;amp;gt; javax.management.InstanceAlreadyExistsException:&#010;&gt; &amp;gt; &amp;amp;gt; kafka.consumer:type=app-info,id=consumer-4&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:58)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:757)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:633)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.kafka.clients.consumer.KafkaConsumer.&lt;init&amp;amp;amp;gt;(KafkaConsumer.java:615)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.getConsumer(KafkaConsumerThread.java:502)&#010;&gt; &amp;gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;amp;nbsp; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.run(KafkaConsumerThread.java:181)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; ------------------&amp;amp;amp;nbsp;åŸå§‹é‚®ä»¶&amp;amp;amp;nbsp;------------------&#010;&gt; &amp;gt; &amp;amp;gt; å‘ä»¶äºº:&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; \"user-zh\"&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;gt;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;nbsp; &lt;&#010;&gt; &amp;gt; &amp;amp;gt; qcx978132955@gmail.com&amp;amp;amp;gt;;&#010;&gt; &amp;gt; &amp;amp;gt; å‘é€æ—¶é—´:&amp;amp;amp;nbsp;2020å¹´7æœˆ17æ—¥(æ˜ŸæœŸäº”) æ™šä¸Š10:52&#010;&gt; &amp;gt; &amp;amp;gt; æ”¶ä»¶äºº:&amp;amp;amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&#010;&gt; &amp;amp;amp;gt;;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; ä¸»é¢˜:&amp;amp;amp;nbsp;Re: Flink Cli éƒ¨ç½²é—®é¢˜&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; Hi&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; è¯·é—®ä½ ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬çš„ Flink å‘¢ï¼Ÿèƒ½å¦åˆ†äº«ä¸€ä¸‹&amp;amp;amp;nbsp; Co-Process (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (d0309f26a545e74643382ed3f758269b) è¿™ä¸ª tm çš„ log&#010;&gt; å‘¢ï¼Ÿä»ä¸Šé¢ç»™çš„æ—¥å¿—çœ‹ï¼Œåº”è¯¥æ˜¯åœ¨&#010;&gt; &amp;gt; 083f69d029de&#010;&gt; &amp;gt; &amp;amp;gt; è¿™å°æœºå™¨ä¸Šã€‚&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; Best,&#010;&gt; &amp;gt; &amp;amp;gt; Congxian&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; Z-Z &lt;zz9876543210@qq.com&amp;amp;amp;gt; äº2020å¹´7æœˆ17æ—¥å‘¨äº” ä¸‹åˆ6:22å†™é“ï¼š&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; å¤§å®¶å¥½ï¼Œæˆ‘åœ¨éƒ¨ç½²çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘é€šè¿‡restAPIæ¥å£åœæ‰äº†ä¸€ä¸ªä»»åŠ¡å¹¶ä¿å­˜äº†å®ƒçš„savepoint(æ­¥éª¤ï¼š/jobs/overview&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; ---&amp;amp;amp;amp;gt; /jobs/{jobid}/savepoints&#010;&gt; ---&amp;amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; /jobs/{jobid}/savepoints/{triggerid})ï¼Œä½†æˆ‘é€šè¿‡flinkå‘½ä»¤å¸¦ä¸Šsavepointéƒ¨ç½²ä»»åŠ¡æ—¶ä¼šæŠ¥é”™ï¼Œä½†é€šè¿‡webuiä¸Šä¼ jarå¹¶å¸¦ä¸Šsavepointå°±ä¸ä¼šæŠ¥é”™ï¼ŒæŠ¥é”™å †æ ˆå¦‚ä¸‹ï¼š&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,925 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.resourcemanager.StandaloneResourceManager&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; -&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Request slot with profile&#010;&gt; ResourceProfile{UNKNOWN} for job&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 7639673873b707aa86c4387aa7b4aac3 with&#010;&gt; allocation id&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e8865cdbfe4c3c33099c7112bc2e3231.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source&#010;&gt; -&amp;amp;amp;amp;gt; Filter&#010;&gt; &amp;gt; (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched&#010;&gt; from SCHEDULED to&#010;&gt; &amp;gt; &amp;amp;gt; DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,952 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Source: Custom&#010;&gt; Source&#010;&gt; &amp;gt; -&amp;amp;amp;amp;gt; Filter (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; &amp;gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,953 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Source: Custom&#010;&gt; Source (1/1)&#010;&gt; &amp;gt; (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; &amp;gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Source: Custom&#010;&gt; Source (1/1)&#010;&gt; &amp;gt; (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; &amp;gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process (1/1)&#010;&gt; &amp;gt; (d0309f26a545e74643382ed3f758269b)&#010;&gt; &amp;gt; &amp;amp;gt; switched from&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; SCHEDULED to DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,954 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Co-Process (1/1)&#010;&gt; (attempt #0) to&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; e63d829deafc144cd82efd73979dd056 @ 083f69d029de&#010;&gt; &amp;gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process&#010;&gt; -&amp;amp;amp;amp;gt; (Sink: Unnamed,&#010;&gt; &amp;gt; Sink: Unnamed) (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched&#010;&gt; from SCHEDULED to&#010;&gt; &amp;gt; &amp;amp;gt; DEPLOYING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:48,955 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Deploying Co-Process&#010;&gt; -&amp;amp;amp;amp;gt; (Sink:&#010;&gt; &amp;gt; Unnamed, Sink:&#010;&gt; &amp;gt; &amp;amp;gt; Unnamed) (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (attempt #0) to&#010;&gt; e63d829deafc144cd82efd73979dd056 @&#010;&gt; &amp;gt; 083f69d029de&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (dataPort=35758)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,346 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process&#010;&gt; -&amp;amp;amp;amp;gt; (Sink: Unnamed,&#010;&gt; &amp;gt; Sink: Unnamed) (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (618b75fcf5ea05fb5c6487bec6426e31) switched&#010;&gt; from DEPLOYING&#010;&gt; &amp;gt; to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (274b3df03e1fab627059c1a78e4a26da)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,370 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; (141f0dc22b624b39e21127f637ba63c2)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; switched from DEPLOYING to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process (1/1)&#010;&gt; &amp;gt; (d0309f26a545e74643382ed3f758269b)&#010;&gt; &amp;gt; &amp;amp;gt; switched from&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; DEPLOYING to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,377 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Source: Custom Source&#010;&gt; -&amp;amp;amp;amp;gt; Filter&#010;&gt; &amp;gt; (1/1)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; (1177659bff014e8dbc3f0508055d4307) switched&#010;&gt; from DEPLOYING&#010;&gt; &amp;gt; to RUNNING.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; 2020-07-17 09:51:49,493 INFO&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.runtime.executiongraph.ExecutionGraph&amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;amp;nbsp; &amp;amp;amp;amp;nbsp;&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; &amp;amp;amp;amp;nbsp; - Co-Process (1/1)&#010;&gt; &amp;gt; (d0309f26a545e74643382ed3f758269b)&#010;&gt; &amp;gt; &amp;amp;gt; switched from&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; RUNNING to FAILED.&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; java.lang.Exception: Exception while creating&#010;&gt; &amp;gt; &amp;amp;gt; StreamOperatorStateContext.&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:191)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:255)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.initializeStateAndOpen(StreamTask.java:1006)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$0(StreamTask.java:454)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:94)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:449)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:461)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:707)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; org.apache.flink.runtime.taskmanager.Task.run(Task.java:532)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; java.lang.Thread.run(Thread.java:748)&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Caused by:&#010;&gt; org.apache.flink.util.FlinkException: Could not&#010;&gt; &amp;gt; restore&#010;&gt; &amp;gt; &amp;amp;gt; keyed&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; state backend for&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; LegacyKeyedCoProcessOperator_65e7116c7aa972ad18a796ae22bd6327_(1/1)&#010;&gt; &amp;gt; &amp;amp;gt; from&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; any of the 1 provided restore options.&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:304)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:131)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; ... 9 more&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Caused by:&#010;&gt; &amp;gt; org.apache.flink.runtime.state.BackendBuildingException:&#010;&gt; &amp;gt; &amp;amp;gt; Caught&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; unexpected exception.&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:336)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:548)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:288)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; ... 11 more&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt; Caused by: java.io.EOFException&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:197)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; java.io.DataInputStream.readFully(DataInputStream.java:169)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.deserialize(BytePrimitiveArraySerializer.java:85)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKVStateData(RocksDBFullRestoreOperation.java:221)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restoreKeyGroupsInStateHandle(RocksDBFullRestoreOperation.java:168)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.restore.RocksDBFullRestoreOperation.restore(RocksDBFullRestoreOperation.java:151)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; at&#010;&gt; &amp;gt; &amp;amp;gt; &amp;amp;amp;gt;&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackendBuilder.build(RocksDBKeyedStateBackendBuilder.java:279)&#010;&gt; &amp;gt; &amp;amp;gt;&#010;&gt; &amp;gt;&#010;&gt; &amp;amp;amp;gt;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&amp;amp;amp;nbsp;&#010;&gt; &amp;gt; ... 15 more&#010;&#010;",
        "depth": "3",
        "reply": "<tencent_010040FBFE3A4FFBCBAC43AACB4528F26C09@qq.com>"
    },
    {
        "id": "<AD8A1463-9AD3-4862-9F04-FBBAEEC91F30@gmail.com>",
        "from": "snack white &lt;amazingu...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 07:14:19 GMT",
        "subject": "flink job è·‘ä¸€æ®µæ—¶é—´ watermark ä¸æ¨è¿›çš„é—®é¢˜",
        "content": "HI: &#013;&#010;      flink job è·‘ä¸€æ®µæ—¶é—´ watermark ä¸æ¨è¿›ï¼Œä»»åŠ¡æ²¡æŒ‚ï¼Œsource æ˜¯ kafka ï¼Œkafka&#010;å„ä¸ªpartition å‡æœ‰æ•°æ®ï¼Œ flink job statue backend ä¸º memory ã€‚æœ‰debug çš„å§¿åŠ¿æ¨èå—ï¼Ÿ&#010; çœ‹è¿‡ CPU GC ç­‰æŒ‡æ ‡ï¼Œçœ‹ä¸å‡ºæ¥æœ‰å¼‚å¸¸ã€‚ &#013;&#010;&#013;&#010;Best regards!&#013;&#010;white&#013;&#010;&#013;&#010;",
        "depth": "0",
        "reply": "<AD8A1463-9AD3-4862-9F04-FBBAEEC91F30@gmail.com>"
    },
    {
        "id": "<tencent_407D08B93E72B481CB223AE62D6C50DA3508@qq.com>",
        "from": "&quot;Cayden chen&quot; &lt;1193216...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 08:00:02 GMT",
        "subject": "å›å¤ï¼šflink job è·‘ä¸€æ®µæ—¶é—´ watermark ä¸æ¨è¿›çš„é—®é¢˜",
        "content": "å¯ä»¥åœ¨æœ¬åœ°ideaèµ·localæ¨¡å¼æ‰“æ–­ç‚¹è°ƒè¯•&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;amazinguizz@gmail.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ20æ—¥(æ˜ŸæœŸä¸€) ä¸‹åˆ3:14&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;flink job è·‘ä¸€æ®µæ—¶é—´ watermark ä¸æ¨è¿›çš„é—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;HI: &#013;&#010;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; flink job è·‘ä¸€æ®µæ—¶é—´ watermark ä¸æ¨è¿›ï¼Œä»»åŠ¡æ²¡æŒ‚ï¼Œsource&#010;æ˜¯ kafka ï¼Œkafka å„ä¸ªpartition å‡æœ‰æ•°æ®ï¼Œ flink job statue backend ä¸º memory ã€‚æœ‰debug&#010;çš„å§¿åŠ¿æ¨èå—ï¼Ÿ&amp;nbsp; çœ‹è¿‡ CPU GC ç­‰æŒ‡æ ‡ï¼Œçœ‹ä¸å‡ºæ¥æœ‰å¼‚å¸¸ã€‚ &#013;&#010;&#013;&#010;Best regards!&#013;&#010;white",
        "depth": "1",
        "reply": "<AD8A1463-9AD3-4862-9F04-FBBAEEC91F30@gmail.com>"
    },
    {
        "id": "<CAOMLN=aKakLNua6V1xBxiScxvi127qKRiuOcBVjhPkf8zJVrjQ@mail.gmail.com>",
        "from": "shizk233 &lt;wangwangdaxian...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 08:23:47 GMT",
        "subject": "Re: flink job è·‘ä¸€æ®µæ—¶é—´ watermark ä¸æ¨è¿›çš„é—®é¢˜",
        "content": "Hi,&#013;&#010;&#013;&#010;Flink&#013;&#010;metricsé‡Œæœ‰ä¸€é¡¹æ˜¯taskç›¸å…³çš„æŒ‡æ ‡currentWatermarkï¼Œä»ä¸­å¯ä»¥çŸ¥é“subtask_index,task_name,watermarkä¸‰é¡¹ä¿¡æ¯ï¼Œåº”è¯¥èƒ½å¸®åŠ©æ’æŸ¥watermarkçš„æ¨è¿›æƒ…å†µã€‚&#013;&#010;&#013;&#010;Best,&#013;&#010;shizk233&#013;&#010;&#013;&#010;snack white &lt;amazinguizz@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ3:51å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; HI:&#013;&#010;&gt;       flink job è·‘ä¸€æ®µæ—¶é—´ watermark ä¸æ¨è¿›ï¼Œä»»åŠ¡æ²¡æŒ‚ï¼Œsource æ˜¯ kafka&#010;ï¼Œkafka å„ä¸ªpartition&#013;&#010;&gt; å‡æœ‰æ•°æ®ï¼Œ flink job statue backend ä¸º memory ã€‚æœ‰debug çš„å§¿åŠ¿æ¨èå—ï¼Ÿ&#010; çœ‹è¿‡ CPU GC&#013;&#010;&gt; ç­‰æŒ‡æ ‡ï¼Œçœ‹ä¸å‡ºæ¥æœ‰å¼‚å¸¸ã€‚&#013;&#010;&gt;&#013;&#010;&gt; Best regards!&#013;&#010;&gt; white&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "1",
        "reply": "<AD8A1463-9AD3-4862-9F04-FBBAEEC91F30@gmail.com>"
    },
    {
        "id": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 07:36:11 GMT",
        "subject": "flink1.11å¯åŠ¨é—®é¢˜",
        "content": "&#010;&#010;Flink1.11å¯åŠ¨æ—¶æŠ¥é”™ï¼š&#010;java.lang.LinkageError: ClassCastException: attempting to castjar:file:/data/rt/jar_version/sql/6.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;to jar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;        at javax.ws.rs.ext.RuntimeDelegate.findDelegate(RuntimeDelegate.java:125)&#010;        at javax.ws.rs.ext.RuntimeDelegate.getInstance(RuntimeDelegate.java:97)&#010;        at javax.ws.rs.core.MediaType.valueOf(MediaType.java:172)&#010;        at com.sun.jersey.core.header.MediaTypes.&lt;clinit&gt;(MediaTypes.java:65)&#010;        at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:182)&#010;        at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:175)&#010;        at com.sun.jersey.core.spi.factory.MessageBodyFactory.init(MessageBodyFactory.java:162)&#010;        at com.sun.jersey.api.client.Client.init(Client.java:342)&#010;        at com.sun.jersey.api.client.Client.access$000(Client.java:118)&#010;        at com.sun.jersey.api.client.Client$1.f(Client.java:191)&#010;        at com.sun.jersey.api.client.Client$1.f(Client.java:187)&#010;        at com.sun.jersey.spi.inject.Errors.processWithErrors(Errors.java:193)&#010;        at com.sun.jersey.api.client.Client.&lt;init&gt;(Client.java:187)&#010;        at com.sun.jersey.api.client.Client.&lt;init&gt;(Client.java:170)&#010;        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit(TimelineClientImpl.java:280)&#010;        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#010;        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:169)&#010;        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#010;        at org.apache.flink.yarn.YarnClusterClientFactory.getClusterDescriptor(YarnClusterClientFactory.java:76)&#010;        at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:61)&#010;        at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:43)&#010;        at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:64)&#010;        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1812)&#010;        at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128)&#010;        at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76)&#010;        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1699)&#010;        at com.missfresh.Main.main(Main.java:142)&#010;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;        at java.lang.reflect.Method.invoke(Method.java:498)&#010;        at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;        at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;        at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;        at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;        at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;        at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;        at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;        at java.security.AccessController.doPrivileged(Native Method)&#010;        at javax.security.auth.Subject.doAs(Subject.java:422)&#010;        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)&#010;        at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;        at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&#010;&#010;æˆ‘å·²ç»åœ¨libä¸‹æ·»åŠ äº†javax.ws.rs-api-2.1.1.jar&#010;&#010;",
        "depth": "1",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<E993FE2D-F2C7-4C0C-B768-67F4C8876565@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 12:06:40 GMT",
        "subject": "Re: flink1.11å¯åŠ¨é—®é¢˜",
        "content": "Hi,&#010;çœ‹èµ·æ¥åƒæ˜¯ä¾èµ–å†²çªé—®é¢˜ï¼ŒæŠ¥é”™ä¿¡æ¯çœ‹èµ·æ¥æ˜¯classpathåŠ è½½åˆ°äº†ä¸¤ä¸ªç›¸åŒçš„jar,&#010;javax.ws.rs-api-2.1.1.jar è¿™ä¸ªjaråŒ…æ˜¯ä½ é›†ç¾¤éœ€è¦çš„å—ï¼Ÿ&#010;å¯ä»¥æŠŠä½ åœºæ™¯è¯´ç»†ç‚¹ï¼Œæ¯”å¦‚è¿™ä¸ªé—®é¢˜å¦‚ä½•å¤ç°ï¼Œè¿™æ ·å¤§å®¶å¯ä»¥å¸®å¿™ä¸€èµ·æ’æŸ¥&#010;&#010;ç¥å¥½ï¼Œ&#010;Leonard Xu&#010;&#010;&gt; åœ¨ 2020å¹´7æœˆ20æ—¥ï¼Œ15:36ï¼Œé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; å†™é“ï¼š&#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; Flink1.11å¯åŠ¨æ—¶æŠ¥é”™ï¼š&#010;&gt; java.lang.LinkageError: ClassCastException: attempting to castjar:file:/data/rt/jar_version/sql/6.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;to jar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;&gt;        at javax.ws.rs.ext.RuntimeDelegate.findDelegate(RuntimeDelegate.java:125)&#010;&gt;        at javax.ws.rs.ext.RuntimeDelegate.getInstance(RuntimeDelegate.java:97)&#010;&gt;        at javax.ws.rs.core.MediaType.valueOf(MediaType.java:172)&#010;&gt;        at com.sun.jersey.core.header.MediaTypes.&lt;clinit&gt;(MediaTypes.java:65)&#010;&gt;        at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:182)&#010;&gt;        at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:175)&#010;&gt;        at com.sun.jersey.core.spi.factory.MessageBodyFactory.init(MessageBodyFactory.java:162)&#010;&gt;        at com.sun.jersey.api.client.Client.init(Client.java:342)&#010;&gt;        at com.sun.jersey.api.client.Client.access$000(Client.java:118)&#010;&gt;        at com.sun.jersey.api.client.Client$1.f(Client.java:191)&#010;&gt;        at com.sun.jersey.api.client.Client$1.f(Client.java:187)&#010;&gt;        at com.sun.jersey.spi.inject.Errors.processWithErrors(Errors.java:193)&#010;&gt;        at com.sun.jersey.api.client.Client.&lt;init&gt;(Client.java:187)&#010;&gt;        at com.sun.jersey.api.client.Client.&lt;init&gt;(Client.java:170)&#010;&gt;        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit(TimelineClientImpl.java:280)&#010;&gt;        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#010;&gt;        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:169)&#010;&gt;        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#010;&gt;        at org.apache.flink.yarn.YarnClusterClientFactory.getClusterDescriptor(YarnClusterClientFactory.java:76)&#010;&gt;        at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:61)&#010;&gt;        at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:43)&#010;&gt;        at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:64)&#010;&gt;        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1812)&#010;&gt;        at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128)&#010;&gt;        at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76)&#010;&gt;        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1699)&#010;&gt;        at com.missfresh.Main.main(Main.java:142)&#010;&gt;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt;        at java.lang.reflect.Method.invoke(Method.java:498)&#010;&gt;        at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;&gt;        at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;&gt;        at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;&gt;        at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;&gt;        at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;&gt;        at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;&gt;        at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;&gt;        at java.security.AccessController.doPrivileged(Native Method)&#010;&gt;        at javax.security.auth.Subject.doAs(Subject.java:422)&#010;&gt;        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)&#010;&gt;        at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;&gt;        at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&gt; &#010;&gt; &#010;&gt; æˆ‘å·²ç»åœ¨libä¸‹æ·»åŠ äº†javax.ws.rs-api-2.1.1.jar&#010;&gt; &#010;&#010;&#010;",
        "depth": "2",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<7ad26bcf.6383.1736c268cc4.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 12:15:32 GMT",
        "subject": "å›å¤ï¼š flink1.11å¯åŠ¨é—®é¢˜",
        "content": "1. flink1.11è§£å‹åï¼Œå¯åŠ¨ä¼šæŠ¥ï¼š&#010;java.lang.NoClassDefFoundError: com/sun/jersey/core/util/FeaturesAndProperties&#010;ç„¶åå°†jersey-client-1.9.jarã€jersey-core-1.9.jarå¤åˆ¶åˆ°libä¸‹&#010;2. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥é”™ï¼š&#010;Caused by: java.lang.ClassNotFoundException: javax.ws.rs.ext.MessageBodyReader&#010;ç„¶åå°†javax.ws.rs-api-2.1.1.jarå¤åˆ¶åˆ°libä¸‹&#010;3. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥é”™ï¼š&#010;Caused by: java.lang.ClassNotFoundException: org.glassfish.jersey.internal.RuntimeDelegateImpl&#010;å°†jersey-common-3.0.0-M6.jarå¤åˆ¶åˆ°libä¸‹&#010;4. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥é”™ï¼š&#010;Caused by: java.lang.ClassNotFoundException: jakarta.ws.rs.ext.RuntimeDelegate&#010;å°†jakarta.ws.rs-api-3.0.0-M1.jarå¤åˆ¶åˆ°libä¸‹&#010;5. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥ï¼š&#010;java.lang.LinkageError: ClassCastException: attempting to castjar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;to jar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;6. æˆ‘å´©æºƒäº†&#010;&#010;&#010;&#010;&#010;åœ¨2020å¹´07æœˆ20æ—¥ 20:06ï¼ŒLeonard Xu&lt;xbjtdcq@gmail.com&gt; å†™é“ï¼š&#010;Hi,&#010;çœ‹èµ·æ¥åƒæ˜¯ä¾èµ–å†²çªé—®é¢˜ï¼ŒæŠ¥é”™ä¿¡æ¯çœ‹èµ·æ¥æ˜¯classpathåŠ è½½åˆ°äº†ä¸¤ä¸ªç›¸åŒçš„jar,&#010;javax.ws.rs-api-2.1.1.jar è¿™ä¸ªjaråŒ…æ˜¯ä½ é›†ç¾¤éœ€è¦çš„å—ï¼Ÿ&#010;å¯ä»¥æŠŠä½ åœºæ™¯è¯´ç»†ç‚¹ï¼Œæ¯”å¦‚è¿™ä¸ªé—®é¢˜å¦‚ä½•å¤ç°ï¼Œè¿™æ ·å¤§å®¶å¯ä»¥å¸®å¿™ä¸€èµ·æ’æŸ¥&#010;&#010;ç¥å¥½ï¼Œ&#010;Leonard Xu&#010;&#010;åœ¨ 2020å¹´7æœˆ20æ—¥ï¼Œ15:36ï¼Œé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; å†™é“ï¼š&#010;&#010;&#010;&#010;Flink1.11å¯åŠ¨æ—¶æŠ¥é”™ï¼š&#010;java.lang.LinkageError: ClassCastException: attempting to castjar:file:/data/rt/jar_version/sql/6.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;to jar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;at javax.ws.rs.ext.RuntimeDelegate.findDelegate(RuntimeDelegate.java:125)&#010;at javax.ws.rs.ext.RuntimeDelegate.getInstance(RuntimeDelegate.java:97)&#010;at javax.ws.rs.core.MediaType.valueOf(MediaType.java:172)&#010;at com.sun.jersey.core.header.MediaTypes.&lt;clinit&gt;(MediaTypes.java:65)&#010;at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:182)&#010;at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:175)&#010;at com.sun.jersey.core.spi.factory.MessageBodyFactory.init(MessageBodyFactory.java:162)&#010;at com.sun.jersey.api.client.Client.init(Client.java:342)&#010;at com.sun.jersey.api.client.Client.access$000(Client.java:118)&#010;at com.sun.jersey.api.client.Client$1.f(Client.java:191)&#010;at com.sun.jersey.api.client.Client$1.f(Client.java:187)&#010;at com.sun.jersey.spi.inject.Errors.processWithErrors(Errors.java:193)&#010;at com.sun.jersey.api.client.Client.&lt;init&gt;(Client.java:187)&#010;at com.sun.jersey.api.client.Client.&lt;init&gt;(Client.java:170)&#010;at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit(TimelineClientImpl.java:280)&#010;at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#010;at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:169)&#010;at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#010;at org.apache.flink.yarn.YarnClusterClientFactory.getClusterDescriptor(YarnClusterClientFactory.java:76)&#010;at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:61)&#010;at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:43)&#010;at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:64)&#010;at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1812)&#010;at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128)&#010;at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76)&#010;at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1699)&#010;at com.missfresh.Main.main(Main.java:142)&#010;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;at java.lang.reflect.Method.invoke(Method.java:498)&#010;at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;at java.security.AccessController.doPrivileged(Native Method)&#010;at javax.security.auth.Subject.doAs(Subject.java:422)&#010;at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)&#010;at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&#010;&#010;æˆ‘å·²ç»åœ¨libä¸‹æ·»åŠ äº†javax.ws.rs-api-2.1.1.jar&#010;&#010;",
        "depth": "3",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<C007AAC6-665A-487B-9BF3-D6726E1E699E@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 13:11:01 GMT",
        "subject": "Re: flink1.11å¯åŠ¨é—®é¢˜",
        "content": "Hiï¼Œ&#010;&#010;&gt; åœ¨ 2020å¹´7æœˆ20æ—¥ï¼Œ20:15ï¼Œé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; å†™é“ï¼š&#010;&gt; &#010;&gt; 1. flink1.11è§£å‹åï¼Œå¯åŠ¨ä¼šæŠ¥ï¼š&#010;&gt; java.lang.NoClassDefFoundError: com/sun/jersey/core/util/FeaturesAndProperties&#010;&#010;ç¬¬ä¸€æ­¥å°±æŠ¥é”™ï¼Œåº”è¯¥æ˜¯ä½ æœ¬åœ°ç¯å¢ƒé—®é¢˜ï¼Œåé¢åŠ çš„åŒ…åº”è¯¥éƒ½æ˜¯ä¸éœ€è¦çš„ï¼Œä½ æœ¬åœ°ç”¨çš„JDKç‰ˆæœ¬æ˜¯å¤šå°‘å‘€ï¼Ÿ&#010;&#010;ç¥å¥½&#010;Leonard Xu&#010;",
        "depth": "4",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<tencent_EDAC4F2C5D32E5521E4EFD2A7BA71FEB5D09@qq.com>",
        "from": "&quot;Evan&quot; &lt;chengyanan1...@foxmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 01:43:16 GMT",
        "subject": "å›å¤ï¼š flink1.11å¯åŠ¨é—®é¢˜",
        "content": "Hi,ä½ è¿™ä¸ªåº”è¯¥å°±æ˜¯ä¾èµ–çš„é—®é¢˜ï¼Œä½ é¢å¤–æ·»åŠ äº†jaråŒ…ï¼Œç¬¬1æ­¥åˆ°ç¬¬4æ­¥ï¼Œçœ‹èµ·æ¥æ˜¯ç¼ºå°‘äº†ä»€ä¹ˆä¾èµ–ï¼Œåˆ°ç¬¬5æ­¥çœ‹èµ·æ¥æ˜¯ä¾èµ–å†²çªäº†ï¼Œè¿™è¾¹å»ºè®®ä½ ä»é¢å¤–æ·»åŠ çš„è¿™ä¸ªjaråŒ…ç€æ‰‹æŸ¥èµ·ã€‚&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;------------------&amp;nbsp;åŸå§‹é‚®ä»¶&amp;nbsp;------------------&#013;&#010;å‘ä»¶äºº:                                                                               &#010;                                        \"user-zh\"                                        &#010;                                           &lt;apache22@163.com&amp;gt;;&#013;&#010;å‘é€æ—¶é—´:&amp;nbsp;2020å¹´7æœˆ20æ—¥(æ˜ŸæœŸä¸€) æ™šä¸Š8:15&#013;&#010;æ”¶ä»¶äºº:&amp;nbsp;\"user-zh@flink.apache.org\"&lt;user-zh@flink.apache.org&amp;gt;;&#013;&#010;&#013;&#010;ä¸»é¢˜:&amp;nbsp;å›å¤ï¼š flink1.11å¯åŠ¨é—®é¢˜&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;1. flink1.11è§£å‹åï¼Œå¯åŠ¨ä¼šæŠ¥ï¼š&#013;&#010;java.lang.NoClassDefFoundError: com/sun/jersey/core/util/FeaturesAndProperties&#013;&#010;ç„¶åå°†jersey-client-1.9.jarã€jersey-core-1.9.jarå¤åˆ¶åˆ°libä¸‹&#013;&#010;2. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥é”™ï¼š&#013;&#010;Caused by: java.lang.ClassNotFoundException: javax.ws.rs.ext.MessageBodyReader&#013;&#010;ç„¶åå°†javax.ws.rs-api-2.1.1.jarå¤åˆ¶åˆ°libä¸‹&#013;&#010;3. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥é”™ï¼š&#013;&#010;Caused by: java.lang.ClassNotFoundException: org.glassfish.jersey.internal.RuntimeDelegateImpl&#013;&#010;å°†jersey-common-3.0.0-M6.jarå¤åˆ¶åˆ°libä¸‹&#013;&#010;4. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥é”™ï¼š&#013;&#010;Caused by: java.lang.ClassNotFoundException: jakarta.ws.rs.ext.RuntimeDelegate&#013;&#010;å°†jakarta.ws.rs-api-3.0.0-M1.jarå¤åˆ¶åˆ°libä¸‹&#013;&#010;5. å†æ¬¡å¯åŠ¨ï¼ŒæŠ¥ï¼š&#013;&#010;java.lang.LinkageError: ClassCastException: attempting to castjar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;to jar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#013;&#010;6. æˆ‘å´©æºƒäº†&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;åœ¨2020å¹´07æœˆ20æ—¥ 20:06ï¼ŒLeonard Xu&lt;xbjtdcq@gmail.com&amp;gt; å†™é“ï¼š&#013;&#010;Hi,&#013;&#010;çœ‹èµ·æ¥åƒæ˜¯ä¾èµ–å†²çªé—®é¢˜ï¼ŒæŠ¥é”™ä¿¡æ¯çœ‹èµ·æ¥æ˜¯classpathåŠ è½½åˆ°äº†ä¸¤ä¸ªç›¸åŒçš„jar,&#010;javax.ws.rs-api-2.1.1.jar è¿™ä¸ªjaråŒ…æ˜¯ä½ é›†ç¾¤éœ€è¦çš„å—ï¼Ÿ&#013;&#010;å¯ä»¥æŠŠä½ åœºæ™¯è¯´ç»†ç‚¹ï¼Œæ¯”å¦‚è¿™ä¸ªé—®é¢˜å¦‚ä½•å¤ç°ï¼Œè¿™æ ·å¤§å®¶å¯ä»¥å¸®å¿™ä¸€èµ·æ’æŸ¥&#013;&#010;&#013;&#010;ç¥å¥½ï¼Œ&#013;&#010;Leonard Xu&#013;&#010;&#013;&#010;åœ¨ 2020å¹´7æœˆ20æ—¥ï¼Œ15:36ï¼Œé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&amp;gt; å†™é“ï¼š&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;Flink1.11å¯åŠ¨æ—¶æŠ¥é”™ï¼š&#013;&#010;java.lang.LinkageError: ClassCastException: attempting to castjar:file:/data/rt/jar_version/sql/6.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;to jar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#013;&#010;at javax.ws.rs.ext.RuntimeDelegate.findDelegate(RuntimeDelegate.java:125)&#013;&#010;at javax.ws.rs.ext.RuntimeDelegate.getInstance(RuntimeDelegate.java:97)&#013;&#010;at javax.ws.rs.core.MediaType.valueOf(MediaType.java:172)&#013;&#010;at com.sun.jersey.core.header.MediaTypes.&lt;clinit&amp;gt;(MediaTypes.java:65)&#013;&#010;at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:182)&#013;&#010;at com.sun.jersey.core.spi.factory.MessageBodyFactory.initReaders(MessageBodyFactory.java:175)&#013;&#010;at com.sun.jersey.core.spi.factory.MessageBodyFactory.init(MessageBodyFactory.java:162)&#013;&#010;at com.sun.jersey.api.client.Client.init(Client.java:342)&#013;&#010;at com.sun.jersey.api.client.Client.access$000(Client.java:118)&#013;&#010;at com.sun.jersey.api.client.Client$1.f(Client.java:191)&#013;&#010;at com.sun.jersey.api.client.Client$1.f(Client.java:187)&#013;&#010;at com.sun.jersey.spi.inject.Errors.processWithErrors(Errors.java:193)&#013;&#010;at com.sun.jersey.api.client.Client.&lt;init&amp;gt;(Client.java:187)&#013;&#010;at com.sun.jersey.api.client.Client.&lt;init&amp;gt;(Client.java:170)&#013;&#010;at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit(TimelineClientImpl.java:280)&#013;&#010;at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#013;&#010;at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:169)&#013;&#010;at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)&#013;&#010;at org.apache.flink.yarn.YarnClusterClientFactory.getClusterDescriptor(YarnClusterClientFactory.java:76)&#013;&#010;at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:61)&#013;&#010;at org.apache.flink.yarn.YarnClusterClientFactory.createClusterDescriptor(YarnClusterClientFactory.java:43)&#013;&#010;at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:64)&#013;&#010;at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1812)&#013;&#010;at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128)&#013;&#010;at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76)&#013;&#010;at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1699)&#013;&#010;at com.missfresh.Main.main(Main.java:142)&#013;&#010;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#013;&#010;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#013;&#010;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#013;&#010;at java.lang.reflect.Method.invoke(Method.java:498)&#013;&#010;at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#013;&#010;at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#013;&#010;at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#013;&#010;at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#013;&#010;at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#013;&#010;at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#013;&#010;at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#013;&#010;at java.security.AccessController.doPrivileged(Native Method)&#013;&#010;at javax.security.auth.Subject.doAs(Subject.java:422)&#013;&#010;at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)&#013;&#010;at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#013;&#010;at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#013;&#010;&#013;&#010;&#013;&#010;æˆ‘å·²ç»åœ¨libä¸‹æ·»åŠ äº†javax.ws.rs-api-2.1.1.jar",
        "depth": "4",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<56fc0d26.5f64.1736be01fbb.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 10:58:37 GMT",
        "subject": "flink1.11å¯åŠ¨é—®é¢˜",
        "content": "&#010;&#010;è¿™flink1.11å•¥æƒ…å†µå•Šï¼Œä¸€å¯åŠ¨å°±æŠ¥&#010;java.lang.LinkageError: ClassCastException: attempting to castjar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;to jar:file:/data/server/flink-1.11.0/lib/javax.ws.rs-api-2.1.1.jar!/javax/ws/rs/ext/RuntimeDelegate.class&#010;&#010;&#010;jersey.xxxx.jar   javax.ws.xxx.jaræˆ‘éƒ½æ”¾åˆ°libäº†ï¼Œæ€ä¹ˆè¿˜æ˜¯ä¸è¡Œå•Šï¼Ÿè¿™æŠ¥çš„ä»€ä¹ˆé¬¼ä¸œè¥¿ï¼Ÿ&#010;&#010;",
        "depth": "1",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<5889fdc7.9fb9.1737084c3fc.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 08:36:55 GMT",
        "subject": "flink1.11å¯åŠ¨é—®é¢˜",
        "content": "&#010;&#010;æœäº†å•Šï¼Œè¿™ä¸ªflink1.11å¯åŠ¨æ€ä¹ˆå‡€æ˜¯é—®é¢˜å•Š&#010;&#010;&#010;æˆ‘1.7ï¼Œ1.8ï¼Œ1.9 éƒ½æ²¡æœ‰é—®é¢˜ï¼Œåˆ°11å°±ä¸è¡Œ&#010;./bin/flink run -m yarn-cluster -yqu root.rt_constant -ys 2 -yjm 1024 -yjm 1024 -ynm sql_test&#010;./examples/batch/WordCount.jar --input hdfs://xxx/data/wangty/LICENSE-2.0.txt --output hdfs://xxx/data/wangty/a&#010;&#010;&#010;æŠ¥é”™ï¼š&#010;Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could&#010;not allocate the required slot within slot request timeout. Please make sure that the cluster&#010;has enough resources. at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeWrapWithNoResourceAvailableException(DefaultScheduler.java:441)&#010;... 45 more Caused by: java.util.concurrent.CompletionException: java.util.concurrent.TimeoutException&#010;at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292) at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)&#010;at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593) at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)&#010;... 25 more&#010;&#010;&#010;æˆ‘èµ„æºæ˜¯è¶³çš„å•Šï¼Œå°±flink1.11èµ·ä¸æ¥ï¼Œä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œå¡å¥½ä¹…ç„¶åæŠ¥è¿™ä¸ªé”™ï¼Œå¤§ç¥ä»¬å¸®çœ‹çœ‹å§ï¼Œæ˜¨å¤©çš„jaråŒ…å†²çªé—®é¢˜å·²ç»è§£å†³ï¼ˆåªæœ‰flink1.11å­˜åœ¨çš„é—®é¢˜ï¼‰ï¼Œ&#010;&#010;",
        "depth": "1",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<CABvJ6uWppow75f3D__3G__mKWqoN-U3_46wZd1MVPnE3zMnqtw@mail.gmail.com>",
        "from": "Shuiqiang Chen &lt;acqua....@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 09:22:48 GMT",
        "subject": "Re: flink1.11å¯åŠ¨é—®é¢˜",
        "content": "Hiï¼Œ&#013;&#010;&#013;&#010;å¯ä»¥å°è¯•åœ¨jmçš„logé‡Œçœ‹çœ‹æ˜¯åœ¨ç”³è¯·å“ªä¸ªèµ„æºçš„æ—¶å€™è¶…æ—¶äº†, å¯¹æ¯”ä¸‹æ‰€ç”³è¯·çš„èµ„æºè§„æ ¼å’Œé›†ç¾¤å¯ç”¨èµ„æº&#013;&#010;&#013;&#010;Bestï¼Œ&#013;&#010;Shuiqiang&#013;&#010;&#013;&#010;é…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ4:37å†™é“ï¼š&#013;&#010;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æœäº†å•Šï¼Œè¿™ä¸ªflink1.11å¯åŠ¨æ€ä¹ˆå‡€æ˜¯é—®é¢˜å•Š&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘1.7ï¼Œ1.8ï¼Œ1.9 éƒ½æ²¡æœ‰é—®é¢˜ï¼Œåˆ°11å°±ä¸è¡Œ&#013;&#010;&gt; ./bin/flink run -m yarn-cluster -yqu root.rt_constant -ys 2 -yjm 1024 -yjm&#013;&#010;&gt; 1024 -ynm sql_test ./examples/batch/WordCount.jar --input&#013;&#010;&gt; hdfs://xxx/data/wangty/LICENSE-2.0.txt --output hdfs://xxx/data/wangty/a&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æŠ¥é”™ï¼š&#013;&#010;&gt; Caused by:&#013;&#010;&gt; org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException:&#013;&#010;&gt; Could not allocate the required slot within slot request timeout. Please&#013;&#010;&gt; make sure that the cluster has enough resources. at&#013;&#010;&gt; org.apache.flink.runtime.scheduler.DefaultScheduler.maybeWrapWithNoResourceAvailableException(DefaultScheduler.java:441)&#013;&#010;&gt; ... 45 more Caused by: java.util.concurrent.CompletionException:&#013;&#010;&gt; java.util.concurrent.TimeoutException at&#013;&#010;&gt; java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)&#013;&#010;&gt; at&#013;&#010;&gt; java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)&#013;&#010;&gt; at&#013;&#010;&gt; java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593)&#013;&#010;&gt; at&#013;&#010;&gt; java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)&#013;&#010;&gt; ... 25 more&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘èµ„æºæ˜¯è¶³çš„å•Šï¼Œå°±flink1.11èµ·ä¸æ¥ï¼Œä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œå¡å¥½ä¹…ç„¶åæŠ¥è¿™ä¸ªé”™ï¼Œå¤§ç¥ä»¬å¸®çœ‹çœ‹å§ï¼Œæ˜¨å¤©çš„jaråŒ…å†²çªé—®é¢˜å·²ç»è§£å†³ï¼ˆåªæœ‰flink1.11å­˜åœ¨çš„é—®é¢˜ï¼‰ï¼Œ&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<27000760.148f.17374763bfb.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 02:59:32 GMT",
        "subject": "å›å¤ï¼š flink1.11å¯åŠ¨é—®é¢˜",
        "content": "jmé‡Œé¢æ²¡æœ‰æ—¥å¿—å•Šï¼Œå…³é”®æ˜¯é…ç½®éƒ½æ˜¯ä¸€æ ·çš„ï¼Œæˆ‘åœ¨1.9é‡Œè¿è¡Œå°±æ²¡é—®é¢˜ï¼Œåœ¨flink1.11å°±ä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œä¸åˆ†é…èµ„æºï¼Œåˆ°åº•å¯åŠ¨æ–¹å¼æ”¹å˜äº†å•¥å‘¢ï¼Ÿ&#010;é›†ç¾¤èµ„æºæ˜¯æœ‰çš„ï¼Œå¯æ˜¯ä»»åŠ¡ä¸€ç›´å¡åœ¨é‚£è¯´æ²¡èµ„æºï¼Œè¿™æ€ä¹ˆåŠ&#010;&#010;&#010;&#010;&#010;åœ¨2020å¹´07æœˆ21æ—¥ 17:22ï¼ŒShuiqiang Chen&lt;acqua.csq@gmail.com&gt; å†™é“ï¼š&#010;Hiï¼Œ&#010;&#010;å¯ä»¥å°è¯•åœ¨jmçš„logé‡Œçœ‹çœ‹æ˜¯åœ¨ç”³è¯·å“ªä¸ªèµ„æºçš„æ—¶å€™è¶…æ—¶äº†, å¯¹æ¯”ä¸‹æ‰€ç”³è¯·çš„èµ„æºè§„æ ¼å’Œé›†ç¾¤å¯ç”¨èµ„æº&#010;&#010;Bestï¼Œ&#010;Shuiqiang&#010;&#010;é…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ4:37å†™é“ï¼š&#010;&#010;&#010;&#010;æœäº†å•Šï¼Œè¿™ä¸ªflink1.11å¯åŠ¨æ€ä¹ˆå‡€æ˜¯é—®é¢˜å•Š&#010;&#010;&#010;æˆ‘1.7ï¼Œ1.8ï¼Œ1.9 éƒ½æ²¡æœ‰é—®é¢˜ï¼Œåˆ°11å°±ä¸è¡Œ&#010;./bin/flink run -m yarn-cluster -yqu root.rt_constant -ys 2 -yjm 1024 -yjm&#010;1024 -ynm sql_test ./examples/batch/WordCount.jar --input&#010;hdfs://xxx/data/wangty/LICENSE-2.0.txt --output hdfs://xxx/data/wangty/a&#010;&#010;&#010;æŠ¥é”™ï¼š&#010;Caused by:&#010;org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException:&#010;Could not allocate the required slot within slot request timeout. Please&#010;make sure that the cluster has enough resources. at&#010;org.apache.flink.runtime.scheduler.DefaultScheduler.maybeWrapWithNoResourceAvailableException(DefaultScheduler.java:441)&#010;... 45 more Caused by: java.util.concurrent.CompletionException:&#010;java.util.concurrent.TimeoutException at&#010;java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)&#010;at&#010;java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)&#010;at&#010;java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593)&#010;at&#010;java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)&#010;... 25 more&#010;&#010;&#010;&#010;æˆ‘èµ„æºæ˜¯è¶³çš„å•Šï¼Œå°±flink1.11èµ·ä¸æ¥ï¼Œä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œå¡å¥½ä¹…ç„¶åæŠ¥è¿™ä¸ªé”™ï¼Œå¤§ç¥ä»¬å¸®çœ‹çœ‹å§ï¼Œæ˜¨å¤©çš„jaråŒ…å†²çªé—®é¢˜å·²ç»è§£å†³ï¼ˆåªæœ‰flink1.11å­˜åœ¨çš„é—®é¢˜ï¼‰ï¼Œ&#010;&#010;&#010;",
        "depth": "3",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<CAP+gf36OHu1-0qFsh1RLotf_QgtzadWLxR_GA+ONJnAco1B5YA@mail.gmail.com>",
        "from": "Yang Wang &lt;danrtsey...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 04:49:24 GMT",
        "subject": "Re: flink1.11å¯åŠ¨é—®é¢˜",
        "content": "å¯ä»¥çš„è¯ï¼Œå‘ä¸€ä¸‹clientç«¯å’ŒJMç«¯çš„log&#013;&#010;&#013;&#010;1.11æ˜¯å¯¹æäº¤æ–¹å¼æœ‰ä¸€äº›å˜åŒ–ï¼Œä½†åº”è¯¥éƒ½æ˜¯å’Œä¹‹å‰å…¼å®¹çš„ï¼Œä½ çš„æäº¤å‘½ä»¤çœ‹ç€ä¹Ÿæ˜¯æ²¡æœ‰é—®é¢˜çš„&#013;&#010;æˆ‘è‡ªå·±è¯•äº†ä¸€ä¸‹ä¹Ÿæ˜¯å¯ä»¥æ­£å¸¸è¿è¡Œçš„&#013;&#010;&#013;&#010;&#013;&#010;Best,&#013;&#010;Yang&#013;&#010;&#013;&#010;é…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; äº2020å¹´7æœˆ22æ—¥å‘¨ä¸‰ ä¸Šåˆ11:06å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; jmé‡Œé¢æ²¡æœ‰æ—¥å¿—å•Šï¼Œå…³é”®æ˜¯é…ç½®éƒ½æ˜¯ä¸€æ ·çš„ï¼Œæˆ‘åœ¨1.9é‡Œè¿è¡Œå°±æ²¡é—®é¢˜ï¼Œåœ¨flink1.11å°±ä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œä¸åˆ†é…èµ„æºï¼Œåˆ°åº•å¯åŠ¨æ–¹å¼æ”¹å˜äº†å•¥å‘¢ï¼Ÿ&#013;&#010;&gt; é›†ç¾¤èµ„æºæ˜¯æœ‰çš„ï¼Œå¯æ˜¯ä»»åŠ¡ä¸€ç›´å¡åœ¨é‚£è¯´æ²¡èµ„æºï¼Œè¿™æ€ä¹ˆåŠ&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; åœ¨2020å¹´07æœˆ21æ—¥ 17:22ï¼ŒShuiqiang Chen&lt;acqua.csq@gmail.com&gt; å†™é“ï¼š&#013;&#010;&gt; Hiï¼Œ&#013;&#010;&gt;&#013;&#010;&gt; å¯ä»¥å°è¯•åœ¨jmçš„logé‡Œçœ‹çœ‹æ˜¯åœ¨ç”³è¯·å“ªä¸ªèµ„æºçš„æ—¶å€™è¶…æ—¶äº†, å¯¹æ¯”ä¸‹æ‰€ç”³è¯·çš„èµ„æºè§„æ ¼å’Œé›†ç¾¤å¯ç”¨èµ„æº&#013;&#010;&gt;&#013;&#010;&gt; Bestï¼Œ&#013;&#010;&gt; Shuiqiang&#013;&#010;&gt;&#013;&#010;&gt; é…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ4:37å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æœäº†å•Šï¼Œè¿™ä¸ªflink1.11å¯åŠ¨æ€ä¹ˆå‡€æ˜¯é—®é¢˜å•Š&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘1.7ï¼Œ1.8ï¼Œ1.9 éƒ½æ²¡æœ‰é—®é¢˜ï¼Œåˆ°11å°±ä¸è¡Œ&#013;&#010;&gt; ./bin/flink run -m yarn-cluster -yqu root.rt_constant -ys 2 -yjm 1024 -yjm&#013;&#010;&gt; 1024 -ynm sql_test ./examples/batch/WordCount.jar --input&#013;&#010;&gt; hdfs://xxx/data/wangty/LICENSE-2.0.txt --output hdfs://xxx/data/wangty/a&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æŠ¥é”™ï¼š&#013;&#010;&gt; Caused by:&#013;&#010;&gt; org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException:&#013;&#010;&gt; Could not allocate the required slot within slot request timeout. Please&#013;&#010;&gt; make sure that the cluster has enough resources. at&#013;&#010;&gt;&#013;&#010;&gt; org.apache.flink.runtime.scheduler.DefaultScheduler.maybeWrapWithNoResourceAvailableException(DefaultScheduler.java:441)&#013;&#010;&gt; ... 45 more Caused by: java.util.concurrent.CompletionException:&#013;&#010;&gt; java.util.concurrent.TimeoutException at&#013;&#010;&gt;&#013;&#010;&gt; java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)&#013;&#010;&gt; at&#013;&#010;&gt;&#013;&#010;&gt; java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)&#013;&#010;&gt; at&#013;&#010;&gt; java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593)&#013;&#010;&gt; at&#013;&#010;&gt;&#013;&#010;&gt; java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)&#013;&#010;&gt; ... 25 more&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; æˆ‘èµ„æºæ˜¯è¶³çš„å•Šï¼Œå°±flink1.11èµ·ä¸æ¥ï¼Œä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œå¡å¥½ä¹…ç„¶åæŠ¥è¿™ä¸ªé”™ï¼Œå¤§ç¥ä»¬å¸®çœ‹çœ‹å§ï¼Œæ˜¨å¤©çš„jaråŒ…å†²çªé—®é¢˜å·²ç»è§£å†³ï¼ˆåªæœ‰flink1.11å­˜åœ¨çš„é—®é¢˜ï¼‰ï¼Œ&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "4",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<1b86e89e.1f9e.17374e3235a.Coremail.17610775726@163.com>",
        "from": "JasonLee &lt;17610775...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 04:58:29 GMT",
        "subject": "å›å¤ï¼šflink1.11å¯åŠ¨é—®é¢˜",
        "content": "Hi&#010;æŠ¥é”™æ˜¾ç¤ºçš„æ˜¯èµ„æºä¸è¶³äº† ä½ ç¡®å®šyarnä¸Šçš„èµ„æºæ˜¯å¤Ÿçš„å— çœ‹ä¸‹æ˜¯ä¸æ˜¯èŠ‚ç‚¹æŒ‚äº†&#010;1.11æˆ‘è¿™è¾¹æäº¤ä»»åŠ¡éƒ½æ˜¯æ­£å¸¸çš„&#010;&#010;&#010;| |&#010;JasonLee&#010;|&#010;|&#010;é‚®ç®±ï¼š17610775726@163.com&#010;|&#010;&#010;Signature is customized by Netease Mail Master&#010;&#010;åœ¨2020å¹´07æœˆ21æ—¥ 16:36ï¼Œé…·é…·çš„æµ‘è›‹ å†™é“ï¼š&#010;&#010;&#010;æœäº†å•Šï¼Œè¿™ä¸ªflink1.11å¯åŠ¨æ€ä¹ˆå‡€æ˜¯é—®é¢˜å•Š&#010;&#010;&#010;æˆ‘1.7ï¼Œ1.8ï¼Œ1.9 éƒ½æ²¡æœ‰é—®é¢˜ï¼Œåˆ°11å°±ä¸è¡Œ&#010;./bin/flink run -m yarn-cluster -yqu root.rt_constant -ys 2 -yjm 1024 -yjm 1024 -ynm sql_test&#010;./examples/batch/WordCount.jar --input hdfs://xxx/data/wangty/LICENSE-2.0.txt --output hdfs://xxx/data/wangty/a&#010;&#010;&#010;æŠ¥é”™ï¼š&#010;Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could&#010;not allocate the required slot within slot request timeout. Please make sure that the cluster&#010;has enough resources. at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeWrapWithNoResourceAvailableException(DefaultScheduler.java:441)&#010;... 45 more Caused by: java.util.concurrent.CompletionException: java.util.concurrent.TimeoutException&#010;at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292) at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)&#010;at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593) at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)&#010;... 25 more&#010;&#010;&#010;æˆ‘èµ„æºæ˜¯è¶³çš„å•Šï¼Œå°±flink1.11èµ·ä¸æ¥ï¼Œä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œå¡å¥½ä¹…ç„¶åæŠ¥è¿™ä¸ªé”™ï¼Œå¤§ç¥ä»¬å¸®çœ‹çœ‹å§ï¼Œæ˜¨å¤©çš„jaråŒ…å†²çªé—®é¢˜å·²ç»è§£å†³ï¼ˆåªæœ‰flink1.11å­˜åœ¨çš„é—®é¢˜ï¼‰ï¼Œ&#010;&#010;",
        "depth": "2",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<tencent_DFEE4CCC94D35392CAD7E9CBFA466B00CB07@qq.com>",
        "from": "&quot;chengyanan1008@foxmail.com&quot; &lt;chengyanan1...@foxmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 08:35:14 GMT",
        "subject": "Re: å›å¤ï¼šflink1.11å¯åŠ¨é—®é¢˜",
        "content": "çœ‹ä¸€ä¸‹yarn-containers-vcoresè¿™ä¸ªå‚æ•°ï¼š&#013;&#010;&#013;&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/zh/ops/config.html#yarn-containers-vcores&#013;&#010;&#013;&#010;ç»“åˆè‡ªå·±çš„é›†ç¾¤ï¼Œé€‚å½“è°ƒä½è¿™ä¸ªå‚æ•°&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;chengyanan1008@foxmail.com&#013;&#010; &#013;&#010;å‘ä»¶äººï¼š JasonLee&#013;&#010;å‘é€æ—¶é—´ï¼š 2020-07-22 12:58&#013;&#010;æ”¶ä»¶äººï¼š user-zh&#013;&#010;ä¸»é¢˜ï¼š å›å¤ï¼šflink1.11å¯åŠ¨é—®é¢˜&#013;&#010;Hi&#013;&#010;æŠ¥é”™æ˜¾ç¤ºçš„æ˜¯èµ„æºä¸è¶³äº† ä½ ç¡®å®šyarnä¸Šçš„èµ„æºæ˜¯å¤Ÿçš„å— çœ‹ä¸‹æ˜¯ä¸æ˜¯èŠ‚ç‚¹æŒ‚äº†&#010;1.11æˆ‘è¿™è¾¹æäº¤ä»»åŠ¡éƒ½æ˜¯æ­£å¸¸çš„&#013;&#010; &#013;&#010; &#013;&#010;| |&#013;&#010;JasonLee&#013;&#010;|&#013;&#010;|&#013;&#010;é‚®ç®±ï¼š17610775726@163.com&#013;&#010;|&#013;&#010; &#013;&#010;Signature is customized by Netease Mail Master&#013;&#010; &#013;&#010;åœ¨2020å¹´07æœˆ21æ—¥ 16:36ï¼Œé…·é…·çš„æµ‘è›‹ å†™é“ï¼š&#013;&#010; &#013;&#010; &#013;&#010;æœäº†å•Šï¼Œè¿™ä¸ªflink1.11å¯åŠ¨æ€ä¹ˆå‡€æ˜¯é—®é¢˜å•Š&#013;&#010; &#013;&#010; &#013;&#010;æˆ‘1.7ï¼Œ1.8ï¼Œ1.9 éƒ½æ²¡æœ‰é—®é¢˜ï¼Œåˆ°11å°±ä¸è¡Œ&#013;&#010;./bin/flink run -m yarn-cluster -yqu root.rt_constant -ys 2 -yjm 1024 -yjm 1024 -ynm sql_test&#010;./examples/batch/WordCount.jar --input hdfs://xxx/data/wangty/LICENSE-2.0.txt --output hdfs://xxx/data/wangty/a&#013;&#010; &#013;&#010; &#013;&#010;æŠ¥é”™ï¼š&#013;&#010;Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could&#010;not allocate the required slot within slot request timeout. Please make sure that the cluster&#010;has enough resources. at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeWrapWithNoResourceAvailableException(DefaultScheduler.java:441)&#010;... 45 more Caused by: java.util.concurrent.CompletionException: java.util.concurrent.TimeoutException&#010;at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292) at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)&#010;at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593) at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)&#010;... 25 more&#013;&#010; &#013;&#010; &#013;&#010;æˆ‘èµ„æºæ˜¯è¶³çš„å•Šï¼Œå°±flink1.11èµ·ä¸æ¥ï¼Œä¸€ç›´å¡åœ¨é‚£é‡Œï¼Œå¡å¥½ä¹…ç„¶åæŠ¥è¿™ä¸ªé”™ï¼Œå¤§ç¥ä»¬å¸®çœ‹çœ‹å§ï¼Œæ˜¨å¤©çš„jaråŒ…å†²çªé—®é¢˜å·²ç»è§£å†³ï¼ˆåªæœ‰flink1.11å­˜åœ¨çš„é—®é¢˜ï¼‰ï¼Œ&#013;&#010; &#013;&#010;",
        "depth": "2",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<3efb12de.1d09.17374d6babe.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 04:44:56 GMT",
        "subject": "flink1.11å¯åŠ¨é—®é¢˜",
        "content": "ç°åœ¨æ˜¯ä¸ºä»€ä¹ˆå•Šï¼Ÿå¯åŠ¨ä»»åŠ¡è‡ªåŠ¨å ç”¨æ‰€æœ‰coreï¼Ÿcoreæ•°é‡ä¸€ç›´åœ¨å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ°é˜Ÿåˆ—æœ€å¤§å€¼ï¼Œç„¶åå°±å¡ä½äº†ï¼Œè¿™flink1.11å•¥æƒ…å†µå•Šï¼Ÿ&#010; &#010;&#010;&#010;&#010;",
        "depth": "1",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<2a983e9e.1f1b.17374d9cfe5.Coremail.17610775726@163.com>",
        "from": "JasonLee &lt;17610775...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 04:48:18 GMT",
        "subject": "å›å¤ï¼šflink1.11å¯åŠ¨é—®é¢˜",
        "content": "HI&#010;ä½ ä½¿ç”¨çš„ä»€ä¹ˆæ¨¡å¼ï¼Ÿå¯åŠ¨ä»»åŠ¡çš„å‘½ä»¤å‘å‡ºæ¥çœ‹ä¸€ä¸‹å§&#010;&#010;&#010;| |&#010;JasonLee&#010;|&#010;|&#010;é‚®ç®±ï¼š17610775726@163.com&#010;|&#010;&#010;Signature is customized by Netease Mail Master&#010;&#010;åœ¨2020å¹´07æœˆ22æ—¥ 12:44ï¼Œé…·é…·çš„æµ‘è›‹ å†™é“ï¼š&#010;ç°åœ¨æ˜¯ä¸ºä»€ä¹ˆå•Šï¼Ÿå¯åŠ¨ä»»åŠ¡è‡ªåŠ¨å ç”¨æ‰€æœ‰coreï¼Ÿcoreæ•°é‡ä¸€ç›´åœ¨å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ°é˜Ÿåˆ—æœ€å¤§å€¼ï¼Œç„¶åå°±å¡ä½äº†ï¼Œè¿™flink1.11å•¥æƒ…å†µå•Šï¼Ÿ&#010; &#010;&#010;&#010;&#010;",
        "depth": "2",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<2867b315.228f.173752303f1.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 06:08:15 GMT",
        "subject": "å›å¤ï¼šflink1.11å¯åŠ¨é—®é¢˜",
        "content": "è¿™æ˜¯æˆ‘çš„å¯åŠ¨å‘½ä»¤ï¼š./bin/flink run -m yarn-cluster -p 2 -ys 2 -yqu rt_constant -c com.xx.Main&#010;-yjm 1024 -ynm RTC_TEST xx.jar&#010;ä»»åŠ¡åˆ°yarnä¸Šåå°±ä¸€ç›´åœ¨å ç”¨coreï¼Œcoreæ•°é‡å’Œå†…å­˜æ•°é‡ä¸€ç›´åœ¨å¢åŠ &#010;&#010;&#010;&#010;&#010;åœ¨2020å¹´07æœˆ22æ—¥ 12:48ï¼ŒJasonLee&lt;17610775726@163.com&gt; å†™é“ï¼š&#010;HI&#010;ä½ ä½¿ç”¨çš„ä»€ä¹ˆæ¨¡å¼ï¼Ÿå¯åŠ¨ä»»åŠ¡çš„å‘½ä»¤å‘å‡ºæ¥çœ‹ä¸€ä¸‹å§&#010;&#010;&#010;| |&#010;JasonLee&#010;|&#010;|&#010;é‚®ç®±ï¼š17610775726@163.com&#010;|&#010;&#010;Signature is customized by Netease Mail Master&#010;&#010;åœ¨2020å¹´07æœˆ22æ—¥ 12:44ï¼Œé…·é…·çš„æµ‘è›‹ å†™é“ï¼š&#010;ç°åœ¨æ˜¯ä¸ºä»€ä¹ˆå•Šï¼Ÿå¯åŠ¨ä»»åŠ¡è‡ªåŠ¨å ç”¨æ‰€æœ‰coreï¼Ÿcoreæ•°é‡ä¸€ç›´åœ¨å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ°é˜Ÿåˆ—æœ€å¤§å€¼ï¼Œç„¶åå°±å¡ä½äº†ï¼Œè¿™flink1.11å•¥æƒ…å†µå•Šï¼Ÿ&#010; &#010;&#010;&#010;&#010;",
        "depth": "3",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<2d04edb6.431a.17376900633.Coremail.apache22@163.com>",
        "from": "é…·é…·çš„æµ‘è›‹ &lt;apach...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 12:46:57 GMT",
        "subject": "å›å¤ï¼šflink1.11å¯åŠ¨é—®é¢˜",
        "content": "æˆ‘æ‰¾åˆ°é—®é¢˜äº†ï¼Œæˆ‘è§‰å¾—æˆ‘å‘ç°äº†ä¸€ä¸ªbugï¼Œå¾ˆä¸¥é‡ï¼Œä¼šå¯¼è‡´flinkæŒç»­å èµ„æºï¼Œä¸€ç›´å¢åŠ &#010;&#010;&#010;&#010;&#010;åœ¨2020å¹´07æœˆ22æ—¥ 14:08ï¼Œé…·é…·çš„æµ‘è›‹&lt;apache22@163.com&gt; å†™é“ï¼š&#010;è¿™æ˜¯æˆ‘çš„å¯åŠ¨å‘½ä»¤ï¼š./bin/flink run -m yarn-cluster -p 2 -ys 2 -yqu rt_constant -c&#010;com.xx.Main -yjm 1024 -ynm RTC_TEST xx.jar&#010;ä»»åŠ¡åˆ°yarnä¸Šåå°±ä¸€ç›´åœ¨å ç”¨coreï¼Œcoreæ•°é‡å’Œå†…å­˜æ•°é‡ä¸€ç›´åœ¨å¢åŠ &#010;&#010;&#010;&#010;&#010;åœ¨2020å¹´07æœˆ22æ—¥ 12:48ï¼ŒJasonLee&lt;17610775726@163.com&gt; å†™é“ï¼š&#010;HI&#010;ä½ ä½¿ç”¨çš„ä»€ä¹ˆæ¨¡å¼ï¼Ÿå¯åŠ¨ä»»åŠ¡çš„å‘½ä»¤å‘å‡ºæ¥çœ‹ä¸€ä¸‹å§&#010;&#010;&#010;| |&#010;JasonLee&#010;|&#010;|&#010;é‚®ç®±ï¼š17610775726@163.com&#010;|&#010;&#010;Signature is customized by Netease Mail Master&#010;&#010;åœ¨2020å¹´07æœˆ22æ—¥ 12:44ï¼Œé…·é…·çš„æµ‘è›‹ å†™é“ï¼š&#010;ç°åœ¨æ˜¯ä¸ºä»€ä¹ˆå•Šï¼Ÿå¯åŠ¨ä»»åŠ¡è‡ªåŠ¨å ç”¨æ‰€æœ‰coreï¼Ÿcoreæ•°é‡ä¸€ç›´åœ¨å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ°é˜Ÿåˆ—æœ€å¤§å€¼ï¼Œç„¶åå°±å¡ä½äº†ï¼Œè¿™flink1.11å•¥æƒ…å†µå•Šï¼Ÿ&#010; &#010;&#010;&#010;&#010;",
        "depth": "4",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<A301FD04-AC5D-43C2-A022-0E22ED95AAB6@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 12:49:25 GMT",
        "subject": "Re: flink1.11å¯åŠ¨é—®é¢˜",
        "content": "Helloï¼Œ&#010;å¯ä»¥æè¿°ä¸‹è¿™ä¸ªé—®é¢˜å—ï¼Ÿ å¦‚æœç¡®è®¤æ˜¯bugçš„è¯å¯ä»¥å»jiraä¸Šå¼€ä¸ªissueçš„ã€‚&#010;&#010;ç¥å¥½&#010;Leonard Xu&#010;&#010;&gt; åœ¨ 2020å¹´7æœˆ22æ—¥ï¼Œ20:46ï¼Œé…·é…·çš„æµ‘è›‹ &lt;apache22@163.com&gt; å†™é“ï¼š&#010;&gt; &#010;&gt; æˆ‘æ‰¾åˆ°é—®é¢˜äº†ï¼Œæˆ‘è§‰å¾—æˆ‘å‘ç°äº†ä¸€ä¸ªbugï¼Œå¾ˆä¸¥é‡ï¼Œä¼šå¯¼è‡´flinkæŒç»­å èµ„æºï¼Œä¸€ç›´å¢åŠ &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; åœ¨2020å¹´07æœˆ22æ—¥ 14:08ï¼Œé…·é…·çš„æµ‘è›‹&lt;apache22@163.com&gt; å†™é“ï¼š&#010;&gt; è¿™æ˜¯æˆ‘çš„å¯åŠ¨å‘½ä»¤ï¼š./bin/flink run -m yarn-cluster -p 2 -ys 2 -yqu rt_constant&#010;-c com.xx.Main -yjm 1024 -ynm RTC_TEST xx.jar&#010;&gt; ä»»åŠ¡åˆ°yarnä¸Šåå°±ä¸€ç›´åœ¨å ç”¨coreï¼Œcoreæ•°é‡å’Œå†…å­˜æ•°é‡ä¸€ç›´åœ¨å¢åŠ &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&gt; åœ¨2020å¹´07æœˆ22æ—¥ 12:48ï¼ŒJasonLee&lt;17610775726@163.com&gt; å†™é“ï¼š&#010;&gt; HI&#010;&gt; ä½ ä½¿ç”¨çš„ä»€ä¹ˆæ¨¡å¼ï¼Ÿå¯åŠ¨ä»»åŠ¡çš„å‘½ä»¤å‘å‡ºæ¥çœ‹ä¸€ä¸‹å§&#010;&gt; &#010;&gt; &#010;&gt; | |&#010;&gt; JasonLee&#010;&gt; |&#010;&gt; |&#010;&gt; é‚®ç®±ï¼š17610775726@163.com&#010;&gt; |&#010;&gt; &#010;&gt; Signature is customized by Netease Mail Master&#010;&gt; &#010;&gt; åœ¨2020å¹´07æœˆ22æ—¥ 12:44ï¼Œé…·é…·çš„æµ‘è›‹ å†™é“ï¼š&#010;&gt; ç°åœ¨æ˜¯ä¸ºä»€ä¹ˆå•Šï¼Ÿå¯åŠ¨ä»»åŠ¡è‡ªåŠ¨å ç”¨æ‰€æœ‰coreï¼Ÿcoreæ•°é‡ä¸€ç›´åœ¨å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ°é˜Ÿåˆ—æœ€å¤§å€¼ï¼Œç„¶åå°±å¡ä½äº†ï¼Œè¿™flink1.11å•¥æƒ…å†µå•Šï¼Ÿ&#010; &#010;&gt; &#010;&gt; &#010;&gt; &#010;&#010;&#010;",
        "depth": "5",
        "reply": "<48c9332a.4b49.1736b26ca8e.Coremail.apache22@163.com>"
    },
    {
        "id": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 08:29:06 GMT",
        "subject": "flink1.11 run",
        "content": "hiï¼Œæˆ‘è¿™é¢è¯·ä¸€ä¸ªä¸€ä¸ªkafkaåˆ°hiveçš„ç¨‹åºï¼Œä½†ç¨‹åºæ— æ³•è¿è¡Œï¼Œè¯·é—®ä»€ä¹ˆåŸå› ï¼š&#010;&#010;å¼‚å¸¸ï¼š&#010;The program finished with the following exception:&#010;&#010;org.apache.flink.client.program.ProgramInvocationException: The main method&#010;caused an error: No operators defined in streaming topology. Cannot&#010;generate StreamGraph.&#010;at&#010;org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;at&#010;org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;at&#010;org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;at&#010;org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;at&#010;org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;at java.security.AccessController.doPrivileged(Native Method)&#010;at javax.security.auth.Subject.doAs(Subject.java:422)&#010;at&#010;org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)&#010;at&#010;org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;Caused by: java.lang.IllegalStateException: No operators defined in&#010;streaming topology. Cannot generate StreamGraph.&#010;at&#010;org.apache.flink.table.planner.utils.ExecutorUtils.generateStreamGraph(ExecutorUtils.java:47)&#010;at&#010;org.apache.flink.table.planner.delegation.StreamExecutor.createPipeline(StreamExecutor.java:47)&#010;at&#010;org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;at&#010;com.akulaku.data.flink.StreamingWriteToHive.main(StreamingWriteToHive.java:80)&#010;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;at&#010;sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;at&#010;sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;at java.lang.reflect.Method.invoke(Method.java:498)&#010;at&#010;org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;... 11 more&#010;ä»£ç ï¼š&#010;&#010; StreamExecutionEnvironment environment =&#010;StreamExecutionEnvironment.getExecutionEnvironment();&#010;        EnvironmentSettings settings =&#010;EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();&#010;        StreamTableEnvironment tableEnv =&#010;StreamTableEnvironment.create(environment, settings);&#010;&#010;        environment.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;        environment.setStateBackend(new MemoryStateBackend());&#010;        environment.getCheckpointConfig().setCheckpointInterval(5000);&#010;&#010;        String name = \"myhive\";&#010;        String defaultDatabase = \"tmp\";&#010;        String hiveConfDir = \"/etc/alternatives/hive-conf/\";&#010;        String version = \"1.1.0\";&#010;&#010;        HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;hiveConfDir, version);&#010;        tableEnv.registerCatalog(\"myhive\", hive);&#010;        tableEnv.useCatalog(\"myhive\");&#010;&#010;        tableEnv.executeSql(\"CREATE TABLE tmp.user_behavior (\\n\" +&#010;                \"  user_id BIGINT,\\n\" +&#010;                \"  item_id STRING,\\n\" +&#010;                \"  behavior STRING,\\n\" +&#010;                \"  ts AS PROCTIME()\\n\" +&#010;                \") WITH (\\n\" +&#010;                \" 'connector' = 'kafka-0.11',\\n\" +&#010;                \" 'topic' = 'user_behavior',\\n\" +&#010;                \" 'properties.bootstrap.servers' = 'localhost:9092',\\n\" +&#010;                \" 'properties.group.id' = 'testGroup',\\n\" +&#010;                \" 'scan.startup.mode' = 'earliest-offset',\\n\" +&#010;                \" 'format' = 'json',\\n\" +&#010;                \" 'json.fail-on-missing-field' = 'false',\\n\" +&#010;                \" 'json.ignore-parse-errors' = 'true'\\n\" +&#010;                \")\");&#010;&#010;//        tableEnv.executeSql(\"CREATE TABLE print_table (\\n\" +&#010;//                \" user_id BIGINT,\\n\" +&#010;//                \" item_id STRING,\\n\" +&#010;//                \" behavior STRING,\\n\" +&#010;//                \" tsdata STRING\\n\" +&#010;//                \") WITH (\\n\" +&#010;//                \" 'connector' = 'print'\\n\" +&#010;//                \")\");&#010;        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;        tableEnv.executeSql(\"CREATE TABLE tmp.streamhivetest (\\n\" +&#010;                \" user_id BIGINT,\\n\" +&#010;                \" item_id STRING,\\n\" +&#010;                \" behavior STRING,\\n\" +&#010;                \" tsdata STRING\\n\" +&#010;                \") STORED AS parquet TBLPROPERTIES (\\n\" +&#010;                \" 'sink.rolling-policy.file-size' = '12MB',\\n\" +&#010;                \" 'sink.rolling-policy.rollover-interval' = '1 min',\\n\" +&#010;                \" 'sink.rolling-policy.check-interval' = '1 min',\\n\" +&#010;                \" 'execution.checkpointing.interval' = 'true'\\n\" +&#010;                \")\");&#010;&#010;        tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;        tableEnv.executeSql(\"insert into streamhivetest select&#010;user_id,item_id,behavior,DATE_FORMAT(ts, 'yyyy-MM-dd') as tsdata from&#010;user_behavior\");&#010;&#010;        tableEnv.execute(\"stream-write-hive\");&#010;&#010;",
        "depth": "0",
        "reply": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>"
    },
    {
        "id": "<CADH6UNSAfERA-3mb=n2DvYV0_-kfmz-O=eB94WaCwjrQww=iGQ@mail.gmail.com>",
        "from": "Rui Li &lt;lirui.fu...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 08:43:37 GMT",
        "subject": "Re: flink1.11 run",
        "content": "tableEnv.executeSqlå°±å·²ç»æäº¤ä½œä¸šäº†ï¼Œä¸éœ€è¦å†æ‰§è¡Œexecuteäº†å“ˆ&#010;&#010;On Mon, Jul 20, 2020 at 4:29 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&#010;&gt; hiï¼Œæˆ‘è¿™é¢è¯·ä¸€ä¸ªä¸€ä¸ªkafkaåˆ°hiveçš„ç¨‹åºï¼Œä½†ç¨‹åºæ— æ³•è¿è¡Œï¼Œè¯·é—®ä»€ä¹ˆåŸå› ï¼š&#010;&gt;&#010;&gt; å¼‚å¸¸ï¼š&#010;&gt; The program finished with the following exception:&#010;&gt;&#010;&gt; org.apache.flink.client.program.ProgramInvocationException: The main method&#010;&gt; caused an error: No operators defined in streaming topology. Cannot&#010;&gt; generate StreamGraph.&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;&gt; at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;&gt; at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;&gt; at java.security.AccessController.doPrivileged(Native Method)&#010;&gt; at javax.security.auth.Subject.doAs(Subject.java:422)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;&gt; at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&gt; Caused by: java.lang.IllegalStateException: No operators defined in&#010;&gt; streaming topology. Cannot generate StreamGraph.&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.table.planner.utils.ExecutorUtils.generateStreamGraph(ExecutorUtils.java:47)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.table.planner.delegation.StreamExecutor.createPipeline(StreamExecutor.java:47)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt; at&#010;&gt;&#010;&gt; com.akulaku.data.flink.StreamingWriteToHive.main(StreamingWriteToHive.java:80)&#010;&gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt; at&#010;&gt;&#010;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt; at&#010;&gt;&#010;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt; at java.lang.reflect.Method.invoke(Method.java:498)&#010;&gt; at&#010;&gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;&gt; ... 11 more&#010;&gt; ä»£ç ï¼š&#010;&gt;&#010;&gt;  StreamExecutionEnvironment environment =&#010;&gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt;         EnvironmentSettings settings =&#010;&gt;&#010;&gt; EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();&#010;&gt;         StreamTableEnvironment tableEnv =&#010;&gt; StreamTableEnvironment.create(environment, settings);&#010;&gt;&#010;&gt;&#010;&gt; environment.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&gt;         environment.setStateBackend(new MemoryStateBackend());&#010;&gt;         environment.getCheckpointConfig().setCheckpointInterval(5000);&#010;&gt;&#010;&gt;         String name = \"myhive\";&#010;&gt;         String defaultDatabase = \"tmp\";&#010;&gt;         String hiveConfDir = \"/etc/alternatives/hive-conf/\";&#010;&gt;         String version = \"1.1.0\";&#010;&gt;&#010;&gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; hiveConfDir, version);&#010;&gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt;&#010;&gt;         tableEnv.executeSql(\"CREATE TABLE tmp.user_behavior (\\n\" +&#010;&gt;                 \"  user_id BIGINT,\\n\" +&#010;&gt;                 \"  item_id STRING,\\n\" +&#010;&gt;                 \"  behavior STRING,\\n\" +&#010;&gt;                 \"  ts AS PROCTIME()\\n\" +&#010;&gt;                 \") WITH (\\n\" +&#010;&gt;                 \" 'connector' = 'kafka-0.11',\\n\" +&#010;&gt;                 \" 'topic' = 'user_behavior',\\n\" +&#010;&gt;                 \" 'properties.bootstrap.servers' = 'localhost:9092',\\n\" +&#010;&gt;                 \" 'properties.group.id' = 'testGroup',\\n\" +&#010;&gt;                 \" 'scan.startup.mode' = 'earliest-offset',\\n\" +&#010;&gt;                 \" 'format' = 'json',\\n\" +&#010;&gt;                 \" 'json.fail-on-missing-field' = 'false',\\n\" +&#010;&gt;                 \" 'json.ignore-parse-errors' = 'true'\\n\" +&#010;&gt;                 \")\");&#010;&gt;&#010;&gt; //        tableEnv.executeSql(\"CREATE TABLE print_table (\\n\" +&#010;&gt; //                \" user_id BIGINT,\\n\" +&#010;&gt; //                \" item_id STRING,\\n\" +&#010;&gt; //                \" behavior STRING,\\n\" +&#010;&gt; //                \" tsdata STRING\\n\" +&#010;&gt; //                \") WITH (\\n\" +&#010;&gt; //                \" 'connector' = 'print'\\n\" +&#010;&gt; //                \")\");&#010;&gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt;         tableEnv.executeSql(\"CREATE TABLE tmp.streamhivetest (\\n\" +&#010;&gt;                 \" user_id BIGINT,\\n\" +&#010;&gt;                 \" item_id STRING,\\n\" +&#010;&gt;                 \" behavior STRING,\\n\" +&#010;&gt;                 \" tsdata STRING\\n\" +&#010;&gt;                 \") STORED AS parquet TBLPROPERTIES (\\n\" +&#010;&gt;                 \" 'sink.rolling-policy.file-size' = '12MB',\\n\" +&#010;&gt;                 \" 'sink.rolling-policy.rollover-interval' = '1 min',\\n\" +&#010;&gt;                 \" 'sink.rolling-policy.check-interval' = '1 min',\\n\" +&#010;&gt;                 \" 'execution.checkpointing.interval' = 'true'\\n\" +&#010;&gt;                 \")\");&#010;&gt;&#010;&gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt;         tableEnv.executeSql(\"insert into streamhivetest select&#010;&gt; user_id,item_id,behavior,DATE_FORMAT(ts, 'yyyy-MM-dd') as tsdata from&#010;&gt; user_behavior\");&#010;&gt;&#010;&gt;         tableEnv.execute(\"stream-write-hive\");&#010;&gt;&#010;&#010;&#010;-- &#010;Best regards!&#010;Rui Li&#010;&#010;",
        "depth": "1",
        "reply": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>"
    },
    {
        "id": "<CAEZk0432vhYxxLsC5LMVsVoVYgT-ovHByYTE+jdeVNb7E3-txg@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 09:13:23 GMT",
        "subject": "Re: flink1.11 run",
        "content": " hi&#010;å¥½çš„ï¼Œæƒ³é—®ä¸€ä¸‹streamå†™hiveè¡¨çš„æ—¶å€™ï¼š&#010;1ã€ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&#010;Rui Li &lt;lirui.fudan@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ4:44å†™é“ï¼š&#010;&#010;&gt; tableEnv.executeSqlå°±å·²ç»æäº¤ä½œä¸šäº†ï¼Œä¸éœ€è¦å†æ‰§è¡Œexecuteäº†å“ˆ&#010;&gt;&#010;&gt; On Mon, Jul 20, 2020 at 4:29 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&gt;&#010;&gt; &gt; hiï¼Œæˆ‘è¿™é¢è¯·ä¸€ä¸ªä¸€ä¸ªkafkaåˆ°hiveçš„ç¨‹åºï¼Œä½†ç¨‹åºæ— æ³•è¿è¡Œï¼Œè¯·é—®ä»€ä¹ˆåŸå› ï¼š&#010;&gt; &gt;&#010;&gt; &gt; å¼‚å¸¸ï¼š&#010;&gt; &gt; The program finished with the following exception:&#010;&gt; &gt;&#010;&gt; &gt; org.apache.flink.client.program.ProgramInvocationException: The main&#010;&gt; method&#010;&gt; &gt; caused an error: No operators defined in streaming topology. Cannot&#010;&gt; &gt; generate StreamGraph.&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;&gt; &gt; at&#010;&gt; org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;&gt; &gt; at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;&gt; &gt; at java.security.AccessController.doPrivileged(Native Method)&#010;&gt; &gt; at javax.security.auth.Subject.doAs(Subject.java:422)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;&gt; &gt; at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&gt; &gt; Caused by: java.lang.IllegalStateException: No operators defined in&#010;&gt; &gt; streaming topology. Cannot generate StreamGraph.&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.utils.ExecutorUtils.generateStreamGraph(ExecutorUtils.java:47)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.StreamExecutor.createPipeline(StreamExecutor.java:47)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; com.akulaku.data.flink.StreamingWriteToHive.main(StreamingWriteToHive.java:80)&#010;&gt; &gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt; &gt; at java.lang.reflect.Method.invoke(Method.java:498)&#010;&gt; &gt; at&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;&gt; &gt; ... 11 more&#010;&gt; &gt; ä»£ç ï¼š&#010;&gt; &gt;&#010;&gt; &gt;  StreamExecutionEnvironment environment =&#010;&gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt;         EnvironmentSettings settings =&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();&#010;&gt; &gt;         StreamTableEnvironment tableEnv =&#010;&gt; &gt; StreamTableEnvironment.create(environment, settings);&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; environment.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &gt;         environment.setStateBackend(new MemoryStateBackend());&#010;&gt; &gt;         environment.getCheckpointConfig().setCheckpointInterval(5000);&#010;&gt; &gt;&#010;&gt; &gt;         String name = \"myhive\";&#010;&gt; &gt;         String defaultDatabase = \"tmp\";&#010;&gt; &gt;         String hiveConfDir = \"/etc/alternatives/hive-conf/\";&#010;&gt; &gt;         String version = \"1.1.0\";&#010;&gt; &gt;&#010;&gt; &gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; hiveConfDir, version);&#010;&gt; &gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt; &gt;&#010;&gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.user_behavior (\\n\" +&#010;&gt; &gt;                 \"  user_id BIGINT,\\n\" +&#010;&gt; &gt;                 \"  item_id STRING,\\n\" +&#010;&gt; &gt;                 \"  behavior STRING,\\n\" +&#010;&gt; &gt;                 \"  ts AS PROCTIME()\\n\" +&#010;&gt; &gt;                 \") WITH (\\n\" +&#010;&gt; &gt;                 \" 'connector' = 'kafka-0.11',\\n\" +&#010;&gt; &gt;                 \" 'topic' = 'user_behavior',\\n\" +&#010;&gt; &gt;                 \" 'properties.bootstrap.servers' = 'localhost:9092',\\n\" +&#010;&gt; &gt;                 \" 'properties.group.id' = 'testGroup',\\n\" +&#010;&gt; &gt;                 \" 'scan.startup.mode' = 'earliest-offset',\\n\" +&#010;&gt; &gt;                 \" 'format' = 'json',\\n\" +&#010;&gt; &gt;                 \" 'json.fail-on-missing-field' = 'false',\\n\" +&#010;&gt; &gt;                 \" 'json.ignore-parse-errors' = 'true'\\n\" +&#010;&gt; &gt;                 \")\");&#010;&gt; &gt;&#010;&gt; &gt; //        tableEnv.executeSql(\"CREATE TABLE print_table (\\n\" +&#010;&gt; &gt; //                \" user_id BIGINT,\\n\" +&#010;&gt; &gt; //                \" item_id STRING,\\n\" +&#010;&gt; &gt; //                \" behavior STRING,\\n\" +&#010;&gt; &gt; //                \" tsdata STRING\\n\" +&#010;&gt; &gt; //                \") WITH (\\n\" +&#010;&gt; &gt; //                \" 'connector' = 'print'\\n\" +&#010;&gt; &gt; //                \")\");&#010;&gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.streamhivetest (\\n\" +&#010;&gt; &gt;                 \" user_id BIGINT,\\n\" +&#010;&gt; &gt;                 \" item_id STRING,\\n\" +&#010;&gt; &gt;                 \" behavior STRING,\\n\" +&#010;&gt; &gt;                 \" tsdata STRING\\n\" +&#010;&gt; &gt;                 \") STORED AS parquet TBLPROPERTIES (\\n\" +&#010;&gt; &gt;                 \" 'sink.rolling-policy.file-size' = '12MB',\\n\" +&#010;&gt; &gt;                 \" 'sink.rolling-policy.rollover-interval' = '1 min',\\n\" +&#010;&gt; &gt;                 \" 'sink.rolling-policy.check-interval' = '1 min',\\n\" +&#010;&gt; &gt;                 \" 'execution.checkpointing.interval' = 'true'\\n\" +&#010;&gt; &gt;                 \")\");&#010;&gt; &gt;&#010;&gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt;         tableEnv.executeSql(\"insert into streamhivetest select&#010;&gt; &gt; user_id,item_id,behavior,DATE_FORMAT(ts, 'yyyy-MM-dd') as tsdata from&#010;&gt; &gt; user_behavior\");&#010;&gt; &gt;&#010;&gt; &gt;         tableEnv.execute(\"stream-write-hive\");&#010;&gt; &gt;&#010;&gt;&#010;&gt;&#010;&gt; --&#010;&gt; Best regards!&#010;&gt; Rui Li&#010;&gt;&#010;&#010;",
        "depth": "2",
        "reply": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>"
    },
    {
        "id": "<CABi+2jS=njg62_tF3KD4G=BQbrMMQfKmSrhQRX_YHk8gmgimSw@mail.gmail.com>",
        "from": "Jingsong Li &lt;jingsongl...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 10:11:13 GMT",
        "subject": "Re: flink1.11 run",
        "content": "Hi Dream,&#010;&#010;&gt; 1.ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;&#010;ä¸ç”¨ï¼Œå“ªè¾¹å»ºæ— æ‰€è°“&#010;&#010;&gt; 2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&#010;å¯ä»¥ï¼Œé»˜è®¤ä¸‹ 128MB æ»šåŠ¨ï¼ŒCheckpoint æ»šåŠ¨ã€‚&#010;&#010;Best,&#010;Jingsong&#010;&#010;On Mon, Jul 20, 2020 at 5:15 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&#010;&gt;  hi&#010;&gt; å¥½çš„ï¼Œæƒ³é—®ä¸€ä¸‹streamå†™hiveè¡¨çš„æ—¶å€™ï¼š&#010;&gt; 1ã€ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;&gt; 2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&gt;&#010;&gt; Rui Li &lt;lirui.fudan@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ4:44å†™é“ï¼š&#010;&gt;&#010;&gt; &gt; tableEnv.executeSqlå°±å·²ç»æäº¤ä½œä¸šäº†ï¼Œä¸éœ€è¦å†æ‰§è¡Œexecuteäº†å“ˆ&#010;&gt; &gt;&#010;&gt; &gt; On Mon, Jul 20, 2020 at 4:29 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&gt; &gt;&#010;&gt; &gt; &gt; hiï¼Œæˆ‘è¿™é¢è¯·ä¸€ä¸ªä¸€ä¸ªkafkaåˆ°hiveçš„ç¨‹åºï¼Œä½†ç¨‹åºæ— æ³•è¿è¡Œï¼Œè¯·é—®ä»€ä¹ˆåŸå› ï¼š&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; å¼‚å¸¸ï¼š&#010;&gt; &gt; &gt; The program finished with the following exception:&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; org.apache.flink.client.program.ProgramInvocationException: The main&#010;&gt; &gt; method&#010;&gt; &gt; &gt; caused an error: No operators defined in streaming topology. Cannot&#010;&gt; &gt; &gt; generate StreamGraph.&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;&gt; &gt; &gt; at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;&gt; &gt; &gt; at java.security.AccessController.doPrivileged(Native Method)&#010;&gt; &gt; &gt; at javax.security.auth.Subject.doAs(Subject.java:422)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;&gt; &gt; &gt; at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&gt; &gt; &gt; Caused by: java.lang.IllegalStateException: No operators defined in&#010;&gt; &gt; &gt; streaming topology. Cannot generate StreamGraph.&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.utils.ExecutorUtils.generateStreamGraph(ExecutorUtils.java:47)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.StreamExecutor.createPipeline(StreamExecutor.java:47)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; com.akulaku.data.flink.StreamingWriteToHive.main(StreamingWriteToHive.java:80)&#010;&gt; &gt; &gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt; &gt; &gt; at java.lang.reflect.Method.invoke(Method.java:498)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;&gt; &gt; &gt; ... 11 more&#010;&gt; &gt; &gt; ä»£ç ï¼š&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;  StreamExecutionEnvironment environment =&#010;&gt; &gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt; &gt;         EnvironmentSettings settings =&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();&#010;&gt; &gt; &gt;         StreamTableEnvironment tableEnv =&#010;&gt; &gt; &gt; StreamTableEnvironment.create(environment, settings);&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; environment.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &gt; &gt;         environment.setStateBackend(new MemoryStateBackend());&#010;&gt; &gt; &gt;         environment.getCheckpointConfig().setCheckpointInterval(5000);&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         String name = \"myhive\";&#010;&gt; &gt; &gt;         String defaultDatabase = \"tmp\";&#010;&gt; &gt; &gt;         String hiveConfDir = \"/etc/alternatives/hive-conf/\";&#010;&gt; &gt; &gt;         String version = \"1.1.0\";&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; &gt; hiveConfDir, version);&#010;&gt; &gt; &gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt; &gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.user_behavior (\\n\" +&#010;&gt; &gt; &gt;                 \"  user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt;                 \"  item_id STRING,\\n\" +&#010;&gt; &gt; &gt;                 \"  behavior STRING,\\n\" +&#010;&gt; &gt; &gt;                 \"  ts AS PROCTIME()\\n\" +&#010;&gt; &gt; &gt;                 \") WITH (\\n\" +&#010;&gt; &gt; &gt;                 \" 'connector' = 'kafka-0.11',\\n\" +&#010;&gt; &gt; &gt;                 \" 'topic' = 'user_behavior',\\n\" +&#010;&gt; &gt; &gt;                 \" 'properties.bootstrap.servers' =&#010;&gt; 'localhost:9092',\\n\" +&#010;&gt; &gt; &gt;                 \" 'properties.group.id' = 'testGroup',\\n\" +&#010;&gt; &gt; &gt;                 \" 'scan.startup.mode' = 'earliest-offset',\\n\" +&#010;&gt; &gt; &gt;                 \" 'format' = 'json',\\n\" +&#010;&gt; &gt; &gt;                 \" 'json.fail-on-missing-field' = 'false',\\n\" +&#010;&gt; &gt; &gt;                 \" 'json.ignore-parse-errors' = 'true'\\n\" +&#010;&gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; //        tableEnv.executeSql(\"CREATE TABLE print_table (\\n\" +&#010;&gt; &gt; &gt; //                \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; //                \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt; //                \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt; //                \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt; //                \") WITH (\\n\" +&#010;&gt; &gt; &gt; //                \" 'connector' = 'print'\\n\" +&#010;&gt; &gt; &gt; //                \")\");&#010;&gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.streamhivetest (\\n\" +&#010;&gt; &gt; &gt;                 \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt;                 \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt;                 \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt;                 \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt;                 \") STORED AS parquet TBLPROPERTIES (\\n\" +&#010;&gt; &gt; &gt;                 \" 'sink.rolling-policy.file-size' = '12MB',\\n\" +&#010;&gt; &gt; &gt;                 \" 'sink.rolling-policy.rollover-interval' = '1&#010;&gt; min',\\n\" +&#010;&gt; &gt; &gt;                 \" 'sink.rolling-policy.check-interval' = '1 min',\\n\" +&#010;&gt; &gt; &gt;                 \" 'execution.checkpointing.interval' = 'true'\\n\" +&#010;&gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt; &gt;         tableEnv.executeSql(\"insert into streamhivetest select&#010;&gt; &gt; &gt; user_id,item_id,behavior,DATE_FORMAT(ts, 'yyyy-MM-dd') as tsdata from&#010;&gt; &gt; &gt; user_behavior\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         tableEnv.execute(\"stream-write-hive\");&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt; --&#010;&gt; &gt; Best regards!&#010;&gt; &gt; Rui Li&#010;&gt; &gt;&#010;&gt;&#010;&#010;&#010;-- &#010;Best, Jingsong Lee&#010;&#010;",
        "depth": "3",
        "reply": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>"
    },
    {
        "id": "<CAEZk042x2L55HC-2e_v_nZ333gBFvpvZcOB4TajnxVCO1-wa=Q@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 11:09:35 GMT",
        "subject": "Re: flink1.11 run",
        "content": "hiã€&#010;å¯¹äºä¸‹é¢è¿™ä¸¤ä¸ªçš„æ»šåŠ¨æ–¹å¼ï¼Œæ˜¯é€‰ä¼˜å…ˆåˆ°è¾¾çš„å—ï¼Œå°±æ˜¯1minçš„checkpointå’Œ128mbçš„file&#010;sizeï¼Œä¸ç®¡å“ªä¸ªå…ˆåˆ°éƒ½ä¼šæ»šåŠ¨ç”Ÿæˆæ–°çš„æ–‡ä»¶&#010;&#010;ã€‹å¯ä»¥ï¼Œé»˜è®¤ä¸‹ 128MB æ»šåŠ¨ï¼ŒCheckpoint æ»šåŠ¨&#010;&#010;Jingsong Li &lt;jingsonglee0@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ6:12å†™é“ï¼š&#010;&#010;&gt; Hi Dream,&#010;&gt;&#010;&gt; &gt; 1.ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;&gt;&#010;&gt; ä¸ç”¨ï¼Œå“ªè¾¹å»ºæ— æ‰€è°“&#010;&gt;&#010;&gt; &gt; 2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&gt;&#010;&gt; å¯ä»¥ï¼Œé»˜è®¤ä¸‹ 128MB æ»šåŠ¨ï¼ŒCheckpoint æ»šåŠ¨ã€‚&#010;&gt;&#010;&gt; Best,&#010;&gt; Jingsong&#010;&gt;&#010;&gt; On Mon, Jul 20, 2020 at 5:15 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&gt;&#010;&gt; &gt;  hi&#010;&gt; &gt; å¥½çš„ï¼Œæƒ³é—®ä¸€ä¸‹streamå†™hiveè¡¨çš„æ—¶å€™ï¼š&#010;&gt; &gt; 1ã€ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;&gt; &gt; 2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&gt; &gt;&#010;&gt; &gt; Rui Li &lt;lirui.fudan@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ4:44å†™é“ï¼š&#010;&gt; &gt;&#010;&gt; &gt; &gt; tableEnv.executeSqlå°±å·²ç»æäº¤ä½œä¸šäº†ï¼Œä¸éœ€è¦å†æ‰§è¡Œexecuteäº†å“ˆ&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; On Mon, Jul 20, 2020 at 4:29 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; hiï¼Œæˆ‘è¿™é¢è¯·ä¸€ä¸ªä¸€ä¸ªkafkaåˆ°hiveçš„ç¨‹åºï¼Œä½†ç¨‹åºæ— æ³•è¿è¡Œï¼Œè¯·é—®ä»€ä¹ˆåŸå› ï¼š&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; å¼‚å¸¸ï¼š&#010;&gt; &gt; &gt; &gt; The program finished with the following exception:&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; org.apache.flink.client.program.ProgramInvocationException: The main&#010;&gt; &gt; &gt; method&#010;&gt; &gt; &gt; &gt; caused an error: No operators defined in streaming topology. Cannot&#010;&gt; &gt; &gt; &gt; generate StreamGraph.&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;&gt; &gt; &gt; &gt; at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;&gt; &gt; &gt; &gt; at java.security.AccessController.doPrivileged(Native Method)&#010;&gt; &gt; &gt; &gt; at javax.security.auth.Subject.doAs(Subject.java:422)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;&gt; &gt; &gt; &gt; at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&gt; &gt; &gt; &gt; Caused by: java.lang.IllegalStateException: No operators defined in&#010;&gt; &gt; &gt; &gt; streaming topology. Cannot generate StreamGraph.&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.utils.ExecutorUtils.generateStreamGraph(ExecutorUtils.java:47)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.StreamExecutor.createPipeline(StreamExecutor.java:47)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; com.akulaku.data.flink.StreamingWriteToHive.main(StreamingWriteToHive.java:80)&#010;&gt; &gt; &gt; &gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt; &gt; &gt; &gt; at java.lang.reflect.Method.invoke(Method.java:498)&#010;&gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;&gt; &gt; &gt; &gt; ... 11 more&#010;&gt; &gt; &gt; &gt; ä»£ç ï¼š&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;  StreamExecutionEnvironment environment =&#010;&gt; &gt; &gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt; &gt; &gt;         EnvironmentSettings settings =&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();&#010;&gt; &gt; &gt; &gt;         StreamTableEnvironment tableEnv =&#010;&gt; &gt; &gt; &gt; StreamTableEnvironment.create(environment, settings);&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; environment.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &gt; &gt; &gt;         environment.setStateBackend(new MemoryStateBackend());&#010;&gt; &gt; &gt; &gt;&#010;&gt;  environment.getCheckpointConfig().setCheckpointInterval(5000);&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;         String name = \"myhive\";&#010;&gt; &gt; &gt; &gt;         String defaultDatabase = \"tmp\";&#010;&gt; &gt; &gt; &gt;         String hiveConfDir = \"/etc/alternatives/hive-conf/\";&#010;&gt; &gt; &gt; &gt;         String version = \"1.1.0\";&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; &gt; &gt; hiveConfDir, version);&#010;&gt; &gt; &gt; &gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt; &gt; &gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.user_behavior (\\n\" +&#010;&gt; &gt; &gt; &gt;                 \"  user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; &gt;                 \"  item_id STRING,\\n\" +&#010;&gt; &gt; &gt; &gt;                 \"  behavior STRING,\\n\" +&#010;&gt; &gt; &gt; &gt;                 \"  ts AS PROCTIME()\\n\" +&#010;&gt; &gt; &gt; &gt;                 \") WITH (\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'connector' = 'kafka-0.11',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'topic' = 'user_behavior',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'properties.bootstrap.servers' =&#010;&gt; &gt; 'localhost:9092',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'properties.group.id' = 'testGroup',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'scan.startup.mode' = 'earliest-offset',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'format' = 'json',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'json.fail-on-missing-field' = 'false',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'json.ignore-parse-errors' = 'true'\\n\" +&#010;&gt; &gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; //        tableEnv.executeSql(\"CREATE TABLE print_table (\\n\" +&#010;&gt; &gt; &gt; &gt; //                \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; &gt; //                \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; //                \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; //                \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt; &gt; //                \") WITH (\\n\" +&#010;&gt; &gt; &gt; &gt; //                \" 'connector' = 'print'\\n\" +&#010;&gt; &gt; &gt; &gt; //                \")\");&#010;&gt; &gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.streamhivetest (\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt; &gt;                 \") STORED AS parquet TBLPROPERTIES (\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'sink.rolling-policy.file-size' = '12MB',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'sink.rolling-policy.rollover-interval' = '1&#010;&gt; &gt; min',\\n\" +&#010;&gt; &gt; &gt; &gt;                 \" 'sink.rolling-policy.check-interval' = '1 min',\\n\"&#010;&gt; +&#010;&gt; &gt; &gt; &gt;                 \" 'execution.checkpointing.interval' = 'true'\\n\" +&#010;&gt; &gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt; &gt; &gt;         tableEnv.executeSql(\"insert into streamhivetest select&#010;&gt; &gt; &gt; &gt; user_id,item_id,behavior,DATE_FORMAT(ts, 'yyyy-MM-dd') as tsdata from&#010;&gt; &gt; &gt; &gt; user_behavior\");&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;         tableEnv.execute(\"stream-write-hive\");&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; --&#010;&gt; &gt; &gt; Best regards!&#010;&gt; &gt; &gt; Rui Li&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt;&#010;&gt;&#010;&gt; --&#010;&gt; Best, Jingsong Lee&#010;&gt;&#010;&#010;",
        "depth": "4",
        "reply": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>"
    },
    {
        "id": "<CABi+2jRq9mzxMeT6oO-bowYazu0qBCGxfawXwLUKzZMvqw6zPw@mail.gmail.com>",
        "from": "Jingsong Li &lt;jingsongl...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 11:23:03 GMT",
        "subject": "Re: flink1.11 run",
        "content": "æ˜¯çš„ã€‚&#010;&#010;ä½†æ˜¯ä¸ç®¡æ€ä¹ˆæ»šåŠ¨ï¼Œæœ€ç»ˆéƒ½æ˜¯checkpointå®Œæˆåæ–‡ä»¶æ‰å¯è§&#010;&#010;On Mon, Jul 20, 2020 at 7:10 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&#010;&gt; hiã€&#010;&gt; å¯¹äºä¸‹é¢è¿™ä¸¤ä¸ªçš„æ»šåŠ¨æ–¹å¼ï¼Œæ˜¯é€‰ä¼˜å…ˆåˆ°è¾¾çš„å—ï¼Œå°±æ˜¯1minçš„checkpointå’Œ128mbçš„file&#010;sizeï¼Œä¸ç®¡å“ªä¸ªå…ˆåˆ°éƒ½ä¼šæ»šåŠ¨ç”Ÿæˆæ–°çš„æ–‡ä»¶&#010;&gt;&#010;&gt; ã€‹å¯ä»¥ï¼Œé»˜è®¤ä¸‹ 128MB æ»šåŠ¨ï¼ŒCheckpoint æ»šåŠ¨&#010;&gt;&#010;&gt; Jingsong Li &lt;jingsonglee0@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ6:12å†™é“ï¼š&#010;&gt;&#010;&gt; &gt; Hi Dream,&#010;&gt; &gt;&#010;&gt; &gt; &gt; 1.ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;&gt; &gt;&#010;&gt; &gt; ä¸ç”¨ï¼Œå“ªè¾¹å»ºæ— æ‰€è°“&#010;&gt; &gt;&#010;&gt; &gt; &gt; 2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&gt; &gt;&#010;&gt; &gt; å¯ä»¥ï¼Œé»˜è®¤ä¸‹ 128MB æ»šåŠ¨ï¼ŒCheckpoint æ»šåŠ¨ã€‚&#010;&gt; &gt;&#010;&gt; &gt; Best,&#010;&gt; &gt; Jingsong&#010;&gt; &gt;&#010;&gt; &gt; On Mon, Jul 20, 2020 at 5:15 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&gt; &gt;&#010;&gt; &gt; &gt;  hi&#010;&gt; &gt; &gt; å¥½çš„ï¼Œæƒ³é—®ä¸€ä¸‹streamå†™hiveè¡¨çš„æ—¶å€™ï¼š&#010;&gt; &gt; &gt; 1ã€ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;&gt; &gt; &gt; 2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; Rui Li &lt;lirui.fudan@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ4:44å†™é“ï¼š&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; tableEnv.executeSqlå°±å·²ç»æäº¤ä½œä¸šäº†ï¼Œä¸éœ€è¦å†æ‰§è¡Œexecuteäº†å“ˆ&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; On Mon, Jul 20, 2020 at 4:29 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt;&#010;&gt; wrote:&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt; hiï¼Œæˆ‘è¿™é¢è¯·ä¸€ä¸ªä¸€ä¸ªkafkaåˆ°hiveçš„ç¨‹åºï¼Œä½†ç¨‹åºæ— æ³•è¿è¡Œï¼Œè¯·é—®ä»€ä¹ˆåŸå› ï¼š&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt; å¼‚å¸¸ï¼š&#010;&gt; &gt; &gt; &gt; &gt; The program finished with the following exception:&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt; org.apache.flink.client.program.ProgramInvocationException: The&#010;&gt; main&#010;&gt; &gt; &gt; &gt; method&#010;&gt; &gt; &gt; &gt; &gt; caused an error: No operators defined in streaming topology. Cannot&#010;&gt; &gt; &gt; &gt; &gt; generate StreamGraph.&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;&gt; &gt; &gt; &gt; &gt; at java.security.AccessController.doPrivileged(Native Method)&#010;&gt; &gt; &gt; &gt; &gt; at javax.security.auth.Subject.doAs(Subject.java:422)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&gt; &gt; &gt; &gt; &gt; Caused by: java.lang.IllegalStateException: No operators defined&#010;in&#010;&gt; &gt; &gt; &gt; &gt; streaming topology. Cannot generate StreamGraph.&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.utils.ExecutorUtils.generateStreamGraph(ExecutorUtils.java:47)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.StreamExecutor.createPipeline(StreamExecutor.java:47)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; com.akulaku.data.flink.StreamingWriteToHive.main(StreamingWriteToHive.java:80)&#010;&gt; &gt; &gt; &gt; &gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt; &gt; &gt; &gt; &gt; at java.lang.reflect.Method.invoke(Method.java:498)&#010;&gt; &gt; &gt; &gt; &gt; at&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;&gt; &gt; &gt; &gt; &gt; ... 11 more&#010;&gt; &gt; &gt; &gt; &gt; ä»£ç ï¼š&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;  StreamExecutionEnvironment environment =&#010;&gt; &gt; &gt; &gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt; &gt; &gt; &gt;         EnvironmentSettings settings =&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();&#010;&gt; &gt; &gt; &gt; &gt;         StreamTableEnvironment tableEnv =&#010;&gt; &gt; &gt; &gt; &gt; StreamTableEnvironment.create(environment, settings);&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; environment.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &gt; &gt; &gt; &gt;         environment.setStateBackend(new MemoryStateBackend());&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt;  environment.getCheckpointConfig().setCheckpointInterval(5000);&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;         String name = \"myhive\";&#010;&gt; &gt; &gt; &gt; &gt;         String defaultDatabase = \"tmp\";&#010;&gt; &gt; &gt; &gt; &gt;         String hiveConfDir = \"/etc/alternatives/hive-conf/\";&#010;&gt; &gt; &gt; &gt; &gt;         String version = \"1.1.0\";&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; &gt; &gt; &gt; hiveConfDir, version);&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.user_behavior (\\n\"&#010;+&#010;&gt; &gt; &gt; &gt; &gt;                 \"  user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \"  item_id STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \"  behavior STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \"  ts AS PROCTIME()\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \") WITH (\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'connector' = 'kafka-0.11',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'topic' = 'user_behavior',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'properties.bootstrap.servers' =&#010;&gt; &gt; &gt; 'localhost:9092',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'properties.group.id' = 'testGroup',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'scan.startup.mode' = 'earliest-offset',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'format' = 'json',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'json.fail-on-missing-field' = 'false',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'json.ignore-parse-errors' = 'true'\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt; //        tableEnv.executeSql(\"CREATE TABLE print_table (\\n\" +&#010;&gt; &gt; &gt; &gt; &gt; //                \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt; //                \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt; //                \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt; //                \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt; &gt; &gt; //                \") WITH (\\n\" +&#010;&gt; &gt; &gt; &gt; &gt; //                \" 'connector' = 'print'\\n\" +&#010;&gt; &gt; &gt; &gt; &gt; //                \")\");&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.streamhivetest (\\n\"&#010;+&#010;&gt; &gt; &gt; &gt; &gt;                 \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \") STORED AS parquet TBLPROPERTIES (\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'sink.rolling-policy.file-size' = '12MB',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'sink.rolling-policy.rollover-interval' = '1&#010;&gt; &gt; &gt; min',\\n\" +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'sink.rolling-policy.check-interval' = '1&#010;&gt; min',\\n\"&#010;&gt; &gt; +&#010;&gt; &gt; &gt; &gt; &gt;                 \" 'execution.checkpointing.interval' = 'true'\\n\"&#010;+&#010;&gt; &gt; &gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.executeSql(\"insert into streamhivetest select&#010;&gt; &gt; &gt; &gt; &gt; user_id,item_id,behavior,DATE_FORMAT(ts, 'yyyy-MM-dd') as tsdata&#010;&gt; from&#010;&gt; &gt; &gt; &gt; &gt; user_behavior\");&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; &gt;         tableEnv.execute(\"stream-write-hive\");&#010;&gt; &gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt; &gt; --&#010;&gt; &gt; &gt; &gt; Best regards!&#010;&gt; &gt; &gt; &gt; Rui Li&#010;&gt; &gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt; --&#010;&gt; &gt; Best, Jingsong Lee&#010;&gt; &gt;&#010;&gt;&#010;&#010;&#010;-- &#010;Best, Jingsong Lee&#010;&#010;",
        "depth": "5",
        "reply": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>"
    },
    {
        "id": "<CADH6UNSST2j3GOB6SCCqbqx7uuMvq_gteO3zzOC=i2XVR9QoVA@mail.gmail.com>",
        "from": "Rui Li &lt;lirui.fu...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 02:37:03 GMT",
        "subject": "Re: flink1.11 run",
        "content": "å¯ä»¥å†™å·²æœ‰çš„è¡¨ï¼Œç›¸å…³çš„é…ç½® [1] éœ€è¦æ·»åŠ åˆ°è¡¨çš„propertyå½“ä¸­ã€‚&#010;&#010;[1]&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/hive_streaming.html#streaming-writing&#010;&#010;On Mon, Jul 20, 2020 at 5:14 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&#010;&gt;  hi&#010;&gt; å¥½çš„ï¼Œæƒ³é—®ä¸€ä¸‹streamå†™hiveè¡¨çš„æ—¶å€™ï¼š&#010;&gt; 1ã€ä¸€å®šè¦åœ¨flinkå†…éƒ¨å…ˆå»ºç«‹hiveè¡¨å—ï¼Ÿ&#010;&gt; 2ã€å¦‚æœç›´æ¥å†™hiveå†…ï¼ˆhueå»ºè¡¨ï¼‰å·²ç»å»ºå¥½çš„hiveè¡¨å¯ä»¥å—ï¼Œæ–‡ä»¶ä¼šæœ‰æ»šåŠ¨ç­–ç•¥å—&#010;&gt;&#010;&gt; Rui Li &lt;lirui.fudan@gmail.com&gt; äº2020å¹´7æœˆ20æ—¥å‘¨ä¸€ ä¸‹åˆ4:44å†™é“ï¼š&#010;&gt;&#010;&gt; &gt; tableEnv.executeSqlå°±å·²ç»æäº¤ä½œä¸šäº†ï¼Œä¸éœ€è¦å†æ‰§è¡Œexecuteäº†å“ˆ&#010;&gt; &gt;&#010;&gt; &gt; On Mon, Jul 20, 2020 at 4:29 PM Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#010;&gt; &gt;&#010;&gt; &gt; &gt; hiï¼Œæˆ‘è¿™é¢è¯·ä¸€ä¸ªä¸€ä¸ªkafkaåˆ°hiveçš„ç¨‹åºï¼Œä½†ç¨‹åºæ— æ³•è¿è¡Œï¼Œè¯·é—®ä»€ä¹ˆåŸå› ï¼š&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; å¼‚å¸¸ï¼š&#010;&gt; &gt; &gt; The program finished with the following exception:&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; org.apache.flink.client.program.ProgramInvocationException: The main&#010;&gt; &gt; method&#010;&gt; &gt; &gt; caused an error: No operators defined in streaming topology. Cannot&#010;&gt; &gt; &gt; generate StreamGraph.&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:302)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:149)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:699)&#010;&gt; &gt; &gt; at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:232)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:916)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:992)&#010;&gt; &gt; &gt; at java.security.AccessController.doPrivileged(Native Method)&#010;&gt; &gt; &gt; at javax.security.auth.Subject.doAs(Subject.java:422)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&#010;&gt; &gt; &gt; at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:992)&#010;&gt; &gt; &gt; Caused by: java.lang.IllegalStateException: No operators defined in&#010;&gt; &gt; &gt; streaming topology. Cannot generate StreamGraph.&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.utils.ExecutorUtils.generateStreamGraph(ExecutorUtils.java:47)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.planner.delegation.StreamExecutor.createPipeline(StreamExecutor.java:47)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; com.akulaku.data.flink.StreamingWriteToHive.main(StreamingWriteToHive.java:80)&#010;&gt; &gt; &gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt; &gt; &gt; at java.lang.reflect.Method.invoke(Method.java:498)&#010;&gt; &gt; &gt; at&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:288)&#010;&gt; &gt; &gt; ... 11 more&#010;&gt; &gt; &gt; ä»£ç ï¼š&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;  StreamExecutionEnvironment environment =&#010;&gt; &gt; &gt; StreamExecutionEnvironment.getExecutionEnvironment();&#010;&gt; &gt; &gt;         EnvironmentSettings settings =&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();&#010;&gt; &gt; &gt;         StreamTableEnvironment tableEnv =&#010;&gt; &gt; &gt; StreamTableEnvironment.create(environment, settings);&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; environment.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);&#010;&gt; &gt; &gt;         environment.setStateBackend(new MemoryStateBackend());&#010;&gt; &gt; &gt;         environment.getCheckpointConfig().setCheckpointInterval(5000);&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         String name = \"myhive\";&#010;&gt; &gt; &gt;         String defaultDatabase = \"tmp\";&#010;&gt; &gt; &gt;         String hiveConfDir = \"/etc/alternatives/hive-conf/\";&#010;&gt; &gt; &gt;         String version = \"1.1.0\";&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         HiveCatalog hive = new HiveCatalog(name, defaultDatabase,&#010;&gt; &gt; &gt; hiveConfDir, version);&#010;&gt; &gt; &gt;         tableEnv.registerCatalog(\"myhive\", hive);&#010;&gt; &gt; &gt;         tableEnv.useCatalog(\"myhive\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.user_behavior (\\n\" +&#010;&gt; &gt; &gt;                 \"  user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt;                 \"  item_id STRING,\\n\" +&#010;&gt; &gt; &gt;                 \"  behavior STRING,\\n\" +&#010;&gt; &gt; &gt;                 \"  ts AS PROCTIME()\\n\" +&#010;&gt; &gt; &gt;                 \") WITH (\\n\" +&#010;&gt; &gt; &gt;                 \" 'connector' = 'kafka-0.11',\\n\" +&#010;&gt; &gt; &gt;                 \" 'topic' = 'user_behavior',\\n\" +&#010;&gt; &gt; &gt;                 \" 'properties.bootstrap.servers' =&#010;&gt; 'localhost:9092',\\n\" +&#010;&gt; &gt; &gt;                 \" 'properties.group.id' = 'testGroup',\\n\" +&#010;&gt; &gt; &gt;                 \" 'scan.startup.mode' = 'earliest-offset',\\n\" +&#010;&gt; &gt; &gt;                 \" 'format' = 'json',\\n\" +&#010;&gt; &gt; &gt;                 \" 'json.fail-on-missing-field' = 'false',\\n\" +&#010;&gt; &gt; &gt;                 \" 'json.ignore-parse-errors' = 'true'\\n\" +&#010;&gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt; //        tableEnv.executeSql(\"CREATE TABLE print_table (\\n\" +&#010;&gt; &gt; &gt; //                \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt; //                \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt; //                \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt; //                \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt; //                \") WITH (\\n\" +&#010;&gt; &gt; &gt; //                \" 'connector' = 'print'\\n\" +&#010;&gt; &gt; &gt; //                \")\");&#010;&gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);&#010;&gt; &gt; &gt;         tableEnv.executeSql(\"CREATE TABLE tmp.streamhivetest (\\n\" +&#010;&gt; &gt; &gt;                 \" user_id BIGINT,\\n\" +&#010;&gt; &gt; &gt;                 \" item_id STRING,\\n\" +&#010;&gt; &gt; &gt;                 \" behavior STRING,\\n\" +&#010;&gt; &gt; &gt;                 \" tsdata STRING\\n\" +&#010;&gt; &gt; &gt;                 \") STORED AS parquet TBLPROPERTIES (\\n\" +&#010;&gt; &gt; &gt;                 \" 'sink.rolling-policy.file-size' = '12MB',\\n\" +&#010;&gt; &gt; &gt;                 \" 'sink.rolling-policy.rollover-interval' = '1&#010;&gt; min',\\n\" +&#010;&gt; &gt; &gt;                 \" 'sink.rolling-policy.check-interval' = '1 min',\\n\" +&#010;&gt; &gt; &gt;                 \" 'execution.checkpointing.interval' = 'true'\\n\" +&#010;&gt; &gt; &gt;                 \")\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);&#010;&gt; &gt; &gt;         tableEnv.executeSql(\"insert into streamhivetest select&#010;&gt; &gt; &gt; user_id,item_id,behavior,DATE_FORMAT(ts, 'yyyy-MM-dd') as tsdata from&#010;&gt; &gt; &gt; user_behavior\");&#010;&gt; &gt; &gt;&#010;&gt; &gt; &gt;         tableEnv.execute(\"stream-write-hive\");&#010;&gt; &gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt;&#010;&gt; &gt; --&#010;&gt; &gt; Best regards!&#010;&gt; &gt; Rui Li&#010;&gt; &gt;&#010;&gt;&#010;&#010;&#010;-- &#010;Best regards!&#010;Rui Li&#010;&#010;",
        "depth": "3",
        "reply": "<CAEZk043sO+0RtHCNFLg7_rDv0QyR-L0jLwY1JjYW2LHrwJLHgA@mail.gmail.com>"
    },
    {
        "id": "<tencent_A24CB98A6B82517D3BC96928154713285B0A@qq.com>",
        "from": "&quot;jiafu&quot; &lt;530496...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 11:31:28 GMT",
        "subject": "é•¿æ—¶é—´è¿è¡Œçš„flinkä»»åŠ¡ä¼šæœ‰ä»¥ä¸‹æŠ¥é”™",
        "content": "flinkä»»åŠ¡è¿è¡Œæ—¶ä¼šæœ‰ä»¥ä¸‹çš„æŠ¥é”™ï¼Œç”¨çš„æ˜¯flink-1.8.1&#013;&#010;org.apache.flink.runtime.executiongraph.ExecutionGraphException: Trying to eagerly schedule&#010;a task whose inputs are not ready (result type: PIPELINED_BOUNDED, partition consumable: false,&#010;producer state: SCHEDULED, producer slot: null). &#009;at org.apache.flink.runtime.deployment.InputChannelDeploymentDescriptor.fromEdges(InputChannelDeploymentDescriptor.java:145)&#010;&#009;at org.apache.flink.runtime.executiongraph.ExecutionVertex.createDeploymentDescriptor(ExecutionVertex.java:840)&#010;&#009;at org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:621) &#009;at org.apache.flink.util.function.ThrowingRunnable.lambda$unchecked$0(ThrowingRunnable.java:50)&#010;&#009;at java.util.concurrent.CompletableFuture.uniRun(CompletableFuture.java:705) &#009;at java.util.concurrent.CompletableFuture.uniRunStage(CompletableFuture.java:717)&#010;&#009;at java.util.concurrent.CompletableFuture.thenRun(CompletableFuture.java:2010) &#009;at org.apache.flink.runtime.executiongraph.Execution.scheduleForExecution(Execution.java:436)&#010;&#009;at org.apache.flink.runtime.executiongraph.ExecutionVertex.scheduleForExecution(ExecutionVertex.java:637)&#010;&#009;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.restart(FailoverRegion.java:229)&#010;&#009;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.reset(FailoverRegion.java:186)&#010;&#009;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.allVerticesInTerminalState(FailoverRegion.java:96)&#010;&#009;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.lambda$cancel$0(FailoverRegion.java:146)&#010;&#009;at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:656) &#009;at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:632)&#010;&#009;at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) &#009;at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)&#010;&#009;at org.apache.flink.runtime.concurrent.FutureUtils$WaitingConjunctFuture.handleCompletedFuture(FutureUtils.java:633)&#010;&#009;at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) &#009;at&#010;java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)&#010;&#009;at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) &#009;at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)&#010;&#009;at org.apache.flink.runtime.executiongraph.Execution.lambda$releaseAssignedResource$11(Execution.java:1350)&#010;&#009;at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) &#009;at&#010;java.util.concurrent.CompletableFuture.uniWhenCompleteStage(CompletableFuture.java:778) &#009;at&#010;java.util.concurrent.CompletableFuture.whenComplete(CompletableFuture.java:2140) &#009;at org.apache.flink.runtime.executiongraph.Execution.releaseAssignedResource(Execution.java:1345)&#010;&#009;at org.apache.flink.runtime.executiongraph.Execution.finishCancellation(Execution.java:1115)&#010;&#009;at org.apache.flink.runtime.executiongraph.Execution.completeCancelling(Execution.java:1094)&#010;&#009;at org.apache.flink.runtime.executiongraph.ExecutionGraph.updateState(ExecutionGraph.java:1628)&#010;&#009;at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:517)&#010;&#009;at sun.reflect.GeneratedMethodAccessor63.invoke(Unknown Source) &#009;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&#009;at java.lang.reflect.Method.invoke(Method.java:498) &#009;at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:274)&#010;&#009;at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:189)&#010;&#009;at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)&#010;&#009;at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.onReceive(AkkaRpcActor.java:147) &#009;at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.onReceive(FencedAkkaRpcActor.java:40)&#010;&#009;at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165) &#009;at akka.actor.Actor$class.aroundReceive(Actor.scala:502)&#010;&#009;at akka.actor.UntypedActor.aroundReceive(UntypedActor.scala:95) &#009;at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526)&#010;&#009;at akka.actor.ActorCell.invoke(ActorCell.scala:495) &#009;at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257)&#010;&#009;at akka.dispatch.Mailbox.run(Mailbox.scala:224) &#009;at akka.dispatch.Mailbox.exec(Mailbox.scala:234)&#010;&#009;at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) &#009;at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)&#010;&#009;at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) &#009;at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)",
        "depth": "0",
        "reply": "<tencent_A24CB98A6B82517D3BC96928154713285B0A@qq.com>"
    },
    {
        "id": "<202007201950300801251@163.com>",
        "from": "&quot;sjlsumaitong@163.com&quot; &lt;sjlsumait...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Mon, 20 Jul 2020 11:50:30 GMT",
        "subject": "å›å¤: é•¿æ—¶é—´è¿è¡Œçš„flinkä»»åŠ¡ä¼šæœ‰ä»¥ä¸‹æŠ¥é”™",
        "content": "åŒé—®ï¼Œå¤§ä½¬çœ‹åˆ°å¸®ä¸‹å¿™ï¼&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;sjlsumaitong@163.com&#013;&#010; &#013;&#010;å‘ä»¶äººï¼š jiafu&#013;&#010;å‘é€æ—¶é—´ï¼š 2020-07-20 19:31&#013;&#010;æ”¶ä»¶äººï¼š user-zh&#013;&#010;ä¸»é¢˜ï¼š é•¿æ—¶é—´è¿è¡Œçš„flinkä»»åŠ¡ä¼šæœ‰ä»¥ä¸‹æŠ¥é”™&#013;&#010;flinkä»»åŠ¡è¿è¡Œæ—¶ä¼šæœ‰ä»¥ä¸‹çš„æŠ¥é”™ï¼Œç”¨çš„æ˜¯flink-1.8.1&#013;&#010;org.apache.flink.runtime.executiongraph.ExecutionGraphException: Trying to eagerly schedule&#010;a task whose inputs are not ready (result type: PIPELINED_BOUNDED, partition consumable: false,&#010;producer state: SCHEDULED, producer slot: null). at org.apache.flink.runtime.deployment.InputChannelDeploymentDescriptor.fromEdges(InputChannelDeploymentDescriptor.java:145)&#010;at org.apache.flink.runtime.executiongraph.ExecutionVertex.createDeploymentDescriptor(ExecutionVertex.java:840)&#010;at org.apache.flink.runtime.executiongraph.Execution.deploy(Execution.java:621) at org.apache.flink.util.function.ThrowingRunnable.lambda$unchecked$0(ThrowingRunnable.java:50)&#010;at java.util.concurrent.CompletableFuture.uniRun(CompletableFuture.java:705) at java.util.concurrent.CompletableFuture.uniRunStage(CompletableFuture.java:717)&#010;at java.util.concurrent.CompletableFuture.thenRun(CompletableFuture.java:2010) at org.apache.flink.runtime.executiongraph.Execution.scheduleForExecution(Execution.java:436)&#010;at org.apache.flink.runtime.executiongraph.ExecutionVertex.scheduleForExecution(ExecutionVertex.java:637)&#010;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.restart(FailoverRegion.java:229)&#010;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.reset(FailoverRegion.java:186)&#010;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.allVerticesInTerminalState(FailoverRegion.java:96)&#010;at org.apache.flink.runtime.executiongraph.failover.FailoverRegion.lambda$cancel$0(FailoverRegion.java:146)&#010;at java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:656) at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:632)&#010;at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)&#010;at org.apache.flink.runtime.concurrent.FutureUtils$WaitingConjunctFuture.handleCompletedFuture(FutureUtils.java:633)&#010;at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)&#010;at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)&#010;at org.apache.flink.runtime.executiongraph.Execution.lambda$releaseAssignedResource$11(Execution.java:1350)&#010;at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) at java.util.concurrent.CompletableFuture.uniWhenCompleteStage(CompletableFuture.java:778)&#010;at java.util.concurrent.CompletableFuture.whenComplete(CompletableFuture.java:2140) at org.apache.flink.runtime.executiongraph.Execution.releaseAssignedResource(Execution.java:1345)&#010;at org.apache.flink.runtime.executiongraph.Execution.finishCancellation(Execution.java:1115)&#010;at org.apache.flink.runtime.executiongraph.Execution.completeCancelling(Execution.java:1094)&#010;at org.apache.flink.runtime.executiongraph.ExecutionGraph.updateState(ExecutionGraph.java:1628)&#010;at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:517)&#010;at sun.reflect.GeneratedMethodAccessor63.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:274)&#010;at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:189)&#010;at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)&#010;at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.onReceive(AkkaRpcActor.java:147) at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.onReceive(FencedAkkaRpcActor.java:40)&#010;at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165) at akka.actor.Actor$class.aroundReceive(Actor.scala:502)&#010;at akka.actor.UntypedActor.aroundReceive(UntypedActor.scala:95) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526)&#010;at akka.actor.ActorCell.invoke(ActorCell.scala:495) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257)&#010;at akka.dispatch.Mailbox.run(Mailbox.scala:224) at akka.dispatch.Mailbox.exec(Mailbox.scala:234)&#010;at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)&#010;at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)&#013;&#010;",
        "depth": "1",
        "reply": "<tencent_A24CB98A6B82517D3BC96928154713285B0A@qq.com>"
    },
    {
        "id": "<tencent_2FC2E25192A00A190FB7BC787AE9FC8D800A@qq.com>",
        "from": "&quot;è’‹ä½³æˆ(Jiacheng Jiang)&quot; &lt;920334...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 01:27:56 GMT",
        "subject": "liststate",
        "content": "å¤§å®¶å¥½ï¼š&#013;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;æˆ‘å‘ç°RocksDBListState#getæ–¹æ³•æ˜¯ä¸€æ¬¡æ€§æŠŠæ•°æ®å…¨åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œå¦‚æœlistå¤ªå¤§è¿™æ ·ä¼šä¸ä¼šé€ æˆå†…å­˜æº¢å‡ºã€‚å¯ä¸å¯ä»¥åœ¨nextæ–¹æ³•ä¸­æ‰åŠ è½½æ•°æ®ï¼Ÿ",
        "depth": "0",
        "reply": "<tencent_2FC2E25192A00A190FB7BC787AE9FC8D800A@qq.com>"
    },
    {
        "id": "<CAA8tFvs9QzAHqhVmVY0_vhdMU=3X6G6beboxjaJ6wYnrUz_AvA@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:05:39 GMT",
        "subject": "Re: liststate",
        "content": "Hi&#013;&#010;&#013;&#010;ListState ä¸­çš„ value æ˜¯ä¸€ä¸ªæ•´ä½“ï¼Œæ‰€ä»¥ä¸€æ¬¡æ€§ä¼šå–å›æ¥ï¼Œç°åœ¨ RocksDBMapStat&#010;ä¸­æœ‰ä¸€äº›æ“ä½œ&#013;&#010;(iterator/entries/values ç­‰ï¼‰æ˜¯ä½¿ç”¨ next æ–¹æ³•åŠ è½½çš„ã€‚&#013;&#010;&#013;&#010;Best,&#013;&#010;Congxian&#013;&#010;&#013;&#010;&#013;&#010;è’‹ä½³æˆ(Jiacheng Jiang) &lt;920334586@qq.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸Šåˆ9:28å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; å¤§å®¶å¥½ï¼š&#013;&#010;&gt; &amp;nbsp; &amp;nbsp;&#013;&#010;&gt; &amp;nbsp;æˆ‘å‘ç°RocksDBListState#getæ–¹æ³•æ˜¯ä¸€æ¬¡æ€§æŠŠæ•°æ®å…¨åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œå¦‚æœlistå¤ªå¤§è¿™æ ·ä¼šä¸ä¼šé€ æˆå†…å­˜æº¢å‡ºã€‚å¯ä¸å¯ä»¥åœ¨nextæ–¹æ³•ä¸­æ‰åŠ è½½æ•°æ®ï¼Ÿ&#013;&#010;",
        "depth": "1",
        "reply": "<tencent_2FC2E25192A00A190FB7BC787AE9FC8D800A@qq.com>"
    },
    {
        "id": "<32a8e5d8.23a8.1736f6d1a0c.Coremail.felixzh2020@126.com>",
        "from": "felixzh &lt;felixzh2...@126.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:31:27 GMT",
        "subject": "Flinkæ•´åˆhiveä¹‹åï¼Œé€šè¿‡flinkåˆ›å»ºçš„è¡¨ï¼Œhive beelineå¯è§è¡¨ï¼Œä¸å¯è§å­—æ®µï¼Ÿ",
        "content": "å‚ç…§æ–‡æ¡£https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#connecting-to-hive&#010;é€šè¿‡flinkåˆ›å»ºè¡¨ï¼šCREATE TABLE Orders (product STRING, amount INT)&#010;åœ¨beelineç«¯å¯è§è¡¨ï¼Œä½†æ˜¯descçœ‹ä¸åˆ°å­—æ®µï¼Œselect * from ordersä¹Ÿä¸å¯ç”¨&#010;&#010;",
        "depth": "0",
        "reply": "<32a8e5d8.23a8.1736f6d1a0c.Coremail.felixzh2020@126.com>"
    },
    {
        "id": "<CABi+2jTC0pcz4K2QmhRPRQwPy79CRspGz7qr-sQp7fuYkY99iQ@mail.gmail.com>",
        "from": "Jingsong Li &lt;jingsongl...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:34:18 GMT",
        "subject": "Re: Flinkæ•´åˆhiveä¹‹åï¼Œé€šè¿‡flinkåˆ›å»ºçš„è¡¨ï¼Œhive beelineå¯è§è¡¨ï¼Œä¸å¯è§å­—æ®µï¼Ÿ",
        "content": "é»˜è®¤åˆ›å»ºçš„æ˜¯Flinkè¡¨ï¼ŒHiveç«¯ä¸å¯è§ã€‚&#013;&#010;ä½ æƒ³åˆ›å»ºHiveè¡¨çš„è¯ï¼Œç”¨Hive dialectã€‚&#013;&#010;&#013;&#010;Best,&#013;&#010;Jingsong&#013;&#010;&#013;&#010;On Tue, Jul 21, 2020 at 11:31 AM felixzh &lt;felixzh2020@126.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; å‚ç…§æ–‡æ¡£&#013;&#010;&gt; https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/hive/#connecting-to-hive&#013;&#010;&gt; é€šè¿‡flinkåˆ›å»ºè¡¨ï¼šCREATE TABLE Orders (product STRING, amount INT)&#013;&#010;&gt; åœ¨beelineç«¯å¯è§è¡¨ï¼Œä½†æ˜¯descçœ‹ä¸åˆ°å­—æ®µï¼Œselect * from ordersä¹Ÿä¸å¯ç”¨&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&#013;&#010;-- &#013;&#010;Best, Jingsong Lee&#013;&#010;",
        "depth": "1",
        "reply": "<32a8e5d8.23a8.1736f6d1a0c.Coremail.felixzh2020@126.com>"
    },
    {
        "id": "<6d867f4c.24dc.1736f70e358.Coremail.cxydevelop@163.com>",
        "from": "chenxuying &lt;cxydeve...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:35:36 GMT",
        "subject": "å®˜æ–¹pyflink ä¾‹å­çš„æ‰§è¡Œé—®é¢˜",
        "content": "å®˜æ–¹ä¾‹å­:&#010;https://flink.apache.org/2020/04/09/pyflink-udf-support-flink.html&#010;æŒ‰ç…§ä¾‹å­å†™äº†ç¨‹åº,ä¹Ÿå®‰è£…äº†pyflink&#010;|&#010;python -m pip install apache-flink&#010;|&#010;ä»£ç :&#010;|&#010;from pyflink.datastream import StreamExecutionEnvironment&#010;from pyflink.table import StreamTableEnvironment, DataTypes&#010;from pyflink.table.descriptors import Schema, OldCsv, FileSystem&#010;from pyflink.table.udf import udf&#010;&#010;&#010;env = StreamExecutionEnvironment.get_execution_environment()&#010;env.set_parallelism(1)&#010;t_env = StreamTableEnvironment.create(env)&#010;&#010;&#010;add = udf(lambda i, j: i + j, [DataTypes.BIGINT(), DataTypes.BIGINT()], DataTypes.BIGINT())&#010;&#010;&#010;t_env.register_function(\"add\", add)&#010;&#010;&#010;t_env.connect(FileSystem().path('C:/Users/xuyin/Desktop/docker_compose_test/src.txt')) \\&#010;.with_format(OldCsv()&#010;.field('a', DataTypes.BIGINT())&#010;.field('b', DataTypes.BIGINT())) \\&#010;.with_schema(Schema()&#010;.field('a', DataTypes.BIGINT())&#010;.field('b', DataTypes.BIGINT())) \\&#010;.create_temporary_table('mySource')&#010;&#010;&#010;t_env.connect(FileSystem().path('C:/Users/xuyin/Desktop/docker_compose_test/tar.txt')) \\&#010;.with_format(OldCsv()&#010;.field('sum', DataTypes.BIGINT())) \\&#010;.with_schema(Schema()&#010;.field('sum', DataTypes.BIGINT())) \\&#010;.create_temporary_table('mySink')&#010;&#010;&#010;t_env.from_path('mySource')\\&#010;.select(\"add(a, b)\") \\&#010;.insert_into('mySink')&#010;&#010;&#010;t_env.execute(\"tutorial_job\")&#010;|&#010;&#010;æ‰§è¡Œ:&#010;&#010;|&#010;python test_pyflink.py&#010;|&#010;&#010;æŠ¥é”™:&#010;&#010;&#010;|&#010;Traceback (most recent call last):&#010;  File \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\util\\exceptions.py\",&#010;line 147, in deco&#010;    return f(*a, **kw)&#010;  File \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\py4j\\protocol.py\",&#010;line 328, in get_return_value&#010;    format(target_id, \".\", name), value)&#010;py4j.protocol.Py4JJavaError: An error occurred while calling o2.execute.&#010;: org.apache.flink.table.api.TableException: The configured Task Off-Heap Memory 0 bytes is&#010;less than the least required Python worker Memory 79 mb. The Task Off-Heap Memory can be configured&#010;using the configuration key 'taskmanager.memory.task.off-heap.size'.&#010;        at org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.checkPythonWorkerMemory(CommonPythonBase.scala:158)&#010;        at org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.getMergedConfiguration(CommonPythonBase.scala:119)&#010;        at org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.getConfig(CommonPythonBase.scala:102)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.getConfig(StreamExecPythonCalc.scala:35)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.translateToPlanInternal(StreamExecPythonCalc.scala:61)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.translateToPlanInternal(StreamExecPythonCalc.scala:35)&#010;        at org.apache.flink.table.planner.plan.nodes.exec.ExecNode$class.translateToPlan(ExecNode.scala:58)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecCalcBase.translateToPlan(StreamExecCalcBase.scala:38)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToTransformation(StreamExecLegacySink.scala:158)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:106)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:48)&#010;        at org.apache.flink.table.planner.plan.nodes.exec.ExecNode$class.translateToPlan(ExecNode.scala:58)&#010;        at org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlan(StreamExecLegacySink.scala:48)&#010;        at org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:67)&#010;        at org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:66)&#010;        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#010;        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#010;        at scala.collection.Iterator$class.foreach(Iterator.scala:891)&#010;        at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)&#010;        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)&#010;        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)&#010;        at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)&#010;        at scala.collection.AbstractTraversable.map(Traversable.scala:104)&#010;        at org.apache.flink.table.planner.delegation.StreamPlanner.translateToPlan(StreamPlanner.scala:66)&#010;        at org.apache.flink.table.planner.delegation.PlannerBase.translate(PlannerBase.scala:166)&#010;        at org.apache.flink.table.api.internal.TableEnvironmentImpl.translate(TableEnvironmentImpl.java:1248)&#010;        at org.apache.flink.table.api.internal.TableEnvironmentImpl.translateAndClearBuffer(TableEnvironmentImpl.java:1240)&#010;        at org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;        at java.lang.reflect.Method.invoke(Method.java:497)&#010;        at org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)&#010;        at org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)&#010;        at org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)&#010;        at org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)&#010;        at org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)&#010;        at org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)&#010;        at java.lang.Thread.run(Thread.java:745)&#010;&#010;&#010;&#010;&#010;During handling of the above exception, another exception occurred:&#010;&#010;&#010;Traceback (most recent call last):&#010;  File \"test_pyflink.py\", line 34, in &lt;module&gt;&#010;    t_env.execute(\"tutorial_job\")&#010;  File \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\table\\table_environment.py\",&#010;line 1057, in execute&#010;    return JobExecutionResult(self._j_tenv.execute(job_name))&#010;  File \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\py4j\\java_gateway.py\",&#010;line 1286, in __call__&#010;    answer, self.gateway_client, self.target_id, self.name)&#010;  File \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\util\\exceptions.py\",&#010;line 154, in deco&#010;    raise exception_mapping[exception](s.split(': ', 1)[1], stack_trace)&#010;pyflink.util.exceptions.TableException: \"The configured Task Off-Heap Memory 0 bytes is less&#010;than the least required Python worker Memory 79 mb. The Task Off-Heap Memory can be configured&#010;using the configuration key 'taskmanager.memory.task.off-heap.size'.\"&#010;|&#010;&#010;&#010;&#010;&#010;é‡Œé¢æåˆ°è¿˜è¦é…ç½®taskmanager.memory.task.off-heap.sizeè¿™ä¸ªå±æ€§å— , &#010;&#010;æˆ‘æ‰¾åˆ°..\\Python\\Python37\\Lib\\site-packages\\pyflink\\confä¸‹é¢çš„flink-conf.yaml&#010;&#010;å¢åŠ äº†taskmanager.memory.task.off-heap.size: 100m&#010;&#010;ä½†æ˜¯è¿˜æ˜¯æŠ¥ä¸€æ ·çš„é”™è¯¯&#010;&#010;è¯·é—®ç”¨pythonå®‰è£…çš„flinkå»å“ªé‡Œé…ç½®å±æ€§&#010;&#010;&#010;",
        "depth": "0",
        "reply": "<6d867f4c.24dc.1736f70e358.Coremail.cxydevelop@163.com>"
    },
    {
        "id": "<CAPxmL=EFH_P+D=tfn+UGiAmhcXhCtkWLqEhmAcbr=cBS6dt-uQ@mail.gmail.com>",
        "from": "Xingbo Huang &lt;hxbks...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:44:23 GMT",
        "subject": "Re: å®˜æ–¹pyflink ä¾‹å­çš„æ‰§è¡Œé—®é¢˜",
        "content": "Hi,&#010;ä½ éœ€è¦æ·»åŠ é…ç½®ï¼Œå¦‚æœä½ æ²¡æœ‰ä½¿ç”¨RocksDBä½œä¸ºstatebackendçš„è¯ï¼Œä½ ç›´æ¥é…ç½®t_env.get_config().get_configuration().set_boolean(\"python.fn-execution.memory.managed\",&#010;True)å°±è¡Œï¼Œå¦‚æœä½ ç”¨äº†çš„è¯ï¼Œå°±éœ€è¦é…ç½®off-heap&#010;memoryäº†ï¼Œtable_env.get_config().get_configuration().set_string(\"taskmanager.memory.task.off-heap.size\",&#010;'80m')ã€‚ä½ å¯ä»¥å‚è€ƒæ–‡æ¡£ä¸Šçš„ä¾‹å­ï¼Œä»¥åŠå¯¹åº”çš„noteè¯´æ˜[1]&#010;&#010;[1]&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/python_udfs.html#scalar-functions&#010;&#010;Best,&#010;Xingbo&#010;&#010;&#010;chenxuying &lt;cxydevelop@163.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸Šåˆ11:36å†™é“ï¼š&#010;&#010;&gt; å®˜æ–¹ä¾‹å­:&#010;&gt; https://flink.apache.org/2020/04/09/pyflink-udf-support-flink.html&#010;&gt; æŒ‰ç…§ä¾‹å­å†™äº†ç¨‹åº,ä¹Ÿå®‰è£…äº†pyflink&#010;&gt; |&#010;&gt; python -m pip install apache-flink&#010;&gt; |&#010;&gt; ä»£ç :&#010;&gt; |&#010;&gt; from pyflink.datastream import StreamExecutionEnvironment&#010;&gt; from pyflink.table import StreamTableEnvironment, DataTypes&#010;&gt; from pyflink.table.descriptors import Schema, OldCsv, FileSystem&#010;&gt; from pyflink.table.udf import udf&#010;&gt;&#010;&gt;&#010;&gt; env = StreamExecutionEnvironment.get_execution_environment()&#010;&gt; env.set_parallelism(1)&#010;&gt; t_env = StreamTableEnvironment.create(env)&#010;&gt;&#010;&gt;&#010;&gt; add = udf(lambda i, j: i + j, [DataTypes.BIGINT(), DataTypes.BIGINT()],&#010;&gt; DataTypes.BIGINT())&#010;&gt;&#010;&gt;&#010;&gt; t_env.register_function(\"add\", add)&#010;&gt;&#010;&gt;&#010;&gt; t_env.connect(FileSystem().path('C:/Users/xuyin/Desktop/docker_compose_test/src.txt'))&#010;&gt; \\&#010;&gt; .with_format(OldCsv()&#010;&gt; .field('a', DataTypes.BIGINT())&#010;&gt; .field('b', DataTypes.BIGINT())) \\&#010;&gt; .with_schema(Schema()&#010;&gt; .field('a', DataTypes.BIGINT())&#010;&gt; .field('b', DataTypes.BIGINT())) \\&#010;&gt; .create_temporary_table('mySource')&#010;&gt;&#010;&gt;&#010;&gt; t_env.connect(FileSystem().path('C:/Users/xuyin/Desktop/docker_compose_test/tar.txt'))&#010;&gt; \\&#010;&gt; .with_format(OldCsv()&#010;&gt; .field('sum', DataTypes.BIGINT())) \\&#010;&gt; .with_schema(Schema()&#010;&gt; .field('sum', DataTypes.BIGINT())) \\&#010;&gt; .create_temporary_table('mySink')&#010;&gt;&#010;&gt;&#010;&gt; t_env.from_path('mySource')\\&#010;&gt; .select(\"add(a, b)\") \\&#010;&gt; .insert_into('mySink')&#010;&gt;&#010;&gt;&#010;&gt; t_env.execute(\"tutorial_job\")&#010;&gt; |&#010;&gt;&#010;&gt; æ‰§è¡Œ:&#010;&gt;&#010;&gt; |&#010;&gt; python test_pyflink.py&#010;&gt; |&#010;&gt;&#010;&gt; æŠ¥é”™:&#010;&gt;&#010;&gt;&#010;&gt; |&#010;&gt; Traceback (most recent call last):&#010;&gt;   File&#010;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\util\\exceptions.py\",&#010;&gt; line 147, in deco&#010;&gt;     return f(*a, **kw)&#010;&gt;   File&#010;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\py4j\\protocol.py\",&#010;&gt; line 328, in get_return_value&#010;&gt;     format(target_id, \".\", name), value)&#010;&gt; py4j.protocol.Py4JJavaError: An error occurred while calling o2.execute.&#010;&gt; : org.apache.flink.table.api.TableException: The configured Task Off-Heap&#010;&gt; Memory 0 bytes is less than the least required Python worker Memory 79 mb.&#010;&gt; The Task Off-Heap Memory can be configured using the configuration key&#010;&gt; 'taskmanager.memory.task.off-heap.size'.&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.checkPythonWorkerMemory(CommonPythonBase.scala:158)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.getMergedConfiguration(CommonPythonBase.scala:119)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.getConfig(CommonPythonBase.scala:102)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.getConfig(StreamExecPythonCalc.scala:35)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.translateToPlanInternal(StreamExecPythonCalc.scala:61)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.translateToPlanInternal(StreamExecPythonCalc.scala:35)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.exec.ExecNode$class.translateToPlan(ExecNode.scala:58)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecCalcBase.translateToPlan(StreamExecCalcBase.scala:38)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToTransformation(StreamExecLegacySink.scala:158)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:106)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:48)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.exec.ExecNode$class.translateToPlan(ExecNode.scala:58)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlan(StreamExecLegacySink.scala:48)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:67)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:66)&#010;&gt;         at&#010;&gt; scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#010;&gt;         at&#010;&gt; scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#010;&gt;         at scala.collection.Iterator$class.foreach(Iterator.scala:891)&#010;&gt;         at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)&#010;&gt;         at&#010;&gt; scala.collection.IterableLike$class.foreach(IterableLike.scala:72)&#010;&gt;         at scala.collection.AbstractIterable.foreach(Iterable.scala:54)&#010;&gt;         at&#010;&gt; scala.collection.TraversableLike$class.map(TraversableLike.scala:234)&#010;&gt;         at scala.collection.AbstractTraversable.map(Traversable.scala:104)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.delegation.StreamPlanner.translateToPlan(StreamPlanner.scala:66)&#010;&gt;         at&#010;&gt; org.apache.flink.table.planner.delegation.PlannerBase.translate(PlannerBase.scala:166)&#010;&gt;         at&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.translate(TableEnvironmentImpl.java:1248)&#010;&gt;         at&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.translateAndClearBuffer(TableEnvironmentImpl.java:1240)&#010;&gt;         at&#010;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt;         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt;         at&#010;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt;         at&#010;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt;         at java.lang.reflect.Method.invoke(Method.java:497)&#010;&gt;         at&#010;&gt; org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)&#010;&gt;         at&#010;&gt; org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)&#010;&gt;         at&#010;&gt; org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)&#010;&gt;         at&#010;&gt; org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)&#010;&gt;         at&#010;&gt; org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)&#010;&gt;         at&#010;&gt; org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)&#010;&gt;         at java.lang.Thread.run(Thread.java:745)&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; During handling of the above exception, another exception occurred:&#010;&gt;&#010;&gt;&#010;&gt; Traceback (most recent call last):&#010;&gt;   File \"test_pyflink.py\", line 34, in &lt;module&gt;&#010;&gt;     t_env.execute(\"tutorial_job\")&#010;&gt;   File&#010;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\table\\table_environment.py\",&#010;&gt; line 1057, in execute&#010;&gt;     return JobExecutionResult(self._j_tenv.execute(job_name))&#010;&gt;   File&#010;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\py4j\\java_gateway.py\",&#010;&gt; line 1286, in __call__&#010;&gt;     answer, self.gateway_client, self.target_id, self.name)&#010;&gt;   File&#010;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\util\\exceptions.py\",&#010;&gt; line 154, in deco&#010;&gt;     raise exception_mapping[exception](s.split(': ', 1)[1], stack_trace)&#010;&gt; pyflink.util.exceptions.TableException: \"The configured Task Off-Heap&#010;&gt; Memory 0 bytes is less than the least required Python worker Memory 79 mb.&#010;&gt; The Task Off-Heap Memory can be configured using the configuration key&#010;&gt; 'taskmanager.memory.task.off-heap.size'.\"&#010;&gt; |&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; é‡Œé¢æåˆ°è¿˜è¦é…ç½®taskmanager.memory.task.off-heap.sizeè¿™ä¸ªå±æ€§å— ,&#010;&gt;&#010;&gt; æˆ‘æ‰¾åˆ°..\\Python\\Python37\\Lib\\site-packages\\pyflink\\confä¸‹é¢çš„flink-conf.yaml&#010;&gt;&#010;&gt; å¢åŠ äº†taskmanager.memory.task.off-heap.size: 100m&#010;&gt;&#010;&gt; ä½†æ˜¯è¿˜æ˜¯æŠ¥ä¸€æ ·çš„é”™è¯¯&#010;&gt;&#010;&gt; è¯·é—®ç”¨pythonå®‰è£…çš„flinkå»å“ªé‡Œé…ç½®å±æ€§&#010;&gt;&#010;&gt;&#010;&gt;&#010;&#010;",
        "depth": "1",
        "reply": "<6d867f4c.24dc.1736f70e358.Coremail.cxydevelop@163.com>"
    },
    {
        "id": "<5cd34596.2afe.1736faf5d2b.Coremail.cxydevelop@163.com>",
        "from": "chenxuying  &lt;cxydeve...@163.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 04:43:50 GMT",
        "subject": "Re:Re: å®˜æ–¹pyflink ä¾‹å­çš„æ‰§è¡Œé—®é¢˜",
        "content": "ä½ å¥½&#010;æ˜ç™½äº†,æ„Ÿè°¢ , æˆ‘æ–‡æ¡£æ²¡çœ‹æ¸…æ¥šå“ˆ&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;&#010;åœ¨ 2020-07-21 11:44:23ï¼Œ\"Xingbo Huang\" &lt;hxbks2ks@gmail.com&gt; å†™é“ï¼š&#010;&gt;Hi,&#010;&gt;ä½ éœ€è¦æ·»åŠ é…ç½®ï¼Œå¦‚æœä½ æ²¡æœ‰ä½¿ç”¨RocksDBä½œä¸ºstatebackendçš„è¯ï¼Œä½ ç›´æ¥é…ç½®t_env.get_config().get_configuration().set_boolean(\"python.fn-execution.memory.managed\",&#010;&gt;True)å°±è¡Œï¼Œå¦‚æœä½ ç”¨äº†çš„è¯ï¼Œå°±éœ€è¦é…ç½®off-heap&#010;&gt;memoryäº†ï¼Œtable_env.get_config().get_configuration().set_string(\"taskmanager.memory.task.off-heap.size\",&#010;&gt;'80m')ã€‚ä½ å¯ä»¥å‚è€ƒæ–‡æ¡£ä¸Šçš„ä¾‹å­ï¼Œä»¥åŠå¯¹åº”çš„noteè¯´æ˜[1]&#010;&gt;&#010;&gt;[1]&#010;&gt;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/python/python_udfs.html#scalar-functions&#010;&gt;&#010;&gt;Best,&#010;&gt;Xingbo&#010;&gt;&#010;&gt;&#010;&gt;chenxuying &lt;cxydevelop@163.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸Šåˆ11:36å†™é“ï¼š&#010;&gt;&#010;&gt;&gt; å®˜æ–¹ä¾‹å­:&#010;&gt;&gt; https://flink.apache.org/2020/04/09/pyflink-udf-support-flink.html&#010;&gt;&gt; æŒ‰ç…§ä¾‹å­å†™äº†ç¨‹åº,ä¹Ÿå®‰è£…äº†pyflink&#010;&gt;&gt; |&#010;&gt;&gt; python -m pip install apache-flink&#010;&gt;&gt; |&#010;&gt;&gt; ä»£ç :&#010;&gt;&gt; |&#010;&gt;&gt; from pyflink.datastream import StreamExecutionEnvironment&#010;&gt;&gt; from pyflink.table import StreamTableEnvironment, DataTypes&#010;&gt;&gt; from pyflink.table.descriptors import Schema, OldCsv, FileSystem&#010;&gt;&gt; from pyflink.table.udf import udf&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; env = StreamExecutionEnvironment.get_execution_environment()&#010;&gt;&gt; env.set_parallelism(1)&#010;&gt;&gt; t_env = StreamTableEnvironment.create(env)&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; add = udf(lambda i, j: i + j, [DataTypes.BIGINT(), DataTypes.BIGINT()],&#010;&gt;&gt; DataTypes.BIGINT())&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; t_env.register_function(\"add\", add)&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; t_env.connect(FileSystem().path('C:/Users/xuyin/Desktop/docker_compose_test/src.txt'))&#010;&gt;&gt; \\&#010;&gt;&gt; .with_format(OldCsv()&#010;&gt;&gt; .field('a', DataTypes.BIGINT())&#010;&gt;&gt; .field('b', DataTypes.BIGINT())) \\&#010;&gt;&gt; .with_schema(Schema()&#010;&gt;&gt; .field('a', DataTypes.BIGINT())&#010;&gt;&gt; .field('b', DataTypes.BIGINT())) \\&#010;&gt;&gt; .create_temporary_table('mySource')&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; t_env.connect(FileSystem().path('C:/Users/xuyin/Desktop/docker_compose_test/tar.txt'))&#010;&gt;&gt; \\&#010;&gt;&gt; .with_format(OldCsv()&#010;&gt;&gt; .field('sum', DataTypes.BIGINT())) \\&#010;&gt;&gt; .with_schema(Schema()&#010;&gt;&gt; .field('sum', DataTypes.BIGINT())) \\&#010;&gt;&gt; .create_temporary_table('mySink')&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; t_env.from_path('mySource')\\&#010;&gt;&gt; .select(\"add(a, b)\") \\&#010;&gt;&gt; .insert_into('mySink')&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; t_env.execute(\"tutorial_job\")&#010;&gt;&gt; |&#010;&gt;&gt;&#010;&gt;&gt; æ‰§è¡Œ:&#010;&gt;&gt;&#010;&gt;&gt; |&#010;&gt;&gt; python test_pyflink.py&#010;&gt;&gt; |&#010;&gt;&gt;&#010;&gt;&gt; æŠ¥é”™:&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; |&#010;&gt;&gt; Traceback (most recent call last):&#010;&gt;&gt;   File&#010;&gt;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\util\\exceptions.py\",&#010;&gt;&gt; line 147, in deco&#010;&gt;&gt;     return f(*a, **kw)&#010;&gt;&gt;   File&#010;&gt;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\py4j\\protocol.py\",&#010;&gt;&gt; line 328, in get_return_value&#010;&gt;&gt;     format(target_id, \".\", name), value)&#010;&gt;&gt; py4j.protocol.Py4JJavaError: An error occurred while calling o2.execute.&#010;&gt;&gt; : org.apache.flink.table.api.TableException: The configured Task Off-Heap&#010;&gt;&gt; Memory 0 bytes is less than the least required Python worker Memory 79 mb.&#010;&gt;&gt; The Task Off-Heap Memory can be configured using the configuration key&#010;&gt;&gt; 'taskmanager.memory.task.off-heap.size'.&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.checkPythonWorkerMemory(CommonPythonBase.scala:158)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.getMergedConfiguration(CommonPythonBase.scala:119)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.common.CommonPythonBase$class.getConfig(CommonPythonBase.scala:102)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.getConfig(StreamExecPythonCalc.scala:35)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.translateToPlanInternal(StreamExecPythonCalc.scala:61)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecPythonCalc.translateToPlanInternal(StreamExecPythonCalc.scala:35)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.exec.ExecNode$class.translateToPlan(ExecNode.scala:58)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecCalcBase.translateToPlan(StreamExecCalcBase.scala:38)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToTransformation(StreamExecLegacySink.scala:158)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:106)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlanInternal(StreamExecLegacySink.scala:48)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.exec.ExecNode$class.translateToPlan(ExecNode.scala:58)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.plan.nodes.physical.stream.StreamExecLegacySink.translateToPlan(StreamExecLegacySink.scala:48)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:67)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.delegation.StreamPlanner$$anonfun$translateToPlan$1.apply(StreamPlanner.scala:66)&#010;&gt;&gt;         at&#010;&gt;&gt; scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#010;&gt;&gt;         at&#010;&gt;&gt; scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&#010;&gt;&gt;         at scala.collection.Iterator$class.foreach(Iterator.scala:891)&#010;&gt;&gt;         at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)&#010;&gt;&gt;         at&#010;&gt;&gt; scala.collection.IterableLike$class.foreach(IterableLike.scala:72)&#010;&gt;&gt;         at scala.collection.AbstractIterable.foreach(Iterable.scala:54)&#010;&gt;&gt;         at&#010;&gt;&gt; scala.collection.TraversableLike$class.map(TraversableLike.scala:234)&#010;&gt;&gt;         at scala.collection.AbstractTraversable.map(Traversable.scala:104)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.delegation.StreamPlanner.translateToPlan(StreamPlanner.scala:66)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.planner.delegation.PlannerBase.translate(PlannerBase.scala:166)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.translate(TableEnvironmentImpl.java:1248)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.translateAndClearBuffer(TableEnvironmentImpl.java:1240)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1197)&#010;&gt;&gt;         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#010;&gt;&gt;         at&#010;&gt;&gt; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&#010;&gt;&gt;         at&#010;&gt;&gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#010;&gt;&gt;         at java.lang.reflect.Method.invoke(Method.java:497)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)&#010;&gt;&gt;         at&#010;&gt;&gt; org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)&#010;&gt;&gt;         at java.lang.Thread.run(Thread.java:745)&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; During handling of the above exception, another exception occurred:&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; Traceback (most recent call last):&#010;&gt;&gt;   File \"test_pyflink.py\", line 34, in &lt;module&gt;&#010;&gt;&gt;     t_env.execute(\"tutorial_job\")&#010;&gt;&gt;   File&#010;&gt;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\table\\table_environment.py\",&#010;&gt;&gt; line 1057, in execute&#010;&gt;&gt;     return JobExecutionResult(self._j_tenv.execute(job_name))&#010;&gt;&gt;   File&#010;&gt;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\py4j\\java_gateway.py\",&#010;&gt;&gt; line 1286, in __call__&#010;&gt;&gt;     answer, self.gateway_client, self.target_id, self.name)&#010;&gt;&gt;   File&#010;&gt;&gt; \"C:\\Users\\xuyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyflink\\util\\exceptions.py\",&#010;&gt;&gt; line 154, in deco&#010;&gt;&gt;     raise exception_mapping[exception](s.split(': ', 1)[1], stack_trace)&#010;&gt;&gt; pyflink.util.exceptions.TableException: \"The configured Task Off-Heap&#010;&gt;&gt; Memory 0 bytes is less than the least required Python worker Memory 79 mb.&#010;&gt;&gt; The Task Off-Heap Memory can be configured using the configuration key&#010;&gt;&gt; 'taskmanager.memory.task.off-heap.size'.\"&#010;&gt;&gt; |&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt; é‡Œé¢æåˆ°è¿˜è¦é…ç½®taskmanager.memory.task.off-heap.sizeè¿™ä¸ªå±æ€§å— ,&#010;&gt;&gt;&#010;&gt;&gt; æˆ‘æ‰¾åˆ°..\\Python\\Python37\\Lib\\site-packages\\pyflink\\confä¸‹é¢çš„flink-conf.yaml&#010;&gt;&gt;&#010;&gt;&gt; å¢åŠ äº†taskmanager.memory.task.off-heap.size: 100m&#010;&gt;&gt;&#010;&gt;&gt; ä½†æ˜¯è¿˜æ˜¯æŠ¥ä¸€æ ·çš„é”™è¯¯&#010;&gt;&gt;&#010;&gt;&gt; è¯·é—®ç”¨pythonå®‰è£…çš„flinkå»å“ªé‡Œé…ç½®å±æ€§&#010;&gt;&gt;&#010;&gt;&gt;&#010;&gt;&gt;&#010;",
        "depth": "2",
        "reply": "<6d867f4c.24dc.1736f70e358.Coremail.cxydevelop@163.com>"
    },
    {
        "id": "<tencent_55DB7025A98478D5F51947291466EE26F106@qq.com>",
        "from": "&quot;èƒ¡äº‘å·&quot; &lt;huyunchuan1...@foxmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:40:32 GMT",
        "subject": "Flink å¾€kafkaç”Ÿäº§æ•°æ®ï¼Œé¢‘ç¹å‡ºç°checkpointå¤±è´¥çš„é”™è¯¯",
        "content": "&amp;gt;&amp;gt;&amp;gt;&amp;gt;å¤§ä½¬ä»¬å¥½ï¼Œ&#013;&#010;&amp;gt;&amp;gt;&amp;gt;&amp;gt;åœ¨Flink å¾€kafkaç”Ÿäº§æ•°æ®çš„æ—¶å€™ï¼Œé¢‘ç¹å‡ºå¸­é‚£checkpointå¤±è´¥çš„é”™è¯¯ï¼Œå¼€å¯EXACTLY_ONCE&#013;&#010;&amp;gt;&amp;gt;æŠ¥é”™ä»£ç å¦‚ä¸‹ï¼š&#013;&#010;Producer attempted an operation with an old epoch.Either there is a newer producer with the&#010;same transactionalId, or the producer's transaction has been expired by the broker&#013;&#010;&#013;&#010;&#013;&#010;&amp;gt;&amp;gt;å¤§ä½¬ä»¬æœ‰é‡åˆ°è¿‡å—ï¼Ÿ&#013;&#010;&amp;gt;&amp;gt;ä¸èƒœæ„Ÿæ¿€ï¼",
        "depth": "0",
        "reply": "<tencent_55DB7025A98478D5F51947291466EE26F106@qq.com>"
    },
    {
        "id": "<tencent_D1BDD20BD21C32235A267556B799B23A0309@qq.com>",
        "from": "&quot;sun&quot; &lt;1392427...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 03:52:54 GMT",
        "subject": "æƒ³çŸ¥é“stateå†™åˆ°checkpointæ–‡ä»¶æ²¡æœ‰",
        "content": "&amp;nbsp; è¯·é—®æ€ä¹ˆåç¼–è¯‘checkpointæ–‡ä»¶å•Šï¼Œæˆ‘æƒ³çŸ¥é“stateå†™åˆ°checkpointæ–‡ä»¶æ²¡æœ‰&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&amp;nbsp;&#005; &#002; &#009;_default_&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; OPERATOR_STATE_DISTRIBUTION_MODE&#010;&#016;SPLIT_DISTRIBUTE&amp;nbsp; &amp;nbsp;&#001; &#016;VALUE_SERIALIZER&amp;nbsp; &amp;nbsp;&#002; Gorg.apache.flink.api.common.typeutils.ParameterlessTypeSerializerConfigzSé…¿&amp;nbsp;&#010;&amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;è„‚?&#005;sr -org.apache.flink.runtime.state.JavaSerializerFSXéŸ¦4&#013;&#010;?&amp;nbsp; xr Borg.apache.flink.api.common.typeutils.base.TypeSerializerSingletonyï¹ªî€¦.wE&#002;&amp;nbsp;&#010;xr 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp;&#010;xp&amp;nbsp; &amp;nbsp;&#001; -org.apache.flink.runtime.state.JavaSerializer &#029;topic-partition-offset-states&amp;nbsp;&#010;&amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; OPERATOR_STATE_DISTRIBUTION_MODE &#005;UNION&amp;nbsp;&#010;&amp;nbsp;&#001; &#016;VALUE_SERIALIZER&amp;nbsp; &amp;nbsp;&#002; Iorg.apache.flink.api.java.typeutils.runtime.TupleSerializerConfigSnapshotzSé…¿&amp;nbsp;&#010;&amp;nbsp;&#001;&amp;nbsp; &#008;çŸ›?&#005;sr ;org.apache.flink.api.java.typeutils.runtime.TupleSerializer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp; xr ?org.apache.flink.api.java.typeutils.runtime.TupleSerializerBase&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002; &#004;I &#005;arityI &#006;length[ &#016;fieldSerializerst 7[Lorg/apache/flink/api/common/typeutils/TypeSerializer;L&amp;nbsp;&#013;&#010;tupleClasst &#017;Ljava/lang/Class;xr 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp; xp&amp;nbsp; &amp;nbsp;&#002;ï£µï£µï£µî ºr 7[Lorg.apache.flink.api.common.typeutils.TypeSerializer;9?Ğ§&#022;éº¡&#002;&amp;nbsp;&#010;xp&amp;nbsp; &amp;nbsp;&#002;sr ?org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#003;&#002; &#007;L &#024;defaultSerializerClassest &#025;Ljava/util/LinkedHashMap;L&#010;&#018;defaultSerializersq ~ &#009;L &#017;kryoRegistrationsq ~ &#009;L &#015;registeredTypest &#025;Ljava/util/LinkedHashSet;L&#010;$registeredTypesWithSerializerClassesq ~ &#009;L &#030;registeredTypesWithSerializersq ~ &#009;L &#004;typeq ~&#010;&#003;xq ~ &#004;sr &#023;java.util.LinkedHashMap4ç¹¬\\&#016;låˆ©&#002; &#001;Z &#011;accessOrderxr &#017;java.util.HashMap&#005;&#007;è¯¹?`?&#010;&#002;F&amp;nbsp;&#013;&#010;loadFactorI &#009;thresholdxp?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w&#008;&amp;nbsp; &amp;nbsp;&#016;&amp;nbsp;&#010;&amp;nbsp; x sq ~ &#012;?@&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;w&#008;&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;&#010;x sq ~ &#012;?@&amp;nbsp; &amp;nbsp; &amp;nbsp;&#003;w&#008;&amp;nbsp; &amp;nbsp;&#004;&amp;nbsp; &amp;nbsp;&#002;t&#010;Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionsr &lt;org.apache.flink.api.java.typeutils.runtime.KryoRegistrationJ?å£åo&#002;&#010;&#004;L &#015;registeredClassq ~ &#003;L &#030;serializableSerializerInstancet DLorg/apache/flink/api/common/ExecutionConfig$SerializableSerializer;L&#010;&#015;serializerClassq ~ &#003;L &#024;serializerDefinitionTypet WLorg/apache/flink/api/java/typeutils/runtime/KryoRegistration$SerializerDefinitionType;xpvr&#010;Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&#013;&#010;&#005;[/å‰€X5&#002; &#003;I&amp;nbsp;&#013;&#010;cachedHashI &#009;partitionL &#005;topict &#018;Ljava/lang/String;xppp~r Uorg.apache.flink.api.java.typeutils.runtime.KryoRegistration$SerializerDefinitionType&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &#018;&amp;nbsp; xr &#014;java.lang.Enum&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &#018;&amp;nbsp; xpt &#011;UNSPECIFIEDt )org.apache.avro.generic.GenericData$Arraysq ~ &#018;vr&#010;Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xppvr Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xp~q ~ &#025;t &#005;CLASSx pppq ~ &#024;sr 9org.apache.flink.api.common.typeutils.base.LongSerializer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp; xr Borg.apache.flink.api.common.typeutils.base.TypeSerializerSingletonyï¹ªî€¦.wE&#002;&amp;nbsp;&#010;xq ~ &#004;vr &amp;amp;org.apache.flink.api.java.tuple.Tuple2&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&#010;&#002;L &#002;f0t &#018;Ljava/lang/Object;L &#002;f1q ~ )xr %org.apache.flink.api.java.tuple.Tuple&amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp; xp&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;&#002;&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &#006;;&amp;nbsp; &#014;? &#015;? &#016;)&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; &#006;3î„ˆ &#005;sr ?org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#003;&#002; &#007;L &#024;defaultSerializerClassest &#025;Ljava/util/LinkedHashMap;L&#010;&#018;defaultSerializersq ~ &#001;L &#017;kryoRegistrationsq ~ &#001;L &#015;registeredTypest &#025;Ljava/util/LinkedHashSet;L&#010;$registeredTypesWithSerializerClassesq ~ &#001;L &#030;registeredTypesWithSerializersq ~ &#001;L &#004;typet &#017;Ljava/lang/Class;xr&#010;4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp;&#010;xpsr &#023;java.util.LinkedHashMap4ç¹¬\\&#016;låˆ©&#002; &#001;Z &#011;accessOrderxr &#017;java.util.HashMap&#005;&#007;è¯¹?`? &#002;F&amp;nbsp;&#013;&#010;loadFactorI &#009;thresholdxp?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w&#008;&amp;nbsp; &amp;nbsp;&#016;&amp;nbsp;&#010;&amp;nbsp; x sq ~ &#006;?@&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;w&#008;&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;&#010;x sq ~ &#006;?@&amp;nbsp; &amp;nbsp; &amp;nbsp;&#003;w&#008;&amp;nbsp; &amp;nbsp;&#004;&amp;nbsp; &amp;nbsp;&#002;t&#010;Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionsr &lt;org.apache.flink.api.java.typeutils.runtime.KryoRegistrationJ?å£åo&#002;&#010;&#004;L &#015;registeredClassq ~ &#003;L &#030;serializableSerializerInstancet DLorg/apache/flink/api/common/ExecutionConfig$SerializableSerializer;L&#010;&#015;serializerClassq ~ &#003;L &#024;serializerDefinitionTypet WLorg/apache/flink/api/java/typeutils/runtime/KryoRegistration$SerializerDefinitionType;xpvr&#010;Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&#013;&#010;&#005;[/å‰€X5&#002; &#003;I&amp;nbsp;&#013;&#010;cachedHashI &#009;partitionL &#005;topict &#018;Ljava/lang/String;xppp~r Uorg.apache.flink.api.java.typeutils.runtime.KryoRegistration$SerializerDefinitionType&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &#018;&amp;nbsp; xr &#014;java.lang.Enum&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &#018;&amp;nbsp; xpt &#011;UNSPECIFIEDt )org.apache.avro.generic.GenericData$Arraysq ~ &#012;vr&#010;Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xppvr Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xp~q ~ &#019;t &#005;CLASSx pppq ~ &#018;&amp;nbsp;&#010;&amp;nbsp;&#002; \\org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer$KryoSerializerConfigSnapshotzSé…¿&amp;nbsp;&#010;&amp;nbsp;&#001;&amp;nbsp; &#006;3î„ˆ &#005;sr ?org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#003;&#002; &#007;L &#024;defaultSerializerClassest &#025;Ljava/util/LinkedHashMap;L&#010;&#018;defaultSerializersq ~ &#001;L &#017;kryoRegistrationsq ~ &#001;L &#015;registeredTypest &#025;Ljava/util/LinkedHashSet;L&#010;$registeredTypesWithSerializerClassesq ~ &#001;L &#030;registeredTypesWithSerializersq ~ &#001;L &#004;typet &#017;Ljava/lang/Class;xr&#010;4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp;&#010;xpsr &#023;java.util.LinkedHashMap4ç¹¬\\&#016;låˆ©&#002; &#001;Z &#011;accessOrderxr &#017;java.util.HashMap&#005;&#007;è¯¹?`? &#002;F&amp;nbsp;&#013;&#010;loadFactorI &#009;thresholdxp?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w&#008;&amp;nbsp; &amp;nbsp;&#016;&amp;nbsp;&#010;&amp;nbsp; x sq ~ &#006;?@&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;w&#008;&amp;nbsp; &amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;&#010;x sq ~ &#006;?@&amp;nbsp; &amp;nbsp; &amp;nbsp;&#003;w&#008;&amp;nbsp; &amp;nbsp;&#004;&amp;nbsp; &amp;nbsp;&#002;t&#010;Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionsr &lt;org.apache.flink.api.java.typeutils.runtime.KryoRegistrationJ?å£åo&#002;&#010;&#004;L &#015;registeredClassq ~ &#003;L &#030;serializableSerializerInstancet DLorg/apache/flink/api/common/ExecutionConfig$SerializableSerializer;L&#010;&#015;serializerClassq ~ &#003;L &#024;serializerDefinitionTypet WLorg/apache/flink/api/java/typeutils/runtime/KryoRegistration$SerializerDefinitionType;xpvr&#010;Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&#013;&#010;&#005;[/å‰€X5&#002; &#003;I&amp;nbsp;&#013;&#010;cachå‘é€edHashI &#009;partitionL &#005;topict &#018;Ljava/lang/String;xppp~r Uorg.apache.flink.api.java.typeutils.runtime.KryoRegistration$SerializerDefinitionType&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &#018;&amp;nbsp; xr &#014;java.lang.Enum&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &#018;&amp;nbsp; xpt &#011;UNSPECIFIEDt )org.apache.avro.generic.GenericData$Arraysq ~ &#012;vr&#010;Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xppvr Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xp~q ~ &#019;t &#005;CLASSx pppq ~ &#018;&amp;nbsp;&#010;&amp;nbsp;&#001; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&amp;nbsp;&#010;&amp;nbsp;&#002; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp;)org.apache.avro.generic.GenericData$Array Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&amp;nbsp;&#001; Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&amp;nbsp;&#001;&amp;nbsp; &amp;nbsp;çŒ¬?&#005;sr 9org.apache.flink.api.common.typeutils.base.LongSerializer&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp; xr Borg.apache.flink.api.common.typeutils.base.TypeSerializerSingletonyï¹ªî€¦.wE&#002;&amp;nbsp;&#010;xr 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp;&#010;xp&amp;nbsp; &amp;nbsp;&#002; Porg.apache.flink.api.common.typeutils.base.LongSerializer$LongSerializerSnapshot&amp;nbsp;&#010;&amp;nbsp;&#002; 9org.apache.flink.api.common.typeutils.base.LongSerializerî„ˆ &#005;vr &amp;amp;org.apache.flink.api.java.tuple.Tuple2&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002; &#002;L &#002;f0t &#018;Ljava/lang/Object;L &#002;f1q ~ &#001;xr %org.apache.flink.api.java.tuple.Tuple&amp;nbsp;&#010;&amp;nbsp; &amp;nbsp; &amp;nbsp;&#001;&#002;&amp;nbsp; xp&amp;nbsp;&amp;nbsp;",
        "depth": "0",
        "reply": "<tencent_D1BDD20BD21C32235A267556B799B23A0309@qq.com>"
    },
    {
        "id": "<CAA8tFvunHVRyXOVUOCnrVUXovULr8LUrxpNcqp+-+4ms8qW73Q@mail.gmail.com>",
        "from": "Congxian Qiu &lt;qcx978132...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Wed, 22 Jul 2020 05:17:58 GMT",
        "subject": "Re: æƒ³çŸ¥é“stateå†™åˆ°checkpointæ–‡ä»¶æ²¡æœ‰",
        "content": "Hi&#010;    Checkpoint åŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼š1ï¼‰meta æ–‡ä»¶ï¼›2ï¼‰å…·ä½“çš„æ•°æ®ã€‚å¦‚æœæ˜¯ Meta éƒ¨åˆ†å¯ä»¥å‚è€ƒ&#010;CheckpointMetadataLoadingTest[1] è‡ªå·±å†™ä¸€ä¸ªæµ‹è¯•ï¼Œå¦‚æœä½ çŸ¥é“å…·ä½“çš„å†…å®¹ï¼Œæˆ–è®¸ä¹Ÿå¯ä»¥çœ‹ä¸€ä¸‹&#010;StatePorcessAPI[2]&#010;&#010;[1]&#010;https://github.com/apache/flink/blob/master/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointMetadataLoadingTest.java&#010;[2]&#010;https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/libs/state_processor_api.html&#010;&#010;Best,&#010;Congxian&#010;&#010;&#010;sun &lt;1392427699@qq.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ12:02å†™é“ï¼š&#010;&#010;&gt; &amp;nbsp; è¯·é—®æ€ä¹ˆåç¼–è¯‘checkpointæ–‡ä»¶å•Šï¼Œæˆ‘æƒ³çŸ¥é“stateå†™åˆ°checkpointæ–‡ä»¶æ²¡æœ‰&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; &amp;nbsp;          _default_&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; OPERATOR_STATE_DISTRIBUTION_MODE  SPLIT_DISTRIBUTE&amp;nbsp; &amp;nbsp;&#010;&gt;  VALUE_SERIALIZER&amp;nbsp; &amp;nbsp;&#010;&gt; Gorg.apache.flink.api.common.typeutils.ParameterlessTypeSerializerConfigzSé…¿&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;è„‚? sr&#010;&gt; -org.apache.flink.runtime.state.JavaSerializerFSXéŸ¦4&#010;&gt; ?&amp;nbsp; xr&#010;&gt; Borg.apache.flink.api.common.typeutils.base.TypeSerializerSingletonyï¹ªî€¦.wE&#010;&gt; &amp;nbsp; xr 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xp&amp;nbsp; &amp;nbsp;&#010;&gt; -org.apache.flink.runtime.state.JavaSerializer&#010;&gt; topic-partition-offset-states&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; OPERATOR_STATE_DISTRIBUTION_MODE  UNION&amp;nbsp; &amp;nbsp;&#010;&gt;  VALUE_SERIALIZER&amp;nbsp; &amp;nbsp;&#010;&gt; Iorg.apache.flink.api.java.typeutils.runtime.TupleSerializerConfigSnapshotzSé…¿&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;  çŸ›? sr&#010;&gt; ;org.apache.flink.api.java.typeutils.runtime.TupleSerializer&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xr&#010;&gt; ?org.apache.flink.api.java.typeutils.runtime.TupleSerializerBase&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;    I  arityI  length[  fieldSerializerst&#010;&gt; 7[Lorg/apache/flink/api/common/typeutils/TypeSerializer;L&amp;nbsp;&#010;&gt; tupleClasst  Ljava/lang/Class;xr&#010;&gt; 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;  &amp;nbsp; xp&amp;nbsp; &amp;nbsp; ï£µï£µï£µî ºr&#010;&gt; 7[Lorg.apache.flink.api.common.typeutils.TypeSerializer;9?Ğ§ éº¡ &amp;nbsp;&#010;&gt; xp&amp;nbsp; &amp;nbsp; sr&#010;&gt; ?org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;    L  defaultSerializerClassest&#010;&gt; Ljava/util/LinkedHashMap;L  defaultSerializersq ~  L  kryoRegistrationsq ~&#010;&gt;        L  registeredTypest  Ljava/util/LinkedHashSet;L&#010;&gt; $registeredTypesWithSerializerClassesq ~        L&#010;&gt; registeredTypesWithSerializersq ~    L  typeq ~  xq ~  sr&#010;&gt; java.util.LinkedHashMap4ç¹¬\\ låˆ©   Z  accessOrderxr  java.util.HashMap  è¯¹?`?&#010;&gt; F&amp;nbsp;&#010;&gt; loadFactorI     thresholdxp?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; x sq ~ ?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; x sq ~&#010;&gt; ?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; t&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionsr&#010;&gt; &lt;org.apache.flink.api.java.typeutils.runtime.KryoRegistrationJ?å£åo   L&#010;&gt; registeredClassq ~  L  serializableSerializerInstancet&#010;&gt; DLorg/apache/flink/api/common/ExecutionConfig$SerializableSerializer;L&#010;&gt; serializerClassq ~  L  serializerDefinitionTypet&#010;&gt; WLorg/apache/flink/api/java/typeutils/runtime/KryoRegistration$SerializerDefinitionType;xpvr&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&#010;&gt;  [/å‰€X5   I&amp;nbsp;&#010;&gt; cachedHashI     partitionL  topict  Ljava/lang/String;xppp~r&#010;&gt; Uorg.apache.flink.api.java.typeutils.runtime.KryoRegistration$SerializerDefinitionType&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xr  java.lang.Enum&amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; xpt  UNSPECIFIEDt )org.apache.avro.generic.GenericData$Arraysq ~  vr&#010;&gt; Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xppvr&#010;&gt; Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xp~q ~  t  CLASSx pppq ~  sr&#010;&gt; 9org.apache.flink.api.common.typeutils.base.LongSerializer&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xr&#010;&gt; Borg.apache.flink.api.common.typeutils.base.TypeSerializerSingletonyï¹ªî€¦.wE&#010;&gt; &amp;nbsp; xq ~  vr &amp;amp;org.apache.flink.api.java.tuple.Tuple2&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;    L  f0t  Ljava/lang/Object;L  f1q ~ )xr&#010;&gt; %org.apache.flink.api.java.tuple.Tuple&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;  &amp;nbsp;&#010;&gt; xp&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;  ;&amp;nbsp;&#010; ?  ?  )&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;  3î„ˆ  sr&#010;&gt; ?org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;    L  defaultSerializerClassest&#010;&gt; Ljava/util/LinkedHashMap;L  defaultSerializersq ~  L  kryoRegistrationsq ~&#010;&gt; L  registeredTypest  Ljava/util/LinkedHashSet;L&#010;&gt; $registeredTypesWithSerializerClassesq ~  L&#010;&gt; registeredTypesWithSerializersq ~  L  typet  Ljava/lang/Class;xr&#010;&gt; 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;  &amp;nbsp; xpsr  java.util.LinkedHashMap4ç¹¬\\ låˆ©   Z  accessOrderxr&#010;&gt; java.util.HashMap  è¯¹?`?  F&amp;nbsp;&#010;&gt; loadFactorI     thresholdxp?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; x sq ~  ?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; x sq ~&#010;&gt; ?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; t&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionsr&#010;&gt; &lt;org.apache.flink.api.java.typeutils.runtime.KryoRegistrationJ?å£åo   L&#010;&gt; registeredClassq ~  L  serializableSerializerInstancet&#010;&gt; DLorg/apache/flink/api/common/ExecutionConfig$SerializableSerializer;L&#010;&gt; serializerClassq ~  L  serializerDefinitionTypet&#010;&gt; WLorg/apache/flink/api/java/typeutils/runtime/KryoRegistration$SerializerDefinitionType;xpvr&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&#010;&gt;  [/å‰€X5   I&amp;nbsp;&#010;&gt; cachedHashI     partitionL  topict  Ljava/lang/String;xppp~r&#010;&gt; Uorg.apache.flink.api.java.typeutils.runtime.KryoRegistration$SerializerDefinitionType&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xr  java.lang.Enum&amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; xpt  UNSPECIFIEDt )org.apache.avro.generic.GenericData$Arraysq ~ vr&#010;&gt; Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xppvr&#010;&gt; Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xp~q ~  t  CLASSx pppq ~  &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; \\org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer$KryoSerializerConfigSnapshotzSé…¿&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;  3î„ˆ  sr&#010;&gt; ?org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;    L  defaultSerializerClassest&#010;&gt; Ljava/util/LinkedHashMap;L  defaultSerializersq ~  L  kryoRegistrationsq ~&#010;&gt; L  registeredTypest  Ljava/util/LinkedHashSet;L&#010;&gt; $registeredTypesWithSerializerClassesq ~  L&#010;&gt; registeredTypesWithSerializersq ~  L  typet  Ljava/lang/Class;xr&#010;&gt; 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;  &amp;nbsp; xpsr  java.util.LinkedHashMap4ç¹¬\\ låˆ©   Z  accessOrderxr&#010;&gt; java.util.HashMap  è¯¹?`?  F&amp;nbsp;&#010;&gt; loadFactorI     thresholdxp?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; &amp;nbsp; x sq ~  ?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; x sq ~&#010;&gt; ?@&amp;nbsp; &amp;nbsp; &amp;nbsp; w &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; t&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionsr&#010;&gt; &lt;org.apache.flink.api.java.typeutils.runtime.KryoRegistrationJ?å£åo   L&#010;&gt; registeredClassq ~  L  serializableSerializerInstancet&#010;&gt; DLorg/apache/flink/api/common/ExecutionConfig$SerializableSerializer;L&#010;&gt; serializerClassq ~  L  serializerDefinitionTypet&#010;&gt; WLorg/apache/flink/api/java/typeutils/runtime/KryoRegistration$SerializerDefinitionType;xpvr&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&#010;&gt;  [/å‰€X5   I&amp;nbsp;&#010;&gt; cachå‘é€edHashI   partitionL  topict  Ljava/lang/String;xppp~r&#010;&gt; Uorg.apache.flink.api.java.typeutils.runtime.KryoRegistration$SerializerDefinitionType&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xr  java.lang.Enum&amp;nbsp; &amp;nbsp;&#010;&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; xpt  UNSPECIFIEDt )org.apache.avro.generic.GenericData$Arraysq ~ vr&#010;&gt; Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xppvr&#010;&gt; Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;xp~q ~  t  CLASSx pppq ~  &amp;nbsp;&#010;&amp;nbsp;&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&amp;nbsp;&#010;&gt; &amp;nbsp;&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&#010;&gt; Iorg.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;)org.apache.avro.generic.GenericData$Array&#010;&gt; Uorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroRegisteredClass&amp;nbsp;&#010;&gt; &amp;nbsp;&#010;&gt; Yorg.apache.flink.api.java.typeutils.runtime.kryo.Serializers$DummyAvroKryoSerializerClass&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;çŒ¬? sr&#010;&gt; 9org.apache.flink.api.common.typeutils.base.LongSerializer&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xr&#010;&gt; Borg.apache.flink.api.common.typeutils.base.TypeSerializerSingletonyï¹ªî€¦.wE&#010;&gt; &amp;nbsp; xr 4org.apache.flink.api.common.typeutils.TypeSerializer&amp;nbsp;&#010;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;  &amp;nbsp; xp&amp;nbsp; &amp;nbsp;&#010;&gt; Porg.apache.flink.api.common.typeutils.base.LongSerializer$LongSerializerSnapshot&amp;nbsp;&#010;&gt; &amp;nbsp;  9org.apache.flink.api.common.typeutils.base.LongSerializerî„ˆ  vr&#010;&gt; &amp;amp;org.apache.flink.api.java.tuple.Tuple2&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; L  f0t  Ljava/lang/Object;L  f1q ~  xr&#010;&gt; %org.apache.flink.api.java.tuple.Tuple&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;  &amp;nbsp;&#010;&gt; xp&amp;nbsp;&amp;nbsp;&#010;&#010;",
        "depth": "1",
        "reply": "<tencent_D1BDD20BD21C32235A267556B799B23A0309@qq.com>"
    },
    {
        "id": "<1595305859055-0.post@n8.nabble.com>",
        "from": "jindy_liu &lt;286729...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 04:30:59 GMT",
        "subject": "flink 1.11 cdc: kafkaä¸­å­˜äº†canal-jsonæ ¼å¼çš„å¤šå¼ è¡¨ä¿¡æ¯ï¼Œéœ€è¦æŒ‰è¡¨è§£æåšå¤„ç†ï¼Œsinkè‡³ä¸åŒçš„ä¸‹æ¸¸ï¼Œè¦æ€ä¹ˆæ”¯æŒï¼Ÿ",
        "content": "ä¾‹å¦‚ï¼š&#010;&#010;mysqlè¡¨ï¼š&#010;CREATE TABLE `test` (&#010;  `id` int(11) NOT NULL,&#010;  `name` varchar(255) NOT NULL,&#010;  `time` datetime NOT NULL,&#010;  `status` int(11) NOT NULL,&#010;  PRIMARY KEY (`id`)&#010;) ENGINE=InnoDB DEFAULT CHARSET=utf8&#010;&#010;CREATE TABLE `status` (&#010;  `id` int(11) NOT NULL,&#010;  `name` varchar(255) NOT NULL,&#010;  PRIMARY KEY (`id`)&#010;) ENGINE=InnoDB DEFAULT CHARSET=utf8&#010;&#010;kafkaä¸­æ•°æ®ï¼š&#010;// è¡¨test ä¸­insertäº‹ä»¶&#010;{\"data\":[{\"id\":\"1745\",\"name\":\"jindy1745\",\"time\":\"2020-07-03&#010;18:04:22\",\"status\":\"0\"}],\"database\":\"ai_audio_lyric_task\",\"es\":1594968168000,\"id\":42,\"isDdl\":false,\"mysqlType\":{\"id\":\"int(11)\",\"name\":\"varchar(255)\",\"time\":\"datetime\",\"status\":\"int(11)\"},\"old\":null,\"pkNames\":[\"id\"],\"sql\":\"\",\"sqlType\":{\"id\":4,\"name\":12,\"time\":93,\"status\":4},\"table\":\"test\",\"ts\":1594968168789,\"type\":\"INSERT\"}&#010;&#010;//è¡¨status ä¸­çš„äº‹ä»¶&#010;{\"data\":[{\"id\":\"10\",\"name\":\"status\"}],\"database\":\"ai_audio_lyric_task\",\"es\":1595305259000,\"id\":589240,\"isDdl\":false,\"mysqlType\":{\"id\":\"int(11)\",\"name\":\"varchar(255)\"},\"old\":null,\"pkNames\":[\"id\"],\"sql\":\"\",\"sqlType\":{\"id\":4,\"name\":12},\"table\":\"status\",\"ts\":1595305259386,\"type\":\"INSERT\"}&#010;&#010;å¦‚ä½•ç”±äºkafkaä¸­çš„jsonåŠ¨æ€çš„å˜åŒ–çš„ï¼Œæ¯”å¦‚æ–°å¢ä¸€ä¸ªè¡¨ï¼Œå¦‚ä½•èƒ½è½¬æˆåº”å¯¹çš„RowDataï¼Œ&#010;æ„Ÿè§‰æ— æ³•ç›´æ¥ç”¨JsonRowDeserializationSchemaæˆ–CanalJsonDeserializationSchemaæ¥åšå¤„ç†ã€‚&#010;&#010;&#010;&#010;&#010;&#010;&#010;--&#010;Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&#010;",
        "depth": "0",
        "reply": "<1595305859055-0.post@n8.nabble.com>"
    },
    {
        "id": "<CADQYLGtos9J8kRw1VFSoPSRHaPbFm_rSvJT=f4WwBokBuR9ThA@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 07:18:38 GMT",
        "subject": "Re: flink 1.11 cdc: kafkaä¸­å­˜äº†canal-jsonæ ¼å¼çš„å¤šå¼ è¡¨ä¿¡æ¯ï¼Œéœ€è¦æŒ‰è¡¨è§£æåšå¤„ç†ï¼Œsinkè‡³ä¸åŒçš„ä¸‹æ¸¸ï¼Œè¦æ€ä¹ˆæ”¯æŒï¼Ÿ",
        "content": "http://apache-flink.147419.n8.nabble.com/flink-1-10-sql-kafka-format-json-schema-json-object-tt4665.html&#013;&#010; è¿™ä¸ªé‚®ä»¶é‡Œæåˆ°äº†ç±»ä¼¼çš„é—®é¢˜ã€‚&#013;&#010;&#013;&#010;https://issues.apache.org/jira/browse/FLINK-18002 è¿™ä¸ªissueå®Œæˆå(1.12)ï¼Œä½ å¯ä»¥å°†&#013;&#010;â€œdataâ€ï¼Œâ€œmysqlTypeâ€ç­‰æ ¼å¼ä¸ç¡®å®šçš„å­—æ®µå®šä¹‰ä¸ºStringç±»å‹ï¼Œ&#013;&#010;ä¸‹æ¸¸é€šè¿‡udfè‡ªå·±å†è§£æå¯¹åº”çš„json&#013;&#010;&#013;&#010;&#013;&#010;Best,&#013;&#010;Godfrey&#013;&#010;&#013;&#010;jindy_liu &lt;286729788@qq.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ12:37å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; ä¾‹å¦‚ï¼š&#013;&#010;&gt;&#013;&#010;&gt; mysqlè¡¨ï¼š&#013;&#010;&gt; CREATE TABLE `test` (&#013;&#010;&gt;   `id` int(11) NOT NULL,&#013;&#010;&gt;   `name` varchar(255) NOT NULL,&#013;&#010;&gt;   `time` datetime NOT NULL,&#013;&#010;&gt;   `status` int(11) NOT NULL,&#013;&#010;&gt;   PRIMARY KEY (`id`)&#013;&#010;&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8&#013;&#010;&gt;&#013;&#010;&gt; CREATE TABLE `status` (&#013;&#010;&gt;   `id` int(11) NOT NULL,&#013;&#010;&gt;   `name` varchar(255) NOT NULL,&#013;&#010;&gt;   PRIMARY KEY (`id`)&#013;&#010;&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8&#013;&#010;&gt;&#013;&#010;&gt; kafkaä¸­æ•°æ®ï¼š&#013;&#010;&gt; // è¡¨test ä¸­insertäº‹ä»¶&#013;&#010;&gt; {\"data\":[{\"id\":\"1745\",\"name\":\"jindy1745\",\"time\":\"2020-07-03&#013;&#010;&gt;&#013;&#010;&gt; 18:04:22\",\"status\":\"0\"}],\"database\":\"ai_audio_lyric_task\",\"es\":1594968168000,\"id\":42,\"isDdl\":false,\"mysqlType\":{\"id\":\"int(11)\",\"name\":\"varchar(255)\",\"time\":\"datetime\",\"status\":\"int(11)\"},\"old\":null,\"pkNames\":[\"id\"],\"sql\":\"\",\"sqlType\":{\"id\":4,\"name\":12,\"time\":93,\"status\":4},\"table\":\"test\",\"ts\":1594968168789,\"type\":\"INSERT\"}&#013;&#010;&gt;&#013;&#010;&gt; //è¡¨status ä¸­çš„äº‹ä»¶&#013;&#010;&gt;&#013;&#010;&gt; {\"data\":[{\"id\":\"10\",\"name\":\"status\"}],\"database\":\"ai_audio_lyric_task\",\"es\":1595305259000,\"id\":589240,\"isDdl\":false,\"mysqlType\":{\"id\":\"int(11)\",\"name\":\"varchar(255)\"},\"old\":null,\"pkNames\":[\"id\"],\"sql\":\"\",\"sqlType\":{\"id\":4,\"name\":12},\"table\":\"status\",\"ts\":1595305259386,\"type\":\"INSERT\"}&#013;&#010;&gt;&#013;&#010;&gt; å¦‚ä½•ç”±äºkafkaä¸­çš„jsonåŠ¨æ€çš„å˜åŒ–çš„ï¼Œæ¯”å¦‚æ–°å¢ä¸€ä¸ªè¡¨ï¼Œå¦‚ä½•èƒ½è½¬æˆåº”å¯¹çš„RowDataï¼Œ&#013;&#010;&gt; æ„Ÿè§‰æ— æ³•ç›´æ¥ç”¨JsonRowDeserializationSchemaæˆ–CanalJsonDeserializationSchemaæ¥åšå¤„ç†ã€‚&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; --&#013;&#010;&gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#013;&#010;&gt;&#013;&#010;",
        "depth": "1",
        "reply": "<1595305859055-0.post@n8.nabble.com>"
    },
    {
        "id": "<CAELO931JwYGTo9Nu772=4LqKDOmOY8ik5TQDgOqrzXfkYpYVQA@mail.gmail.com>",
        "from": "Jark Wu &lt;imj...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 14:23:40 GMT",
        "subject": "Re: flink 1.11 cdc: kafkaä¸­å­˜äº†canal-jsonæ ¼å¼çš„å¤šå¼ è¡¨ä¿¡æ¯ï¼Œéœ€è¦æŒ‰è¡¨è§£æåšå¤„ç†ï¼Œsinkè‡³ä¸åŒçš„ä¸‹æ¸¸ï¼Œè¦æ€ä¹ˆæ”¯æŒï¼Ÿ",
        "content": "Hi,&#013;&#010;&#013;&#010;ç›®å‰ Flink SQL CDC æ˜¯ä¸æ”¯æŒè‡ªåŠ¨æ„ŸçŸ¥æ–°è¡¨çš„ï¼Œå¾—è¦æå‰å®šä¹‰è¦è¡¨çš„ schema&#010;ç„¶åæäº¤åŒæ­¥ä½œä¸šã€‚æ¯”å¦‚ä½ ä¸Šé¢çš„ä¾‹å­ï¼Œå°±éœ€è¦å®šä¹‰ä¸¤ä¸ª&#013;&#010;source è¡¨ï¼š&#013;&#010;&#013;&#010;CREATE TABLE `test` (&#013;&#010;  `id` int,&#013;&#010;  `name` string,&#013;&#010;  `time` timestamp(3),&#013;&#010;  `status` int&#013;&#010;) with (&#013;&#010;  'connector' = 'kafka',&#013;&#010;  'format' = 'canal-json',&#013;&#010;  ...&#013;&#010;);&#013;&#010;&#013;&#010;insert into downstream1 select * from `test`;&#013;&#010;&#013;&#010;&#013;&#010;CREATE TABLE `status` (&#013;&#010;  `id` int&#013;&#010;  `name` string&#013;&#010;) with (&#013;&#010;  'connector' = 'kafka',&#013;&#010;  'format' = 'canal-json',&#013;&#010;  ...&#013;&#010;);&#013;&#010;&#013;&#010;insert into downstream2 select * from `status`;&#013;&#010;&#013;&#010;&#013;&#010;Best,&#013;&#010;Jark&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;On Tue, 21 Jul 2020 at 15:19, godfrey he &lt;godfreyhe@gmail.com&gt; wrote:&#013;&#010;&#013;&#010;&gt;&#013;&#010;&gt; http://apache-flink.147419.n8.nabble.com/flink-1-10-sql-kafka-format-json-schema-json-object-tt4665.html&#013;&#010;&gt;  è¿™ä¸ªé‚®ä»¶é‡Œæåˆ°äº†ç±»ä¼¼çš„é—®é¢˜ã€‚&#013;&#010;&gt;&#013;&#010;&gt; https://issues.apache.org/jira/browse/FLINK-18002 è¿™ä¸ªissueå®Œæˆå(1.12)ï¼Œä½ å¯ä»¥å°†&#013;&#010;&gt; â€œdataâ€ï¼Œâ€œmysqlTypeâ€ç­‰æ ¼å¼ä¸ç¡®å®šçš„å­—æ®µå®šä¹‰ä¸ºStringç±»å‹ï¼Œ&#013;&#010;&gt; ä¸‹æ¸¸é€šè¿‡udfè‡ªå·±å†è§£æå¯¹åº”çš„json&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; Best,&#013;&#010;&gt; Godfrey&#013;&#010;&gt;&#013;&#010;&gt; jindy_liu &lt;286729788@qq.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ12:37å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt; &gt; ä¾‹å¦‚ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; mysqlè¡¨ï¼š&#013;&#010;&gt; &gt; CREATE TABLE `test` (&#013;&#010;&gt; &gt;   `id` int(11) NOT NULL,&#013;&#010;&gt; &gt;   `name` varchar(255) NOT NULL,&#013;&#010;&gt; &gt;   `time` datetime NOT NULL,&#013;&#010;&gt; &gt;   `status` int(11) NOT NULL,&#013;&#010;&gt; &gt;   PRIMARY KEY (`id`)&#013;&#010;&gt; &gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; CREATE TABLE `status` (&#013;&#010;&gt; &gt;   `id` int(11) NOT NULL,&#013;&#010;&gt; &gt;   `name` varchar(255) NOT NULL,&#013;&#010;&gt; &gt;   PRIMARY KEY (`id`)&#013;&#010;&gt; &gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; kafkaä¸­æ•°æ®ï¼š&#013;&#010;&gt; &gt; // è¡¨test ä¸­insertäº‹ä»¶&#013;&#010;&gt; &gt; {\"data\":[{\"id\":\"1745\",\"name\":\"jindy1745\",\"time\":\"2020-07-03&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; 18:04:22\",\"status\":\"0\"}],\"database\":\"ai_audio_lyric_task\",\"es\":1594968168000,\"id\":42,\"isDdl\":false,\"mysqlType\":{\"id\":\"int(11)\",\"name\":\"varchar(255)\",\"time\":\"datetime\",\"status\":\"int(11)\"},\"old\":null,\"pkNames\":[\"id\"],\"sql\":\"\",\"sqlType\":{\"id\":4,\"name\":12,\"time\":93,\"status\":4},\"table\":\"test\",\"ts\":1594968168789,\"type\":\"INSERT\"}&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; //è¡¨status ä¸­çš„äº‹ä»¶&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; {\"data\":[{\"id\":\"10\",\"name\":\"status\"}],\"database\":\"ai_audio_lyric_task\",\"es\":1595305259000,\"id\":589240,\"isDdl\":false,\"mysqlType\":{\"id\":\"int(11)\",\"name\":\"varchar(255)\"},\"old\":null,\"pkNames\":[\"id\"],\"sql\":\"\",\"sqlType\":{\"id\":4,\"name\":12},\"table\":\"status\",\"ts\":1595305259386,\"type\":\"INSERT\"}&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; å¦‚ä½•ç”±äºkafkaä¸­çš„jsonåŠ¨æ€çš„å˜åŒ–çš„ï¼Œæ¯”å¦‚æ–°å¢ä¸€ä¸ªè¡¨ï¼Œå¦‚ä½•èƒ½è½¬æˆåº”å¯¹çš„RowDataï¼Œ&#013;&#010;&gt; &gt; æ„Ÿè§‰æ— æ³•ç›´æ¥ç”¨JsonRowDeserializationSchemaæˆ–CanalJsonDeserializationSchemaæ¥åšå¤„ç†ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; --&#013;&#010;&gt; &gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<1595305859055-0.post@n8.nabble.com>"
    },
    {
        "id": "<1595316869156-0.post@n8.nabble.com>",
        "from": "lgs &lt;9925...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 07:34:29 GMT",
        "subject": "flink1.11 pyflink stream job é€€å‡º",
        "content": "python flink_cep_example.py è¿‡å‡ ç§’å°±é€€å‡ºäº†ï¼Œåº”è¯¥ä¸€ç›´è¿è¡Œä¸é€€å‡ºçš„å•Šã€‚&#010;ä»£ç å¦‚ä¸‹ï¼Œä½¿ç”¨äº†MATCH_RECOGNIZEï¼š&#010;&#010;    s_env = StreamExecutionEnvironment.get_execution_environment()&#010;    b_s_settings =&#010;EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()&#010;    st_env = StreamTableEnvironment.create(s_env,&#010;environment_settings=b_s_settings)&#010;    configuration = st_env.get_config().get_configuration()&#010;    configuration.set_string(\"taskmanager.memory.task.off-heap.size\",&#010;\"500m\")&#010;&#010;    s_env.set_parallelism(1)&#010;&#010;    kafka_source = \"\"\"CREATE TABLE source (&#010;         flow_name STRING,&#010;         flow_id STRING,&#010;         component STRING,&#010;         filename STRING,&#010;         event_time TIMESTAMP(3),&#010;         WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND&#010;        ) WITH (&#010;         'connector' = 'kafka',&#010;         'topic' = 'cep',&#010;         'properties.bootstrap.servers' = 'localhost:9092',&#010;         'format' = 'json',&#010;         'scan.startup.mode' = 'latest-offset'&#010;        )\"\"\"&#010;&#010;&#010;&#010;    postgres_sink = \"\"\"&#010;        CREATE TABLE cep_result (&#010;        `filename`         STRING,&#010;        `start_tstamp`          TIMESTAMP(3),&#010;        `end_tstamp`           TIMESTAMP(3)&#010;        ) WITH (&#010;        'connector.type' = 'jdbc',&#010;        'connector.url' = 'jdbc:postgresql://127.0.0.1:5432/postgres',&#010;        'connector.table' = 'cep_result',&#010;        'connector.driver' = 'org.postgresql.Driver',&#010;        'connector.username' = 'postgres',&#010;        'connector.password' = 'my_password',&#010;        'connector.write.flush.max-rows' = '1'&#010;        )&#010;        \"\"\"&#010;&#010;    st_env.sql_update(kafka_source)&#010;    st_env.sql_update(postgres_sink)&#010;&#010;    postgres_sink_sql = '''&#010;        INSERT INTO cep_result&#010;        SELECT *&#010;        FROM source&#010;            MATCH_RECOGNIZE (&#010;                PARTITION BY filename&#010;                ORDER BY event_time&#010;                MEASURES&#010;                    (A.event_time) AS start_tstamp,&#010;                    (D.event_time) AS end_tstamp&#010;                ONE ROW PER MATCH&#010;                AFTER MATCH SKIP PAST LAST ROW&#010;                PATTERN (A B C D)&#010;                DEFINE&#010;                    A AS component = 'XXX',&#010;                    B AS component = 'YYY',&#010;                    C AS component = 'ZZZ',&#010;                    D AS component = 'WWW'&#010;            ) MR&#010;    '''&#010;&#010;    sql_result = st_env.execute_sql(postgres_sink_sql)&#010;&#010;&#010;&#010;--&#010;Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&#010;",
        "depth": "0",
        "reply": "<1595316869156-0.post@n8.nabble.com>"
    },
    {
        "id": "<CAPxmL=ELkWmfK4TihptLtxwEXk4ZfoDGZ0cjcX5fjGN_BUqsjQ@mail.gmail.com>",
        "from": "Xingbo Huang &lt;hxbks...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 07:40:52 GMT",
        "subject": "Re: flink1.11 pyflink stream job é€€å‡º",
        "content": "Hi,&#010;execute_sqlæ˜¯ä¸€ä¸ªå¼‚æ­¥éé˜»å¡çš„æ–¹æ³•ï¼Œæ‰€ä»¥ä½ éœ€è¦åœ¨ä½ çš„ä»£ç æœ«å°¾åŠ ä¸Š&#010;sql_result.get_job_client().get_job_execution_result().result()&#010;å¯¹æ­¤æˆ‘å·²ç»åˆ›å»ºäº†JIRA[1]&#010;&#010;[1] https://issues.apache.org/jira/browse/FLINK-18598&#010;&#010;Best,&#010;Xingbo&#010;&#010;lgs &lt;9925174@qq.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ3:35å†™é“ï¼š&#010;&#010;&gt; python flink_cep_example.py è¿‡å‡ ç§’å°±é€€å‡ºäº†ï¼Œåº”è¯¥ä¸€ç›´è¿è¡Œä¸é€€å‡ºçš„å•Šã€‚&#010;&gt; ä»£ç å¦‚ä¸‹ï¼Œä½¿ç”¨äº†MATCH_RECOGNIZEï¼š&#010;&gt;&#010;&gt;     s_env = StreamExecutionEnvironment.get_execution_environment()&#010;&gt;     b_s_settings =&#010;&gt;&#010;&gt; EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()&#010;&gt;     st_env = StreamTableEnvironment.create(s_env,&#010;&gt; environment_settings=b_s_settings)&#010;&gt;     configuration = st_env.get_config().get_configuration()&#010;&gt;     configuration.set_string(\"taskmanager.memory.task.off-heap.size\",&#010;&gt; \"500m\")&#010;&gt;&#010;&gt;     s_env.set_parallelism(1)&#010;&gt;&#010;&gt;     kafka_source = \"\"\"CREATE TABLE source (&#010;&gt;          flow_name STRING,&#010;&gt;          flow_id STRING,&#010;&gt;          component STRING,&#010;&gt;          filename STRING,&#010;&gt;          event_time TIMESTAMP(3),&#010;&gt;          WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND&#010;&gt;         ) WITH (&#010;&gt;          'connector' = 'kafka',&#010;&gt;          'topic' = 'cep',&#010;&gt;          'properties.bootstrap.servers' = 'localhost:9092',&#010;&gt;          'format' = 'json',&#010;&gt;          'scan.startup.mode' = 'latest-offset'&#010;&gt;         )\"\"\"&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;     postgres_sink = \"\"\"&#010;&gt;         CREATE TABLE cep_result (&#010;&gt;         `filename`         STRING,&#010;&gt;         `start_tstamp`          TIMESTAMP(3),&#010;&gt;         `end_tstamp`           TIMESTAMP(3)&#010;&gt;         ) WITH (&#010;&gt;         'connector.type' = 'jdbc',&#010;&gt;         'connector.url' = 'jdbc:postgresql://127.0.0.1:5432/postgres',&#010;&gt;         'connector.table' = 'cep_result',&#010;&gt;         'connector.driver' = 'org.postgresql.Driver',&#010;&gt;         'connector.username' = 'postgres',&#010;&gt;         'connector.password' = 'my_password',&#010;&gt;         'connector.write.flush.max-rows' = '1'&#010;&gt;         )&#010;&gt;         \"\"\"&#010;&gt;&#010;&gt;     st_env.sql_update(kafka_source)&#010;&gt;     st_env.sql_update(postgres_sink)&#010;&gt;&#010;&gt;     postgres_sink_sql = '''&#010;&gt;         INSERT INTO cep_result&#010;&gt;         SELECT *&#010;&gt;         FROM source&#010;&gt;             MATCH_RECOGNIZE (&#010;&gt;                 PARTITION BY filename&#010;&gt;                 ORDER BY event_time&#010;&gt;                 MEASURES&#010;&gt;                     (A.event_time) AS start_tstamp,&#010;&gt;                     (D.event_time) AS end_tstamp&#010;&gt;                 ONE ROW PER MATCH&#010;&gt;                 AFTER MATCH SKIP PAST LAST ROW&#010;&gt;                 PATTERN (A B C D)&#010;&gt;                 DEFINE&#010;&gt;                     A AS component = 'XXX',&#010;&gt;                     B AS component = 'YYY',&#010;&gt;                     C AS component = 'ZZZ',&#010;&gt;                     D AS component = 'WWW'&#010;&gt;             ) MR&#010;&gt;     '''&#010;&gt;&#010;&gt;     sql_result = st_env.execute_sql(postgres_sink_sql)&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; --&#010;&gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&gt;&#010;&#010;",
        "depth": "1",
        "reply": "<1595316869156-0.post@n8.nabble.com>"
    },
    {
        "id": "<1595318179889-0.post@n8.nabble.com>",
        "from": "lgs &lt;9925...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 07:56:19 GMT",
        "subject": "Re: flink1.11 pyflink stream job é€€å‡º",
        "content": "è°¢è°¢ã€‚åŠ ä¸Šåå°±å¯ä»¥äº†ã€‚&#010;&#010;æ”¹æˆåŸæ¥çš„sql_updateç„¶åst_env.execute(\"job\")å¥½åƒä¹Ÿå¯ä»¥ã€‚&#010;&#010;&#010;&#010;--&#010;Sent from: http://apache-flink.147419.n8.nabble.com/&#010;&#010;",
        "depth": "2",
        "reply": "<1595316869156-0.post@n8.nabble.com>"
    },
    {
        "id": "<CAPxmL=Fw1gWvQfNKPc+yRGL5fcvS++-9jW=V8mcKAqZoOnL0mg@mail.gmail.com>",
        "from": "Xingbo Huang &lt;hxbks...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 08:01:26 GMT",
        "subject": "Re: flink1.11 pyflink stream job é€€å‡º",
        "content": "æ˜¯çš„ï¼Œexecuteæ˜¯1.10åŠä»¥å‰ä½¿ç”¨çš„ï¼Œexecute_sqlæ˜¯1.11ä¹‹åæ¨èä½¿ç”¨çš„&#013;&#010;&#013;&#010;Best,&#013;&#010;Xingbo&#013;&#010;&#013;&#010;lgs &lt;9925174@qq.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ3:57å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; è°¢è°¢ã€‚åŠ ä¸Šåå°±å¯ä»¥äº†ã€‚&#013;&#010;&gt;&#013;&#010;&gt; æ”¹æˆåŸæ¥çš„sql_updateç„¶åst_env.execute(\"job\")å¥½åƒä¹Ÿå¯ä»¥ã€‚&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; --&#013;&#010;&gt; Sent from: http://apache-flink.147419.n8.nabble.com/&#013;&#010;&gt;&#013;&#010;",
        "depth": "3",
        "reply": "<1595316869156-0.post@n8.nabble.com>"
    },
    {
        "id": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 08:08:05 GMT",
        "subject": "flinkè§£ækafka jsonæ•°æ®",
        "content": "hi&#013;&#010;æˆ‘è¿™é¢åœ¨ä½¿ç”¨sql apiè§£ækafka&#013;&#010;jsonæ•°æ®ï¼Œåœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘ç°jsonæ•°æ®è§£æçš„æ—¶å€™æœ‰ä¸‹é¢ä¸¤é¡¹ï¼Œè¿™ä¸¤é¡¹å¦‚æœå¼€å¯é‚£ä¹ˆè§£æå¤±è´¥çš„æ•°æ®æ˜¯ä¼šè¢«ä¸¢æ‰å—ï¼Œæœ‰æ²¡æœ‰æ–¹å¼å¯ä»¥æŠŠè§£æå¤±è´¥çš„æ•°æ®æ‰“åˆ°å¤–éƒ¨å­˜å‚¨&#013;&#010;&#013;&#010;json.ignore-parse-errors&#013;&#010;son.fail-on-missing-field&#013;&#010;",
        "depth": "0",
        "reply": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>"
    },
    {
        "id": "<9DB7BC3E-8CF9-4217-9E51-F1E87AE331CF@gmail.com>",
        "from": "Leonard Xu &lt;xbjt...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 08:18:06 GMT",
        "subject": "Re: flinkè§£ækafka jsonæ•°æ®",
        "content": "Hi,&#013;&#010;æˆ‘ç†è§£åº”è¯¥åšä¸åˆ°ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªformatå‚æ•°åœ¨formaté‡Œå°±åšçš„ã€‚&#013;&#010;json.ignore-parse-errors æ˜¯åœ¨ formatè§£ææ—¶è·³è¿‡è§£æå¤±è´¥çš„æ•°æ®ç»§ç»­è§£æä¸‹ä¸€è¡Œï¼Œjson.fail-on-missing-field&#010;æ˜¯æ ‡è®°å¦‚æœå­—æ®µå°‘æ—¶æ˜¯å¦å¤±è´¥è¿˜æ˜¯ç»§ç»­(ç¼ºå°‘çš„å­—æ®µç”¨nullè¡¥ä¸Šï¼‰&#013;&#010;è¿™ä¸¤ä¸ªä¸èƒ½åŒæ—¶ä¸ºtureï¼Œè¯­ä¹‰ä¸Šå°±æ˜¯äº’æ–¥çš„ã€‚&#013;&#010;&#013;&#010;Best&#013;&#010;Leonard Xu&#013;&#010;&gt; åœ¨ 2020å¹´7æœˆ21æ—¥ï¼Œ16:08ï¼ŒDream-åº•é™ &lt;zhangyu@akulaku.com&gt; å†™é“ï¼š&#013;&#010;&gt; &#013;&#010;&gt; jsonæ•°æ®ï¼Œåœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘ç°jsonæ•°æ®è§£æçš„æ—¶å€™æœ‰ä¸‹é¢ä¸¤é¡¹ï¼Œè¿™ä¸¤é¡¹å¦‚æœå¼€å¯é‚£ä¹ˆè§£æå¤±è´¥çš„æ•°æ®æ˜¯ä¼šè¢«ä¸¢æ‰å—ï¼Œæœ‰æ²¡æœ‰æ–¹å¼å¯ä»¥æŠŠè§£æå¤±è´¥çš„æ•°æ®æ‰“åˆ°å¤–éƒ¨å­˜å‚¨&#013;&#010;&#013;&#010;",
        "depth": "1",
        "reply": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>"
    },
    {
        "id": "<CAEZk042wH3w_rPqmjZ3_LxkcZB=qa+AOu7giDMe+ibekOn7Ajg@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 10:52:34 GMT",
        "subject": "Re: flinkè§£ækafka jsonæ•°æ®",
        "content": "hi&#013;&#010; json.ignore-parse-errorsé‚£åªé…ç½®è¿™ä¸ªå°±å¥½äº†ï¼Œ å…¶å®æˆ‘æƒ³æŠŠè§£æå¤±è´¥çš„æ•°æ®å­˜å‚¨åˆ°å¤–éƒ¨ç³»ç»Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ä¸¢å¼ƒ&#013;&#010;&#013;&#010;Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ4:18å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; Hi,&#013;&#010;&gt; æˆ‘ç†è§£åº”è¯¥åšä¸åˆ°ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªformatå‚æ•°åœ¨formaté‡Œå°±åšçš„ã€‚&#013;&#010;&gt; json.ignore-parse-errors æ˜¯åœ¨&#013;&#010;&gt; formatè§£ææ—¶è·³è¿‡è§£æå¤±è´¥çš„æ•°æ®ç»§ç»­è§£æä¸‹ä¸€è¡Œï¼Œjson.fail-on-missing-field&#013;&#010;&gt; æ˜¯æ ‡è®°å¦‚æœå­—æ®µå°‘æ—¶æ˜¯å¦å¤±è´¥è¿˜æ˜¯ç»§ç»­(ç¼ºå°‘çš„å­—æ®µç”¨nullè¡¥ä¸Šï¼‰&#013;&#010;&gt; è¿™ä¸¤ä¸ªä¸èƒ½åŒæ—¶ä¸ºtureï¼Œè¯­ä¹‰ä¸Šå°±æ˜¯äº’æ–¥çš„ã€‚&#013;&#010;&gt;&#013;&#010;&gt; Best&#013;&#010;&gt; Leonard Xu&#013;&#010;&gt; &gt; åœ¨ 2020å¹´7æœˆ21æ—¥ï¼Œ16:08ï¼ŒDream-åº•é™ &lt;zhangyu@akulaku.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; jsonæ•°æ®ï¼Œåœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘ç°jsonæ•°æ®è§£æçš„æ—¶å€™æœ‰ä¸‹é¢ä¸¤é¡¹ï¼Œè¿™ä¸¤é¡¹å¦‚æœå¼€å¯é‚£ä¹ˆè§£æå¤±è´¥çš„æ•°æ®æ˜¯ä¼šè¢«ä¸¢æ‰å—ï¼Œæœ‰æ²¡æœ‰æ–¹å¼å¯ä»¥æŠŠè§£æå¤±è´¥çš„æ•°æ®æ‰“åˆ°å¤–éƒ¨å­˜å‚¨&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "2",
        "reply": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>"
    },
    {
        "id": "<CAELO930GUN6bNuhfq=KGmV1+z3WEvaFumDY4DDr6LJLJD9euZA@mail.gmail.com>",
        "from": "Jark Wu &lt;imj...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 14:29:55 GMT",
        "subject": "Re: flinkè§£ækafka jsonæ•°æ®",
        "content": "ç›®å‰æ˜¯ä¸æ”¯æŒçš„ã€‚è¿™ä¸ªéœ€æ±‚æœ‰ç‚¹å¤ªä¸šåŠ¡ç‰¹å®šäº†ã€‚flink ä¸å¯èƒ½ä¸ºäº†ä¸€ä¸ªé”™è¯¯æ—¥å¿—å»æŠ½è±¡ã€å¯¹æ¥å„ç§å­˜å‚¨ç³»ç»Ÿã€‚&#013;&#010;ä¸€ç§æ–¹æ¡ˆæ˜¯ç¤¾åŒºå¯ä»¥è€ƒè™‘æ”¯æŒä¸‹æ‰“å°åˆ°æ—¥å¿—é‡Œï¼Œç„¶åç”¨æˆ·å¯ä»¥é€šè¿‡è‡ªå®šä¹‰æ’ä»¶&#010;log appender å†™å…¥å¤–éƒ¨å­˜å‚¨ã€‚&#013;&#010;&#013;&#010;Best,&#013;&#010;Jark&#013;&#010;&#013;&#010;On Tue, 21 Jul 2020 at 18:53, Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; hi&#013;&#010;&gt;  json.ignore-parse-errorsé‚£åªé…ç½®è¿™ä¸ªå°±å¥½äº†ï¼Œ å…¶å®æˆ‘æƒ³æŠŠè§£æå¤±è´¥çš„æ•°æ®å­˜å‚¨åˆ°å¤–éƒ¨ç³»ç»Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ä¸¢å¼ƒ&#013;&#010;&gt;&#013;&#010;&gt; Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ4:18å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt; &gt; Hi,&#013;&#010;&gt; &gt; æˆ‘ç†è§£åº”è¯¥åšä¸åˆ°ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªformatå‚æ•°åœ¨formaté‡Œå°±åšçš„ã€‚&#013;&#010;&gt; &gt; json.ignore-parse-errors æ˜¯åœ¨&#013;&#010;&gt; &gt; formatè§£ææ—¶è·³è¿‡è§£æå¤±è´¥çš„æ•°æ®ç»§ç»­è§£æä¸‹ä¸€è¡Œï¼Œjson.fail-on-missing-field&#013;&#010;&gt; &gt; æ˜¯æ ‡è®°å¦‚æœå­—æ®µå°‘æ—¶æ˜¯å¦å¤±è´¥è¿˜æ˜¯ç»§ç»­(ç¼ºå°‘çš„å­—æ®µç”¨nullè¡¥ä¸Šï¼‰&#013;&#010;&gt; &gt; è¿™ä¸¤ä¸ªä¸èƒ½åŒæ—¶ä¸ºtureï¼Œè¯­ä¹‰ä¸Šå°±æ˜¯äº’æ–¥çš„ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Best&#013;&#010;&gt; &gt; Leonard Xu&#013;&#010;&gt; &gt; &gt; åœ¨ 2020å¹´7æœˆ21æ—¥ï¼Œ16:08ï¼ŒDream-åº•é™ &lt;zhangyu@akulaku.com&gt; å†™é“ï¼š&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; jsonæ•°æ®ï¼Œåœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘ç°jsonæ•°æ®è§£æçš„æ—¶å€™æœ‰ä¸‹é¢ä¸¤é¡¹ï¼Œè¿™ä¸¤é¡¹å¦‚æœå¼€å¯é‚£ä¹ˆè§£æå¤±è´¥çš„æ•°æ®æ˜¯ä¼šè¢«ä¸¢æ‰å—ï¼Œæœ‰æ²¡æœ‰æ–¹å¼å¯ä»¥æŠŠè§£æå¤±è´¥çš„æ•°æ®æ‰“åˆ°å¤–éƒ¨å­˜å‚¨&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "3",
        "reply": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>"
    },
    {
        "id": "<CAEZk040+2AdHOpiZb0At5bg8TaDPvyWkM8GnGsBOuc3h_e41qg@mail.gmail.com>",
        "from": "Dream-åº•é™ &lt;zhan...@akulaku.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 24 Jul 2020 03:36:02 GMT",
        "subject": "Re: flinkè§£ækafka jsonæ•°æ®",
        "content": "hi jark wuã€&#013;&#010;å°†è§£æé”™è¯¯æ•°æ®ç›´æ¥æ‰“åˆ°æ—¥å¿—é‡Œç¡®å®æ˜¯æ¯”è¾ƒé€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼›&#013;&#010;æˆ‘ç°åœ¨ä½¿ç”¨flink sqlå¯¹æ¥kafka&#013;&#010;jsonæ•°æ®çš„æ—¶å€™ï¼Œå‘ç°å¯¹jsonæ•°æ®çš„è§£ææœ‰ä¸€äº›å±€é™æ€§ï¼Œå³æ¯”å¦‚æˆ‘æœ‰ä¸€æ¡æ•°æ®æ˜¯jsonobjectï¼Œä½†æ˜¯æˆ‘åœ¨å®šä¹‰flink&#010;sql&#013;&#010;connectoræ•°æ®ç±»å‹çš„æ—¶å€™å¦‚æœç›´æ¥å®šä¹‰ä¸ºstringï¼Œä¼šå¯¼è‡´æ•°æ®è§£æå¤±è´¥ï¼ˆå½“ç„¶ï¼Œè¿™ä¸ªå¤±è´¥æ˜¯æ­£å¸¸çš„ï¼‰&#013;&#010;ä½†æ˜¯è¿™ä¼šæœ‰ä¸€ä¸ªå±€é™æ€§å°±æ˜¯æˆ‘æ²¡åŠæ³•ä»¥ä¸€ä¸ªstringæ–¹å¼è·å–ä¸€ä¸ªjsonobjectæ•°æ®ï¼ˆç”±äºä¸€äº›æ¯”è¾ƒå°´å°¬çš„åŸå› å°±æƒ³ä»¥stringæ–¹å¼è·å–jsonobjectæ•°æ®ï¼‰ï¼ŒæŸ¥çœ‹ä»£ç å‘ç°è¿™æ˜¯jacksonå¯¼è‡´çš„è·å–å¤±è´¥ï¼Œè¿™ä¸ªç¤¾åŒºè€ƒè™‘å…¼å®¹ä¸€ä¸‹å—ï¼Ÿ&#013;&#010;&#013;&#010;if (simpleTypeInfo == Types.STRING) {&#013;&#010;   return Optional.of((mapper, jsonNode) -&gt; jsonNode.asText());//&#013;&#010;è¿™é‡Œä¼šè¿”å›ç©ºï¼Œæ”¹æˆä¸‹é¢æ ·å­å…¼å®¹ä¸€ä¸‹&#013;&#010;&#013;&#010;if (simpleTypeInfo == Types.STRING) {&#013;&#010;   return Optional.of((mapper, jsonNode) -&gt;&#013;&#010;jsonNode.isTextual()?jsonNode.asText():jsonNode.toString());&#013;&#010;&#013;&#010;&#013;&#010;Jark Wu &lt;imjark@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ10:30å†™é“ï¼š&#013;&#010;&#013;&#010;&gt; ç›®å‰æ˜¯ä¸æ”¯æŒçš„ã€‚è¿™ä¸ªéœ€æ±‚æœ‰ç‚¹å¤ªä¸šåŠ¡ç‰¹å®šäº†ã€‚flink ä¸å¯èƒ½ä¸ºäº†ä¸€ä¸ªé”™è¯¯æ—¥å¿—å»æŠ½è±¡ã€å¯¹æ¥å„ç§å­˜å‚¨ç³»ç»Ÿã€‚&#013;&#010;&gt; ä¸€ç§æ–¹æ¡ˆæ˜¯ç¤¾åŒºå¯ä»¥è€ƒè™‘æ”¯æŒä¸‹æ‰“å°åˆ°æ—¥å¿—é‡Œï¼Œç„¶åç”¨æˆ·å¯ä»¥é€šè¿‡è‡ªå®šä¹‰æ’ä»¶&#010;log appender å†™å…¥å¤–éƒ¨å­˜å‚¨ã€‚&#013;&#010;&gt;&#013;&#010;&gt; Best,&#013;&#010;&gt; Jark&#013;&#010;&gt;&#013;&#010;&gt; On Tue, 21 Jul 2020 at 18:53, Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt;&#013;&#010;&gt; &gt; hi&#013;&#010;&gt; &gt;  json.ignore-parse-errorsé‚£åªé…ç½®è¿™ä¸ªå°±å¥½äº†ï¼Œ å…¶å®æˆ‘æƒ³æŠŠè§£æå¤±è´¥çš„æ•°æ®å­˜å‚¨åˆ°å¤–éƒ¨ç³»ç»Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ä¸¢å¼ƒ&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ4:18å†™é“ï¼š&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; &gt; Hi,&#013;&#010;&gt; &gt; &gt; æˆ‘ç†è§£åº”è¯¥åšä¸åˆ°ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªformatå‚æ•°åœ¨formaté‡Œå°±åšçš„ã€‚&#013;&#010;&gt; &gt; &gt; json.ignore-parse-errors æ˜¯åœ¨&#013;&#010;&gt; &gt; &gt; formatè§£ææ—¶è·³è¿‡è§£æå¤±è´¥çš„æ•°æ®ç»§ç»­è§£æä¸‹ä¸€è¡Œï¼Œjson.fail-on-missing-field&#013;&#010;&gt; &gt; &gt; æ˜¯æ ‡è®°å¦‚æœå­—æ®µå°‘æ—¶æ˜¯å¦å¤±è´¥è¿˜æ˜¯ç»§ç»­(ç¼ºå°‘çš„å­—æ®µç”¨nullè¡¥ä¸Šï¼‰&#013;&#010;&gt; &gt; &gt; è¿™ä¸¤ä¸ªä¸èƒ½åŒæ—¶ä¸ºtureï¼Œè¯­ä¹‰ä¸Šå°±æ˜¯äº’æ–¥çš„ã€‚&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; Best&#013;&#010;&gt; &gt; &gt; Leonard Xu&#013;&#010;&gt; &gt; &gt; &gt; åœ¨ 2020å¹´7æœˆ21æ—¥ï¼Œ16:08ï¼ŒDream-åº•é™ &lt;zhangyu@akulaku.com&gt;&#010;å†™é“ï¼š&#013;&#010;&gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; jsonæ•°æ®ï¼Œåœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘ç°jsonæ•°æ®è§£æçš„æ—¶å€™æœ‰ä¸‹é¢ä¸¤é¡¹ï¼Œè¿™ä¸¤é¡¹å¦‚æœå¼€å¯é‚£ä¹ˆè§£æå¤±è´¥çš„æ•°æ®æ˜¯ä¼šè¢«ä¸¢æ‰å—ï¼Œæœ‰æ²¡æœ‰æ–¹å¼å¯ä»¥æŠŠè§£æå¤±è´¥çš„æ•°æ®æ‰“åˆ°å¤–éƒ¨å­˜å‚¨&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "4",
        "reply": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>"
    },
    {
        "id": "<CAELO931_fU0EJoyWMQ=ReVPdpOLxaWaTNdikdpMQgHLwBZ4thw@mail.gmail.com>",
        "from": "Jark Wu &lt;imj...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Fri, 24 Jul 2020 04:16:01 GMT",
        "subject": "Re: flinkè§£ækafka jsonæ•°æ®",
        "content": "å“ˆå“ˆï¼Œçœ‹æ¥æ˜¯ä¸€ä¸ªå¾ˆé€šç”¨çš„éœ€æ±‚å•Šã€‚ æœ¬è¶…åŒå­¦å·²ç»åœ¨1.12 ä¸­æ”¯æŒäº†è¿™ä¸ªåŠŸèƒ½äº†ï¼Œ&#010;see&#013;&#010;https://issues.apache.org/jira/browse/FLINK-18002&#013;&#010;&#013;&#010;Best,&#013;&#010;Jark&#013;&#010;&#013;&#010;On Fri, 24 Jul 2020 at 11:36, Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&#013;&#010;&gt; hi jark wuã€&#013;&#010;&gt; å°†è§£æé”™è¯¯æ•°æ®ç›´æ¥æ‰“åˆ°æ—¥å¿—é‡Œç¡®å®æ˜¯æ¯”è¾ƒé€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼›&#013;&#010;&gt; æˆ‘ç°åœ¨ä½¿ç”¨flink sqlå¯¹æ¥kafka&#013;&#010;&gt; jsonæ•°æ®çš„æ—¶å€™ï¼Œå‘ç°å¯¹jsonæ•°æ®çš„è§£ææœ‰ä¸€äº›å±€é™æ€§ï¼Œå³æ¯”å¦‚æˆ‘æœ‰ä¸€æ¡æ•°æ®æ˜¯jsonobjectï¼Œä½†æ˜¯æˆ‘åœ¨å®šä¹‰flink&#010;sql&#013;&#010;&gt; connectoræ•°æ®ç±»å‹çš„æ—¶å€™å¦‚æœç›´æ¥å®šä¹‰ä¸ºstringï¼Œä¼šå¯¼è‡´æ•°æ®è§£æå¤±è´¥ï¼ˆå½“ç„¶ï¼Œè¿™ä¸ªå¤±è´¥æ˜¯æ­£å¸¸çš„ï¼‰&#013;&#010;&gt;&#013;&#010;&gt; ä½†æ˜¯è¿™ä¼šæœ‰ä¸€ä¸ªå±€é™æ€§å°±æ˜¯æˆ‘æ²¡åŠæ³•ä»¥ä¸€ä¸ªstringæ–¹å¼è·å–ä¸€ä¸ªjsonobjectæ•°æ®ï¼ˆç”±äºä¸€äº›æ¯”è¾ƒå°´å°¬çš„åŸå› å°±æƒ³ä»¥stringæ–¹å¼è·å–jsonobjectæ•°æ®ï¼‰ï¼ŒæŸ¥çœ‹ä»£ç å‘ç°è¿™æ˜¯jacksonå¯¼è‡´çš„è·å–å¤±è´¥ï¼Œè¿™ä¸ªç¤¾åŒºè€ƒè™‘å…¼å®¹ä¸€ä¸‹å—ï¼Ÿ&#013;&#010;&gt;&#013;&#010;&gt; if (simpleTypeInfo == Types.STRING) {&#013;&#010;&gt;    return Optional.of((mapper, jsonNode) -&gt; jsonNode.asText());//&#013;&#010;&gt; è¿™é‡Œä¼šè¿”å›ç©ºï¼Œæ”¹æˆä¸‹é¢æ ·å­å…¼å®¹ä¸€ä¸‹&#013;&#010;&gt;&#013;&#010;&gt; if (simpleTypeInfo == Types.STRING) {&#013;&#010;&gt;    return Optional.of((mapper, jsonNode) -&gt;&#013;&#010;&gt; jsonNode.isTextual()?jsonNode.asText():jsonNode.toString());&#013;&#010;&gt;&#013;&#010;&gt;&#013;&#010;&gt; Jark Wu &lt;imjark@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ10:30å†™é“ï¼š&#013;&#010;&gt;&#013;&#010;&gt; &gt; ç›®å‰æ˜¯ä¸æ”¯æŒçš„ã€‚è¿™ä¸ªéœ€æ±‚æœ‰ç‚¹å¤ªä¸šåŠ¡ç‰¹å®šäº†ã€‚flink ä¸å¯èƒ½ä¸ºäº†ä¸€ä¸ªé”™è¯¯æ—¥å¿—å»æŠ½è±¡ã€å¯¹æ¥å„ç§å­˜å‚¨ç³»ç»Ÿã€‚&#013;&#010;&gt; &gt; ä¸€ç§æ–¹æ¡ˆæ˜¯ç¤¾åŒºå¯ä»¥è€ƒè™‘æ”¯æŒä¸‹æ‰“å°åˆ°æ—¥å¿—é‡Œï¼Œç„¶åç”¨æˆ·å¯ä»¥é€šè¿‡è‡ªå®šä¹‰æ’ä»¶&#010;log appender å†™å…¥å¤–éƒ¨å­˜å‚¨ã€‚&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; Best,&#013;&#010;&gt; &gt; Jark&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; On Tue, 21 Jul 2020 at 18:53, Dream-åº•é™ &lt;zhangyu@akulaku.com&gt; wrote:&#013;&#010;&gt; &gt;&#013;&#010;&gt; &gt; &gt; hi&#013;&#010;&gt; &gt; &gt;  json.ignore-parse-errorsé‚£åªé…ç½®è¿™ä¸ªå°±å¥½äº†ï¼Œ å…¶å®æˆ‘æƒ³æŠŠè§£æå¤±è´¥çš„æ•°æ®å­˜å‚¨åˆ°å¤–éƒ¨ç³»ç»Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ä¸¢å¼ƒ&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; Leonard Xu &lt;xbjtdcq@gmail.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ4:18å†™é“ï¼š&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; &gt; Hi,&#013;&#010;&gt; &gt; &gt; &gt; æˆ‘ç†è§£åº”è¯¥åšä¸åˆ°ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªformatå‚æ•°åœ¨formaté‡Œå°±åšçš„ã€‚&#013;&#010;&gt; &gt; &gt; &gt; json.ignore-parse-errors æ˜¯åœ¨&#013;&#010;&gt; &gt; &gt; &gt; formatè§£ææ—¶è·³è¿‡è§£æå¤±è´¥çš„æ•°æ®ç»§ç»­è§£æä¸‹ä¸€è¡Œï¼Œjson.fail-on-missing-field&#013;&#010;&gt; &gt; &gt; &gt; æ˜¯æ ‡è®°å¦‚æœå­—æ®µå°‘æ—¶æ˜¯å¦å¤±è´¥è¿˜æ˜¯ç»§ç»­(ç¼ºå°‘çš„å­—æ®µç”¨nullè¡¥ä¸Šï¼‰&#013;&#010;&gt; &gt; &gt; &gt; è¿™ä¸¤ä¸ªä¸èƒ½åŒæ—¶ä¸ºtureï¼Œè¯­ä¹‰ä¸Šå°±æ˜¯äº’æ–¥çš„ã€‚&#013;&#010;&gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; &gt; Best&#013;&#010;&gt; &gt; &gt; &gt; Leonard Xu&#013;&#010;&gt; &gt; &gt; &gt; &gt; åœ¨ 2020å¹´7æœˆ21æ—¥ï¼Œ16:08ï¼ŒDream-åº•é™ &lt;zhangyu@akulaku.com&gt;&#010;å†™é“ï¼š&#013;&#010;&gt; &gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt; jsonæ•°æ®ï¼Œåœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘ç°jsonæ•°æ®è§£æçš„æ—¶å€™æœ‰ä¸‹é¢ä¸¤é¡¹ï¼Œè¿™ä¸¤é¡¹å¦‚æœå¼€å¯é‚£ä¹ˆè§£æå¤±è´¥çš„æ•°æ®æ˜¯ä¼šè¢«ä¸¢æ‰å—ï¼Œæœ‰æ²¡æœ‰æ–¹å¼å¯ä»¥æŠŠè§£æå¤±è´¥çš„æ•°æ®æ‰“åˆ°å¤–éƒ¨å­˜å‚¨&#013;&#010;&gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt; &gt;&#013;&#010;&gt; &gt; &gt;&#013;&#010;&gt; &gt;&#013;&#010;&gt;&#013;&#010;",
        "depth": "5",
        "reply": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>"
    },
    {
        "id": "<DM6PR01MB3625BB7333A3C958994444D6A3750@DM6PR01MB3625.prod.exchangelabs.com>",
        "from": "å´ ç¥¥å¹³ &lt;wxp4...@outlook.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Sun, 26 Jul 2020 01:35:05 GMT",
        "subject": "Re: flinkè§£ækafka jsonæ•°æ®",
        "content": "æ”¹ç”¨csvç”¨ä¸€ä¸ªå¾ˆä¸å¸¸ç”¨çš„åˆ†éš”ç¬¦å»è·å–æ˜¯å¯ä»¥çš„ï¼Œæ¯”å¦‚/u0005&#013;&#010;&#013;&#010;Get Outlook for Android&lt;https://aka.ms/ghei36&gt;&#013;&#010;&#013;&#010;",
        "depth": "5",
        "reply": "<CAEZk040ypJ95iC7C-SikBo9HiCW5+KDEaj5mNL7GjZJwJxkSiw@mail.gmail.com>"
    },
    {
        "id": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>",
        "from": "&quot;å°å­¦ç”Ÿ&quot; &lt;201782...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 08:32:46 GMT",
        "subject": "flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®",
        "content": "å„ä½å¤§ä½¬å¥½ï¼Œè¯·æ•™ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨flinkå†…éƒ¨å®šä¹‰ä¸€ä¸ªè¡¨g_unit(åˆå§‹ä¸ºç©º)ï¼Œæ¥å—ä¸€ä¸ªkafkaæºçš„å†™å…¥ï¼ŒåŒæ—¶g_unitåˆè¦ä½œä¸ºä¸‹æ¸¸è¡¨g_summaryçš„è¾“å…¥æºï¼Œæµ‹è¯•å‘ç°g_lineè¡¨ä¸€ç›´ä¸ä¼šå†™å…¥æ•°æ®ï¼Œä»£ç å¦‚ä¸‹ï¼Œçƒ¦è¯·å¤§ä½¬è§£ç­”ã€‚&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;from pyflink.datastream import StreamExecutionEnvironment, TimeCharacteristic, CheckpointingMode&#013;&#010;from pyflink.table import StreamTableEnvironment, EnvironmentSettings&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;env = StreamExecutionEnvironment.get_execution_environment()&#013;&#010;env.set_stream_time_characteristic(TimeCharacteristic.EventTime)&#013;&#010;env.set_parallelism(1)&#013;&#010;env_settings = EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()&#013;&#010;t_env = StreamTableEnvironment.create(env, environment_settings=env_settings)&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;kafka_source_ddl = \"\"\"&#013;&#010;CREATE TABLE kafka_source_tab (&#013;&#010;&amp;nbsp;id VARCHAR,&amp;nbsp; &amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;trck_id VARCHAR&amp;nbsp;&#013;&#010;&#013;&#010;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'kafka',&#013;&#010;&amp;nbsp;'topic' = 'gg',&amp;nbsp; &amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;'scan.startup.mode' = 'specific-offsets',&amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;'scan.startup.specific-offsets'='partition:1,offset:0',&#013;&#010;&amp;nbsp;'properties.bootstrap.servers' = '****',&#013;&#010;&amp;nbsp;'format' = 'json'&amp;nbsp;&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_unit_sink_ddl = \"\"\"&#013;&#010;CREATE TABLE g_sink_unit (&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;trck_id VARCHAR&amp;nbsp;&#013;&#010;&amp;nbsp;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_unit',&amp;nbsp; &amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&amp;nbsp; &amp;nbsp; &amp;nbsp;&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_summary_ddl = \"\"\"&#013;&#010;CREATE TABLE g_summary_base(&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;trck_id VARCHAR&amp;nbsp;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_summary',&amp;nbsp;&amp;nbsp;&#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;&#013;&#010;t_env.execute_sql(kafka_source_ddl)&#013;&#010;t_env.execute_sql(g_unit_sink_ddl)&#013;&#010;t_env.execute_sql(g_summary_ddl)&#013;&#010;&#013;&#010;&#013;&#010;sql1='''Insert into g_unit_sink_ddl select alarm_id,trck_id from kafka_source_tab'''&#013;&#010;sql2='''Insert into g_summary_ddl select alarm_id,trck_id from g_unit_sink_ddl'''&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;stmt_set = t_env.create_statement_set()&#013;&#010;stmt_set.add_insert_sql(sql1)&#013;&#010;stmt_set.add_insert_sql(sql2)&#013;&#010;&#013;&#010;&#013;&#010;stmt_set.execute().get_job_client().get_job_execution_result().result()",
        "depth": "1",
        "reply": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>"
    },
    {
        "id": "<tencent_BCB2BBB235EA17507CF6DC57D2F143AE3A08@qq.com>",
        "from": "&quot;å°å­¦ç”Ÿ&quot; &lt;201782...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 08:38:20 GMT",
        "subject": "flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®",
        "content": "å„ä½å¤§ä½¬å¥½ï¼Œè¯·æ•™ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨flinkå†…éƒ¨å®šä¹‰ä¸€ä¸ªè¡¨g_unit(åˆå§‹ä¸ºç©º)ï¼Œæ¥å—ä¸€ä¸ªkafkaæºçš„å†™å…¥ï¼ŒåŒæ—¶g_unitåˆè¦ä½œä¸ºä¸‹æ¸¸è¡¨g_summaryçš„è¾“å…¥æºï¼Œæµ‹è¯•å‘ç°g_lineè¡¨ä¸€ç›´ä¸ä¼šå†™å…¥æ•°æ®ï¼Œä»£ç å¦‚ä¸‹ï¼Œçƒ¦è¯·å¤§ä½¬è§£ç­”ã€‚&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;from pyflink.datastream import StreamExecutionEnvironment, TimeCharacteristic, CheckpointingMode&#013;&#010;from pyflink.table import StreamTableEnvironment, EnvironmentSettings&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;env = StreamExecutionEnvironment.get_execution_environment()&#013;&#010;env.set_stream_time_characteristic(TimeCharacteristic.EventTime)&#013;&#010;env.set_parallelism(1)&#013;&#010;env_settings = EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()&#013;&#010;t_env = StreamTableEnvironment.create(env, environment_settings=env_settings)&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;kafka_source_ddl = \"\"\"&#013;&#010;CREATE TABLE kafka_source_tab (&#013;&#010;&amp;nbsp;id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;&#013;&#010;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'kafka',&#013;&#010;&amp;nbsp;'topic' = 'gg',&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;'scan.startup.mode' = 'specific-offsets',&amp;nbsp; &#013;&#010;&amp;nbsp;'scan.startup.specific-offsets'='partition:1,offset:0',&#013;&#010;&amp;nbsp;'properties.bootstrap.servers' = '****',&#013;&#010;&amp;nbsp;'format' = 'json' &#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_unit_sink_ddl = \"\"\"&#013;&#010;CREATE TABLE g_sink_unit (&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;&amp;nbsp;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_unit',&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&amp;nbsp; &amp;nbsp; &amp;nbsp;&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_summary_ddl = \"\"\"&#013;&#010;CREATE TABLE g_summary_base(&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_summary',&amp;nbsp; &#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;&#013;&#010;t_env.execute_sql(kafka_source_ddl)&#013;&#010;t_env.execute_sql(g_unit_sink_ddl)&#013;&#010;t_env.execute_sql(g_summary_ddl)&#013;&#010;&#013;&#010;&#013;&#010;sql1='''Insert into g_unit_sink_ddl select alarm_id,trck_id from kafka_source_tab'''&#013;&#010;sql2='''Insert into g_summary_ddl select alarm_id,trck_id from g_unit_sink_ddl'''&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;stmt_set = t_env.create_statement_set()&#013;&#010;stmt_set.add_insert_sql(sql1)&#013;&#010;stmt_set.add_insert_sql(sql2)&#013;&#010;&#013;&#010;&#013;&#010;stmt_set.execute().get_job_client().get_job_execution_result().result()",
        "depth": "1",
        "reply": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>"
    },
    {
        "id": "<tencent_DF5D99202962A778955FD3ADF597D6169608@qq.com>",
        "from": "&quot;chengyanan1008@foxmail.com&quot; &lt;chengyanan1...@foxmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 09:02:40 GMT",
        "subject": "å›å¤: flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®",
        "content": "ä½ å¥½ï¼š&#013;&#010;&#013;&#010;sql1='''Insert into g_unit_sink_ddl select alarm_id,trck_id from kafka_source_tab'''&#013;&#010;sql2='''Insert into g_summary_ddl select alarm_id,trck_id from g_unit_sink_ddl'''&#013;&#010;&#013;&#010;è¿™é‡Œå†™é”™äº†å§ï¼Œä½ çš„è¡¨åæ˜¯g_sink_unit å’Œ g_summary_base&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;chengyanan1008@foxmail.com&#013;&#010; &#013;&#010;å‘ä»¶äººï¼š å°å­¦ç”Ÿ&#013;&#010;å‘é€æ—¶é—´ï¼š 2020-07-21 16:38&#013;&#010;æ”¶ä»¶äººï¼š user-zh&#013;&#010;ä¸»é¢˜ï¼š flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®&#013;&#010;å„ä½å¤§ä½¬å¥½ï¼Œè¯·æ•™ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨flinkå†…éƒ¨å®šä¹‰ä¸€ä¸ªè¡¨g_unit(åˆå§‹ä¸ºç©º)ï¼Œæ¥å—ä¸€ä¸ªkafkaæºçš„å†™å…¥ï¼ŒåŒæ—¶g_unitåˆè¦ä½œä¸ºä¸‹æ¸¸è¡¨g_summaryçš„è¾“å…¥æºï¼Œæµ‹è¯•å‘ç°g_lineè¡¨ä¸€ç›´ä¸ä¼šå†™å…¥æ•°æ®ï¼Œä»£ç å¦‚ä¸‹ï¼Œçƒ¦è¯·å¤§ä½¬è§£ç­”ã€‚&#013;&#010; &#013;&#010; &#013;&#010; &#013;&#010; &#013;&#010;from pyflink.datastream import StreamExecutionEnvironment, TimeCharacteristic, CheckpointingMode&#013;&#010;from pyflink.table import StreamTableEnvironment, EnvironmentSettings&#013;&#010; &#013;&#010; &#013;&#010; &#013;&#010;env = StreamExecutionEnvironment.get_execution_environment()&#013;&#010;env.set_stream_time_characteristic(TimeCharacteristic.EventTime)&#013;&#010;env.set_parallelism(1)&#013;&#010;env_settings = EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()&#013;&#010;t_env = StreamTableEnvironment.create(env, environment_settings=env_settings)&#013;&#010; &#013;&#010; &#013;&#010; &#013;&#010;kafka_source_ddl = \"\"\"&#013;&#010;CREATE TABLE kafka_source_tab (&#013;&#010;&amp;nbsp;id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010; &#013;&#010; &#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'kafka',&#013;&#010;&amp;nbsp;'topic' = 'gg',&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;'scan.startup.mode' = 'specific-offsets',&amp;nbsp; &#013;&#010;&amp;nbsp;'scan.startup.specific-offsets'='partition:1,offset:0',&#013;&#010;&amp;nbsp;'properties.bootstrap.servers' = '****',&#013;&#010;&amp;nbsp;'format' = 'json' &#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_unit_sink_ddl = \"\"\"&#013;&#010;CREATE TABLE g_sink_unit (&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;&amp;nbsp;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_unit',&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&amp;nbsp; &amp;nbsp; &amp;nbsp;&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_summary_ddl = \"\"\"&#013;&#010;CREATE TABLE g_summary_base(&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_summary',&amp;nbsp; &#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010; &#013;&#010;t_env.execute_sql(kafka_source_ddl)&#013;&#010;t_env.execute_sql(g_unit_sink_ddl)&#013;&#010;t_env.execute_sql(g_summary_ddl)&#013;&#010; &#013;&#010; &#013;&#010;sql1='''Insert into g_unit_sink_ddl select alarm_id,trck_id from kafka_source_tab'''&#013;&#010;sql2='''Insert into g_summary_ddl select alarm_id,trck_id from g_unit_sink_ddl'''&#013;&#010; &#013;&#010; &#013;&#010; &#013;&#010;stmt_set = t_env.create_statement_set()&#013;&#010;stmt_set.add_insert_sql(sql1)&#013;&#010;stmt_set.add_insert_sql(sql2)&#013;&#010; &#013;&#010; &#013;&#010;stmt_set.execute().get_job_client().get_job_execution_result().result()&#013;&#010;",
        "depth": "2",
        "reply": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>"
    },
    {
        "id": "<tencent_C17525A805FBB82BF2F80DD73D592ED97107@qq.com>",
        "from": "&quot;å°å­¦ç”Ÿ&quot; &lt;201782...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 09:40:36 GMT",
        "subject": "flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®",
        "content": "å„ä½å¤§ä½¬å¥½ï¼Œè¯·æ•™ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨flinkå†…éƒ¨å®šä¹‰ä¸€ä¸ªè¡¨g_unit(åˆå§‹ä¸ºç©º)ï¼Œæ¥å—ä¸€ä¸ªkafkaæºçš„å†™å…¥ï¼ŒåŒæ—¶g_unitåˆè¦ä½œä¸ºä¸‹æ¸¸è¡¨g_summaryçš„è¾“å…¥æºï¼Œæµ‹è¯•å‘ç°g_lineè¡¨ä¸€ç›´ä¸ä¼šå†™å…¥æ•°æ®ï¼Œä»£ç å¦‚ä¸‹ï¼Œçƒ¦è¯·å¤§ä½¬è§£ç­”ã€‚&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;from pyflink.datastream import StreamExecutionEnvironment, TimeCharacteristic, CheckpointingMode&#013;&#010;from pyflink.table import StreamTableEnvironment, EnvironmentSettings&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;env = StreamExecutionEnvironment.get_execution_environment()&#013;&#010;env.set_stream_time_characteristic(TimeCharacteristic.EventTime)&#013;&#010;env.set_parallelism(1)&#013;&#010;env_settings = EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()&#013;&#010;t_env = StreamTableEnvironment.create(env, environment_settings=env_settings)&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;kafka_source_ddl = \"\"\"&#013;&#010;CREATE TABLE kafka_source_tab (&#013;&#010;&amp;nbsp;id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;&#013;&#010;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'kafka',&#013;&#010;&amp;nbsp;'topic' = 'gg',&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;'scan.startup.mode' = 'specific-offsets',&amp;nbsp; &#013;&#010;&amp;nbsp;'scan.startup.specific-offsets'='partition:1,offset:0',&#013;&#010;&amp;nbsp;'properties.bootstrap.servers' = '****',&#013;&#010;&amp;nbsp;'format' = 'json' &#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_unit_sink_ddl = \"\"\"&#013;&#010;CREATE TABLE g_sink_unit (&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;&amp;nbsp;&#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_unit',&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&amp;nbsp; &amp;nbsp; &amp;nbsp;&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;g_summary_ddl = \"\"\"&#013;&#010;CREATE TABLE g_summary_base(&#013;&#010;&amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp; &#013;&#010;&amp;nbsp;trck_id VARCHAR &#013;&#010;) WITH (&#013;&#010;&amp;nbsp;'connector' = 'jdbc',&#013;&#010;&amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#013;&#010;&amp;nbsp;'table-name' = 'g_summary',&amp;nbsp; &#013;&#010;&amp;nbsp;'username' = 'root',&#013;&#010;&amp;nbsp;'password' = 'root',&#013;&#010;&amp;nbsp;'sink.buffer-flush.interval' = '1s'&#013;&#010;)&#013;&#010;\"\"\"&#013;&#010;&#013;&#010;t_env.execute_sql(kafka_source_ddl)&#013;&#010;t_env.execute_sql(g_unit_sink_ddl)&#013;&#010;t_env.execute_sql(g_summary_ddl)&#013;&#010;&#013;&#010;&#013;&#010;sql1='''Insert into g_sink_unit&amp;nbsp;select alarm_id,trck_id from kafka_source_tab'''&#013;&#010;sql2='''Insert into g_summary_base&amp;nbsp;select alarm_id,trck_id from g_sink_unit&amp;nbsp;'''&#013;&#010;&#013;&#010;&#013;&#010;&#013;&#010;stmt_set = t_env.create_statement_set()&#013;&#010;stmt_set.add_insert_sql(sql1)&#013;&#010;stmt_set.add_insert_sql(sql2)&#013;&#010;&#013;&#010;&#013;&#010;stmt_set.execute().get_job_client().get_job_execution_result().result()",
        "depth": "1",
        "reply": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>"
    },
    {
        "id": "<CADQYLGsAyAe5kQuKT29tfzYTuzua85D42=rTxo-8QyevkCzH=w@mail.gmail.com>",
        "from": "godfrey he &lt;godfre...@gmail.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 10:09:15 GMT",
        "subject": "Re: flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®",
        "content": "ä½ å¯ä»¥å…ˆåªè·‘ç¬¬ä¸€ä¸ªinsertï¼Œç„¶åcheckä¸€ä¸‹g_sink_unitæ˜¯å¦æœ‰æ•°æ®ã€‚&#010;&#010;å¦å¤–ï¼Œä½ å¯ä»¥æŠŠquery æ”¹ä¸ºéƒ½è¯»å– kafka_source_tab å†åˆ†åˆ«å†™åˆ°ä¸¤ä¸ªä¸åŒçš„sinkï¼š&#010;&#010;sql1='''Insert into g_sink_unit select alarm_id,trck_id from&#010;kafka_source_tab'''&#010;sql2='''Insert into g_summary_base select alarm_id,trck_id from&#010;kafka_source_tab;'''&#010;&#010;å°å­¦ç”Ÿ &lt;201782053@qq.com&gt; äº2020å¹´7æœˆ21æ—¥å‘¨äºŒ ä¸‹åˆ5:47å†™é“ï¼š&#010;&#010;&gt;&#010;&gt; å„ä½å¤§ä½¬å¥½ï¼Œè¯·æ•™ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨flinkå†…éƒ¨å®šä¹‰ä¸€ä¸ªè¡¨g_unit(åˆå§‹ä¸ºç©º)ï¼Œæ¥å—ä¸€ä¸ªkafkaæºçš„å†™å…¥ï¼ŒåŒæ—¶g_unitåˆè¦ä½œä¸ºä¸‹æ¸¸è¡¨g_summaryçš„è¾“å…¥æºï¼Œæµ‹è¯•å‘ç°g_lineè¡¨ä¸€ç›´ä¸ä¼šå†™å…¥æ•°æ®ï¼Œä»£ç å¦‚ä¸‹ï¼Œçƒ¦è¯·å¤§ä½¬è§£ç­”ã€‚&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; from pyflink.datastream import StreamExecutionEnvironment,&#010;&gt; TimeCharacteristic, CheckpointingMode&#010;&gt; from pyflink.table import StreamTableEnvironment, EnvironmentSettings&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; env = StreamExecutionEnvironment.get_execution_environment()&#010;&gt; env.set_stream_time_characteristic(TimeCharacteristic.EventTime)&#010;&gt; env.set_parallelism(1)&#010;&gt; env_settings =&#010;&gt; EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()&#010;&gt; t_env = StreamTableEnvironment.create(env,&#010;&gt; environment_settings=env_settings)&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; kafka_source_ddl = \"\"\"&#010;&gt; CREATE TABLE kafka_source_tab (&#010;&gt; &amp;nbsp;id VARCHAR,&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;trck_id VARCHAR&#010;&gt;&#010;&gt;&#010;&gt; ) WITH (&#010;&gt; &amp;nbsp;'connector' = 'kafka',&#010;&gt; &amp;nbsp;'topic' = 'gg',&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;'scan.startup.mode' = 'specific-offsets',&amp;nbsp;&#010;&gt; &amp;nbsp;'scan.startup.specific-offsets'='partition:1,offset:0',&#010;&gt; &amp;nbsp;'properties.bootstrap.servers' = '****',&#010;&gt; &amp;nbsp;'format' = 'json'&#010;&gt; )&#010;&gt; \"\"\"&#010;&gt; g_unit_sink_ddl = \"\"\"&#010;&gt; CREATE TABLE g_sink_unit (&#010;&gt; &amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;trck_id VARCHAR&#010;&gt; &amp;nbsp;&#010;&gt; ) WITH (&#010;&gt; &amp;nbsp;'connector' = 'jdbc',&#010;&gt; &amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#010;&gt; &amp;nbsp;'table-name' = 'g_unit',&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;'username' = 'root',&#010;&gt; &amp;nbsp;'password' = 'root',&#010;&gt; &amp;nbsp;'sink.buffer-flush.interval' = '1s'&amp;nbsp; &amp;nbsp; &amp;nbsp;&#010;&gt; )&#010;&gt; \"\"\"&#010;&gt; g_summary_ddl = \"\"\"&#010;&gt; CREATE TABLE g_summary_base(&#010;&gt; &amp;nbsp;alarm_id VARCHAR,&amp;nbsp; &amp;nbsp;&#010;&gt; &amp;nbsp;trck_id VARCHAR&#010;&gt; ) WITH (&#010;&gt; &amp;nbsp;'connector' = 'jdbc',&#010;&gt; &amp;nbsp;'url' = 'jdbc:mysql://10.2.2.70:3306/bdoa?useSSL=false',&#010;&gt; &amp;nbsp;'table-name' = 'g_summary',&amp;nbsp;&#010;&gt; &amp;nbsp;'username' = 'root',&#010;&gt; &amp;nbsp;'password' = 'root',&#010;&gt; &amp;nbsp;'sink.buffer-flush.interval' = '1s'&#010;&gt; )&#010;&gt; \"\"\"&#010;&gt;&#010;&gt; t_env.execute_sql(kafka_source_ddl)&#010;&gt; t_env.execute_sql(g_unit_sink_ddl)&#010;&gt; t_env.execute_sql(g_summary_ddl)&#010;&gt;&#010;&gt;&#010;&gt; sql1='''Insert into g_sink_unit&amp;nbsp;select alarm_id,trck_id from&#010;&gt; kafka_source_tab'''&#010;&gt; sql2='''Insert into g_summary_base&amp;nbsp;select alarm_id,trck_id from&#010;&gt; g_sink_unit&amp;nbsp;'''&#010;&gt;&#010;&gt;&#010;&gt;&#010;&gt; stmt_set = t_env.create_statement_set()&#010;&gt; stmt_set.add_insert_sql(sql1)&#010;&gt; stmt_set.add_insert_sql(sql2)&#010;&gt;&#010;&gt;&#010;&gt; stmt_set.execute().get_job_client().get_job_execution_result().result()&#010;&#010;",
        "depth": "2",
        "reply": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>"
    },
    {
        "id": "<tencent_CE196495D475A004ECFDAE78E2115D496409@qq.com>",
        "from": "&quot;å°å­¦ç”Ÿ&quot; &lt;201782...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 11:39:03 GMT",
        "subject": "Re: flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®",
        "content": "1.ä½ å¯ä»¥å…ˆåªè·‘ç¬¬ä¸€ä¸ªinsertï¼Œç„¶åcheckä¸€ä¸‹g_sink_unitæ˜¯å¦æœ‰æ•°æ®ï¼Œè¿™ä¸ªæ˜¯æœ‰æ•°æ®çš„ï¼Œ&#013;&#010;2.è¿™ä¸ªä¾‹å­é‡Œå½“ç„¶éƒ½å†™å®Œkafkaçš„åˆå§‹æºæ˜¯å®Œå…¨æ²¡é—®é¢˜çš„ï¼Œå®é™…ä¸­ç¡®å®æ˜¯éœ€è¦g_unitä½œä¸ºæ¡¥æ¢çš„ã€‚",
        "depth": "3",
        "reply": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>"
    },
    {
        "id": "<1595331365591-0.post@n8.nabble.com>",
        "from": "å’¿å’¿å‘€å‘€ &lt;201782...@qq.com&gt;",
        "to": "user-zh@flink.apache.org",
        "date": "Tue, 21 Jul 2020 11:36:05 GMT",
        "subject": "Re: flink tableåŒæ—¶ä½œä¸ºå†™å‡ºåŠè¾“å…¥æ—¶ä¸‹æ¸¸æ— æ•°æ®",
        "content": "å°±æ˜¯æ²¡æœ‰æ•°æ®ï¼Œæˆ‘è¿™ä¸ªæ˜¯ç®€åŒ–ç‰ˆæœ¬çš„ï¼Œéƒ½åˆ‡æ¢ä¸ºkafkaçš„åˆå§‹æºæ˜¯æ²¡é—®é¢˜çš„&#010;&#010;&#010;&#013;&#010;--&#013;&#010;Sent from: http://apache-flink.147419.n8.nabble.com/",
        "depth": "2",
        "reply": "<tencent_21EA535062F66A5754F102AEA1B223B28E08@qq.com>"
    }
]